Position,Details,parsed_description
IT Manager,"Position Title: IT Manager

Location: Vancouver, BC

Type: Permanent, full-time, hybrid

The Position

Our client is seeking a dynamic, communicative, and strategic IT Manager to join their team in the engineering space. Successful candidates will bring hands-on technical prowess, mastery of vendor management, exceptional stakeholder engagement and communication, and familiarity with engineering environments and technologies.

What You'll Do

IT Operational Management -

Oversee performance of third-party Managed Service Providers (MSPs) and Managed Security Service Providers (MSSPs), including monitoring service agreements covering hardware and network administration, helpdesk support, data backup, and retention.
Ensure IT infrastructure and information systems are secure, compatible, and scalable to meet current and future company needs.
Lead IT project management and business analysis, collecting requirements, prioritizing projects, and ensuring alignment with business needs and budget.
Perform routine audits of MSP reports, including inventory, security patches, and administrative actions.
Draft and submit incident reports for adverse incidents affecting information systems.
Document and evaluate change management activities impacting IT infrastructure and systems.
Conduct security and risk assessments prior to implementing system changes and maintain assessment records.
Lead disaster recovery efforts, ensuring plans are maintained and communicated.

Leadership –

Develop and maintain policies, processes, and procedures for IT infrastructure, cybersecurity, and data management.
Provide training to system users on proper use and interaction with information systems and technology.
Deliver regulatory training on cybersecurity, insider threats, and information systems security.
Prepare annual department plans and budgets, including objectives, KPIs, hiring, training, and spending, for approval by the VP of Business Operations.
Monitor and report on actual spending against the IT budget.

Mandatories

Bachelor’s degree in Computer Science, Information Systems, or similar field.
Experience in an engineering environment utilizing technologies such as AutoCad, Rhino, etc.
10+ years of post-graduation industry experience.
Proven experience as an IT Manager, or similar.
Vendor management experience.
Broad knowledge in technical personnel management, network infrastructure, software applications, information systems security, and data management.
Knowledge of information security regulatory compliance (North America) is highly beneficial.
Ability to manage personnel, both internal and outsourced.

If you are interested in this position and meet the above criteria, please click the 'Apply for Job' button below to send your resume securely and in confidence directly to the recruiter in charge of this position. We thank all applicants; however, only those selected for interviews will be contacted.

All applicants must be legally entitled to work in Canada.

WE APPRECIATE YOUR INTEREST IN 10 PERCENT RECRUITING LTD.

We invite you to become one of our satisfied candidates! 10 Percent Recruiting Ltd. believes in transparency with our candidates and our employers; we understand that open communication and collaboration are fundamental to our success. Our professional recruiters are passionate about helping you find a fulfilling job or career and ensuring your complete satisfaction with our process. We are committed to actively building lasting relationships and building trust by listening, following through, and keeping our word. We look forward to exceeding your expectations!

Learn more about 10 Percent Recruiting Ltd. and view our current job opportunities, career tips, and tools at https://10percentrecruiting.com","{""role_summary"":""The IT Manager will oversee IT operations, manage vendors, and ensure IT infrastructure and information systems are secure, compatible, and scalable to meet company needs."",""key_terms"":[{""term"":""Managed Service Providers (MSPs)"",""explanation"":""Third-party providers that manage IT services, such as hardware and network administration, helpdesk support, data backup, and retention.""},{""term"":""Managed Security Service Providers (MSSPs)"",""explanation"":""Third-party providers that manage IT security services, including monitoring and incident response.""},{""term"":""AutoCad"",""explanation"":""A software application used in engineering environments for designing and drafting.""},{""term"":""Rhino"",""explanation"":""A software application used in engineering environments for 3D modeling and design.""},{""term"":""Information Systems Security"",""explanation"":""The practice of protecting information systems from unauthorized access, use, disclosure, disruption, modification, or destruction.""}],""skill_priorities"":{""must_have"":[""10+ years of post-graduation industry experience"",""Proven experience as an IT Manager, or similar"",""Vendor management experience"",""Broad knowledge in technical personnel management, network infrastructure, software applications, information systems security, and data management""],""nice_to_have"":[""Knowledge of information security regulatory compliance (North America)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with vendor management in an IT environment?"",""example_answer"":""In my previous role, I managed multiple vendors providing IT services, including MSPs and MSSPs. I ensured that service agreements were met, and vendors were held accountable for their performance.""},{""question"":""How do you stay current with emerging trends and technologies in IT?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read relevant publications to stay informed about the latest developments in IT.""}],""red_flags"":[""Lack of experience in an engineering environment"",""Inability to manage personnel, both internal and outsourced""],""confidence_score"":90.0}"
"Manager, IT Support","On behalf of our public sector client, PROCOM is looking for a Manager, IT Support


Manager, IT Support -
Job Description:

As the IT Lead for our vendor-managed IT Support, you are a strategic, analytical, collaborative, and results focused leader who thrives on stellar service delivery and can multi-task in our dynamic environment. You are directly responsible for managing the daily operations of IT Support, ensuring effective vendor governance, and ensuring that the IT Support achieves premium customer service and operational excellence.


Manager, IT Support -
Responsibilities

Operational Management:
Responsible for user experience at 6 regional offices in Ontario and up to 900 employees
Implementing and monitoring of IT Service Management best practices and procedures including automation
Maintain and improve IT Support business continuity plan
Lead the operational environment of high productivity and continuous service improvement
Ensure prompt, accurate proactive status and feedback of all incidents and service requests to customers and management
Work with the IT Support Team to develop training plans for IT Support
Proactively drive and Lead the cross functional collaboration efforts between IT Support and Infrastructure Team Systems Admin teams to resolve issues promptly
Ensure correct staffing levels maintained: plan rosters; approve & schedule annual leave; arrange sickness cover and shift breaks to ensure IT Support coverage


Customer Experience & Issue Resolution:
Ensure effective resolution of all service issues through effective governance and management of IT Support
Act as the point of escalation to ensure the IT Support team effectively and efficiently reviews, responds, and handles all client complaints, rectifies issues, and liaises with appropriate departments and/ or outside vendors to handle complex issues in a bid to provide effective solutions
Work cross-departmentally to address gaps in the IT Support process


Process/Framework:
Define, develop, or enhance foundational components of the IT Support team through statistical and data-driven processes
Develop and maintain IT Support procedures based on ITIL best practices and ensure that procedures are followed
Define, develop, and adhere to inventory tracking framework and accountabilities
Observe IT Support operation techniques, determine effectiveness and if applicable, implement new techniques adhering to the guiding principle of delivering the ultimate customer experience
Create a mode of operations to be adhered to by team members in order to maintain good routine and orderliness and update and maintain SOP (Standard Operating Procedure)
Knowledge of the ITSM framework with goal of implementation and improvement in best practices in Incident and Change Management
Good to have: Knowledge of ITOM; Implementation of CMDB, integrating with ITSM


Reporting:
Experience in developing IT Support reports & dashboard with a focus on analysis and trending issues
Provide regular weekly, monthly and quarterly reports based on industry best practice KPIs and leading indicators
Develop and provide data and reporting of KPIs (Key Performance Indicators) and trends to IT department and others both scheduled and on-demand with a focus on executive level dashboards
Analyze and improve SLA and KPI metrics, FCR (First Call Resolution), CSAT (Customer Satisfaction) and AHT (Average Handle Time)
Develop daily, weekly, and monthly reports on IT Support team productivity

Manager, IT Support -Required Skills:

Substantial experience leading an IT Support team, including defining, building, executing, and streamlining processes to ensure efficiencies
Experience in IT end user support and business applications
ITIL v3 Foundations certification required
Demonstrated leadership of end-user support, IT Support operations, desk side support, remote support, and system administration team experience
Experience as the point of escalation, strong analytical and technical problem-solving skills with ability to quickly adapt to dynamic environments
Experience with developing and adhering to user off/onboarding processes
Proven ability to collaborate and communicate effectively both verbally and written with high level of customer service
Strong organizational skills, including planning and execution
A hands-on, self motivated individual with strong communication and facilitation skills with the ability to work with minimal supervision
A solution-oriented mindset with a strong orientation towards innovation and continuous service improvement of problem-solving techniques
Proven ability to develop professional and effective working relationships with customers and key stakeholders
Proven ability to work well under pressure and deal with constraints which are often outside of your control
Experience in vendor management, specifically in the escalation of major incidents

Technical Knowledge:

Proficient knowledge of enterprise IT Service Management solutions e.g. Service Now, Remedy, JIRA
Experience driving service improvements and offer specialist advice and support on IT-related issues
Experience triaging and managing incidents and service requests through a telephone, chat, web submissions, email, and appointment-based services
Experience troubleshooting errors and system issues by providing support to Tier 1, and Tier 2 teams
Proficient knowledge of Microsoft applications (e.g. Office Suite, M365, Azure)
Proficient experience of hardware devices such as Lenovo, Apple, Android
Experience with managing Audio Visual and communications technologies like Microsoft Teams and HP Poly
Effectively manage a device agnostics environment (i.e. Windows, iOS, Android, etc.)
Experience with administrating MDM platforms like InTune
Experience with administrating Active Directory, GPO and OUs
Advanced knowledge with end user applications/toolsets like Citrix, RDP, Multifactor authentication, Single Sign On, MS Defender Anti virus/malware systems
Experience working around network technology stacks ranging from firewalls, switches, routers, access points, MPLS and ISPs

Manager, IT Support-
Assignment Start Date

ASAP – 6 months to start


Manager, IT Support-
Assignment Location

Toronto (Hybrid)","{""role_summary"":""The Manager, IT Support is responsible for leading the daily operations of IT Support, ensuring effective vendor governance, and achieving premium customer service and operational excellence."",""key_terms"":[{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of best practices for IT service management.""},{""term"":""ITSM"",""explanation"":""IT Service Management, a framework for delivering IT services to customers.""},{""term"":""CMDB"",""explanation"":""Configuration Management Database, a database that stores information about IT assets and their relationships.""},{""term"":""ITOM"",""explanation"":""IT Operations Management, a set of practices for managing IT operations.""},{""term"":""SLA"",""explanation"":""Service Level Agreement, a formal agreement between IT and customers on service quality.""},{""term"":""KPI"",""explanation"":""Key Performance Indicator, a metric used to measure IT service performance.""},{""term"":""FCR"",""explanation"":""First Call Resolution, a metric that measures the percentage of issues resolved on the first call.""},{""term"":""CSAT"",""explanation"":""Customer Satisfaction, a metric that measures customer satisfaction with IT services.""},{""term"":""AHT"",""explanation"":""Average Handle Time, a metric that measures the average time taken to resolve an issue.""}],""skill_priorities"":{""must_have"":[""ITIL v3 Foundations certification"",""Experience leading an IT Support team"",""Experience in IT end user support and business applications"",""Strong analytical and technical problem-solving skills"",""Experience with developing and adhering to user off/onboarding processes"",""Proven ability to collaborate and communicate effectively"",""Strong organizational skills, including planning and execution""],""nice_to_have"":[""Knowledge of ITOM"",""Implementation of CMDB, integrating with ITSM""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure effective vendor governance in IT Support?"",""example_answer"":""I ensure effective vendor governance by implementing and monitoring IT Service Management best practices and procedures, including automation, and maintaining and improving the IT Support business continuity plan.""},{""question"":""How do you drive service improvements in IT Support?"",""example_answer"":""I drive service improvements by developing and maintaining IT Support procedures based on ITIL best practices, defining and developing a mode of operations, and analyzing and improving SLA and KPI metrics.""}],""red_flags"":[""Lack of experience in leading an IT Support team"",""Inability to adapt to dynamic environments"",""Poor analytical and technical problem-solving skills""],""confidence_score"":90.0}"
Director of Information Technology,"Southampton Financials’ Mission: Bring Clarity to Insurance

Southampton Financial is a value-added strategic investor in the Canadian property and casualty distribution space. We are the majority equity owner of Alteri Insurance and have acquired Onlia Insurance and aha insurance in recent months. Our goal is to build the insurance brokerage of the future by combining leading-edge technology with high-quality brokers catering to the overall insurance needs of Canadians by providing them with customized solutions to suit their individual needs.

At Southampton Group of Companies, we're not just merging companies; we're fusing expertise, innovation, and a relentless commitment to excellence. Our purpose is clear: to disrupt the insurance landscape in Canada. As we assemble a team of industry heavyweights, our goal is to make this vision a reality. In our collaborative, fast-paced, and agile environment, we strongly believe in empowering every member of our team to take ownership of their role. Together, we're dedicated to building a best-in-class experience for our customers.

The IT Development & Operations Director will lead and manage the IT department, responsible for Development, Operations, Security, and Compliance of the entire IT platform for a growing digital insurance brokerage company. The main objective is to create and execute an IT roadmap of projects to achieve the company’s business plan (application and domain integration after multiple acquisitions and creating a future-proof technology stack for further profitable growth). This role involves building out more mature processes and teams for both the Agile development and Operations support areas of the IT department, as well as managing the ecosystem of vendors and partners that are part of the digital platform.

The IT Development & Operations Director requires experience in developing and building out application platforms (preferably in the insurance industry) with a good understanding of the AWS stack. You should know how to build cross-platform web applications and be familiar with security guidelines and frameworks for the web.

Key Accountabilities:

KA1 People Leader: Lead a multidisciplinary team of Business Analysts, Development, Quality Assurance, Data Engineers, and the IT Operations Manager.

KA2 Target Architecture: Maintain, develop, and ensure compliance of the IT and Data architecture in line with integration plans and company strategy. Ensure effective, secure, and available system architecture and consistent data storage and maintenance.

KA3 Development & Code Quality: Lead and manage web/external developers, BA, and QA teams. Support them in integrating and building out the capabilities of the company’s digital brokerage platform and infrastructure. Develop a strategy to meet the company’s goals and improve service quality. Assure the quality of the codebase, monitor it constantly, ensure the right third-party frameworks are used, and collaborate with the product owner on improving/refactoring the codebase.

KA4 Release Management & QA: Plan the release of project deliverables and oversee the release life cycle. Oversee the team establishing and enforcing quality standards for products and services. Build and release new features on the platform and work with the development team to deliver new features for each sprint as the company expands its products nationally.

KA5 Data Migration and Analytics capabilities: Align on data requirements needed to migrate insurance portfolios from another platform to a broker management system. Ensure the buildout of the data warehousing, data management, and mining capabilities of the organization.

KA6 Vendor management: Manage contacts and contracts with development partners. Ensure vendor delivery aligns with needs and contracts. Anticipate potential changes and maintain good relationships with partners.

KA7 Governance: Create and maintain a structure for IT governance, security, and control frameworks for the group of companies.

Qualifications and Competencies:

Proven experience in IT with at least a bachelor’s degree, preferably with a specialization in IT.
At least 5 years’ experience in a comparable role.
In-depth knowledge and experience of (AWS-based) IT-architecture solutions, including integration, security, and performance aspects.
Knowledge of and experience with insurance platforms such as Guidewire, Duck Creek, and Applied Systems.
Experience with the following Technology Stack: Angular, React, Vue, Java, Sitecore, SQL, Postgres, MongoDB, Salesforce, Mulesoft, Azure Data Warehouse, AWS EC2 and Lambda
Ability to translate business requirements into IT solutions that fit the target architecture and infrastructure setup.
Provide leadership, direction, and definition for the development and analytics teams and the IT Operations Manager, including planning, scheduling, test coordination, and implementation.
Manage risks and resolve issues affecting release scope, schedule, and quality.
Work with QA, Development, DevOps, and Product teams to ensure development projects adhere to release processes and change procedure guidelines.
Design, establish, and maintain a departmental structure to accomplish organizational goals and objectives effectively and efficiently.
Collaborate with decision-makers in other departments to identify, recommend, develop, implement, and support cost-effective technology solutions for all aspects of the organization.
Hands-on approach.
Ability to work independently and collaborate with various roles and disciplines within the organization.

WORKING AT SOUTHAMPTON FINANCIAL

Our mission is to cultivate a workforce that is diverse and inclusive, with an unwavering commitment to creating an open, equitable, and respectful workplace for all. We are deeply dedicated to fostering an environment where every individual is genuinely respected, included, and empowered to contribute their unique perspectives and talents.

We encourage submissions from candidates who represent the various dimensions of diversity. We are committed to providing barrier-free and accessible employment practices.

Southampton Financial is an equal-opportunity employer and provides accommodations upon request to ensure all candidates feel comfortable and supported throughout the selection process.","{""role_summary"":""The IT Development & Operations Director leads and manages the IT department, responsible for Development, Operations, Security, and Compliance of the entire IT platform for a growing digital insurance brokerage company."",""key_terms"":[{""term"":""AWS stack"",""explanation"":""A suite of cloud computing services offered by Amazon Web Services, including infrastructure, database, analytics, and more.""},{""term"":""Agile development"",""explanation"":""An iterative approach to project management and software development that emphasizes flexibility, collaboration, and continuous improvement.""},{""term"":""Cross-platform web applications"",""explanation"":""Web applications that can run on multiple platforms, such as Windows, macOS, and Linux, and can be accessed through various devices and browsers.""},{""term"":""Data warehousing"",""explanation"":""A system used for reporting and data analysis, which stores data in a single location to support business intelligence and analytics.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development (Dev) and IT operations (Ops) to improve collaboration, automation, and delivery of software applications.""},{""term"":""Guidewire, Duck Creek, and Applied Systems"",""explanation"":""Insurance platform software solutions used for policy administration, claims management, and distribution management.""}],""skill_priorities"":{""must_have"":[""Experience in developing and building out application platforms"",""Knowledge of AWS stack"",""Leadership and management skills"",""Experience with insurance platforms"",""In-depth knowledge of IT-architecture solutions""],""nice_to_have"":[""Experience with Angular, React, Vue, Java, Sitecore, SQL, Postgres, MongoDB, Salesforce, Mulesoft, Azure Data Warehouse, AWS EC2 and Lambda"",""Knowledge of DevOps and Agile development"",""Experience with data migration and analytics capabilities""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with building out application platforms, and how you would approach integrating multiple acquisitions into a single platform?"",""example_answer"":""I have experience building out application platforms using AWS, and I would approach integration by first assessing the current architecture, identifying areas for improvement, and then developing a roadmap for integration. I would work closely with the development team to ensure a smooth transition and minimize downtime.""},{""question"":""How do you stay current with the latest developments in IT-architecture solutions, and how do you ensure your team is up-to-date with the latest technologies?"",""example_answer"":""I regularly attend industry conferences, read industry publications, and participate in online forums to stay current with the latest developments. I also encourage my team to do the same, and we have a budget for training and professional development to ensure we're always up-to-date with the latest technologies.""}],""red_flags"":[""Lack of experience with insurance platforms"",""Inability to translate business requirements into IT solutions"",""Poor leadership and management skills""],""confidence_score"":90.0}"
"Manager, Information Technology Services","The Town of Tillsonburg is looking for a Manager, Information Technology Services who would be responsible for planning, development and maintenance of a comprehensive information technology program and strategy for the Town. Coordinates Town-wide information systems planning and ensures mid to long-term plans are prioritized and consistent with available funding. Works closely with Town Department Heads and staff to co-ordinate automated systems operations for the Town.

This is a permanent full-time position with an excellent benefits package including immediate group benefits coverage, OMERS defined pension plan and free Employee Health Club Membership at the Tillsonburg Community Centre.

Department: Corporate Services

Division: Information Technology Services

Reports To: Director of Corporate Services/Clerk

Hourly rate: $48.66 - $56.92/hour

Weekly hours: 40

Criminal Record Check is required for this position.

Interested candidates please apply prior to the end of a business day on Thursday July 18, 2024

Responsibilities

Directs, manages and coordinates the Information Systems’ activities
Develops and implements a Town-wide long-range information systems strategy which involves facilitating discussions with Town management regarding current and anticipated information services requirements, applications development and enhancement requests
Prioritizes the acquisition, development and/or implementation of new and enhanced information technology systems to meet user needs
Coordinates Town-wide acquisition of software and hardware, including reviewing department requests and making recommendations on alternative options
Develops and implements a long-range funding plan for maintenance and replacement of hardware
Recommends Town-wide standards for hardware, software and local area networks
Oversees the operation and maintenance of telephone and other communication systems
Manages customer support for business applications, personal computers, networks and telecommunication equipment
Develops, plans and implements goals, objectives and work plans
Ensures compliance with legislative and regulatory requirements and professional standards
Evaluates services and directs the development and implementation of new/improved programs and procedures
Recommends and communicates appropriate application of policy and operational procedures
Prepares and presents written and oral reports and recommendations for consideration of the Director of Corporate Services/Clerk
Serves as a technical advisor
Participates in Management team meetings during the review and development of IT technological approaches in order to ensure achievement of Town goals and objectives
Monitors and reviews IT operations in order to ensure customer satisfaction and efficient, effective Town operations and, as required, develops and implements staff development programs
In conjunction with the Director of Corporate Services/Clerk, develops and oversees implementation of systems that encourage productive and exceptional performance throughout the organization
Prepares the annual Capital and Operating Budgets for IT in cooperation with the Clerk
Manages and assures compliances of all software licensing agreements
Monitors the network on a daily basis and corrects all network problems, referring unusual problems to outside consultants or vendors
If requested by the Director of Corporate Services/Clerk, attends meetings of Town Council to answer specific questions about the Town’s IT systems
If requested by the Director of Corporate Services/Clerk, assists with special projects and assists neighbouring municipalities with IT problems
Follow safe work practices related to job responsibilities and have basic understanding of the Occupational Health & Safety Act as it relates to the work environment
Adhere to all Town policies and procedures
Perform other duties as assigned by Supervisor

Qualifications

Post-secondary degree or diploma in Computer Science, Information Technology or related field
Five (5) years of relevant progressive experience
Two (2) years of leadership and supervisory experience
Strong knowledge of operating systems, networks, virtualized server environments and storage.
Hands-on experience in the administration of enterprise IT networks & infrastructure
Proficiency in the hands-on use of cybersecurity tools and technologies
Excellent interpersonal, communication and presentation skills
Ability to be self-directed and work independently
Strong organizational skills
Ability to prioritize competing tasks and meet multiple deadlines
Experience managing IT projects using project management methodologies an asset

About The Recruitment Process

All new Town of Tillsonburg employees are required to complete a police record check.

The Town will accommodate any individual needs you have throughout the recruitment process in accordance with the

The Town of Tillsonburg is an equal opportunity employer and all information collected will be used in accordance with the Municipal Freedom of Information and Protection of Privacy Act for the purpose of job selection.

We thank all those who apply for positions, but only applicants invited for an interview will be contacted.

Powered by JazzHR

y5iPZIIvy5","{""role_summary"":""The Manager, Information Technology Services is responsible for planning, developing, and maintaining a comprehensive information technology program and strategy for the Town of Tillsonburg, ensuring alignment with available funding and coordinating with department heads and staff."",""key_terms"":[{""term"":""Information Technology Services"",""explanation"":""The department responsible for managing and maintaining the town's IT systems and infrastructure.""},{""term"":""Enterprise IT networks & infrastructure"",""explanation"":""Large-scale IT systems and infrastructure that support the town's operations.""},{""term"":""Cybersecurity tools and technologies"",""explanation"":""Software and systems used to protect the town's IT systems and data from cyber threats.""},{""term"":""Virtualized server environments"",""explanation"":""A technology that allows multiple virtual servers to run on a single physical server, improving efficiency and reducing costs.""}],""skill_priorities"":{""must_have"":[""Post-secondary degree or diploma in Computer Science, Information Technology or related field"",""Five (5) years of relevant progressive experience"",""Two (2) years of leadership and supervisory experience"",""Strong knowledge of operating systems, networks, virtualized server environments and storage"",""Hands-on experience in the administration of enterprise IT networks & infrastructure"",""Proficiency in the hands-on use of cybersecurity tools and technologies""],""nice_to_have"":[""Experience managing IT projects using project management methodologies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with developing and implementing a long-range information systems strategy?"",""example_answer"":""In my previous role, I developed a 5-year IT strategy that aligned with the organization's goals and objectives, resulting in a 30% reduction in IT costs and a 25% increase in user satisfaction.""},{""question"":""How do you prioritize and manage competing IT projects and tasks?"",""example_answer"":""I use project management methodologies such as Agile and Waterfall to prioritize and manage projects, ensuring that deadlines are met and stakeholders are informed throughout the process.""}],""red_flags"":[""Lack of experience in managing IT projects"",""Limited knowledge of cybersecurity tools and technologies""],""confidence_score"":90.0}"
Systems Manager,"Company Description

""Why work for Accor?""

We are far more than a worldwide leader. We welcome you as you are and you can find a job and brand that matches your personality. We support you to grow and learn every day, making sure that work brings purpose to your life, so that during your journey with us, you can continue to explore Accor’s limitless possibilities.

By joining Accor, every chapter of your story is yours to write and together we can imagine tomorrow's hospitality. Discover the life that awaits you at Accor, visit https://careers.accor.com/

Do what you love, care for the world, dare to challenge the status quo! #BELIMITLESS

Job Description

Reporting to the Area IT Manager and the Director of Finance, the Systems manager is an integral part of the leadership team. Focused on all areas of technology services with a key focus on hardware, operating systems and security.

What You Will Be Doing

Consistently offer professional, friendly and engaging service to all internal and external guests
Lead and manage the hotel’s day-to-day IT activity ensuring all standards are followed
A confident & dynamic speaker, able to communicate and interact effectively with all levels of an organization
Excellent communication, analytical and problem-solving skills
Comply with the company’s IT Security Policy as it pertains to hardware, software, security/data safety
Assist with preparation of the annual IT budget for the hotel/s and working with the hotel team, administer that budget in a fiscally responsible manner
Support the hotel’s standalone systems, including but not limited to, systems connected to the Network, point of sales systems, all related interfaces, file server, UPS related devices
Execute all IT projects
Work and consult with hardware and software vendors to setup and maintain all required equipment
Ensure that the usage and installation of software is in accordance with the software licensing laws
Liaison for the hotel team and Help desk. Work to solve root issues resulting in help desk tickets
Work with department tech champions to ensure smooth working of software and hardware. Recommend improvements on established incident management processes.
Responsible for maintaining Corporate IT standards
Balance operational, administrative and Colleague needs
Follow departmental policies and procedures
Follow all safety policies
Provides training/guidance to hotel team on hardware and software applications.
Recommends improvements on established incident management processes.
Ensure monitoring of ALL recovery systems (system backup and virus protection)
Implement and support ACCOR best practices.
Look for opportunities for new technology that may be beneficial to driving efficiency or supporting internal/external customer satisfaction.
Participate after-hours on call support(24/7) with the regional IT team.
Participate in management of projects as directed by RSM
Other duties as assigned

Qualifications

University degree or equivalent experience
A+ Certification
Microsoft Certified System Engineer
Cisco certification or equivalent experience
Understanding of hotel operations, an asset.
Good verbal & written communication skills
Strong interpersonal skills
Self-starter with a strong sense of commitment.
Ability to work as part of a team
Previous supervisory and training experience an asset
Ability to focus attention on guest needs, always remaining calm and courteous

Additional Information

Located in the heart of vibrant downtown Winnipeg, Manitoba -- at the historic corner of Portage and Main -- Fairmont Winnipeg luxury hotel extends the naturally warm reception of the Prairies. Just step outside our Winnipeg hotel and the city is at your feet.

Our Commitment To Diversity & Inclusion

We are an inclusive company and our ambition is to attract, recruit and promote diverse talent.

Visa Requirements: To be eligible for employment with Fairmont Winnipeg, you must be in possession of a working visa for Canada. We do not provide offer letters to applicants seeking to get their work visas. Applicants must have their work visas in place prior to applying.","{""role_summary"":""The Systems Manager is a leadership role responsible for overseeing all areas of technology services, including hardware, operating systems, and security, to ensure smooth hotel operations and excellent guest experience."",""key_terms"":[{""term"":""IT Security Policy"",""explanation"":""A set of guidelines and rules to ensure the security and integrity of the hotel's IT systems and data.""},{""term"":""Software licensing laws"",""explanation"":""Regulations governing the use and installation of software to ensure compliance with licensing agreements.""},{""term"":""Incident management processes"",""explanation"":""Procedures for identifying, reporting, and resolving IT incidents to minimize downtime and ensure business continuity.""},{""term"":""ACCOR best practices"",""explanation"":""Established guidelines and standards for IT operations and management within the ACCOR group.""}],""skill_priorities"":{""must_have"":[""A+ Certification"",""Microsoft Certified System Engineer"",""Cisco certification or equivalent experience"",""Good verbal & written communication skills"",""Strong interpersonal skills""],""nice_to_have"":[""Understanding of hotel operations"",""Previous supervisory and training experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you ensure the security and integrity of our hotel's IT systems and data?"",""example_answer"":""I would implement and enforce the company's IT Security Policy, conduct regular security audits, and ensure all software and hardware are up-to-date and compliant with licensing agreements.""},{""question"":""Can you describe a time when you had to troubleshoot and resolve a complex IT issue?"",""example_answer"":""In my previous role, I encountered a network outage that affected hotel operations. I worked with the team to identify the root cause, developed a plan to resolve the issue, and implemented a solution that minimized downtime and ensured business continuity.""}],""red_flags"":[""Lack of experience in hotel operations or IT management"",""Inability to communicate technical information to non-technical stakeholders"",""No experience with IT budgeting and financial management""],""confidence_score"":85.0}"
IT MANAGER,"Our client is a growing part of the Higher Education technology industry. They are a Global SaaS EdTech Company with over 625 campus partners and 4 million students actively using their platform.

They help higher education institutions better engage their students, improve the student life experience on campus, and student success. They are committed to improving student success and college graduation rates worldwide by crafting digital experiences that build communities and increase student engagement. They have a diverse and world-class global team poised for their next phase of rapid growth and are looking for an IT Manager to join their team!
As the IT Manager, you will directly impact their vision and mission of helping students succeed by supporting and collaborating with internal teams.
They live their values every day through their work. Here's what you can expect and what they are looking for -
Put Student Success First - The team exists to improve student success.
Accomplish More as a Team - The team comprises passionate, hardworking people who support, care for, and challenge each other to achieve wins together.
Have a Learning Mentality - They look for intellectually curious people who never stop learning and growing and embrace change, which is essential at a constantly evolving tech company.
Move Fast and Innovate - To be successful on the team, you will need to be self-motivated and confident to act in an empowered manner.
They are looking for a remote IT Manager who can be a key resourceful go-to person for the company, ensuring networks are running, managing software security, access levels and more.
As an IT Manager, you will take responsibility for ensuring their IT systems are secure, consistent and reliable. The ideal IT Manager will not be afraid to roll up their sleeves with a strategic mindset with experience in planning and carrying out security measures to protect internal data and information.
In terms of the role responsibilities, you will:
• Work closely with Engineering, Product and Customer Experience team on compliance requirements
• Procure all computer and related technology hardware and softwares
• Support and administer third-party applications used internally
• Assess system performance and recommend improvements
• Fully support, configure, maintain and upgrade networks (serverless environment)
• Monitor and manage updates & upgrade software and hardware with new releases and models
• Monitor network performance and test for weaknesses
• Ensure security of data, network access and backup systems
• Set up user accounts, permissions and passwords and workstations virtually
• Resolve problems reported by end-user & troubleshoot issues and outages
• Design, develop, implement and coordinate IT systems, policies, procedures, and practices
• Build a wiki with technical documentation and IT policies
• Ensure security through access controls, backups and firewalls
• Develop expertise to train staff on new software and technologies
• One-stop help desk operation
• Contribute to improving team member support by actively responding to queries and handling complaints
• Produce relevant documentation and reports
• Work collaboratively and provide feedback to leadership and internal stakeholders
• Control costs and budgets regarding IT systems
• Manage contracts with vendors and software licenses.'
• Preserve assets and control structures
Qualifications:
• Proven experience in an IT Manager or similar role in IT Management for at least three years, with overall five years of hands-on experience in networking and support
• Experience with firewalls, Internet VPN's remote implementation, troubleshooting, and problem resolution is desired
• Apple and PC support experience
• Familiarity with backup and recovery software and methodologies
• Knowledge of system security and last privilege access control
• Resourcefulness and customer-service oriented with a problem-solving attitude
• Solid technical background with an ability to give instructions to a non-technical audience
• Excellent knowledge of technical management, information analysis and computer hardware/software systems
• You are a driven self-starter who is excited about collaborating cross-functionally.
• Experience working in a fast-paced, autonomous environment with the opportunity to make an impact quickly
• A creative problem-solver and can communicate your ideas with clarity.
Individuals who are most successful in this role will live their values and have expertise in the following areas
• Proven work expertise in helping team members remotely
• Experience working in a Cloud-based environment
• Great at organizing, prioritizing and multitasking
• Data protection operations and compliance.
•Managing multiple projects and shifting priorities effectively.
• You are a team player focusing on what's best for the team, company, and customers.
•Experience in IT Management in the Startup/SaaS/B2B space is a bonus.
This is a remote role based anywhere in North America.","{""role_summary"":""The IT Manager will support and collaborate with internal teams to ensure the company's IT systems are secure, consistent, and reliable, ultimately contributing to the company's mission of improving student success."",""key_terms"":[{""term"":""SaaS EdTech Company"",""explanation"":""A software as a service company that provides educational technology solutions.""},{""term"":""Cloud-based environment"",""explanation"":""A computing environment where resources are provided over the internet, rather than on-premises.""},{""term"":""Serverless environment"",""explanation"":""A computing environment where the cloud provider manages the infrastructure, and the company only writes and runs code.""},{""term"":""Last privilege access control"",""explanation"":""A security approach that grants users the minimum level of access required to perform their job functions.""}],""skill_priorities"":{""must_have"":[""Proven experience in IT Management"",""Experience with firewalls, Internet VPN's remote implementation, troubleshooting, and problem resolution"",""Apple and PC support experience"",""Familiarity with backup and recovery software and methodologies"",""Knowledge of system security and last privilege access control""],""nice_to_have"":[""Experience working in a Cloud-based environment"",""Experience in IT Management in the Startup/SaaS/B2B space""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach ensuring the security of our IT systems?"",""example_answer"":""I would implement a layered security approach, including firewalls, access controls, and regular software updates. I would also conduct regular security audits to identify vulnerabilities and prioritize remediation efforts.""},{""question"":""Can you give an example of a time when you had to troubleshoot a complex technical issue?"",""example_answer"":""In my previous role, I encountered an issue with our VPN connection. I worked with the team to identify the root cause, implemented a temporary fix, and then collaborated with our vendor to resolve the issue permanently.""}],""red_flags"":[""Lack of experience working in a remote IT management role"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Information Technology (IT) Manager,"Job Description

Interested in developing or advancing your career with one of the fastest growing automotive dealer groups? Alpha Auto Group is a growing and nationally focused auto dealer group. We are focused on delivering best in class service for our valued customers. As our Group continues to grow, we are looking for highly motivated, enthusiastic team players that share the same vision and desire for success. We are looking for you to join us, to grow with us, and to excel with us!

The Information Technology Manager will provide management of personnel, services infrastructure required to support dealerships across the Alpha Auto-Group.

Responsibilities

Lead IT projects for network/system upgrades and business initiatives
Establish and monitor IT KPIs, mentoring team members
Manage vendor relationships and establish new ones in new geographies
Collaborate with business leaders to align technology investments with business goals
Translate complex tech solutions into business-friendly terms
Support and develop enterprise cyber security solutions
Provide user support for applications, OS, and network issues
Manage Hyper-V servers, Office 365 tenancies, and Azure AD Sync
Administer Active Directory and Group Policy
Configure and report on backups for applications and VMs
Manage Fortinet firewalls and core networking
Administer wireless access points, switches, and routers
Configure and manage RingCentral phone system
Monitor network/application performance across stores
Develop and maintain IT documentation

Qualifications

Post-secondary degree/diploma in Information Technology, Computer Science, or a related field
3+ years IT management experience
5+ years of IT support and Administration experience in a 1000+ network user environment
5+ years of experience deploying and managing MS-Windows Services
5+ years of experience administering a Hyper-V virtual environment
2+ years of experience managing Azure infrastructure services/ Office 365
Strong DHCP, DNS, Active Directory and Group Policy administration skills
Work experience in Automotive Industry will be considered an asset
Work Experience with Dealer Management Systems will be considered and asset
N-Able N-Central experience is considered an asset

Please note: Must be willing to travel up to 30% of the time to oversee multiple dealerships.","{""role_summary"":""The Information Technology Manager will lead IT projects, manage personnel, and oversee infrastructure to support dealerships across the Alpha Auto Group."",""key_terms"":[{""term"":""IT KPIs"",""explanation"":""Key Performance Indicators for Information Technology, used to measure and track IT performance and progress.""},{""term"":""Hyper-V"",""explanation"":""A virtualization platform that allows multiple virtual machines to run on a single physical server.""},{""term"":""Azure AD Sync"",""explanation"":""A service that synchronizes user identities between on-premises Active Directory and Azure Active Directory.""},{""term"":""Fortinet firewalls"",""explanation"":""A type of network security system that monitors and controls incoming and outgoing network traffic.""},{""term"":""RingCentral phone system"",""explanation"":""A cloud-based business phone system that provides voice, video, and messaging services.""}],""skill_priorities"":{""must_have"":[""IT management experience"",""IT support and administration experience"",""MS-Windows Services deployment and management"",""Hyper-V virtual environment administration"",""Azure infrastructure services/Office 365 management"",""DHCP, DNS, Active Directory, and Group Policy administration skills""],""nice_to_have"":[""Work experience in Automotive Industry"",""Work Experience with Dealer Management Systems"",""N-Able N-Central experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with IT project management and how you would approach a network/system upgrade?"",""example_answer"":""I have managed multiple IT projects, including network upgrades, and I would approach this by first assessing the current infrastructure, identifying areas for improvement, and then developing a plan to implement the upgrade with minimal disruption to the business.""},{""question"":""How do you stay current with the latest developments in IT and cybersecurity?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read relevant publications to stay up-to-date on the latest trends and best practices in IT and cybersecurity.""}],""red_flags"":[""Lack of experience with Hyper-V virtual environment administration"",""Inability to travel up to 30% of the time""],""confidence_score"":90.0}"
IT Manager North America,"Ayming is the leading international consultancy firm specialized in Business Performance. We constantly create and implement new ways to bring extra and authentic Sustainable Business Performance to our clients by advising them on critical issues and opportunities supported by three major pillars: Operational Excellence, Employee Commitment and Innovation Management

Ayming’s North America (Canada & US) is looking for a IT Manager North America to help us achieve our growth strategy

Your job

You will be part of the company’s leadership team.

Project Management

Lead projects within the Canadian and US business units aimed at revitalizing the software utilized for sales, sales administration, operational management, and consulting production.

Enhance the utilization of SalesForce,
Coordinate software deployment in alignment with other Ayming countries,
Provide support to the business team for the implementation of AI and Data platform rollout.


Workspace Management

Laptops and cell phone management,
Handling employee incidents and requests,
Managing business application accounts,


Your talent

You Have

A degree ranging from Bachelor’s to Master’s level in IT
At least 5 years’ experience in Project Management
Customer service orientation and teamwork spirit
Good knowledge of the Windows environment,
Microsoft Office, and Outlook


You Are

Organized, rigorous and proactive,
Synthetic and Methodical,
Excellent interpersonal skills.


If you become an Aymer:

We offer an ideal work environment for our employees – Ayming Canada is proud to announce that we have been certified Great Place to Work® after an extensive and independent analysis conducted by Great Place to Work Institute® Canada. This certification is based on direct feedback from employees, provided through a thorough and anonymous survey of their workplace experience.
Career growth and progression, within a dynamic and growing organization.
Globally established brand where you can grow your career and make a meaningful impact.
Autonomy, balanced with a strong level of support and collaboration.
Flexibility – design your own work schedule and work from home 3 days/week.
Excellent base salary, with high earning potential in bonuses, benefits, vacations, etc.
We offer personal days, holidays and half-day Fridays all summer long;
Excellent benefits package with 100% of employee benefits covered by the company.
Competitive retirement plan with employer contribution (RRSP).
Salary range: 100.000 – 150.000 CAD


Apply now Send to a friend ›

Share this post

Data Privacy Notice

AYMING CONFIDENTIAL

Apply now Send to a friend ›

First Name *
Last Name *
Phone *
Email *
Upload your Resume / CV * Accepted file types: pdf, doc, rtf, txt, Max. file size: 24 MB.
Position I'm interested in *
*
I am happy for Ayming to use these details to contact me in response to this job application.","{""role_summary"":""The IT Manager North America will lead projects to revitalize software used for sales, sales administration, operational management, and consulting production, and manage workspace operations, ensuring alignment with Ayming's growth strategy."",""key_terms"":[{""term"":""Operational Excellence"",""explanation"":""A business approach focused on achieving efficient and effective operations.""},{""term"":""SalesForce"",""explanation"":""A customer relationship management (CRM) platform used for sales and customer management.""},{""term"":""AI and Data platform"",""explanation"":""A technology platform that uses artificial intelligence and data analytics to support business operations.""}],""skill_priorities"":{""must_have"":[""Project Management"",""Customer service orientation"",""Good knowledge of the Windows environment"",""Microsoft Office, and Outlook""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with project management in an IT environment?"",""example_answer"":""I have managed multiple projects in my previous role, ensuring timely delivery and effective resource allocation. I'm familiar with Agile methodologies and have experience with project management tools like Asana or Trello.""},{""question"":""How would you approach the implementation of a new AI and Data platform in our organization?"",""example_answer"":""I would start by assessing our current data infrastructure and identifying areas for improvement. Then, I would work closely with stakeholders to develop a rollout plan, ensuring minimal disruption to business operations and providing training to end-users.""}],""red_flags"":[""Lack of experience with SalesForce or similar CRM platforms"",""Inability to work in a fast-paced environment with multiple priorities""],""confidence_score"":85.0}"
IT Support Manager,"CAREER OPPORTUNITY AT LOGISTEC

LOGISTEC offers a unique combination of maritime and environmental services, both water related. Our reputation rests on excellence, thanks to the dedication of over 3,500 employees throughout North America, committed to finding solutions to support reliable and sustainable supply chains, while also protecting our environment and water resources.

Diversity helps us grow, and inclusion propels us forward. When everyone is included, great things can be achieved together. That's why we continue to strengthen our commitment to employment equity, inclusive recruitment, and development.

We are determined to find and support the best talent, and we are currently looking to fill a position for an IT Support Manager in Montreal.

Seize this opportunity and come make great things happen with us!

What does your day look like as an IT Support Manager?
Overseeing the day-to-day operations of the service desk.
Ensuring timely and effective resolution of customer issues and inquiries.
Managing a team of service desk agents, including hiring, training, and performance management.
Developing and implementing service desk policies, procedures, and best practices based on ITSM methodologies.
Monitoring and analyzing service desk performance metrics to identify areas for improvement.
Collaborating with other departments to streamline processes and improve service delivery.
Serving as a point of escalation for complex or high-priority issues.
Implementing and maintaining service desk technologies and tools.
Providing regular reports and updates to senior management on service desk performance and initiatives.
Staying current on industry trends and best practices in service desk management.

To succeed as an IT Support Manager, you must have:
Bachelor's degree in information technology, computer science, or a related field (or equivalent work experience)
Proven experience in a service desk or technical support role, with at least 3-5 years in a leadership or managerial position
Strong understanding of ITIL framework and best practices
Excellent communication and interpersonal skills, with the ability to effectively communicate technical information to non-technical stakeholders
Demonstrated leadership abilities, including the ability to motivate and manage a team
Experience in hiring, training, and performance management of service desk staff
Proficiency in service desk management tools and technologies
Strong analytical and problem-solving skills, with the ability to identify trends and patterns in service desk data
Ability to work well under pressure and prioritize tasks in a fast-paced environment
Knowledge of IT service management principles and methodologies
Certifications such as ITIL Foundation, HDI Support Center Manager, or similar are preferred but not required.","{""role_summary"":""Manage the day-to-day operations of the service desk, ensuring timely and effective resolution of customer issues, and leading a team of service desk agents to improve service delivery."",""key_terms"":[{""term"":""ITSM"",""explanation"":""Information Technology Service Management, a set of policies, procedures, and best practices for managing IT services.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management that provides best practices for delivering high-quality IT services.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in information technology, computer science, or a related field"",""Proven experience in a service desk or technical support role"",""Strong understanding of ITIL framework and best practices"",""Excellent communication and interpersonal skills"",""Demonstrated leadership abilities"",""Experience in hiring, training, and performance management of service desk staff"",""Proficiency in service desk management tools and technologies"",""Strong analytical and problem-solving skills""],""nice_to_have"":[""Certifications such as ITIL Foundation, HDI Support Center Manager, or similar""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to implement a new service desk policy or procedure? How did you ensure its successful adoption?"",""example_answer"":""In my previous role, I implemented a new ticketing system for our service desk. I worked closely with the team to develop a comprehensive training program, and we saw a significant reduction in errors and an increase in customer satisfaction.""},{""question"":""How do you stay current with industry trends and best practices in service desk management?"",""example_answer"":""I regularly attend industry conferences and webinars, and I'm an active member of online forums and discussion groups focused on service desk management. I also make it a point to read industry publications and blogs to stay informed.""}],""red_flags"":[""Lack of experience in a leadership or managerial position"",""Inability to effectively communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Information Technology Operations Manager,"Our client in Waterdown, ON is looking for an IT Operations Manager to join their team!

Role:

Our hospitality client is seeking a skilled and motivated IT Operations Manager to maintain and advance their technological infrastructure. This hands-on role involves managing and improving day-to-day IT operations, ensuring efficient and high-performing service delivery across 14 locations. You will be responsible for providing strategic direction for the infrastructure function and leading the planning, installation, maintenance, and upgrade of IT systems. You will manage the coordination of IT resources to ensure that work objectives are consistently met and that the team strives for operational excellence.

Work Type:

Fully Onsite – 5 days a week in office
Location: Waterdown, ON
9am – 5pm, Mon-Fri – some weekend/off hours work may be required

Company Culture:

You will work for a growing organization that fosters a culture thriving on self-motivation, dedication, and a genuine passion for technology and hospitality. As an IT Operations Manager, you won’t just be part of the workforce - you’ll actively participate in shaping the future of infrastructure operations. Your insights and contributions will play a vital role in driving ongoing success and fortifying security for the organization.

As an IT Operations Manager, you will:

Oversee the day-to-day IT operations, ensuring optimal performance of all systems and networks
Monitor daily operations, including server hardware, software and operating systems
Manage and mentor IT staff, including hiring, training, assigning tasks, and evaluating performance
Supervise the Service Desk operations, handling urgent and complex support issues, acting as the escalation point for all incidents and requests
Develop and enforce IT standards and best practices to optimize the use of network resources and ensure consistent service levels
Analyze performance of IT services and documented resolutions to identify problem areas, delivering solutions to enhance quality of service and prevent future issues
Learn and support business applications to better service organizational needs
Oversee relationships with IT vendors and service providers, ensuring service levels are maintained
Identify opportunities for team training and skills advancement, ensuring continuous improvement in service delivery
Work closely with business leaders to understand and support the organization’s IT needs and roadmap

What you will bring:

A minimum of 5 years of experience in IT operations, with experience in leadership/management
Ability to effectively lead and motivate a team
Strong technical skills and hands-on experience with troubleshooting level 3 tickets
Strong understanding of IT systems and infrastructure, including servers, networks, and operating systems
Proficiency in managing Active Directory, Windows Server, VMware, network protocols, security controls, backup and antivirus software
Experience with O365, SharePoint, OneDrive, Windows deployment toolkit, and remote management technologies
Familiarity with LAN technologies, routing, switching, firewalls, VPN, VoIP and telephony
Knowledge of PCI compliance
Experience in the hospitality industry would be considered an asset

Compensation:

Salary: $120,000 - $125,000
Paid Time-Off
Full Health Benefits","{""role_summary"":""Manage and advance technological infrastructure, ensuring efficient and high-performing service delivery across multiple locations."",""key_terms"":[{""term"":""IT Operations"",""explanation"":""The management and maintenance of an organization's IT systems and infrastructure.""},{""term"":""Infrastructure Function"",""explanation"":""The underlying systems and structures that support an organization's operations, including IT systems, networks, and facilities.""},{""term"":""Operational Excellence"",""explanation"":""A state of high performance and efficiency in an organization's operations, achieved through continuous improvement and optimization.""},{""term"":""PCI Compliance"",""explanation"":""A set of security standards designed to ensure that companies that handle credit card information maintain a secure environment.""}],""skill_priorities"":{""must_have"":[""IT operations management"",""Leadership/management experience"",""Technical skills (troubleshooting level 3 tickets)"",""Knowledge of IT systems and infrastructure"",""Proficiency in managing Active Directory, Windows Server, VMware, network protocols, security controls, backup and antivirus software""],""nice_to_have"":[""Experience in the hospitality industry"",""Familiarity with LAN technologies, routing, switching, firewalls, VPN, VoIP and telephony"",""Knowledge of O365, SharePoint, OneDrive, Windows deployment toolkit, and remote management technologies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with IT operations management and how you've optimized service delivery in previous roles?"",""example_answer"":""In my previous role, I implemented a ticketing system that reduced response times by 30% and increased customer satisfaction ratings by 25%. I also developed a training program for IT staff, resulting in a 40% reduction in errors and a 20% increase in productivity.""},{""question"":""How do you stay current with emerging trends and technologies in IT operations, and how do you prioritize their adoption in your organization?"",""example_answer"":""I regularly attend industry conferences and participate in online forums to stay informed about the latest developments in IT operations. I prioritize adoption based on business needs and ROI, and work closely with stakeholders to ensure successful implementation.""}],""red_flags"":[""Lack of experience in IT operations management"",""Inability to effectively lead and motivate a team"",""Limited technical skills or hands-on experience with troubleshooting""],""confidence_score"":90.0}"
IT Service Center Director,"Leclerc is a family business with 117 years of experience, tradition and know-how passed down from people with heart. Thanks to our 1,400 employees in nine plants in Canada and the United States, we are constantly innovating to exceed the expectations of both small and large appetites.

Working at Leclerc means...

Working in a family business
Evolving in a clean, temperate environment with the latest technology
Starting a new job with paid and adapted training
Benefit from a complete benefits program (drug and dental insurance, 1 week of sick leave [conditions apply], telemedicine, group RRSP with employer participation and more)
Enjoy quality meals at low prices in the cafeteria (unlimited coffee, tea, cookies and bars)
Enjoy free use of the sports facilities (basketball court, training room and cardio room)
Save on our delicious products and discover exclusive novelties
Take advantage of job security and opportunities for advancement within the company
Integrate a rich company culture (Christmas, birthday and maternity gifts, use of the Poka platform and more)

Summary Of The Function

Reporting to the Senior Director of Information Technology, the IT Service Center Manager manages the activities surrounding user services and the technical services outsourcing process. He plays an important role in the service delivery strategy, and his concern for security and customer satisfaction is constant. His experience enables him to act as an expert in recommending the solutions and investments required, and in justifying them. Aware of the CYBER risk, he is highly committed to immediate proactivity and reactivity to actions required to reduce risk exposure.

Responsibilities

Coordinate the activities of your group and ensure that projects and recurring activities are carried out efficiently;
Participate in the planning and monitoring of budgets;
Ensure the resolution of problems related to the systems under your responsibility;
Identify opportunities for improvement and optimization of these systems;
Proactively recommend technological enhancements and investments in information systems and ensure their implementation;
Promote interactions and synergy between the various IT teams;
Coordinate and ensure the follow-up of service agreements with external suppliers related to the technologies under your responsibility;
Be responsible for the development of case studies leading to decision-making;
Monitor new developments in your area of expertise and assess the relevance of these advances for the organization according to the determined business strategy;
Report on the status of internal and external operational services (outsourcing) and maintain metrics such as open tickets, technician performance and SLAs;
Ensure that the tools and processes put in place are respected and improved;
Supervise IT technical support activities (helpdesk) and ensure customer satisfaction while respecting predefined IT norms and standards;
Audit the documentation update of the user procedures, technical documentation, support processes and operations manual;
Maintain close contact with customers by conducting regular satisfaction surveys.

Skills And Abilities Required

University degree in computer science or bachelor's degree in business administration specializing in information technology;
6 to 9 years' relevant experience, including 3 as an IT support manager;
Good knowledge of Windows environments, O365 and equipment lifecycle management;
In-depth knowledge of the indicators and best practices required to manage your environment;
Certification and/or knowledge of ITIL, CoBit
Fluent in spoken and written French and English;
Customer service oriented;
Autonomy / Initiative / Creativity;
Leadership / Ability to influence / Teamwork;
Analysis / Synthesis / Judgement;
Ability to solve problems / Ability to make recommendations;
Stress resistance / Time and priority management;
Professional / Rigorous / Proactive and able to react quickly;
Results-oriented;
Ability to respect budgets and deadlines.

Biscuits Leclerc is committed to recruiting and hiring the best candidates for all roles and is committed to integration and equal opportunity. Upon request, Biscuits Leclerc will provide suitable accommodations during the recruitment and hiring process to candidates with accessibility needs due to disability to ensure that the standards outlined in Accessibility for Ontarians with Disabilities Act (AODA) are upheld. If you require an accommodation during the application or interview process, please contact the HR responsible at 613-632-0777 ext: 4204","{""role_summary"":""The IT Service Center Manager oversees user services and technical services outsourcing, ensuring efficient project delivery, budget planning, and problem resolution, while maintaining a customer-centric approach and prioritizing security and risk reduction."",""key_terms"":[{""term"":""CYBER risk"",""explanation"":""The risk of cyber attacks or data breaches, which the IT Service Center Manager must proactively mitigate.""},{""term"":""ITIL"",""explanation"":""A set of best practices for IT service management, which the IT Service Center Manager should be certified in or have knowledge of.""},{""term"":""CoBit"",""explanation"":""A framework for IT governance and management, which the IT Service Center Manager should be certified in or have knowledge of.""},{""term"":""O365"",""explanation"":""A cloud-based suite of productivity applications, including Office, which the IT Service Center Manager should have good knowledge of.""}],""skill_priorities"":{""must_have"":[""University degree in computer science or business administration"",""6-9 years of relevant experience, including 3 as an IT support manager"",""Good knowledge of Windows environments and O365"",""In-depth knowledge of IT service management indicators and best practices"",""Certification and/or knowledge of ITIL and CoBit"",""Fluent in spoken and written French and English""],""nice_to_have"":[""Autonomy, initiative, and creativity"",""Leadership and ability to influence"",""Analysis, synthesis, and judgment"",""Ability to solve problems and make recommendations"",""Stress resistance and time and priority management""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with IT service management frameworks such as ITIL and CoBit?"",""example_answer"":""I have worked with ITIL for 5 years and have implemented several processes to improve our service delivery. I'm also familiar with CoBit and have used it to assess our IT governance and management.""},{""question"":""How do you stay up-to-date with the latest developments in IT service management and cybersecurity?"",""example_answer"":""I regularly attend industry conferences and webinars, and I'm an active member of online forums and communities focused on IT service management and cybersecurity.""}],""red_flags"":[""Lack of experience with IT service management frameworks"",""Inability to communicate technical information to non-technical stakeholders"",""Poor problem-solving skills""],""confidence_score"":90.0}"
"Manager, Information Technology Operations","Join Jones Healthcare Group - Where Innovation Meets Purpose!

At Jones, we’re committed to the environment, our team, communities, and consumers, and we're inspired to make a meaningful impact through advanced packaging and medication dispensing solutions.

Learn more about us here: www.joneshealthcaregroup.com.

Summary Of Position

If you love leading technological advancements and excel in a dynamic, fast-paced setting, this position is the right fit for you.

If you get inspired by leading a team to achieve operational excellence and ensuring seamless IT infrastructure, you're in the right place.

If you are driven by the challenge of managing critical data center operations and network infrastructure to support a global organization, then we want to hear from you.

The Manager, Information Technology Operations is responsible for overseeing the day-to-day functions of the Information & Business Technology (IBT) department’s Infrastructure and Support, including managing and maintaining the key data center and network infrastructure, and ensuring operational targets are met. Manager, IT Operations will also be accountable for leading a small team of IT support colleagues, providing shared service support to all company locations and business units.

We are proud to foster a collaborative environment where teamwork thrives and meaningful relations are made in person. Therefore, this role is primarily on-site, with flexibility for a hybrid model that includes work-from-home opportunities. This setup allows you to fully immerse yourself in our dynamic workplace culture while enjoying the benefits of both in-person and remote work.

More About Your Responsibilities

Ownership in designing, installing, monitoring, and supporting both production and non-production data center and network infrastructure.
Plan and execute server OS and application upgrades, bug fixes, backups, and restores, ensuring smooth operations.
Develop and implement new system and application plans, along with risk assessments and contingency procedures, to uphold operational reliability.
Maintain high availability and performance standards for critical production assets, supporting 24x7 manufacturing and distribution across the organization in multiple time zones.
Lead and mentor IT support colleagues to meet internal SLAs and performance targets.
Provide guidance on technology maintenance, replacements, and upgrades, prioritizing initiatives effectively.
Offer after-hours leadership during emergencies and occasional weekend maintenance.
Ensure IT systems' security and compliance with data protection policies through audits and proactive measures.
Collaborate with third-party data center staff and act as a primary escalation point for helpdesk issues across multiple locations.
Contribute to disaster recovery planning, policy creation, and implementation alongside the VP, IBT.
Evaluate and recommend new IT technologies to enhance compatibility and effectiveness across platforms.
Mentor team members on existing and emerging technologies, fostering skill development.
Uphold Health & Safety and Quality Management System policies and procedures diligently.

What You’ll Bring

Values that mirror ours, from the Inside Out: Ingenuity, Nimble, Supportive, Inclusive, Driven, Empathetic.
Degree or Diploma in Computer Science or related field.
7+ years of progressive IT experience, encompassing in-house and outsourced systems.
Extensive hands-on experience (7+ years) managing technology infrastructure in Windows and Linux environments.
Advanced proficiency in Windows Server (2003 and above) and Windows 10/11 OS.
Strong knowledge of cybersecurity practices, including NIST 800-53, ISO/IEC 27001/27002, and/or CIS Controls v7/v8.
Solid understanding of LAN/WAN networking.
Experience with VMWare virtualized environments.
Familiarity with building, managing, and securing Linux servers is advantageous.
Consider as an asset:
Experience with Microsoft SQL Server and TSQL.
Proficiency in Microsoft Office 365, Sharepoint, and OneDrive.
Experience with VPN, IAM, MFA, and infrastructure tools (e.g., RMM, IDS, SIEM).
Knowledge of cloud infrastructure (e.g., AWS, Azure).
Previous ERP experience, particularly with SAP R/3, Infor Visual 10, or Sage 50/200.
We care about our colleagues, some benefits we offer are:

A safe, respectful, and inclusive environment
Competitive compensation and equitable people practices
Opportunities to grow and develop, alongside a supportive team
Employee and family assistance program
Referral bonuses
Colleague appreciation events
and more!

Join us in shaping the future of healthcare! Apply now to join our dynamic team and make a meaningful impact in a collaborative environment.

Please submit a resume and let us know why you are interested.

While we thank all candidates for their interest, only those selected for an interview will be contacted.

As part of our commitment to accessibility for all persons with disabilities, Jones Healthcare Group will, upon the request of the applicant, provide accommodation during the recruitment process to ensure equal access to applicants with disabilities. Please contact the Jones Human Resources department at 1.800.265.9093 about your needs, and we will consult with you to ensure suitable accommodation is provided.

For all feedback on equity and accommodation needs, please also contact the Human Resources department.","{""role_summary"":""The Manager, Information Technology Operations oversees the day-to-day functions of the Information & Business Technology department's Infrastructure and Support, ensuring operational targets are met and leading a team of IT support colleagues."",""key_terms"":[{""term"":""Data center operations"",""explanation"":""Managing and maintaining critical data center infrastructure to support a global organization.""},{""term"":""Network infrastructure"",""explanation"":""Ensuring seamless IT infrastructure and supporting global operations.""},{""term"":""IT support"",""explanation"":""Providing shared service support to all company locations and business units.""},{""term"":""Server OS and application upgrades"",""explanation"":""Planning and executing upgrades, bug fixes, backups, and restores to ensure smooth operations.""},{""term"":""Cybersecurity practices"",""explanation"":""Ensuring IT systems' security and compliance with data protection policies through audits and proactive measures.""}],""skill_priorities"":{""must_have"":[""7+ years of progressive IT experience"",""Extensive hands-on experience managing technology infrastructure in Windows and Linux environments"",""Advanced proficiency in Windows Server (2003 and above) and Windows 10/11 OS"",""Strong knowledge of cybersecurity practices""],""nice_to_have"":[""Experience with Microsoft SQL Server and TSQL"",""Proficiency in Microsoft Office 365, Sharepoint, and OneDrive"",""Experience with VPN, IAM, MFA, and infrastructure tools"",""Knowledge of cloud infrastructure (e.g., AWS, Azure)"",""Previous ERP experience, particularly with SAP R/3, Infor Visual 10, or Sage 50/200""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with managing critical data center operations and network infrastructure?"",""example_answer"":""I have 7+ years of experience managing technology infrastructure in Windows and Linux environments, ensuring seamless IT infrastructure and supporting global operations.""},{""question"":""How do you ensure IT systems' security and compliance with data protection policies?"",""example_answer"":""I ensure IT systems' security and compliance with data protection policies through audits and proactive measures, following cybersecurity practices such as NIST 800-53, ISO/IEC 27001/27002, and/or CIS Controls v7/v8.""}],""red_flags"":[""Lack of experience in managing critical data center operations and network infrastructure"",""Insufficient knowledge of cybersecurity practices""],""confidence_score"":90.0}"
Information Technology Manager,"About the job
Consistently offer professional, engaging, and friendly service.
Deliver high levels of service and support to each property as per Service Level Agreement (SLA).
Resolve complex problems in consultation with other senior IT resources.
Provide training and guidance to less experienced staff.
Recommend improvements to established incident management processes.
Assist in maintaining IT standard guidelines.
Ensure monitoring of ALL recovery systems (tape backup and virus protection).
Provide escalated support to Technology Services staff.
Assist and support strategic plan implementation.
Implement and support best practices.
Contribute to Technology Services knowledge base.
Look for opportunities for new technology that may benefit customers.
Provide after-hours pager support.
Participate in managing all aspects of a project as directed by RSM.
Follow all safety policies.
Perform other duties as assigned.

Skills required

University degree or equivalent experience.
Microsoft Certified System Engineer.
Cisco certification or equivalent experience.
Understanding of hotel operations (an asset).
Good verbal and written communication skills.
Strong interpersonal skills.
Self-starter with a strong sense of commitment.
Previous supervisory experience.","{""role_summary"":""Provide high-level IT support and service to properties, resolving complex problems, training staff, and implementing best practices to ensure efficient incident management."",""key_terms"":[{""term"":""Service Level Agreement (SLA)"",""explanation"":""A formal agreement between IT and properties outlining expected service quality and response times.""},{""term"":""Incident management"",""explanation"":""The process of identifying, resolving, and documenting IT issues to minimize downtime and impact on business operations.""},{""term"":""Tape backup"",""explanation"":""A data backup method using physical tapes to store and recover data in case of system failure or data loss.""},{""term"":""Virus protection"",""explanation"":""Software or systems designed to detect, prevent, and remove malicious code or viruses from computer systems.""}],""skill_priorities"":{""must_have"":[""Microsoft Certified System Engineer"",""Cisco certification or equivalent experience"",""Good verbal and written communication skills"",""Strong interpersonal skills"",""Self-starter with a strong sense of commitment"",""Previous supervisory experience""],""nice_to_have"":[""Understanding of hotel operations""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a complex IT problem you resolved in the past, and how you approached it?"",""example_answer"":""In my previous role, I encountered a network issue affecting multiple properties. I worked with senior IT resources to identify the root cause, developed a plan to resolve it, and implemented the solution, resulting in minimal downtime and improved network reliability.""},{""question"":""How do you stay current with emerging technologies and best practices in IT?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read relevant publications to stay informed about the latest developments and trends in IT. I also contribute to our internal knowledge base to share my knowledge with colleagues.""}],""red_flags"":[""Lack of experience with IT service management frameworks"",""Inability to work independently with minimal supervision"",""Poor communication skills, leading to ineffective incident resolution""],""confidence_score"":85.0}"
IT Manager - Construction,"The IT Manager will be responsible for responsible for the overall planning, organizing, and execution of all information technology functions within the organization. This includes directing all IT operations to meet customer requirements as well as the support and maintenance of existing applications and development of new technical solutions.

Responsibilities

Strategic Planning: Recommend technologies aligned with organizational goals; evaluate and adopt emerging technologies; stay informed on industry trends.
Team Leadership: Lead the IT team; partner with departments to meet their IT needs.
Infrastructure Management: Manage IT infrastructure including networks and cloud systems; maintain software applications.
Project Management: Oversee IT projects, ensuring effective management of timelines, budgets, and stakeholder communication.
Security and Compliance: Implement cybersecurity measures; ensure compliance with standards; oversee disaster recovery planning.
Vendor Management: Handle vendor relationships and contract negotiations to optimize organizational value.
IT Support: Provide technical support and maintain IT policies to ensure user compliance.
Budgeting and Cost Control: Oversee the IT budget and identify cost efficiencies.
Continuous Improvement: Monitor and implement best practices for IT governance and improvements.

Qualifications

Bachelor's degree in computer science, information technology, or a related field.
Proven experience (3 to 5 years) as an IT Manager or a similar leadership role.
Strong knowledge of IT systems, infrastructure, and cybersecurity best practices.
Excellent leadership and team management skills.
Exceptional problem-solving and decision-making abilities.
Effective communication and interpersonal skills.
Experience in strategic planning and execution.","{""role_summary"":""The IT Manager is responsible for planning, organizing, and executing all IT functions to meet customer requirements and support business goals."",""key_terms"":[{""term"":""Cybersecurity measures"",""explanation"":""Implementing security protocols to protect the organization's IT systems and data from threats.""},{""term"":""Cloud systems"",""explanation"":""Using cloud-based infrastructure to store, manage, and process data.""},{""term"":""IT governance"",""explanation"":""Establishing policies, procedures, and standards to ensure effective management of IT resources.""},{""term"":""Disaster recovery planning"",""explanation"":""Developing strategies to restore IT systems and data in the event of a disaster or system failure.""}],""skill_priorities"":{""must_have"":[""Strong knowledge of IT systems, infrastructure, and cybersecurity best practices"",""Proven experience as an IT Manager or similar leadership role"",""Excellent leadership and team management skills""],""nice_to_have"":[""Experience in strategic planning and execution""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach implementing a new cybersecurity measure to protect our organization's data?"",""example_answer"":""I would first conduct a risk assessment to identify vulnerabilities, then develop a plan to implement the measure, ensuring minimal disruption to business operations. I would also provide training to the IT team and stakeholders to ensure a smooth transition.""},{""question"":""Can you describe your experience with cloud system management?"",""example_answer"":""In my previous role, I managed a team that migrated our organization's infrastructure to a cloud-based system, resulting in improved scalability and cost savings. I worked closely with the vendor to ensure a seamless transition and developed a plan to monitor and optimize cloud usage.""}],""red_flags"":[""Lack of experience with cloud system management"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
IT Infrastructure and Service Manager,"OnX is looking for a Sr IT Infrastructure and Services Manager

Location: New Brunswick (hybrid work model - must be able to work onsite/ fully remote is NOT possible) - local NB candidates are highest priority
Duration: 6m (very possible extension or/and conversation to permanent F/T) - must be open to FT after initial contract

Core Requirements (must-haves):
Minimum of 10 years of experience in IT (network/infrastructure/cybersecurity, etc...) combined with 5+ years of metamaterial experience
IT infrastructure including network, servers, storage, databases, wireless technology, communications and telephony systems, file and print services, etc.
Cisco environment
Network and Server operating systems
ServiceNow
Azure migration experience
Vendor relationships and management experience
Experience managing budgets, developing business cases and cost / benefit analyses for IT","{""role_summary"":""Manage IT infrastructure and services, overseeing network, servers, storage, and databases, with a focus on cybersecurity and vendor relationships."",""key_terms"":[{""term"":""Metamaterial"",""explanation"":""A type of material engineered to have properties not typically found in naturally occurring materials, often used in IT infrastructure.""},{""term"":""Cisco environment"",""explanation"":""A network infrastructure built using Cisco Systems' products and technologies.""},{""term"":""ServiceNow"",""explanation"":""A cloud-based IT service management platform for managing IT services, assets, and workflows.""},{""term"":""Azure migration"",""explanation"":""The process of moving applications, data, and other business elements from on-premises environments to Microsoft Azure, a cloud computing platform.""}],""skill_priorities"":{""must_have"":[""10+ years of IT experience"",""5+ years of metamaterial experience"",""IT infrastructure management"",""Cisco environment"",""Network and Server operating systems"",""ServiceNow"",""Azure migration experience"",""Vendor relationships and management"",""Budget management and cost/benefit analysis""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with IT infrastructure management, including network, servers, and storage?"",""example_answer"":""I have managed IT infrastructure for over 10 years, including designing and implementing network architectures, server virtualization, and storage solutions.""},{""question"":""How do you stay current with the latest developments in metamaterials and their applications in IT?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read research papers to stay up-to-date on the latest advancements in metamaterials and their potential applications in IT infrastructure.""}],""red_flags"":[""Lack of experience with Cisco environments"",""Inability to work in a hybrid work model (onsite and remote)""],""confidence_score"":90.0}"
IT Operations Manager,"Dragados Canada, Inc., the Canadian construction arm of the ACS Group (one of the world’s largest international construction and engineering companies), is seeking a talented and experienced IT Operations Manager to join its dynamic and energetic team.

Dragados Canada was established in 2008 and has grown steadily into an industry-leader in Canada, with offices in Toronto, Vancouver and Montreal, successfully performing a variety of large-scale transportation, bridge, dam, tunnel, and other major infrastructure projects.

Salary range: $80,000-$110,000 (based on relevant experience, qualifications and skills).

Responsibilities

Maintain facility’s IT environment to ensure business continuity and progression
Prepare relevant and concise written status update reports within established timeframe for IT team leads
Liaison between the site clients/stakeholders and the rest of the IT team and their leads
Install, configure, and deploy software/hardware
Establish vendor relations and perform purchasing comparisons for goods and services
Collaboration to perform maintenance activities such as upgrades, system patching, and backups
Act as a link between end-users and higher tier advanced support as needed
Coordinate with manufacturers, vendors, and service providers to ensure best possible outcome based on economics, schedule, and solution provided terms
Ensure established policies and procedures are followed and adhered to while communicating anomalies accordingly
Provide input and guidance towards the implementation of IT solutions
Maintain accurate licensing, inventory, and maintenance contracts
Assist with budgeting, including the purchase of new equipment and software and consequent billing review
Ensure accurate and up to date records between local and online portal systems
Promote continued utilization of IT service management solutions

Qualifications

BS/BA in information technology or computer science is preferred
Comprehensive knowledge of infrastructure and network topologies
Solid knowledge of IT systems and applications
Past role as IT manager or similar position
Understanding of M365 and Azure cloud offerings
Cybersecurity conscious and conforming
Project and time management skills
Exceptional attention to detail
Excellent organizational and coordination abilities
Extensive experience working in a team-oriented, collaborative environment
Able to explain technical details to non-technical personnel in a clear and coherent manner
Guide and mentor junior team members
Communicate clearly with both technical and non-technical team members
Accept accountability and scheduling of tasks assigned
Willing and able to accept and provide objective based criticism
Observant and willing to express and adopt new ideas
No agency phone calls/emails/submissions please**

Dragados is an equal opportunity employer. While only qualified candidates will be contacted for an interview, be sure to continually check our website for other related positions as they are posted.

Appropriate accommodations will be provided upon request throughout the recruitment and hiring process.","{""role_summary"":""The IT Operations Manager is responsible for maintaining the IT environment, ensuring business continuity, and providing technical support to the team. They will also collaborate with stakeholders, manage vendors, and implement IT solutions."",""key_terms"":[{""term"":""M365"",""explanation"":""Microsoft 365, a cloud-based productivity suite""},{""term"":""Azure"",""explanation"":""Microsoft's cloud computing platform""},{""term"":""IT service management solutions"",""explanation"":""Software and systems used to manage and deliver IT services""}],""skill_priorities"":{""must_have"":[""Comprehensive knowledge of infrastructure and network topologies"",""Solid knowledge of IT systems and applications"",""Past role as IT manager or similar position"",""Understanding of M365 and Azure cloud offerings"",""Cybersecurity conscious and conforming"",""Project and time management skills""],""nice_to_have"":[""BS/BA in information technology or computer science""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of maintaining accurate licensing and inventory records in an IT environment?"",""example_answer"":""Accurate records are crucial to ensure compliance with software licenses, track inventory, and plan for future upgrades or replacements. This helps prevent legal and financial issues, and ensures the IT team can provide efficient support to the organization.""},{""question"":""How would you approach explaining technical details to non-technical stakeholders?"",""example_answer"":""I would use clear, non-technical language, avoiding jargon and focusing on the benefits and impact of the technical solution. I would also provide examples or analogies to help stakeholders understand complex concepts.""}],""red_flags"":[""Lack of experience in IT management or similar roles"",""Inability to communicate technical details to non-technical personnel""],""confidence_score"":90.0}"
Information Technology Manager – Consumer & Dealer,"Rank P6 /P7

Scarborough, ON

Toyota Canada currently has an exciting opportunity - Information Technology Manager – Consumer & Dealer. We are looking for a leader in the Application Development and Business Relationship areas. This is a full-time role and will report to the National Manager, Enterprise Business Solutions. The selected candidate will provide leadership to technical teams, guidance and mentoring SDLC and Application Portfolio Management, and build relationship with several internal business units and our dealer stakeholders.

What We’ll Bring

Company & Culture

A hybrid work environment
A work environment built on teamwork, flexibility and respect
Professional growth and development programs to help advance your career
A focus on respect for people and continuous improvement
Summer Hours – condensed work week during the summer

Benefits

Competitive compensation package including bonus
Extended health care and dental benefits effective immediately
Company pension plan with additional employer contributions
Company demo vehicle
Associate vehicle discount program
Reimbursement programs (tuition & fitness)
Paid holiday shutdown and competitive paid time off benefits
Sabbatical leave program

What You’ll Be Doing

Leadership

Lead a team of Analysts, Developers, Solution Architects, Development Lead, vendors, and partners, throughout the PMLC, SDLC, from requirement, design, and delivery, to support and on-going maintenance
Guide and develop competencies in Application Portfolio Management and Technology Roadmaps
Define and deliver IT capabilities and solutions across multiple platforms and technologies for the TCI enterprise and the TCI Dealer network
Lead Continuous Improvement initiatives towards excellence in service delivery
Set goals and objectives, provide feedback, coach for performance, develop technical, analytical, and interpersonal skills of the team and mature their knowledge of the business

Business Relationship Management

Act as a Business Relationship Manager for several TCI business units Network (8 to 12, in average), and the TCI Dealer network to deliver technology consulting in business terms, lead initiatives around process definition, budget planning, intake and prioritization of new enhancement, requests, and projects

Administration

Provide guidance and direction in vendor negotiation, RFP Vendor Selection, definition of SOW and KPI
Manage budgets, purchase orders, vendors, contracts, and daily departmental tasks
Manage resources, scheduling, performance, and provide support to your staff
Manage daily activities, issue resolution, and communication across project execution teams in order to deliver projects on-time, and on-budget

PMLS & SDLC & Technical Practices

Ensure projects do not diverge from approved and established architecture guidelines
Lead the following practices: DevSecOps, Adobe, Salesforce, and Software Development. Ensure SDLC best practices are followed, technical roadmaps are kept up to date and facilitate dissemination of knowledge across Enterprise Business Solutions
Manage teams of Application Managed Services (AMS) partners including contract renewals, performance metrics, and resource management

Collaboration

Built relationship and work collaboratively with other Toyota affiliates, peers from other IS functional areas, external vendors, and leaders across the organization

What You’ll Bring

University Degree in computer science or related discipline
Minimum of 7 years’ experience leading teams in large scale business systems implementations
Minimum of 5 years related work in a supervisory/managerial and business support role within IT environment
Experience in implementation and leadership on technical practices
Ability to lead, motivate and direct within a matrixed organization structure
Strong understanding of application architecture and how it interconnects with enterprise architecture strategy, middleware, and security standards
Experience in application development including DevSecOps and SDLC utilizing varied environments including Azure DevOps, MuleSoft, AWS (Ruby, Lambda, S3, Cognito) Java, SaaS, PaaS solutions running on multiple databases and integration across varying types of systems e.g., SAP, Salesforce, Adobe Experience Manager and Dealer Management Systems
Ability to organize several teams and focus on best practices, particularly regarding coding standards and quality assurance
Solid experience in the following areas: Project Management, Change Management, Release Management, Systems Development Life Cycle Methodologies, Quality Assurance and Testing, Requirements Gathering, and Systems Analysis and Design. Certifications related to PMP, ITIL, Agile, CMMI, and TOGAF will be considered asset
Proven ability facilitating negotiation of competing requirements among stakeholders
Understanding of organizational change management practices and how to bridge the gap between technology and the business
Ability to work with other teams, partners, and external organizations for the resolution of business or technical problems
Outstanding communication, organization, time management, presentation, problem-solving, interpersonal skills
Ability to demonstrate initiative, good judgment, and effective decision-making, exhibit strong process improvement orientation, and have the experience to lead discussions and achieve positive results amongst inter-disciplinary groups

About Us

Toyota Canada Inc. (TCI) is the exclusive Canadian distributor of Toyota and Lexus vehicles. Toyota Canada's head office is in Toronto, with regional offices in Vancouver, Calgary, Montreal and Halifax. Toyota parts and accessories are distributed through TCI's Parts Distribution Centres in Bowmanville and Vancouver. TCI supports over 287 Toyota and Lexus dealers in Canada with services that include training, sales, marketing, environmental and customer satisfaction initiatives.

What Sets Us Apart?

A focus on People, Passion for Toyota, Innovation and Make Things Better has made us an award-winning company, recognized worldwide for our technological leadership and superior standards of quality, community involvement and environmental responsibility.

What You Should Know

Our success begins and ends with our people. We embrace diverse perspectives and value unique human experiences. We are proud to be an equal opportunity employer that celebrates the diversity of the communities where we live and do business. Applicants for our positions are considered without regard to race, ethnicity, national origin, sex, sexual orientation, gender identity or expression, age, disability, religion, or any other characteristics protected by law. Please advise us at any point during the recruitment and selection process or your employment if you require accommodation.","{""role_summary"":""The Information Technology Manager – Consumer & Dealer leads technical teams, provides guidance on SDLC and Application Portfolio Management, and builds relationships with internal business units and dealer stakeholders."",""key_terms"":[{""term"":""SDLC"",""explanation"":""Software Development Life Cycle, a process used to design, develop, test, and deliver software products.""},{""term"":""Application Portfolio Management"",""explanation"":""A process of managing and maintaining a collection of applications to meet business needs.""},{""term"":""DevSecOps"",""explanation"":""A set of practices that combines software development, security, and operations to improve collaboration and automation.""},{""term"":""PMLC"",""explanation"":""Project Management Life Cycle, a framework for managing projects from initiation to closure.""},{""term"":""Technology Roadmaps"",""explanation"":""A plan outlining the technology strategy and direction for an organization.""}],""skill_priorities"":{""must_have"":[""Leadership experience in IT"",""Experience in application development"",""Knowledge of SDLC and Application Portfolio Management"",""Strong understanding of application architecture"",""Experience in project management""],""nice_to_have"":[""Certifications in PMP, ITIL, Agile, CMMI, or TOGAF"",""Experience with Azure DevOps, MuleSoft, AWS, Java, SaaS, PaaS solutions"",""Knowledge of Salesforce, Adobe Experience Manager, and Dealer Management Systems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with SDLC and how you ensure best practices are followed?"",""example_answer"":""I have led teams in implementing SDLC best practices, including Agile and Waterfall methodologies. I ensure that technical roadmaps are up-to-date and facilitate knowledge sharing across teams.""},{""question"":""How do you approach building relationships with internal business units and dealer stakeholders?"",""example_answer"":""I believe in regular communication, active listening, and understanding business needs. I have successfully built relationships with stakeholders by providing technology consulting and leading initiatives around process definition and budget planning.""}],""red_flags"":[""Lack of experience in leading technical teams"",""Inability to communicate technical information to non-technical stakeholders"",""Limited knowledge of application architecture and SDLC""],""confidence_score"":90.0}"
IT Service Desk Manager,"Description

Job Title: IT Service Desk Manager 
Job Type: Permanent, Fulltime 
Location: Sault Ste. Marie, Ontario 
Work Model: Hybrid  
Deadline for Submissions: July 19th, 2024
Position Summary 
As an IT Service Desk Manager in our Lotteries department, you will be accountable for the day-to-day operations of the IT Service Desk and Tier 2 support team, ensuring efficient incident management and asset tracking processes.  By delivering world-class IT support to North American electronic raffle and bingo customers, you will contribute to positive customer experiences, reduced downtime, and support charitable initiatives and community development. 
What We Can Offer You 
Compensation: We seek long term relationships with our employees and recognize and reward them with a competitive total compensation package that includes:  
An industry leading defined contribution pension plan with company matching contributions (up to 5%) and payment of service fees, 
Best-in-class health, medical and life insurance benefits;  
Access to virtual and telehealth services and apps; and  
Very progressive fertility, adoption and surrogacy benefits to support all definitions of family. 
Career: As a knowledge-based organization we will provide you with a wealth of learning opportunities and challenging work that will grow your knowledge, skills and abilities. At CBN, we encourage and empower our employees to chart their own career path, putting you in control of your future. 
Culture: Personal character is the foundation of our culture. CBN’s 7 Core Principles shape and guide our behaviors and underpin the sense of community you will experience at CBN. Equality, diversity and inclusivity are important to us as an organization, and we are committed to fostering and developing a work environment where every employee is treated with dignity and respect. 
What You Will Do 
Manage day-to-day operations of IT Service Desk and IT Operations support team; 
Review and update standard operating procedures (SOP) regularly; 
Continually monitor and improve customer service. 
Maintain up-to-date support documentation and training materials; 
Foster a positive work environment, set clear performance objectives, and provide training and feedback to team members; 
Manage staff schedule with equity and fairness;  
Produce Service Levels and KPI reports; and 
Various other duties and responsibilities. 
Qualifications 
Knowledge and Experience 
Bachelor’s degree in an IT related field or an equivalent combination of education and experience.   
5+ years of experience working in a fast paced/high-volume IT Service Desk or other IT support role in a management capacity 
Broad knowledge of ITIL processes and functions (ITIL certification is an asset). 
Deep experience in Incident Management and Asset Management.  
Understanding of Service Level Agreements   
Experience working in an Agile environment. 
Skills and Abilities 
Hard Skills (Working Knowledge) 
Software: MS 365 (Excel, Outlook, Teams, PowerPoint, SharePoint, Visio)  
ITSM/IVR: FreshDesk, FreshCaller (or equivalent ITSM products)  
O/S: Windows (Desktop, Server, Active Directory)  
Workflow Automation: Developing and testing workflows in FreshService. 
System Administration: Configuration and administration of ITSM and IVR. 
Presentation skills 
Soft Skills and Traits 
Leadership skills (conflict resolution, negotiation, decision and problem analysis) 
Mentoring and coaching skills 
Communication skills (verbal and written)  
Analytical/trouble shooting skills 
Organization/time management/prioritization skills.  
Customer focused 
Mandatory Requirements 
Ability to work outside of core hours and be on-call for incident escalation. 
Ability to travel domestically and internationally approximately 2-4 times per year. 
About Us 
CBN designs and develops industry leading solutions for the following domains: Border Security, Civil Identity, Driver Identification and Vehicle Information, Currency and Excise Control, and Lottery and Charitable Gaming. To learn more, visit www.cbnco.com. 
As an Equal Opportunity Employer, Canadian Bank Note Company, Limited is committed to achieving a skilled workforce that reflects the diversity of the Canadian population. We encourage applications from women, visible minorities, people with disabilities and Aboriginal people. Canadian Bank Note Company Limited is committed to developing inclusive, barrier-free selection processes and work environments. If contacted regarding this competition, please advise the interview coordinator of any accommodation measures you may require. ","{""role_summary"":""Manage the IT Service Desk and Tier 2 support team, ensuring efficient incident management and asset tracking processes, and delivering world-class IT support to customers."",""key_terms"":[{""term"":""ITIL"",""explanation"":""A set of best practices for IT service management, focusing on aligning IT services with business needs.""},{""term"":""Agile environment"",""explanation"":""A project management approach that emphasizes flexibility, collaboration, and rapid delivery in response to changing requirements.""},{""term"":""Service Level Agreements"",""explanation"":""Formal agreements between IT service providers and customers that define the expected service quality, availability, and responsiveness.""},{""term"":""ITSM/IVR"",""explanation"":""IT Service Management and Interactive Voice Response systems that enable efficient incident management and customer support.""}],""skill_priorities"":{""must_have"":[""ITIL knowledge"",""Experience in Incident Management and Asset Management"",""Leadership skills"",""Communication skills"",""Analytical/trouble shooting skills"",""Organization/time management/prioritization skills""],""nice_to_have"":[""ITIL certification"",""Experience working in an Agile environment"",""Presentation skills"",""Mentoring and coaching skills""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach improving customer service in an IT Service Desk environment?"",""example_answer"":""I would focus on streamlining incident management processes, implementing efficient workflows, and providing regular training to the support team to ensure they have the necessary skills to resolve customer issues effectively.""},{""question"":""Can you describe a time when you had to troubleshoot a complex technical issue in a fast-paced IT support environment?"",""example_answer"":""In my previous role, I encountered an issue with a critical system failure. I worked closely with the team to identify the root cause, developed a plan to resolve the issue, and implemented a solution that minimized downtime and ensured customer satisfaction.""}],""red_flags"":[""Lack of experience in IT Service Desk management"",""Inability to work outside of core hours or be on-call for incident escalation"",""Limited knowledge of ITIL processes and functions""],""confidence_score"":90.0}"
"Manager, IT Service Desk","Position: Manager, IT Service Desk

Department: Information Technology

Reports to: Director, Technology

Position Summary

The Aquilini Group (AG) encompasses a wide range of businesses, among them Canucks Sports & Entertainment (CSE). The Manager, IT Service Desk will lead the service desk team and play a crucial role in planning and coordinating the provision of user applications and systems essential for smooth business operations.

The Manager, IT Service Desk leads a service desk team that provides exceptional customer service for both AG and CSE on technical issues. The incumbent will be the subject matter expert regarding all end-user applications within the organization’s infrastructure, including technology training, software and hardware procurement, and spearheading customer-focused initiatives. This role works with a diverse group of important clients, visitors, and internal contacts at all levels; independent judgement is required to plan, prioritize, and organize a diverse workload.

This Role Will Focus On

Leading and managing the IT Service Desk team, fostering a culture of excellent customer service and high performance
Overseeing a team responsible for maintaining optimal functionality of user components, including computers, laptops, and mobile devices
Developing and implementing comprehensive IT training initiatives for new hires and ongoing staff development for AG and CSE employees
Acting as the initial point of escalation for unresolved calls, technical issues, and complex requests, providing effective resolutions and support
Proactively monitoring and managing the Help Desk ticket system queue, ensuring timely resolution of issues and efficient ticket handling
Collaborating in the procurement process of IT resources for various AG divisions
Coordinating event support scheduling, working with event managers to ensure seamless IT support during events
Providing expert first- and second-level support for computer hardware and software issues on both Microsoft and Apple platforms
Maintaining a comprehensive hardware and software inventory to facilitate efficient asset management
Providing support outside normal business hours, including events at Rogers Arena and at various offsite locations

We Have

A team you can belong to and believe in
A fun, high energy environment
An open mind for new ideas
The opportunity to embark on a career development journey
Lots of fun staff events throughout the year
Onsite gym underground parking

You Have

At least four years of experience within the Information Technology industry in a support capacity
A post-secondary degree or diploma in a technical field
Strong competence in the Microsoft Ecosystem (Office365, Exchange 2013/16, Remote Desktop, Server, and Desktop OS)
Strong knowledge of MacOS and iOS devices
Ability to thrive in a fast-paced, team-oriented environment
Strong attention to detail and organization skills, with the ability to balance priorities and multitask
Exceptional communication and customer service skills, with an ability to interact in a professional and friendly manner with end users at all levels within the organization
Solid problem-solving and troubleshooting skills coupled with a willingness to learn
A valid driver’s license and access to a vehicle
Ability to work flexible, extended hours
A strong understanding of and commitment to uphold our company values of discipline, respect, excellent, attitude, and mindset (DREAM)
Onsite role at our office in downtown Vancouver

You May Also Have

Previous experience with Point-of-Sale hardware and software

Vancouver is one of the most diverse cities in the world, and Canucks Sports & Entertainment strives to create a workforce that is inclusive, equitable and represents our beautiful, unique community. We value unique perspectives, ideas, and creativity that support a diverse, inclusive, respectful, collaborative, and fun work environment. Canucks Sports & Entertainment is committed to building and supporting a diverse team.

This position will remain open until filled.","{""role_summary"":""The Manager, IT Service Desk leads a team providing exceptional customer service for technical issues, planning and coordinating user applications and systems for smooth business operations."",""key_terms"":[{""term"":""IT Service Desk"",""explanation"":""A team responsible for providing technical support and resolving user issues.""},{""term"":""Microsoft Ecosystem"",""explanation"":""A suite of Microsoft products and services, including Office365, Exchange, Remote Desktop, Server, and Desktop OS.""},{""term"":""Point-of-Sale hardware and software"",""explanation"":""Systems used for processing transactions and managing sales operations.""}],""skill_priorities"":{""must_have"":[""At least four years of experience in IT support"",""Post-secondary degree or diploma in a technical field"",""Strong competence in Microsoft Ecosystem"",""Strong knowledge of MacOS and iOS devices"",""Exceptional communication and customer service skills""],""nice_to_have"":[""Previous experience with Point-of-Sale hardware and software""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach resolving a complex technical issue escalated to the IT Service Desk?"",""example_answer"":""I would first acknowledge the issue, then gather information to understand the root cause. Next, I would prioritize the issue based on its impact and work with the team to develop a solution, ensuring timely communication with the end-user.""},{""question"":""Can you describe a time when you had to balance multiple priorities and deadlines in a fast-paced IT support environment?"",""example_answer"":""In my previous role, I had to manage multiple tickets with varying levels of urgency. I prioritized tasks based on their impact and deadlines, ensuring timely resolution while maintaining open communication with end-users.""}],""red_flags"":[""Lack of experience in IT support"",""Inability to work flexible, extended hours"",""Poor communication and customer service skills""],""confidence_score"":90.0}"
IT Manager II,"Job Description

Position Overview

The IT Manager II is a hands-on management position responsible for the coordination of the IT Department function and IT infrastructure plans. The IT Manager II helps to manage a group of technicians, as well as IT vendors, and service providers. The IT Manager II is responsible for directing, planning organizing, implementing all IT activities required for effective and efficient information technology and information management to support TCR’s business objectives in all branches. The IT Manager II reports to the COO.

Please note this is an onsite position Monday to Friday.

Responsibilities

Salary shall be determined based on experience.

Manage and provide technical support and assistance to other business units
Maintain IT infrastructure
Maintain an efficient build-out of services and back-office equipment (for example: firewalls, phone systems, internal business needs including secure and effective data management)
Work effectively with outside vendors and consultants, as needed
Provide regular and pertinent reporting of IT activities.
Proactively seek out ways to improve value, response, security, availability and effectiveness of all aspects of the department
Organize, oversee and maintain projects and project objectives
Research and negotiate financial and business objectives where required
Onboard, develop, train and mentor IT staff
Develop and maintain documentation, process and procedures based on required industry certifications
Other duties and projects as mandated by TCR management.

Requirements

Able to work on site, Monday to Friday
University degree in Information Technology
5+ years of relevant work experience
Excellent oral and written communication skills
Excellent understanding of telephony/SIP
Knowledge of Genesis Pure Connect phone system
Knowledge of network architecture
Knowledge of SharePoint Windows/Exchange/Active Directory/FTP/SFTP and Telnet
Knowledge of NICE Platforms
Experience with ISO and SOC compliance
Experience with M365

Company Description

Total Credit Recovery (TCR) was founded by George Krieser with a notepad, phone, and an idea. Since 1980, TCR has remained 100% Canadian owned and provided stable employment from coast to coast while helping Canadians restore their credit.

We’re always looking to add to our team of work from home Debt Counsellors. We provide the computer, training, and a base hourly wage, and you provide the energy, passion, and your commission.

TCR works with some of the largest and most prestigious Canadian banks, credit grantors, and telecom and utility companies, and has exciting and profitable portfolios for Counsellors to work.

Total Credit Recovery Limited is proud to be an equal opportunity employer. We are committed to offering equal employment opportunities and fostering an inclusive, equitable and accessible environment. We welcome applications from persons representing the diversity of our community. Please notify us if you require accommodation at any time during the recruitment process.

For more on this and other employment opportunities at Total Credit Recovery Limited please visit our website: https://www.tcr.ca/en

Total Credit Recovery (TCR) was founded by George Krieser with a notepad, phone, and an idea. Since 1980, TCR has remained 100% Canadian owned and provided stable employment from coast to coast while helping Canadians restore their credit. We’re always looking to add to our team of work from home Debt Counsellors. We provide the computer, training, and a base hourly wage, and you provide the energy, passion, and your commission. TCR works with some of the largest and most prestigious Canadian banks, credit grantors, and telecom and utility companies, and has exciting and profitable portfolios for Counsellors to work. Total Credit Recovery Limited is proud to be an equal opportunity employer. We are committed to offering equal employment opportunities and fostering an inclusive, equitable and accessible environment. We welcome applications from persons representing the diversity of our community. Please notify us if you require accommodation at any time during the recruitment process. For more on this and other employment opportunities at Total Credit Recovery Limited please visit our website: https://www.tcr.ca/en","{""role_summary"":""The IT Manager II is responsible for managing the IT Department function and infrastructure plans, directing and planning IT activities to support business objectives, and overseeing a team of technicians and vendors."",""key_terms"":[{""term"":""IT infrastructure"",""explanation"":""The underlying systems and technology that support an organization's information technology operations.""},{""term"":""SIP"",""explanation"":""Session Initiation Protocol, a communication protocol used for voice and video calls over IP networks.""},{""term"":""Genesis Pure Connect"",""explanation"":""A phone system used for managing and directing phone calls within an organization.""},{""term"":""Network architecture"",""explanation"":""The design and structure of a computer network, including the relationships between devices, protocols, and services.""},{""term"":""SharePoint"",""explanation"":""A web-based collaborative platform used for document management, workflow, and team collaboration.""},{""term"":""Windows/Exchange/Active Directory/FTP/SFTP and Telnet"",""explanation"":""A suite of Microsoft products and protocols used for managing and securing access to computer resources and data.""},{""term"":""NICE Platforms"",""explanation"":""A suite of software solutions used for customer experience management, workforce optimization, and analytics.""},{""term"":""ISO and SOC compliance"",""explanation"":""International Organization for Standardization (ISO) and Service Organization Control (SOC) standards for information security and data protection.""},{""term"":""M365"",""explanation"":""Microsoft 365, a suite of cloud-based productivity and collaboration tools, including Office, Teams, and SharePoint.""}],""skill_priorities"":{""must_have"":[""University degree in Information Technology"",""5+ years of relevant work experience"",""Excellent oral and written communication skills"",""Knowledge of telephony/SIP"",""Knowledge of network architecture"",""Knowledge of SharePoint Windows/Exchange/Active Directory/FTP/SFTP and Telnet"",""Knowledge of NICE Platforms"",""Experience with ISO and SOC compliance"",""Experience with M365""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with IT infrastructure planning and management?"",""example_answer"":""I have managed IT infrastructure for a team of 10 technicians, ensuring 99.99% uptime and implementing cost-saving measures.""},{""question"":""How would you approach improving the security and effectiveness of our IT department?"",""example_answer"":""I would conduct a thorough risk assessment, identify areas for improvement, and implement a plan to address vulnerabilities and optimize our systems.""}],""red_flags"":[""Lack of experience with IT infrastructure planning and management"",""Inability to work on site, Monday to Friday""],""confidence_score"":90.0}"
"Manager, Application Support","Company Description

Canada Goose isn't like anything else. We've built something great, something special - an iconic lifestyle brand with an inspirational and authentic story. At the heart of it is our promise to inspire and enable all people to thrive in the world outside. To Live in the Open. At Canada Goose, you're part of a movement that belongs to something bigger. One that seeks out the restorative power of nature and is driven by a purpose to keep the planet cold and the people on it warm. We endure any condition, observe every detail, and are building a community that believes in living bravely and coming together to support game-changing people.

Here, opportunities are everywhere - to try something new, to learn, to do meaningful and impactful work, and they're yours for the taking.

Job Description

The Application Support Manager will oversee the resolution of incidents related to enterprise applications used throughout Canada Goose. The successful candidate will manage a team responsible for troubleshooting, resolving issues, and optimizing the performance of our ERP applications, with a focus on D365 Finance & Operations. They will be responsible for managing the end-to-end incident management process, ensuring timely resolution, minimizing business impact, and driving continuous improvement in our support services. This role requires strong leadership, technical expertise, and a commitment to delivering high-quality support to our internal stakeholders.

What You’ll Do:

Lead and mentor a team of Application support specialists, providing guidance, coaching, and performance feedback.
Foster a culture of collaboration, innovation, and continuous improvement within the support team.
Set clear objectives and priorities for the team, ensuring alignment with business goals and objectives.
Serve as the primary point of contact for all incidents related to all enterprise applications, including initial triage, assessment, and prioritization.
Coordinate the resolution efforts of cross-functional teams, including support specialists, developers, and business stakeholders.
Monitor the progress of incidents, escalate as necessary to ensure timely resolution, and communicate updates to stakeholders.
Conduct root cause analysis for major incidents and identify underlying issues contributing to recurring problems.
Develop and implement corrective actions and preventive measures to address identified problems and prevent future incidents.
Collaborate with technical teams to implement system changes or enhancements aimed at improving system stability and reliability.
Serve as the primary point of contact for application-related issues.
Communicate effectively with stakeholders to provide status updates and gather requirements.
Collaborate with other IT teams and departments to ensure cohesive support efforts.
Maintain accurate records of all incidents, including details of the incident, resolution activities, and any follow-up actions taken.
Analyze incident trends and performance metrics to identify opportunities for service improvement and optimization.
Prepare regular reports and presentations for management, highlighting key performance indicators and areas for improvement.
Manage relationships with software vendors and service providers.
Monitor vendor performance to ensure they meet contractual obligations.
Coordinate with vendors for application updates, patches, and technical support.
Drive a culture of continuous improvement within the incident management process, seeking opportunities to streamline workflows and enhance efficiency.
Collaborate with other teams to implement best practices and standards for incident management and service delivery.

Let's Talk About You:

A post-secondary education in Computer Science, Information Systems, or related field.
Minimum of 5 years of experience in IT incident management, with a focus on enterprise applications such as Microsoft Dynamics 365.
Strong technical knowledge of Dynamics 365 applications, including configuration, customization, and integration capabilities.
Proven leadership skills with the ability to inspire and motivate a team.
Excellent communication and stakeholder management skills, with the ability to coordinate and collaborate effectively across teams.
Experience working in an Agile Environment
Experience with compliance and governance frameworks (SOX preferred)
Industry certifications preferred such as: Microsoft Certified: Dynamics 365 Functional Consultant Associate (MB-300, MB-320, MB-330, MB-310)
Knowledge of the ITIL framework and related support processes
Experience supporting applications in a Discrete Manufacturing or Retail vertical
Strong organizational, writing, interpersonal and communication skills
Exceptional attention to detail and committed to a high degree of accuracy
A team player who builds strong relationships based on trust and integrity
Creativity and demonstrated ability working in a fast-paced environment with a high degree of change
Embraces continuous improvement by proposing new and/or better ways of doing things
Ability to work efficiently under pressure and effectively multi-task

Additional Information

What’s in it For You?

A company built on Canadian roots and heritage
Your work is recognized with a comprehensive and competitive Total Rewards Program
Opportunities for career growth through numerous internal and external programs
Recognize and be recognized by your peers with our Goose Rewards & ICON Rewards
Be a part of CG Gives. Donation matching and paid volunteer time to help the organizations you care about
Access to tools and resources to support physical and mental health, embracing change and connecting with colleagues
Inspiring leaders and colleagues who will lift you up and help you grow

We believe in the power of inclusion and are passionate about building and sustaining an inclusive and equitable working environment where all employees can bring their authentic selves to work everyday. We believe every one of our team members enriches our diversity by exposing us to varying ways to understand the world, identify challenges, and to discover, design, produce, and deliver great products and service. Our different perspectives are what enable us to create, dream and live in the open.

Canada Goose is an equal opportunity employer and is committed to providing employment accommodation in accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act.

There are multiple ways to interview with us! If you require any interview accommodation for your interview, please e-mail us at HR@canadagoose.com.","{""role_summary"":""The Application Support Manager oversees the resolution of incidents related to enterprise applications, managing a team to troubleshoot, resolve issues, and optimize performance, focusing on D365 Finance & Operations."",""key_terms"":[{""term"":""D365 Finance & Operations"",""explanation"":""A Microsoft Dynamics 365 module for financial and operational management.""},{""term"":""ERP"",""explanation"":""Enterprise Resource Planning, a type of software that manages business operations and resources.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management.""},{""term"":""Agile Environment"",""explanation"":""A project management approach that emphasizes flexibility, collaboration, and continuous improvement.""}],""skill_priorities"":{""must_have"":[""Minimum 5 years of experience in IT incident management"",""Strong technical knowledge of Dynamics 365 applications"",""Proven leadership skills"",""Excellent communication and stakeholder management skills""],""nice_to_have"":[""Industry certifications (Microsoft Certified: Dynamics 365 Functional Consultant Associate)"",""Experience with compliance and governance frameworks (SOX)"",""Knowledge of the ITIL framework and related support processes"",""Experience supporting applications in a Discrete Manufacturing or Retail vertical""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach incident management for a critical enterprise application?"",""example_answer"":""I would follow a structured approach, prioritizing incidents based on business impact, and collaborating with cross-functional teams to resolve issues efficiently. I would also conduct root cause analysis to identify underlying issues and implement corrective actions to prevent future incidents.""},{""question"":""Can you describe your experience with Dynamics 365 applications, including configuration, customization, and integration capabilities?"",""example_answer"":""I have worked with Dynamics 365 Finance & Operations, configuring and customizing the application to meet business requirements. I have also integrated it with other systems to ensure seamless data flow and optimized performance.""}],""red_flags"":[""Lack of experience with Dynamics 365 applications"",""Inability to demonstrate leadership and team management skills"",""Poor communication and stakeholder management skills""],""confidence_score"":90.0}"
"Technician, Information Technology - Lead","Primary Responsibilities

Works under the supervision of the corporate IT Manager – US Plants, but must utilize the resources of multiple IT personnel throughout the organization to accomplish objectives

Responsible to be a part of the North American IT Site Coordinators team and take ownership to ensure their plant is following all corporate IT technology guidelines

Continuously aware of the operating conditions of the networks. Monitors the operation of all communication related equipment and lines. Troubleshoots and take corrective action to maintain client access to the network

Maintains documentation on the type of IT technology equipment installed, its location, and specific routing of all cable servicing the equipment

Maintains knowledge of network and data communication concepts and related hardware. Uses this knowledge along with various types of test and diagnostic equipment to trouble shoot problems within the network. Works with the corporate IT network services group in setting up and configuring new LAN and wireless equipment

Works with numerous vendors and others in the trouble shooting and correcting of IT systems problems

Responsible for sending IT hardware to the proper service center for repair

Responds to user calls and tickets requesting IT systems and services help or reporting a problem. Identifies and solves the problem if possible but quickly seeks additional help if it is outside their expertise

Responsible for managing all PC and Network software in the plant. Orders, installs and maintains all PC office automation software using corporate IT guidelines. Maintains control and licensing of all Cooper Standard PC software utilized in the plant

Has a base knowledge of all plant business systems, including, but not limited to; Vanguard, Kronos, MP2, legacy plant MS-Access data bases, data reporting and software and data manipulation. Able to trouble shoot user problems and/or document situations on these systems for taking an issue further up in the IT organization

May, at times, due to the nature of duties performed, come in contact with confidential information. Is responsible for guarding against the disclosure of such information to unauthorized personnel

Due to the nature of the job, comes in contact with all levels of the company’s personnel as well as Cooper’s customers and vendors and must always reflect a courteous and professional attitude

Required to carry a cell phone after normal working hours (24/7) for response to critical IT business system problems preventing or hindering production processes

May, on occasion, be required to perform duties other than those specified in this description

Education And Qualifications

Bachelor’s degree in an IT or Business Administration related field and 1-3 years job experience required or Associates Degree with similar job experience and willing to complete a Bachelor’s degree as part of accepting this position

Knowledge of IT networking, PC’s, printers and telecom technology

Business process experience in a production environment is a plus

Strong Technical And Communication Skills Required

Must have strong interpersonal skills for dealing with all levels of salaried and hourly employees

Must have strong communications skills (written and verbal)

Must have a wide range of IT technical support knowledge in being able to quickly troubleshoot IT business system problems to get them back into production

Responsible for the continuous maintenance of the plant IT business systems infrastructure necessary for meeting our internal and customer driven business requirements. Must be able to react quickly and creatively in providing corrective actions to IT systems problems in meeting our customer requirements

Responsible for providing user support for IT business systems having the potential impact of causing production workflow disruptions in the event of making incorrect decisions or incorrect corrective actions

Reports directly to the corporate IT Manager – US Plants

Part of the corporate IT Site Coordinators team working with corporate IT resources and other plant IT resources in maintaining IT technology standards and seeking resources to correct IT business system problems

Commitment and ability to travel, as necessary","{""role_summary"":""The IT Site Coordinator is responsible for ensuring the plant's IT infrastructure is aligned with corporate technology guidelines, maintaining network and data communication systems, and providing technical support to users."",""key_terms"":[{""term"":""LAN"",""explanation"":""Local Area Network, a computer network that connects devices in a limited geographical area.""},{""term"":""Wireless equipment"",""explanation"":""Devices that allow for wireless communication and connectivity.""},{""term"":""Network services group"",""explanation"":""A team responsible for managing and maintaining an organization's network infrastructure.""},{""term"":""PC office automation software"",""explanation"":""Software used to automate and streamline office tasks and processes.""},{""term"":""Vanguard, Kronos, MP2, legacy plant MS-Access data bases"",""explanation"":""Specific business systems and software used in the plant.""}],""skill_priorities"":{""must_have"":[""IT networking knowledge"",""PC and printer knowledge"",""Telecom technology knowledge"",""Strong technical and communication skills"",""Interpersonal skills"",""Business process experience in a production environment""],""nice_to_have"":[""Experience with Vanguard, Kronos, MP2, and legacy plant MS-Access data bases""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you troubleshoot a network connectivity issue in a production environment?"",""example_answer"":""I would first identify the source of the issue, then use diagnostic tools to isolate the problem. If necessary, I would escalate the issue to the network services group for further assistance.""},{""question"":""How do you stay current with new IT technologies and trends?"",""example_answer"":""I regularly read industry publications, attend webinars, and participate in online forums to stay up-to-date on the latest developments in IT.""}],""red_flags"":[""Lack of experience with IT technology guidelines and standards"",""Inability to work independently with minimal supervision"",""Poor communication and interpersonal skills""],""confidence_score"":90.0}"
IT Technical Administrator,"Position Scope

The Technical Administrator’s role is to ensure proper computer operation so that end users can accomplish business tasks.

Responsibilities & Duties

Asset tagging and management
RF Handheld administration (Windows Mobile)
Mobile Device administration (All versions)
Administration and training
Printer and Toner Management
Document all pertinent end user identification information, including name, department, contact information, and nature of problem or issue through the Apollo Support Desk system
Prioritize and schedule problems. Escalate problems (when required) to the appropriately experienced Engineer.
Record, track, and document the help desk request problem-solving process through the help desk database
Apply diagnostic utilities to aid in troubleshooting.
Access software updates, drivers, knowledge bases, and frequently asked questions resources on the Internet to aid in problem resolution.
Identify and learn appropriate software and hardware used and supported by the organization.
Perform hands-on fixes at the desktop level, including installing and upgrading software, installing hardware, implementing file backups, and configuring systems and applications.
Performing preventative maintenance, including checking and cleaning of workstations, printers, and peripherals.
Test fixes to ensure problem has been adequately resolved.
Evaluate documented resolutions and analyze trends for ways to prevent future problems.
Develop help sheets and frequently asked questions lists for end users.
Weekly off site calls to various locations
Perform other duties as assigned

Job Specifications

KNOWLEDGE/EDUCATION/EXPERIENCE: 4-5 years’ experience required; post-secondary education required; Experience with Windows XP/7/8.1/10 desktop server operating systems required; Experience with MAC computers; Support experience with Microsoft Office 2010/2016

INTERPERSONAL SKILLS/CONTACTS: moderate access to confidential or sensitive information; regular internal interactions and/or occasional external interactions; purpose of internal/external contacts may occasionally related to complex matters; occasional selling, negotiating, consulting, teaching/instructing, or advising; above average level of written and verbal communication skills required for successful job performance

PROBLEM SOLVING/JUDGMENT: position is generally monitored and decisions usually follow prescribed guidelines; occasional analysis required; occasionally makes recommendations or referrals; responsible for solving simple to moderate problems

MENTAL EFFORT: requires moderate levels of concentration and/or attentiveness; moderate duration and/or intensity of efforts; requires moderate amounts of thinking, watching, listening, verifying, checking numbers, creating or designing

PHYSICAL EFFORT: occasional duration or intensity of physical effort; some moderate energy required in terms of standing, walking, lifting, keyboarding, pushing, pulling, sitting, packing, assembling, bending or twisting; includes moderate fine or coarse movements

MATERIAL RESOURCES: moderate level of consequence and costs associated with errors as related to losses of time, money, or property; moderate responsibility for machinery, work aids, equipment, materials, properties, products, stock, inventory or tools

INFORMATION RESOURCES: moderate level of consequence and costs associated with errors as related to losses of time, money or property; moderate responsibility for information and or services; some access to confidential, sensitive or proprietary information

PEOPLE/POLICIES/PRACTICES: no responsibility for people, policies or practices in terms of assigning work, development, evaluation, supervision, health and safety, performance, scheduling of work, training, coaching, or well-being; may occasionally demonstrate work practices to others

FINANCIAL RESOURCES: little responsibility for financial data, money or financial transactions, financial records, expenditures, acquisition, financial analysis or risk management; has limited to no opportunity to cause a negative impact to the organization or cause a serious consequence as a result of an error

ENVIRONMENT: works in an environment with little to no exposure to dirt, dust, grease, oil, or temperature extremes; occasionally may face multiple demands or distractions; has limited or no exposure to poor ventilation, noise, or verbal abuse

HAZARDS: limited or no exposure to chemicals, fumes or smoke; has little or unlikely potential of injury, harm, illness or infectious disease; has little to or limited exposure to machinery or equipment; does not require travel

“Apollo Health & Beauty Care Ltd. will ensure accommodations are available in consultation with candidates during all stages of the recruitment process”

The preceding job description has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. Duties outlined on this job description may not be all-inclusive, and can be modified at any time if requested by management. Apollo is committed to providing accommodations for people with disabilities in all parts of the hiring process. Apollo will work with applicants to meet accommodation needs that are made known in advance.

We thank all applicants for their interest however only those meeting the minimum qualifications will be interviewed.","{""role_summary"":""The Technical Administrator ensures proper computer operation, providing technical support to end-users, and performing administrative tasks to resolve issues and maintain systems."",""key_terms"":[{""term"":""RF Handheld administration"",""explanation"":""Managing and configuring handheld devices running on Windows Mobile operating system.""},{""term"":""Mobile Device administration"",""explanation"":""Managing and configuring mobile devices across various versions.""},{""term"":""Apollo Support Desk system"",""explanation"":""A help desk system used to document and track end-user issues and resolutions.""}],""skill_priorities"":{""must_have"":[""Experience with Windows XP/7/8.1/10 desktop server operating systems"",""Experience with MAC computers"",""Support experience with Microsoft Office 2010/2016""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you troubleshoot a printer issue in a Windows 10 environment?"",""example_answer"":""I would first check the printer settings and connections, then use diagnostic utilities to identify the issue. If necessary, I would escalate the problem to a senior engineer or access online resources for further assistance.""},{""question"":""What steps would you take to perform preventative maintenance on workstations and peripherals?"",""example_answer"":""I would regularly clean and inspect workstations, printers, and peripherals, update software and drivers, and implement file backups to prevent data loss.""}],""red_flags"":[""Lack of experience with Windows desktop server operating systems"",""Inability to work independently with moderate levels of concentration and attentiveness""],""confidence_score"":85.0}"
IT Administrator,"IT Administrator

Longbow Advantage is an end-to-end warehousing strategy company that leverages real-time data to manage people, processes, and warehouses through The Rebus® Platform, and WMS (Warehouse Management System) consulting services purpose-built to expand and enhance warehouse technologies.

We take a holistic approachto warehousing strategy, understanding that technology is only one piece in the solution process. Our warehouse experts work with customers to understand challenges and goals, developing a recommendation that is aligned to the customer’s business objectives and supply chain initiatives.

What to expect
Reporting to our IT Manager, the IT Administrator would be responsible for the design, implementation, monitoring, security, and maintenance of cloud and Co-location IT infrastructure, including cloud data center and networking space, virtual servers, storage infrastructure, networking components and routing.
You would also be responsible for helping in the provisioning of new equipment, as well as providing internal technical support to the different teams within Longbow.

This position is preferably based in Toronto (Mississauga) and is hybrid.

Once you join our team, you will…
Maintain and improve the Google Cloud Platform infrastructure and Co-Location infrastructure
Play a leading role in designing and implementing ongoing and future cloud infrastructure projects and Co-Location infrastructure
Build and implement software standards for servers, operating systems, and cloud environments
Leverage optimization techniques to maximize the efficiency of all computer systems
Work with third-party vendors and consultants on developing system-specific skills
Comply with policies and practices related to Longbow SOC2 compliance
Build and implement automated infrastructure management tools
Provision and maintain equipment for internal employees
Be responsible for the day-to-day maintenance and monitoring of all related cloud and Co-Location infrastructure to ensure availability, stability, and scalability
Provide internal technical support to Longbow’s teams and user tickets
Monitor and Troubleshoot mission critical systems on nights and weekends on a rotating schedule
Take proper action or escalating alerts as received
Skills & Experience
Bachelor’s degree in Computer Science or equivalent desired
Minimum 4 years of experience in Linux and Windows Environments, Networking Knowledge of Linux servers:
Knowledge of Linux command line
Knowledge of multiple Linux distributions an asset
Understanding of Linux security principles and best-practices
Bash scripting experience
Knowledge of Windows Servers and Workstations
Knowledge of Network security principles and firewalling
Knowledge of TCP/IP as well as network services such as HTTP(S), TLS, DNS, SSH, SFTP, and VPN protocols (OpenVPN, L2TP, IPsec, etc.)
Knowledge of LAN/WAN network architecture and security
Experience managing and maintaining Active Directory
Experience managing and maintaining VMWare platform
Experience managing and maintaining SQL Server, MySQL Databases
Experience troubleshooting and repairing hardware (Laptop, Server, SAN, NAS, ...)
Experience providing technical support and provisioning equipment to internal employees
Strong oral and written communication skills; ability to explain complex technical information to technical and non-technical contacts
Ability to work weekends and/or afterhours as required based on maintenance schedule, or high priority incidents
Ability to react quickly to unexpected issues in a time-sensitive and high-pressure environment and develop strong and effective solutions
Valid Driving license – may need to drive to Data Center from time to time
Nice To Have
Experience managing and maintaining Google Cloud Platform
Experience managing and maintaining Atlassian JIRA (Server & Cloud)
Experience working with Veeam Backup
Experience with Dell Server and Storages
Experience managing and maintaining Office 365 Admin Portal and platform
Why Join Longbow?
Supportive work environment
Work/life balance
Competitive Salary
4-weeks of paid vacation
6 paid sick days, 2 paid personal days per year
Excellent health and dental benefits, eligible as of your first day!
Group RRSP/401k Matching
Work from Home
Longbow Advantage is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.


We are not able to assist with relocation or work permit applications for this role.


All your information will be kept confidential according to EEO guidelines.","{""role_summary"":""The IT Administrator is responsible for designing, implementing, monitoring, securing, and maintaining cloud and Co-location IT infrastructure, as well as providing internal technical support to teams within Longbow Advantage."",""key_terms"":[{""term"":""Cloud Infrastructure"",""explanation"":""Refers to the virtualized computing resources and services provided over the internet, such as cloud data centers and virtual servers.""},{""term"":""Co-Location Infrastructure"",""explanation"":""Refers to the shared physical space and resources for housing computer servers and equipment, often used for data storage and networking.""},{""term"":""SOC2 Compliance"",""explanation"":""Refers to the auditing standard for service organizations, ensuring the secure management of data and systems.""},{""term"":""Linux Environments"",""explanation"":""Refers to operating systems based on the Linux kernel, used for servers, workstations, and other devices.""},{""term"":""VMWare Platform"",""explanation"":""Refers to a virtualization software that allows multiple virtual machines to run on a single physical machine.""}],""skill_priorities"":{""must_have"":[""Linux and Windows Environments"",""Networking Knowledge"",""Linux command line"",""TCP/IP"",""Network security principles"",""Active Directory"",""VMWare platform"",""SQL Server"",""MySQL Databases"",""Troubleshooting and repairing hardware""],""nice_to_have"":[""Google Cloud Platform"",""Atlassian JIRA"",""Veeam Backup"",""Dell Server and Storages"",""Office 365 Admin Portal""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with Linux command line, and how have you used it in previous roles?"",""example_answer"":""I have used Linux command line for scripting and automation tasks, and have experience with bash scripting. In my previous role, I used Linux command line to automate server deployments and configurations.""},{""question"":""How do you approach network security, and what principles do you follow?"",""example_answer"":""I follow best practices for network security, including implementing firewalls, configuring access controls, and regularly updating software and firmware. I also ensure compliance with industry standards and regulations.""}],""red_flags"":[""Lack of experience with Linux and Windows Environments"",""Inability to work weekends and/or afterhours as required"",""Limited knowledge of network security principles and best-practices""],""confidence_score"":90.0}"
Director of IT,"DIRECTOR OF IT The IT Development & Operations Director will lead and manage the IT department, responsible for Development, Operations, Security, and Compliance of the entire IT platform for a growing digital insurance brokerage company. The main objective is to create and execute an IT roadmap of projects to achieve the company's business plan (application and domain integration after multiple acquisitions and creating a future-proof technology stack for further profitable growth). This role involves building out more mature processes and teams for both the Agile development and Operations support areas of the IT department, as well as managing the ecosystem of vendors and partners that are part of the digital platform.

The IT Development & Operations Director requires experience in developing and building out application platforms (preferably in the insurance industry) with a good understanding of the AWS stack. You should know how to build cross-platform web applications and be familiar with security guidelines and frameworks for the web.

Key Accountabilities:

People Leader: Lead a multidisciplinary team of Business Analysts, Development, Quality Assurance, Data Engineers, and the IT Operations Manager.

Target Architecture: Maintain, develop, and ensure compliance of the IT and Data architecture in line with integration plans and company strategy. Ensure effective, secure, and available system architecture and consistent data storage and maintenance.

Development & Code Quality: Lead and manage web/external developers, BA, and QA teams. Support them in integrating and building out the capabilities of the company's digital brokerage platform and infrastructure. Develop a strategy to meet the company's goals and improve service quality. Assure the quality of the codebase, monitor it constantly, ensure the right third-party frameworks are used, and collaborate with the product owner on improving/refactoring the codebase.

Release Management & QA: Plan the release of project deliverables and oversee the release life cycle. Oversee the team establishing and enforcing quality standards for products and services. Build and release new features on the platform and work with the development team to deliver new features for each sprint as the company expands its products nationally.

Data Migration and Analytics capabilities: Align on data requirements needed to migrate insurance portfolios from another platform to a broker management system. Ensure the buildout of the data warehousing, data management, and mining capabilities of the organization.

Vendor management: Manage contacts and contracts with development partners. Ensure vendor delivery aligns with needs and contracts. Anticipate potential changes and maintain good relationships with partners.

Governance: Create and maintain a structure for IT governance, security, and control frameworks for the group of companies.



Qualifications and Competencies:

Proven experience in IT with at least a bachelor's degree, preferably with a specialization in IT.
At least 5 years' experience in a comparable role.
In-depth knowledge and experience of (AWS-based) IT-architecture solutions, including integration, security, and performance aspects.
Knowledge of and experience with insurance platforms such as Guidewire, Duck Creek, and Applied Systems.
Experience with the following Technology Stack:

o Angular,React,Vue,Java o Sitecore
o SQL,Postgres,MongoDB o Salesforce o Mulesoft
o AzureDataWarehouse o AWSEC2andLambda
Ability to translate business requirements into IT solutions that fit the target architecture and infrastructure setup.
Provide leadership, direction, and definition for the development and analytics teams and the IT Operations Manager, including planning, scheduling, test coordination, and implementation.
Manage risks and resolve issues affecting release scope, schedule, and quality.
Work with QA, Development, DevOps, and Product teams to ensure development projects adhere to release processes and change procedure guidelines.
Design, establish, and maintain a departmental structure to accomplish organizational goals and objectives effectively and efficiently.
Collaborate with decision-makers in other departments to identify, recommend, develop, implement, and support cost-effective technology solutions for all aspects of the organization.
Hands-on approach.
Ability to work independently and collaborate with various roles and disciplines within the organization.","{""role_summary"":""The Director of IT will lead and manage the IT department, responsible for developing and executing an IT roadmap to achieve the company's business plan, building out mature processes and teams, and managing vendors and partners."",""key_terms"":[{""term"":""Agile development"",""explanation"":""An iterative approach to project management that focuses on flexibility and continuous improvement.""},{""term"":""AWS stack"",""explanation"":""A collection of cloud computing services offered by Amazon Web Services, including EC2, Lambda, and more.""},{""term"":""Cross-platform web applications"",""explanation"":""Web applications that can run on multiple platforms, such as Windows, macOS, and Linux.""},{""term"":""Data warehousing"",""explanation"":""A system for storing and managing large amounts of data to support business intelligence and analytics.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""IT governance"",""explanation"":""A framework for managing IT resources and ensuring they align with business objectives.""},{""term"":""Mulesoft"",""explanation"":""An integration platform for connecting applications, data, and APIs.""},{""term"":""Sitecore"",""explanation"":""A web content management system for building and managing websites and digital experiences.""}],""skill_priorities"":{""must_have"":[""Experience in developing and building out application platforms"",""Knowledge of AWS stack"",""Ability to build cross-platform web applications"",""Experience with insurance platforms such as Guidewire, Duck Creek, and Applied Systems"",""In-depth knowledge of IT-architecture solutions, including integration, security, and performance aspects""],""nice_to_have"":[""Experience with Angular, React, Vue, Java, SQL, Postgres, MongoDB, Salesforce, Azure Data Warehouse, and Mulesoft"",""Knowledge of DevOps and Agile development methodologies""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach building a future-proof technology stack for a growing digital insurance brokerage company?"",""example_answer"":""I would start by assessing the company's current technology infrastructure and identifying areas for improvement. Then, I would develop a roadmap for implementing new technologies and processes that align with the company's business objectives. This would involve evaluating cloud-based solutions, such as AWS, and selecting the most suitable options for the company's needs.""},{""question"":""How do you ensure the quality of the codebase in a fast-paced development environment?"",""example_answer"":""I would implement a robust testing strategy that includes automated testing, code reviews, and continuous integration. I would also work closely with the development team to establish coding standards and best practices, and ensure that they have the necessary tools and resources to write high-quality code.""}],""red_flags"":[""Lack of experience in the insurance industry"",""Inability to manage and lead a multidisciplinary team"",""Limited knowledge of IT governance and security frameworks""],""confidence_score"":90.0}"
"Manager, IT Operations","As a recognized national business law firm, we support, grow, and impact our communities through our work. We help entrepreneurs, companies, and professionals shape and build the Canadian economy.

When you start a career with Miller Thomson, you join a firm that puts its people first. We provide the opportunity to influence the course of your career, community, and workplace with the support and backing of a national organization. While teamwork and collaboration are hallmarks of our culture, we accept and encourage individuality. You can expect a friendly, safe, and supportive environment where your colleagues will rally around to help you succeed.

Find the spark that will propel your career to new heights. Apply today to join a firm that is dedicated to you.

We are seeking a Manager, IT Operations to join our team.

Overseeing an integrated framework of infrastructure services, the Infrastructure and Operations team is responsible for the design, build and operate aspects of Network, Datacenter, Security solutions and services. Assisting the Director, Enterprise Solutions in the preparation and governance of infrastructure, lifecycle and operational standards and portfolio. Supporting the infrastructure team in all areas of infrastructure and operations. A subject matter expert in Infrastructure design and operations including data center, network, security and EUC. A liaison with core IT functional teams and a catalyst for information and communication transparency.

The Manager, IT Operations possesses proven expertise in systems and security technologies and concepts. The role requires proficiency in data center, network and security management and service delivery including, capacity, problem, incident, security and change management. As a subject matter expert in multiple domains, the candidate will participate or lead in projects, operations and service delivery activities. Those who aspire to work within an infrastructure and operations team, admire this role. Candidate must be willing to share information and teach aspiring staff. At this level, it is expected that the candidate has chosen this area as their career focus and have committed to professional development and achievement. Progression of responsibility and professional development can lead to opportunities in management, advanced network, datacenter and/or security.

Keys Responsibilities:

Infrastructure Support and Maintenance

Supporting the Director, Enterprise Solutions in the planning and coordination of the infrastructure portfolio life cycle. The infrastructure portfolio life cycle entails the planning, prioritization, development, maintenance (including break-fix), refreshes, and end-of-life decommissioning of the infrastructure portfolio, which includes data centers, servers, end-user computing devices, storage, telecommunication/networking and security;
Developing, facilitating and maintaining key operation standards, infrastructure technology standards, and infrastructure roadmaps, build and run documentation and knowledge transfer;
Supporting the Director, Enterprise Solutions and team to ensure infrastructures are designed/configured to meet business requirements; tested in accordance with the testing methodology; performed in accordance with operating requirements; deployed to meet service/operating requirements; maintained & operated in compliance to IT policies and procedures (including security policy).

Risk Assessment And Quality Assurance

Providing advice and recommendations to the Director, Enterprise Solutions on emerging infrastructure technologies and opportunities to improve performance/capacity of infrastructure and operations. Management of risk profiles pertaining to infrastructure technologies and operations; and providing recommendations to mitigate risks;
Assisting the Director, Enterprise Solutions to ensure timely delivery of work programs and conduct quality assurance/reviews of work program deliverables of the Infrastructure team & vendors.

Service

Supporting the Director, Enterprise Solutions and team to ensure day-to-day operation of IT services and their underlying applications and infrastructure. This includes server operations, monitoring, troubleshooting, user account management, security & access controls, messaging, file & print operations, database administration, storage operation, backup & recovery, data centre operations, etc.;
Providing expert advice and engaging in the resolution of complex infrastructure and operational issues in collaboration with stakeholders in IT, business practice groups, and vendors;
Ensuring the Infrastructure team adheres to standard IT and ITIL (Information Technology Infrastructure Library) practices, which include incident management, problem management, release management, change management, availability management, capacity management, etc.

Special Projects

Other duties as required. (This establishes the premise that the job’s essential duties are not all-inclusive, and other functions may be added dependent on the situation)

What you'll bring:

University degree or equivalent in Information Technology;
Minimum of five years of information technology experience, three years of which in a senior or lead infrastructure and/or operations role;
Possess a broad range of infrastructure and operation knowledge (server operations, monitoring, troubleshooting, user account management, security & access controls, messaging, file & print operations, database administration, storage operation, backup & recovery, data centre operations, etc.) and systems development life cycle experience in multiple technological platforms;
Experience and ability in exercising a lead role in the conceptualization, design, and implementation of infrastructure technology initiatives;
Possess practical ITIL experience; certification, an asset;
PMP certification, an asset;
Experience and ability in exercising a senior role in the analysis of business requirements, process and policy development/enforcement with a vision and strategy for continual improvement;
Directory Services (e.g. Microsoft AD, GPO, LDAP);
Cisco Intra/Internetworking;
Network Services (e.g. QoS, 802.1x, DNS, DHCP, SNMP, SMTP);
Network Security (e.g. Dell, Cisco ASA, ACS, SSL VPN, 2FA);
Network and Enterprise Storage;
Communications Network (e.g. VoIP, Jabber, Conferencing);
Wireless Infrastructure;
Virtualization;
RDBMS (e.g. MS SQL Server);
Internet Security Services (Web Gateway and Application layer firewalls);
Messaging Services (MS Exchange 2010/2013, Archiving, Gateway Security);
WAN Optimization;
Anti-malware Solutions (Client and server);
Backup and Replication.

What we offer:

We believe in the importance of a Total Compensation package, ensuring our mix of salary, benefits, and perks are competitive within the market as well as a work-life balance. We offer:

A comprehensive Benefits package that includes Health, Dental and Vision Care, Employee Assistance Program, Life Insurance, Short Term and Long Term Disability Insurance, 3+ Weeks’ Vacation and 10 Personal Days;
A Diverse and Inclusive Workplace;
Flexible working options;
Maternity Leave Top-up;
A Firm matching Group Retirement Savings plan;
An individual TFSA with low fund management fees and competitive investment options;
Employee Assistance Program to support you and your family;
A wellness spending account to foster employee well-being;
Professional Development opportunities;
Employee appreciation events;
Charitable giving programs.

Who we are:

Miller Thomson LLP is one of Canada’s fastest-growing national business law firms, with ten offices across the country. Our consistent ability to provide practical, creative and cost-effective advice, combined with an unyielding service commitment to our clients and a strong dedication to our lawyers, staff and the communities in which we practice, gives us a unique position in the Canadian legal industry.

Miller Thomson LLP is an equal-opportunity employer and is committed to equity, diversity, inclusion, and accessibility.

While we thank all applicants for their interest, due to the high volume of applications we receive, we are unable to respond to queries individually, and only those selected for an interview will be contacted. No phone calls or agencies, please.

Miller Thomson will provide accommodation on request throughout the recruitment, selection and assessment process for applicants with disabilities. If you require accommodation, please inform our Talent department of the nature of the accommodation that you may require, to ensure your equal participation.

We respect the privacy and confidentiality of personal information provided by or on behalf of those who apply for a position with us.

By submitting your personal information on this platform, you freely consent to the collection, use, and disclosure of that information in connection with our application process. By applying you further understand and accept that there is the possibility of your information being transmitted and stored in another province.

You may decide to withdraw your consent to the collection, use, and disclosure of your personal information at any time by notifying us at talentacquisition@millerthomson.com or herein.","{""role_summary"":""The Manager, IT Operations is responsible for overseeing the infrastructure and operations team, ensuring the design, build, and operation of network, data center, security solutions, and services. The role requires expertise in systems and security technologies, data center, network, and security management, and service delivery."",""key_terms"":[{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of practices for IT service management""},{""term"":""EUC"",""explanation"":""End-User Computing, refers to the computing resources and services provided to end-users""},{""term"":""PMP"",""explanation"":""Project Management Professional, a certification for project managers""}],""skill_priorities"":{""must_have"":[""University degree or equivalent in Information Technology"",""Minimum of five years of information technology experience"",""Three years of experience in a senior or lead infrastructure and/or operations role"",""Broad range of infrastructure and operation knowledge"",""Practical ITIL experience""],""nice_to_have"":[""PMP certification"",""Directory Services experience"",""Cisco Intra/Internetworking experience"",""Network Services experience"",""Network Security experience""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with ITIL, and how have you applied it in your previous roles?"",""example_answer"":""I have worked with ITIL for the past three years, and I have implemented incident management, problem management, and change management processes in my previous role.""},{""question"":""How do you stay current with emerging infrastructure technologies and trends?"",""example_answer"":""I regularly attend industry conferences, read trade publications, and participate in online forums to stay current with emerging infrastructure technologies and trends.""}],""red_flags"":[""Lack of experience with ITIL"",""Limited knowledge of infrastructure and operations"",""No experience with data center, network, and security management""],""confidence_score"":90.0}"
IT Help Desk Administrator,"Designated Office

Young Tower

6080 Young Street

This Position Is

Hybrid, at least 3 days per week in office

Eastlink is a family owned, entrepreneurial and innovative company headquartered in Halifax, Nova Scotia. We take great pride in being a leader in delivering creative competitive, customer focused telecommunications solutions, and connecting our customers to the things and people that matter most. Serving a customer base across seven provinces, our advanced solutions include Internet, Mobile, TV, Telephone, Security and Automation, Data Communications, and exclusive locally produced programming on Eastlink Community TV.

We embrace diversity, inclusion, equity, and accessibility throughout all levels of the organization and encourage members of equity groups to self-identify during the application process.

The IT Helpdesk Administrator will be a key member of the Information Technology team. Reporting to the Manager of Desktop Support, the IT Helpdesk Administrator will act as the central point of contact for our Internal IT Support Helpdesk, performing Tier 1 support of mobile and desktop computing technologies, trouble ticket creation and assignment. The customers that the IT helpdesk Administrator will support are all Eastlink employees and Contractors hired by Eastlink to perform tasks on Eastlink’s behalf. This position is a hybrid role which will allow working from home and our office location at 6080 Young St, Halifax, NS

Responsibilities

Specific responsibilities will include, but are not limited to the following:

Respond to telephone calls, email, and personnel requests for technical support from our internal Eastlink employee.
Perform high level problem determination, information gathering by asking probing questions and triaging calls to assess the urgency and impact to the employee or business.
Install applications and drivers, password resets, as well as fix minor issues.
Trouble ticket creation & assignment to our IT Operations team


The successful candidate will be customer focused, have exceptional leadership, communication and troubleshooting ability, and thrives in a fast paced, dynamic work environment.

Qualifications

The IT Helpdesk Administrator should have completed or be in the process of completing a related technical diploma, university degree or equivalent program.
Strong customer service skills, with the ability to make the customer their priority, determine their needs, and set realistic expectations. Previous experience in a customer service focused role with be an asset.
Solid written and verbal communication skills
Able to work effectively in a busy, interrupt driven environment, while maintaining a friendly and professional manner
A good sense of responsibility and commitment
Takes pride in their work, with the goal of producing error free work the majority of the time
Interest and ability to look for new and innovative ways of improving efficiency
Strong interest in and demonstrated aptitude for troubleshooting PC hardware and software related problems with the ability to learn new skills quickly.
Able to stay highly organized with their work area, equipment, and assigned tasks.
Has a good sense of integrity and treats others with respect.
Ability to work overtime as required.


Why Choose Eastlink?

Eastlink operates in a culture of continuous improvement through listening, learning and adapting, which enables us to respond quickly to the evolving needs of both employees and customers. We recognize that our truly greatest competitive edge is our people and that delivering a great customer experience begins with a great employee experience. Our philosophy of developing and training our team “on the ground” not only helps to create a strong onboarding experience but also readies employees for future growth opportunities within the organization.

We are extremely proud of our employees and believe the best people make the best companies. As we continue to grow, our goal is to continue to attract the best people.

Ready to explore an exciting career at Eastlink? Your journey begins here.

Apply Now","{""role_summary"":""The IT Helpdesk Administrator provides technical support to internal Eastlink employees and contractors, resolving IT issues and ensuring efficient operations."",""key_terms"":[{""term"":""Tier 1 support"",""explanation"":""Basic technical support provided to customers, typically involving troubleshooting and resolving simple issues.""},{""term"":""Trouble ticket creation"",""explanation"":""The process of documenting and tracking technical issues reported by customers, allowing for efficient assignment and resolution.""}],""skill_priorities"":{""must_have"":[""Customer service skills"",""Troubleshooting ability"",""Communication skills"",""Technical diploma or university degree""],""nice_to_have"":[""Previous experience in a customer service focused role"",""Ability to work overtime""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to troubleshoot a technical issue with a customer?"",""example_answer"":""In my previous role, a customer reported an issue with their computer. I asked probing questions to determine the root cause, and then walked them through a series of steps to resolve the issue. The customer was satisfied, and I was able to document the solution for future reference.""},{""question"":""How do you prioritize tasks in a fast-paced, dynamic work environment?"",""example_answer"":""I use a task list to stay organized, and focus on resolving the most urgent issues first. I also communicate proactively with customers to set realistic expectations and ensure they are informed throughout the resolution process.""}],""red_flags"":[""Lack of technical aptitude or experience"",""Poor communication or customer service skills""],""confidence_score"":90.0}"
Information Technology Manager -18921,"The Information Technology Managers responsibly is to oversee, coordinate, and manage the information systems, data, and infrastructure both on and offsite.

Role Overview

The Manager of Information Technology role ensures the effective and efficient implementation, maintenance, and support of cross-organization technology systems and projects, including optimizing the technical infrastructure. They will coordinate information activities with other departments and directly advise the Executive leadership team on the implications of proposed actions and decisions taken by the IT and Security Departments.

Key Responsibilities

Create and maintain a preventive maintenance schedule for equipment and facilities.
Project Management
Train new hires and other team members.
Lead the process to oversee the IT requirements and guide the team to adhere to required company standards.
Prepare documentation of the inspection process, which includes detailed reports and performance records.
Coordinate with vendors to schedule IT visits and ensure timely completion of outsourced tasks.
Ensure accurate documentation of work order details, including scope, time estimates, and materials required.
Monitor work order progress and update stakeholders on the status of ongoing IT tasks.
Review completed IT work orders/invoices for accuracy, completeness, and quality of work.
Assist with the identification and evaluation of potential vendors for IT services and assist with the negotiation of contracts.
Actively search for and recommend improvements to the system and processes.
Perform other duties as assigned or needed.
Utilize CMMS system and other required software and applications, review, enter, schedule based on priority, and track work orders for IT requests.
Schedule maintenance tasks and allocate appropriate resources to complete them.

Qualifications:

Bachelors degree in computer science, Information Technology, or a related field (Master's degree preferred).
Project Management experience an asset
Excellent communication and interpersonal skills
Proficiency in using IT Service Management Systems (ITSM).
Ability to prioritize tasks and manage multiple projects simultaneously.
Clear criminal record is required.
Proficient in an array of software, including, SAP and other ERP/MRP systems, SQL, Application Programming Interface (API), Microsoft office programs (MSSE would be an asset), Power BI, etc.
Customer service experience required.
Strong organizational and time management skills.
Knowledge of IT best practices and security, privacy, and confidentiality standards.
Strong leadership and team management skills, with the ability to inspire and motivate a diverse team.
In-depth knowledge of IT infrastructure, networking, cybersecurity, and cloud technologies.
Experience in developing and implementing IT strategies aligned with business objectives.
Strong problem-solving and decision-making abilities, with a focus on innovation and continuous improvement.
Knowledge of ITIL (Information Technology Infrastructure Library) and other industry frameworks.

What You Will Receive:

Annual salary range: $110,000-$120,000
Paid annual vacation
Extended medical benefits

Only candidates already eligible to work in Canada will be reviewed. Only qualified candidates will be contacted.","{""role_summary"":""The Information Technology Manager oversees and manages information systems, data, and infrastructure, ensuring effective and efficient implementation, maintenance, and support of technology systems and projects."",""key_terms"":[{""term"":""IT Service Management Systems (ITSM)"",""explanation"":""Software used to manage IT services, including incident, problem, and change management.""},{""term"":""ERP/MRP systems"",""explanation"":""Enterprise Resource Planning and Manufacturing Resource Planning systems used to manage business operations.""},{""term"":""SQL"",""explanation"":""Structured Query Language used for managing and manipulating data in relational database management systems.""},{""term"":""API"",""explanation"":""Application Programming Interface used for building software applications and integrating with other systems.""},{""term"":""ITIL (Information Technology Infrastructure Library)"",""explanation"":""A framework for IT service management that provides best practices for delivering high-quality IT services.""},{""term"":""Cloud technologies"",""explanation"":""On-demand computing resources and services provided over the internet, allowing for scalability and flexibility.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in computer science, Information Technology, or a related field"",""Proficiency in using IT Service Management Systems (ITSM)"",""Excellent communication and interpersonal skills"",""Ability to prioritize tasks and manage multiple projects simultaneously"",""Strong organizational and time management skills"",""Knowledge of IT best practices and security, privacy, and confidentiality standards"",""In-depth knowledge of IT infrastructure, networking, cybersecurity, and cloud technologies""],""nice_to_have"":[""Master's degree"",""Project Management experience"",""MSSE"",""Experience in developing and implementing IT strategies aligned with business objectives""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure the effective and efficient implementation of technology systems and projects?"",""example_answer"":""I prioritize tasks, manage multiple projects simultaneously, and utilize IT Service Management Systems to ensure effective implementation and maintenance of technology systems and projects.""},{""question"":""How do you stay current with the latest developments in IT infrastructure, networking, cybersecurity, and cloud technologies?"",""example_answer"":""I engage in continuous learning, attend industry conferences, and participate in online forums to stay current with the latest developments in IT infrastructure, networking, cybersecurity, and cloud technologies.""}],""red_flags"":[""Lack of experience in IT service management"",""Inability to prioritize tasks and manage multiple projects simultaneously"",""Limited knowledge of IT best practices and security, privacy, and confidentiality standards""],""confidence_score"":90.0}"
"Manager, IT Client Services - (01074.13)","Summary:

The Manager of IT Client Services holds a pivotal role in ensuring the efficient and effective delivery of IT services to the university support and timely resolution of IT-related issues. Additionally, the manager fosters a culture of customer-centric support within the IT department and ensures team readiness for agile service delivery in a rapidly evolving digital environment.

Major Responsibilities:

Provides leadership, direction, and guidance to the Client Services team
Oversees recruitment, selection and deployment, training, development and review of staff performance.
Establishes clear performance objectives and expectations by conducting regular evaluations and providing feedback
Ensures compliance with occupational health and safety standards.
Fosters a collaborative and inclusive work environment, promoting teamwork and professional development opportunities
Manages day-to-day operations of Client Services Teams to ensure timely and effective response to IT support requests
Develops and implements Service Level Agreements (SLAs) and standard operating procedures for consistency and quality in service delivery
Monitors metrics and key performance indicators to identify trends, areas for improvement and opportunities for enhanced service delivery
Administers the TRU Technology Leasing by collaborating with IT Asset administration to review equipment specifications and coordinate with external contractors. Program
Co-ordinates the development of university-wide IT support policies, standards and procedures
Undertakes projects involving supplier selection and evaluation of IT equipment and services
Organizes and co-ordinates technology education and awareness training programs within the University
Monitors software licenses, maintenance, and support arrangements for University Site Licensed Software
Oversees the change management processes for systems and services
Initiates client surveys and other procedures to measure service quality;
Co-ordinates critical incident activities by coordinating between Client Services and other relevant stakeholders to resolve the issues
Serves as an escalation point for complex or high-priority IT support issues, collaborating with technical specialists and other IT teams for resolution
Oversees IT Service Management system
Coordinates the Active Directory Integration within Client Services
Builds and maintains strong relationships with University Stakeholders, including faculty, staff, students, and academic departments
Acts as a liaison between the IT department and campus community, soliciting feedback, addressing concerns, and advocating for user needs.
Communicates IT Service updates, initiatives, and best practices to stakeholders through various channels and committees
Manages departmental resources effectively, including staffing levels, equipment and budget allocations
Identifies opportunities for cost optimization and efficiency improvements, prioritizing investments to enhance service quality and user experience

Qualifications:

Bachelor's Degree with at least 5 years of relevant experience
Certifications in ITIL and/or project service management (PMP) are considered an asset
Strong technical background with expertise in IT support methodologies, tools and best practices
Excellent communication and interpersonal skills, with the ability to interact effectively with diverse stakeholders
Working knowledge of relevant programs such as Microsoft Intune/Azure

Pay Band:
$96,263.00 - $108,131.00

Location: Kamloops, BC

Diversity and Inclusion Commitment:
Thompson Rivers University is strongly committed to hiring based on merit with a focus on fostering diversity of thought within our community. We welcome those who would contribute to the further diversification of our staff, our faculty and its scholarship including, but not limited to, women, Indigenous, Black and People of Colour, persons with disabilities and persons of any sexual orientation or gender identity. Please note that all qualified candidates are encouraged to apply, however applications from Canadians and permanent residents will be given priority.","{""role_summary"":""The Manager of IT Client Services leads a team to deliver efficient and effective IT services, ensuring timely resolution of IT issues and fostering a customer-centric culture within the IT department."",""key_terms"":[{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management.""},{""term"":""PMP"",""explanation"":""Project Management Professional, a certification for project management expertise.""},{""term"":""Microsoft Intune/Azure"",""explanation"":""Cloud-based IT management and security solutions for managing devices and applications.""},{""term"":""Service Level Agreements (SLAs)"",""explanation"":""Formal agreements between IT service providers and customers that define service quality and responsiveness.""},{""term"":""TRU Technology Leasing"",""explanation"":""A program for managing technology equipment and services within the university.""}],""skill_priorities"":{""must_have"":[""Strong technical background in IT support methodologies, tools, and best practices"",""Excellent communication and interpersonal skills"",""Ability to interact effectively with diverse stakeholders""],""nice_to_have"":[""Certifications in ITIL and/or project service management (PMP)"",""Working knowledge of Microsoft Intune/Azure""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you ensure timely and effective response to IT support requests?"",""example_answer"":""I would establish clear performance objectives, monitor metrics and key performance indicators, and foster a collaborative and inclusive work environment to ensure team readiness for agile service delivery.""},{""question"":""How do you stay current with emerging trends and best practices in IT service management?"",""example_answer"":""I engage in ongoing professional development, participate in industry forums, and collaborate with peers to stay informed about the latest developments in IT service management.""}],""red_flags"":[""Lack of experience in IT service management"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
"IT Consultant - Kelowna, British Columbia","Job Description

Job Title: IT Consultant

Job Location: Remote: Kelowna, British Columbia

Company Profile

IX Solutions is Western Canada’s go-to boutique IT firm, sought after by leading tech talent and forward-thinking organizations for their innovative approach, trusted team, award-winning service and standout company culture.

We act as a trusted advisor to forward-thinking organizations and their IT teams, empowering them to fulfill their potential through innovative solutions and technology that solves business problems. We help our clients effectively leverage modern technology and embrace digital transformation to achieve their critical business outcomes.

Ultimately, we’re here to inspire innovation — for our customers and our people. For us, that means inviting ambitious individuals to the table — those who are primed to push the envelope — and fostering an imaginative environment for them to thrive. Why? Because we believe when you bring visionaries together with a genuine drive to do better and give them transformative technology as the toolkit, the possibilities and potential for your business become boundless.

For us, success is measured in the lasting relationships we build with our clients. We go the extra mile to deliver a positive customer experience and trusted solutions that are flexible to meet their needs. Founded in 2018, our company supports clients across Western Canada from remote offices in Calgary, Edmonton, Vancouver, and the BC Interior.

Position Summary

This role is intended for a dynamic individual excited about the opportunity to use technology to help drive customer success while building a successful business with a collaborative and customer-centric culture.

The role is responsible for providing general IT consultancy services to managed clients on a proactive and reactive basis. The person in this role will be required to deliver remote and on-site IT support while developing and maintaining strong and lasting client relationships.

The IT Consultant collaborates with client stakeholders, other technical consultants, and Account Executives to design and document proposed technical solutions that accurately address and align with the client’s business requirements. This role includes acting in a mentorship and escalation capacity for less-senior consultants.

The position reports to the Manager, Service Delivery. The position works 40 hours per week, with business hours being 7:00am to 5:00pm PST, Monday to Friday. There is a requirement for after-hours work including scheduled afterhours support rotation, time sensitive client requests and project work. Balancing multiple priorities with deadlines is a requirement.

IX Solutions is committed to helping employees grow and develop within the organization, so the responsibilities below may be adjusted periodically to align with employee goals or aptitudes while supporting overall business objectives.

Is This Position a Fit For You?

This position is a fit for you if you

Are an IT generalist with multiple areas of technical depth including Microsoft Azure
Are looking for mentorship and opportunity to grow. This is the place for you
Understand technology and are skilled at translating business requirements from clients into technical requirements
Are skilled at building rapport and enjoy supporting partnerships
Are committed to client success

What You’ll Do Here

Deliver IT support, and technical delivery services to a broad range of clients
Implement and manage technology solutions built on Microsoft Azure cloud services
Implement and maintain Microsoft 365 office productivity and security solutions
Implement and maintain Hyper-V and VMware virtualization solutions
Deploy and maintain server, storage, and backup solutions
Install, configure, troubleshoot, support, and optimize Microsoft Windows Server environments
Implement and maintain network and network security solutions
Triage issues based on criticality, escalating per our escalation procedure and Service Level Objectives
Provide technical support and escalation response to end-users and client IT staff
Complete recurring managed services tasks within multiple client environments, documenting work within our time management system
Participate in scheduled 24/7 afterhours support, monitoring email and providing phone support
Work with the Technical Director to plan and deploy improvements for managed services
Create accurate and effective documentation, and assist with developing processes and repeatable technical practices
Assist with projects from initial assessment, through planning, design, and implementation
Develop, define, or improve solution offerings for customers using new and emerging technologies
Assist account executive and clientele in defining technical requirements and solutions
Create accurate and effective documentation, assisting with best practices development

Qualifications/Expertise

Minimum 5 years of IT Consulting experience
Working knowledge of Azure Active Directory and synchronization mechanisms
Microsoft Endpoint Configuration Manager experience is an asset
Experience with deployment, management, and maintenance of Microsoft Server environments
Experience with deployment, management, and maintenance of Active Directory environments
Experience with deployment, management, and maintenance of server, storage and virtualization infrastructure solutions
Working knowledge of basic networking concepts and ability to troubleshoot networking issues
Continuing education and training a must
Certifications Achieved (or willing to work towards):
Microsoft 365 Certified: Endpoint Administrator Associate (MD-102)
Microsoft 365 Certified: Administrator Expert (MS-102)
Microsoft Azure Administrator (AZ-104) or equivalent experience
Microsoft 365 Teams Administrator Associate (MS-700) or equivalent experience
Ability to distill complex software concepts into benefits that both customers and salespeople can understand

Accountabilities, Tasks and Duties

Client Relationships

Understand and interpret customer needs to provide excellent service levels
Develop strong and lasting customer relationships with key clients
Pass certification exams and complete training as appropriate to demonstrate skillset to clients and foster strong vendor relationships

Team

Communicate in an open, helpful manner and build relationships across the organization
Ability to work with a range of technical staff and cross-functional teams to develop joint solutions
Foster a collaborative work environment and culture
Challenge the status quo
Take personal accountability and provide end to end ownership of a solution or obstacle
Be willing to put in the effort when it really counts
Create accurate and effective documentation and develop standards
Engage with team and demonstrate commitment to alignment with the organizational mission and corporate values
Other duties as required, such as the timely completion of expense reports and timesheets
Ability to travel occasionally for business purposes

Requirements

Must be legally permitted to work in Canada
Hold a valid Driver’s License and vehicle
Proficient business English (written/verbal) communication

Compensation

The position is a full time, salaried position. Compensation is expected to be between $60,000 - $100,000 commensurate with experience, and abilities.

IX Solutions is pleased to offer remote work opportunities for our employees, however we do require employees to reside in Alberta or British Columbia, Canada.

Powered by JazzHR

FTqJbyiVmq","{""role_summary"":""The IT Consultant provides general IT consultancy services to managed clients, delivering remote and on-site IT support, and developing strong client relationships. They collaborate with stakeholders to design and document technical solutions, and act as a mentor for less-senior consultants."",""key_terms"":[{""term"":""Microsoft Azure"",""explanation"":""A cloud computing platform used for building, deploying, and managing applications and services.""},{""term"":""Hyper-V"",""explanation"":""A virtualization platform used for creating and managing virtual machines.""},{""term"":""VMware"",""explanation"":""A virtualization platform used for creating and managing virtual machines.""},{""term"":""Microsoft 365"",""explanation"":""A suite of productivity and security solutions used for office applications and security.""}],""skill_priorities"":{""must_have"":[""IT consulting experience"",""Microsoft Azure knowledge"",""Microsoft 365 knowledge"",""Networking concepts"",""Virtualization infrastructure experience""],""nice_to_have"":[""Microsoft Endpoint Configuration Manager experience"",""Certifications in Microsoft 365 and Azure""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would troubleshoot a networking issue in a Microsoft Azure environment?"",""example_answer"":""I would first identify the symptoms of the issue, then use Azure's built-in troubleshooting tools to identify the root cause. I would also review the network configuration and ensure that all components are properly configured.""},{""question"":""How do you stay current with new and emerging technologies in the IT industry?"",""example_answer"":""I regularly read industry publications and attend webinars to stay up-to-date on the latest developments. I also participate in online forums and discussion groups to learn from others in the field.""}],""red_flags"":[""Lack of experience with Microsoft Azure and Microsoft 365"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
IT Team Lead,"Job Description

Cloud9 Solutions is a rapidly growing Managed Services Provider that offers a broad range of IT Consulting, Managed IT, and Cloud services for organizations looking to source and implement IT solutions and IT services in their businesses or in the cloud.

At Cloud9 Solutions, our mission is to provide our clients with solutions that help them address the technology challenges in meeting their business objectives. In addition to a vast range of Private Cloud, Hybrid Cloud and Public Cloud offerings customized to suit any business, big or small, we offer a range of solutions for Connectivity, Unified Communications, and VoIP. This positions Cloud9 Solutions as your true one-stop-shop for any business's IT and Communications needs.

About the job:

We are looking for a highly motivated, hands-on, experienced IT Team Lead to join our business. The candidate will collaborate with all levels of technical resources as well as the leadership team and oversee the company's service delivery to its existing and new clients. This role will also be the base of our new client onboardings, from creating the project to assigning the tasks and resources to the follow-up process to ensure they are completed on schedule.

Job Duties:

Oversee the service delivery to our clients
Ensure client tickets and calls are getting addressed in a timely fashion
Be well versed in the ITIL foundation and ensure these best practices are being followed
Meet with clients to discuss system requirements, specifications, costs and timelines
Lead a team of technicians and allocate resources to facilitate escalations
Work with client contacts and team resources to schedule task
Supervise, hire, train and provide direction for Tier1 and Tier2 staff
Work side by side with the leadership team to implement policies and procedures
Work with shipping/receiving staff to organize hardware setup and delivery
Oversee projects for our client's onboarding and offboarding
Perform other duties and special projects as assigned

Skills And Qualifications

1+ years in IT manager or relevant experience
1+ years in MSP experience
Excellent communication, interpersonal and organization skills
Demonstrated good business judgement and decision-making skills
Creative thinker and problem solver with hands-on troubleshooting skills, attention to detail, thoroughness and follow-through

Job Type: Full-time

Pay: $25.00-$35.00 per hour

Expected hours: 40 per week

Benefits:

Casual dress
Dental care
Extended health care
Vision care

Flexible Language Requirement:

French not required

Schedule:

8 hour shift
Monday to Friday

Licence/Certification: BC Driver's License and reliable vehicle (required)

Work Location: In person

Company Description

Cloud9 Solutions is a rapidly growing Managed Services Provider that offers a broad range of IT Consulting, Managed IT, and Cloud services for organizations looking to source and implement IT solutions and services in their businesses or in the cloud.

Cloud9 Solutions is a rapidly growing Managed Services Provider that offers a broad range of IT Consulting, Managed IT, and Cloud services for organizations looking to source and implement IT solutions and services in their businesses or in the cloud.","{""role_summary"":""Lead a team of IT technicians to deliver services to clients, ensuring timely resolution of client issues and overseeing project onboarding and offboarding."",""key_terms"":[{""term"":""ITIL foundation"",""explanation"":""A set of best practices for IT service management, focusing on aligning IT services with business needs.""},{""term"":""MSP"",""explanation"":""Managed Services Provider, a company that offers outsourced IT services to clients.""},{""term"":""Tier1 and Tier2 staff"",""explanation"":""Levels of technical support, with Tier1 being the initial point of contact and Tier2 providing more advanced technical support.""}],""skill_priorities"":{""must_have"":[""1+ years in IT manager or relevant experience"",""1+ years in MSP experience"",""Excellent communication, interpersonal and organization skills"",""Demonstrated good business judgement and decision-making skills""],""nice_to_have"":[""Creative thinker and problem solver with hands-on troubleshooting skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to troubleshoot a complex technical issue and how you resolved it?"",""example_answer"":""In my previous role, I encountered a network connectivity issue that affected multiple clients. I worked closely with the team to identify the root cause, developed a plan to resolve the issue, and implemented a solution that restored connectivity within a few hours. The client was satisfied, and we received positive feedback.""},{""question"":""How do you ensure that client tickets and calls are addressed in a timely fashion?"",""example_answer"":""I prioritize tasks based on urgency and impact, delegate tasks to team members, and set clear expectations for resolution timelines. I also conduct regular check-ins with clients to ensure their issues are being addressed and provide updates on progress.""}],""red_flags"":[""Lack of experience in IT service management or MSP environment"",""Poor communication or interpersonal skills""],""confidence_score"":90.0}"
Assistant IT Manager,"About Four Seasons

Four Seasons is powered by our people. We are a collective of individuals who crave to become better, to push ourselves to new heights and to treat each other as we wish to be treated in return. Our team members around the world create amazing experiences for our guests, residents, and partners through a commitment to luxury with genuine heart. We know that the best way to enable our people to deliver these exceptional guest experiences is through a world-class employee experience and company culture.

At Four Seasons, we believe in recognizing a familiar face, welcoming a new one and treating everyone we meet the way we would want to be treated ourselves. Whether you work with us, stay with us, live with us or discover with us, we believe our purpose is to create impressions that will stay with you for a lifetime. It comes from our belief that life is richer when we truly connect to the people and the world around us.

About the location:

Embrace the alpine warmth surrounded by pristine Canadian wilderness In Whistler, home to North America’s largest ski resort, experience the best of alpine living through world-class ski runs, epic mountain experiences and an upbeat village. When the snow melts, the area becomes a playground for mountain bikers, zip-liners, hikers and adventurers. After an adventurous day, tuck into a meal at SIDECUT Steakhouse, where innovative creations match the seasons, or enjoy the après vibe in the warmth of Braidwood Tavern. Looking to recharge? Visit the Spa or take a dip in our heated pool, with a spectacular backdrop of the mountains and an invigorating dose of fresh alpine air.

The Four Seasons Resort and Residences Whistler is looking for an Assistant IT Manager who shares a passion for excellence and who infuses enthusiasm into everything they do.

Annual Salary: $65,000 - $75,000

About The Role

Four Seasons IT is currently undergoing an exciting transformation, migrating many systems and services to the cloud. Renowned for pioneering cutting-edge guest technology, Four Seasons is committed to leading the hospitality industry in innovation.

This role offers a unique opportunity to expand your IT knowledge and skillset across various areas, including project management, helpdesk support for Windows, PMS, and POS systems, TCP/IP networking, and Microsoft server management. You will be part of a small, dynamic team, working full-time with shared on-call responsibilities among IT team members.

Key Responsibilities

Manage TCP/IP networks.
Provide support for Microsoft Windows and Office 365.
Support the hotel's Property Management System (PMS) and Point of Sale (POS) systems.
Lead project management and implementation of new technologies.
Offer helpdesk support to both staff and guests.

Desired Skills And Experience

A degree in Computer Science or a related field, or equivalent experience.
Professional IT certifications in TCP/IP networking or Windows (e.g., MCSE, CCNA) are advantageous.
Experience in hospitality or customer service is beneficial.
Excellent written and verbal communication skills.
Successful candidates must possess the ability to work in Canada.

What To Expect

Four Seasons can offer what many professionals dream of – an opportunity to build a life-long career with global potential and a real sense of pride in work well done. We believe that attitude counts as much as skill. As a result, Four Seasons hires motivated people who we train to perform superbly, while we create an environment where they can flourish. Ultimately, our culture breeds success, and rewards it in many different ways.

Our Benefits Package Includes

Excellent Training and Development opportunities.
Medical, Dental and sick leave coverage.
Employee Travel Program; complimentary and reduced rates at other Four Seasons Hotels.
Meals on duty.
Employee Recognition Programs.
Dry Cleaning Services.
Use of the Fitness Facility.
Affordable employee housing.
Winter Leisure Pass; credit towards winter activities.

Learn more about what it is like to work at Four Seasons – Visit us at:

https://www.fourseasons.com/careers

https://www.linkedin.com/company/four-seasons-hotel-and-resorts

We look forward to receiving your application!

Our organization is an equal opportunity employer committed to hiring a diverse workforce and sustaining an inclusive culture. We do not discriminate on the basis of gender, ethnicity, religion, sexual orientation, age, disability or any other basis protected under provincial or federal laws.","{""role_summary"":""Assist in managing IT operations at a luxury resort, providing technical support and leading project implementations to enhance guest experiences."",""key_terms"":[{""term"":""TCP/IP networking"",""explanation"":""A fundamental networking protocol suite used to connect devices on the internet.""},{""term"":""PMS (Property Management System)"",""explanation"":""A software application used to manage hotel operations, including room bookings, guest information, and billing.""},{""term"":""POS (Point of Sale) systems"",""explanation"":""A combination of hardware and software used to process transactions and manage sales operations.""},{""term"":""Microsoft server management"",""explanation"":""The administration and maintenance of Microsoft servers to ensure efficient and secure operations.""},{""term"":""Cloud migration"",""explanation"":""The process of transferring data, applications, or other business elements from on-premises infrastructure to the cloud.""}],""skill_priorities"":{""must_have"":[""TCP/IP networking"",""Microsoft Windows and Office 365 support"",""PMS and POS systems support"",""Project management"",""Helpdesk support""],""nice_to_have"":[""Professional IT certifications (e.g., MCSE, CCNA)"",""Experience in hospitality or customer service""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the differences between TCP/IP and other networking protocols?"",""example_answer"":""TCP/IP is a suite of protocols that allows devices to communicate on the internet, whereas other protocols like HTTP and FTP are used for specific applications. TCP/IP is more flexible and scalable, making it the standard for modern networking.""},{""question"":""How would you troubleshoot a PMS system issue?"",""example_answer"":""I would first identify the symptoms of the issue, then review system logs and configuration settings to isolate the problem. If necessary, I would contact the PMS vendor's support team for assistance or escalate the issue to a senior IT team member.""}],""red_flags"":[""Lack of experience with TCP/IP networking"",""Inability to work in a fast-paced, dynamic environment""],""confidence_score"":85.0}"
"IT Manager, Service & Support - Americas","Company Details

Novocol Pharma is a growing contract development and manufacturing organization (CDMO), specialized in sterile injectable cartridges and combination product manufacturing. We strive for excellence and customer-centricity to deliver value to global pharmaceutical clients through contract services for drug development and commercial manufacturing. With over 40 years in operation, our team of 600 employees and modern facilities, located in Cambridge, Ontario provide a personalized and responsive experience for our customers. We are focused on serving our strategic partners and patients with quality, integrity, and value.

Our employees are our number one asset! We offer developmental opportunities, excellent compensation and benefit programs, discounted gym memberships, work/life balance programs, employee recognition, social events and spirit days.

We are a proud member of the Septodont group of companies. Septodont is a pharmaceutical and medical device company with a global leadership position in dental pain management. The group counts over 2000+ employees worldwide and has remained a 100% family owned company for over 90 years. Our Cambridge facility serves as a significant manufacturing site within the Septodont group with high volume dental anesthetic production for a global customer base.

We have an opportunity for an IT Manager, Service & Support – Americas.

Job Summary

The IT Manager, Service & Support – Americas reports to the Senior IT Manager, Operations and manages all areas of IT Service and Support in the region. Acting as the management level contact for local needs including for the Cambridge site. This includes managing and mentoring the IT staff responsible for service delivery, help desk, and end user computing. This leadership role is a champion of customer centric behaviours, focusing the IT Service and Support team on achieving service levels and enhancing end user computing through customer centric service delivery.

Responsibilities

Delivers cost-effective operations that fully support and enable strategic objectives for the region.

Leads by example, reinforcing expected behaviours within the team, driving a service excellence culture:

Seeing everything through the lens of the customer.
Paying attention to the physical environment because everything speaks.
Providing service delivery that will create service wows.
Developing processes that make employees service heroes for doing an outstanding job.

Champions ongoing improvement, and markets I&O to the organization by:

Focusing on customer-facing activities.
Acts as the local business partner for the region ensuring customer requirements are understood and facilitating communication with local management teams with specific focus as the first point of contact for the Cambridge site.
Managing from a customer value creation perspective using:
Customer value creation metrics (what is important to the business).
An emphasis on customer-focused problem solving workflows (agile, lean).
All staff empowered to take proactive action to prevent performance issues.
Prioritizing customer-centric behavioural competencies and technical skills for developing and hiring staff:
Developing behavioural competencies, as well as new technical skills.
Protecting staff time for development.

Leads the local Service Support function with a mission focused on:

Champion service excellence in:
The onboarding of new employees ensuring all tools and technologies are properly prepared and trained.
The management of service delivery ensuring the support team and end users are properly prepared for delivery of new or updated services / applications.
Support help desk (including Incident, Problem, Change, and reporting)
Deployment and support of employee devices including management of the hardware lifecycle
Follow up on end user device metrics including hardware, software (i.e. Windows Updates), and security deployments (i.e. disk encryption, endpoint protection) to ensure devices maintain a high level of security and capabilities

Manages help desk and support service levels, including for on-call support outside of regular business hours, to ensure: availability of resources according to business needs (internal and external); and timely escalation of requests/issues.

Leads continuous improvement activities related to service delivery and end user experience liasing with the appropriate I&O teams.

Ensure IT Security playbooks are followed and security incidents are properly prioritized and escalated.

Contributes to the preparation and management of staffing, capital and operations spending plans.

Manages the performance and development of all direct reports.

Responsible for hiring, identifying skill gaps, and appropriate training/development.

Ensures hardware and software assets are tracked and software license compliance is maintained.

Responsible for compliance to GxP guidelines

Qualifications

Education:

Bachelor’s degree in Computer Science or Information Systems, or IT diploma with relevant certification (i.e. ITIL, Lean IT, Microsoft Expert or Architect level).

Experience:

Minimum of 5 years of progressive IT experience with diverse enterprise environments including 2 years of experience supervising teams in a technical support/customer service environment.
Pharmaceutical, food, or cosmetic industry experience is considered an asset.
Demonstrated track record of providing great customer service.
Strong team player with the ability to lead and mentor staff, including remotely, as well as within cross-cultural teams.
Excellent written and verbal communication skills with diverse teams.
Proficiency Portuguese (Brazilian) is an asset.
Agile in thought and action with the ability to tackle difficult problems analytically and to make well-reasoned business decisions (business acumen).
Demonstrated experience guiding conflict resolution and facilitating employee relations activities.
Experience in planning and execution of multi-location projects utilizing formal project management methodology.
Proven knowledge of Health and Safety legislation and other Employment related legislation such as the Employment Standards Act.
Valid Driver’s license and passport (i.e. eligible to travel Internationally up to 10% of the time).
Must be available to work on all shifts.
This is a Hybrid role - 3 days office and 2 days WFH

What we offer

Excellent compensation/benefits package.
Bonus and reward programs
Discounted gym memberships
Programs supporting work life balance
Employee recognition program
Professional and personal development programs
Social events and spirit days

We are committed to diversity and inclusion, and thank all applicants in advance; however, we will be corresponding only with those selected for an interview.

In accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act, we are committed to providing an inclusive and barrier free recruitment and selection process.

Recruitment Fraud – please be aware of recruitment fraud. Novocol Pharmaceutical of Canada Inc. will never ask for banking information, money or any personal information up front. We will only respond to official applications submitted through our careers site. In addition, we will only use official corporate e-mail addresses (septodont.com or novocolpharma.com) to communicate with applicants. Should you be contacted without submitting an application, please delete the message and advise your e-mail provider.

For Internal

Internal Job Posting Grade 12. The due date for internal applicants to apply for this role is April 1, 2024.

Contract type

Permanent","{""role_summary"":""The IT Manager, Service & Support – Americas leads the IT Service and Support team in the region, focusing on customer-centric service delivery, managing and mentoring staff, and ensuring cost-effective operations that support strategic objectives."",""key_terms"":[{""term"":""ITIL"",""explanation"":""ITIL (Information Technology Infrastructure Library) is a set of best practices for IT service management that focuses on aligning IT services with business needs.""},{""term"":""Lean IT"",""explanation"":""Lean IT is an adaptation of the lean manufacturing principles to IT service management, aiming to eliminate waste, reduce variability, and improve flow.""},{""term"":""GxP"",""explanation"":""GxP (Good Practice) is a set of guidelines for ensuring the quality and integrity of pharmaceutical products, including Good Manufacturing Practice (GMP), Good Laboratory Practice (GLP), and Good Clinical Practice (GCP).""},{""term"":""Agile"",""explanation"":""Agile is an iterative approach to project management that emphasizes flexibility, collaboration, and rapid delivery, often used in software development and IT projects.""}],""skill_priorities"":{""must_have"":[""5+ years of progressive IT experience"",""2+ years of experience supervising teams in a technical support/customer service environment"",""Strong team player with leadership and mentoring skills"",""Excellent written and verbal communication skills"",""Agile mindset and business acumen""],""nice_to_have"":[""Pharmaceutical, food, or cosmetic industry experience"",""Portuguese (Brazilian) proficiency"",""Experience with formal project management methodology"",""Proven knowledge of Health and Safety legislation and Employment related legislation""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to lead a team to resolve a complex technical issue?"",""example_answer"":""In my previous role, I led a team to troubleshoot a network outage that affected multiple locations. We worked collaboratively to identify the root cause, developed a plan to resolve the issue, and implemented a solution within a tight deadline. The outcome was a 99.99% uptime rate for our critical systems.""},{""question"":""How do you ensure that your team is providing excellent customer service?"",""example_answer"":""I believe in leading by example and setting clear expectations for customer-centric behavior. I also conduct regular feedback sessions with customers and team members to identify areas for improvement and provide coaching and training to ensure that our team is equipped to deliver exceptional service.""}],""red_flags"":[""Lack of experience in managing teams in a technical support/customer service environment"",""Inability to communicate technical information to non-technical stakeholders"",""No experience with IT service management frameworks such as ITIL or Lean IT""],""confidence_score"":90.0}"
Director of Security and IT,"What We’re Building

Honeycomb is built to help engineering teams deeply explore and understand their own production systems — in real time. It's a service for the near future and present, where distributed systems are the new default, every service is a platform, and empowered generalist software engineers are the new ops. We believe in the dream of consumer-quality developer tools and are excited to be building a product that raises our industry's expectations of what our tools can do for us. It enables engineers to answer novel questions about their ever-evolving cloud applications, so they can deploy confidently, resolve incidents faster and focus on high-value work that drives innovation. We’re working with well known companies like HelloFresh, Slack, LaunchDarkly, and Vanguard and more across a range of industries. This is an exciting time in our trajectory, we’ve closed Series D funding, scaled past the 150-person mark, and were named to Forbes’ America’s Best Startups of 2022 and 2023!

In this role, you’ll bring together two functions, our information security team and IT team, building a unified strategy and outlook across both teams to help us better serve our internal partners and customers. Key aspects of the role will involve managing our IT and security leaders and helping us plan for a future where security, compliance, and IT best practices grow increasingly central to our business as we scale and go upmarket. You’ll also support aspects of our compliance and privacy programs, in coordination with our GRC program manager.

We are open to hiring a Senior Manager or Director level for this role.

We can hire this role in the United States and Canada.

What you’ll do:

Help define and unify our strategy for IT, Security, and compliance, and expand our planning horizon. Look ahead and help us understand how we need to mature these functions as we scale
Help us build a data-driven and outcome-oriented culture within IT & Security
Lead our IT and Security functions, including growing and mentoring the leaders and ICs on those teams
Seek balance across investment streams, and help us assess and codify our appetite for risk . IT and Security aren’t just about putting more and more locks and controls on every source of risk; as a growing business, we have to balance security against other goals like employee productivity, user experience, etc.
Assist with keeping our compliance and privacy programs running smoothly, by partnering closely with our GRC manager and supervising the aspects of those programs owned by Security and IT


About You:

You have experience managing an information security function and an IT team, an internal tooling team, a platform team, or other team with internal customers. We don’t necessarily need you to be a deep subject matter expert in every area of security and IT, but we’re looking for someone who is fluent in the concerns of both domains and has some experience leading the unique activities these teams may take on. Experience with compliance and privacy programs, including SOC 2 Type II or ISO 27001 certification and GDPR compliance, will also be helpful
You have experience with B2B SaaS software as well as startups/scale-ups. While all software has security and compliance needs, the world of a cloud-based software startup is a little different; and the security and compliance needs of businesses aren’t the same as those of consumers. Having experience in these domain areas, as well as experience with scaling teams, will be helpful
You know how to be a great manager and leader first, and a technologist second. While this domain will bring together two teams with exciting technical charters, we’re looking for a people-first leader. You should be excited to help these teams thrive through supporting and mentoring their respective leaders and team members, rather than getting hands-on with every technical decision yourself.
You know how to define, communicate, and execute against a strategy — and is excited to help others learn these skills too. As we scale our team, we’re working on shifting more of our strategy from implicit to explicit, and from short-term to long-term. We want to clarify and expand how our team members can contribute to this work and help them level up their strategic thinking in the process
You understand the value of automation and great tools. We have a strong engineering culture and love to find places where technology can help us work smarter. It’ll be helpful if you have experience investing in automation and tooling, and can help guide our security and IT strategy in these areas
You understand the value of a diverse, equitable, and inclusive team — and has some experience building them. Scaling a team always brings both opportunities and growing pains. We’re looking for a leader who can help us capitalize on the former and minimize the latter, while continuing to diversify on key axes. We are trying to raise the standards for developer tools, and we know that a diverse, inclusive team will help us build better products for a larger swath of the industry.
You have management experience. We’re looking for at least three years of people management experience and a year of experience managing managers, with demonstrated success in the role.


What You Get When You Join The Hive!

Base pay (range) of $200,000 - $260,000 USD (range is for Senior Manager up through Director)
A stake in our success - generous equity with employee-friendly stock program
It’s not about how strong of a negotiator you are - our pay is based on transparent levels relative to experience
Compensation benchmarked to San Francisco market - no matter where you live (or move)!
401k plan to help you plan for your future
A remote-first mindset and culture (really!)
100% employee coverage for Health, Dental, Vision, Life and Disability insurance and 75% for dependents
Time to Recharge - In addition to our Unlimited PTO policy, we provide :23 days off through out the year. This includes a company wide break at the end of the year, and we honor having at least one three day weekend a month (if there is not already a locally observed holiday that month, we add one!)
Pick Your Perk - $600 a year to spend on the perks that you care about most
Work Life Balance and Flexible Schedule options
The tech you need AND a $500 Home Setup Stipend
$200 Reimbursement for Cell/Wifi/CoWorking
$1500+ Annual Professional Development Allowance
Up to 16 weeks of paid parental leave, regardless of path to parenthood
Maven Inclusive Family-Building benefit including unlimited virtual appointments, coaches & counselors, and $10K ‘wallet’ to support adoption, surrogacy, IVF, and egg/sperm freezing
Modern Health well-being benefit including self guided resources and access to 12 mental health and 8 coaching sessions - at no additional cost to you
Semi-annual performance conversations (we call them Review & Rewards conversations) - so you know where you stand, and how you’ll be rewarded for your impact
Annual compensation review, benchmarking to industry and inflation changes


Please note we cannot currently sponsor or do visa transfers at this time.

Diversity & Accommodations:

We're building a diverse and inclusive workplace where we learn from each other, and welcome nontraditional candidates, and people of all backgrounds, experiences, abilities and perspectives. You don't need to be a millennial to join us, all gens are welcome! Further, we (of course) follow federal and state disability laws and are happy to provide reasonable accommodations during the application phase, interview process, and employment. Please email Talent@honeycomb.io to discuss accessible formats or accommodations. As an equal opportunity employer our hiring process is designed to put you at ease and help you show your best work; if we can do better - we want to know!","{""role_summary"":""Lead the IT and Security functions, unifying strategy and outlook across both teams, and help plan for a future where security, compliance, and IT best practices grow increasingly central to the business as it scales and goes upmarket."",""key_terms"":[{""term"":""SOC 2 Type II"",""explanation"":""A security compliance certification that ensures a company's systems are secure and available.""},{""term"":""ISO 27001"",""explanation"":""An international standard for information security management systems that helps organizations protect their information assets.""},{""term"":""GDPR compliance"",""explanation"":""A regulation that ensures the protection of personal data and privacy of individuals within the European Union.""},{""term"":""B2B SaaS software"",""explanation"":""Business-to-business software as a service, which provides software applications over the internet to businesses.""}],""skill_priorities"":{""must_have"":[""Experience managing an information security function and an IT team"",""Experience with compliance and privacy programs"",""Experience with B2B SaaS software and startups/scale-ups"",""People management experience""],""nice_to_have"":[""Experience with automation and tooling"",""Experience building diverse, equitable, and inclusive teams""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach unifying the strategy and outlook of the IT and Security teams?"",""example_answer"":""I would start by conducting a thorough analysis of the current state of both teams, identifying areas of overlap and opportunities for improvement. Then, I would work closely with the leaders of both teams to develop a shared vision and strategy that aligns with the company's overall goals.""},{""question"":""How do you balance security and compliance with other business goals, such as employee productivity and user experience?"",""example_answer"":""I believe that security and compliance should be integrated into the overall business strategy, rather than being seen as separate goals. I would work with the leadership team to identify areas where security and compliance can be improved without negatively impacting employee productivity and user experience.""}],""red_flags"":[""Lack of experience managing an information security function and an IT team"",""Inability to balance security and compliance with other business goals""],""confidence_score"":90.0}"
"Manager, IT Portfolio Management","Work Illustration

The incumbent is accountable for delivering and supporting mid-to-large scale Information Technology (IT) enabled projects and programs. In addition, s/he delivers and supports application support services for the assigned business unit partner and works with stakeholders to elicit, analyze, communicate and validate requirements for changes to business processes, policies and information systems. This role includes direct interaction and collaboration with a broad range of senior, technical and functional management and subject matter experts throughout the organization.

The role is focused on managing a portfolio of projects ranging in size, budget and complexity. The portfolio may have both IT projects as well as pure process improvement projects. Projects vary depending on size and scope and will require flexibility and may require tailored project management solutions. This position requires day to day management of project team personnel (including full time employees and contractors), management of vendors, communication with key stakeholders, working with business subject management experts to ensure successful project execution. This role will also include direct interaction with the senior management team and subject matter experts throughout the organization.

Key Responsibilities

Leads a team of designated and technical professionals and support staff (internal and external resources and vendors) to manage the day-to-day operational delivery, support, performance monitoring, and reporting for information technology systems and applications for the designated business unit, to ensure client systems are secure and reliable
In alignment with organizational programs, practices and collective agreements, manages employee performance, attendance and training and development. Motivates and engages employees in the attainment of departmental goals and objectives and acts to address gaps in performance which may impact outcomes
Collaborates with business units for the execution of divisional projects, support of software applications, management of incidents and service requests for the designated portfolio
Educates and supports business unit users in the use of information technology securely, providing or arranging for end-user training as required
Provides coaching and feedback to team (internal and external) to reduce and/or eliminate environment, health and safety (EHS) hazards and risks, and introduce controls to maintain EHS performance
Identifies opportunities for continuous improvement in the day-to-day operational support and IT software implementation lifecycle
Responsible to respond and resolve real-time incidents in alignment with the divisional service level agreements. Performs post-incident root cause analysis and creates long term mitigation plans

Requirements

Bachelor’s Degree (Computer Science/Engineering preferred)
Ten (10) years of progressively more senior technical experience
Five (5) years IT project management or IT operations experience
Post-Graduate degree (preferred)
Experience in utility environment with union involvement and management experience (preferred)
Experience in business system analysis and development of functional and systems specifications
Project Management certifications e.g. PMP (preferred)
Knowledge of business and technology domains, such as products, processes, markets sand systems (specific to work stream being supported)
Good understanding of systems delivery, project management, Software Development Life Cycle (SDLC), and ITIL methodologies
Basic knowledge of standard programming and data modeling methodologies
Proficient with structured methods for process and organizational analysis requirements elicitation techniques (e.g. requirement workshops, focus groups, interviews)
Experience in successfully managing multi-million dollar project or portfolio of multiple projects
Program management experience including program management, resource load and capacity management and supervision of staff
Excellent analytical and organizational skills
Ability to manage stakeholder expectations and time conflicting priorities/business interests
Skilled in managing contractors and third-party vendors
Ability to communicate (verbal and written) effectively with clients, stakeholders, senior leadership
Fully proficient in use of MS Office, MS Project, Visio and other PM tools

Toronto Hydro has introduced a Hybrid Work Arrangement. This position allows for remote work up to three days per week, based on business needs. Employees will be required to come onsite on those days when they are involved in activities that they or their leader feel are better conducted in person. You are expected to live in Ontario and within reasonable commuting distance of the office.","{""role_summary"":""The role is responsible for delivering and supporting mid-to-large scale IT projects and programs, managing a portfolio of projects, and collaborating with stakeholders to elicit, analyze, and validate requirements for changes to business processes, policies, and information systems."",""key_terms"":[{""term"":""IT enabled projects"",""explanation"":""Projects that use technology to achieve business objectives.""},{""term"":""Application support services"",""explanation"":""Services that ensure software applications are running smoothly and efficiently.""},{""term"":""Project management"",""explanation"":""The process of planning, organizing, and controlling resources to achieve specific goals and objectives.""},{""term"":""ITIL methodologies"",""explanation"":""A set of best practices for IT service management that focuses on aligning IT services with business needs.""},{""term"":""SDLC"",""explanation"":""Software Development Life Cycle, a process used to design, develop, and test software.""}],""skill_priorities"":{""must_have"":[""Project management experience"",""IT operations experience"",""Analytical and organizational skills"",""Ability to manage stakeholder expectations"",""Excellent communication skills""],""nice_to_have"":[""Post-Graduate degree"",""Experience in utility environment with union involvement"",""Project Management certifications (e.g. PMP)"",""Knowledge of business and technology domains""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with managing a portfolio of projects with varying sizes, budgets, and complexities?"",""example_answer"":""In my previous role, I managed a portfolio of 5 projects with budgets ranging from $500,000 to $2 million. I developed tailored project management solutions to ensure successful execution and delivery.""},{""question"":""How do you ensure effective communication with stakeholders, including senior management and subject matter experts?"",""example_answer"":""I use a combination of regular status updates, project dashboards, and ad-hoc meetings to ensure stakeholders are informed and aligned with project goals and objectives.""}],""red_flags"":[""Lack of experience in managing a team of technical professionals"",""Inability to communicate effectively with stakeholders"",""No experience with IT project management or IT operations""],""confidence_score"":90.0}"
IT Administrator II,"Who We Are

At Mustang Survival, our vision is to enable the ultimate on-water experience. We seek to become the pinnacle waterlife brand by offering authentic, innovative product solutions that instill confidence and trust in our consumers. We require talented, motivated, inspired individuals at all levels of the organization to ensure that we remain true to what we stand for. If you are someone who has curiosity, passion for excellence, and a desire to drive innovative product solutions, come and join us to push the boundaries of what’s possible in delivering the ultimate water life user experience.

What We Offer

Mustang Survival offers a competitive wage of $71,000-85,000. Note: the posted salary ranges are estimates and actual salary may vary depending on the experience of the candidate. As part of our total rewards package, we offer: group RRSP matching, comprehensive health and wellness benefits such as Vacation and Wellness days, Employee Family Assistance Programs, and a Healthcare Spending Account.

Job Purpose

Responsible for responding to tickets from users both locally and at remote offices. This will involve setting up new software and hardware, performing system upgrades and training users. You will work remotely with staff and IT Administrators at other Wing Group Locations around the world, but you’ll be the one covering the needs of the local office and factory.

STRUCTURE

This position reports to the Manager, IT Applications & Infrastructure. This position does not have direct reports.

RESPONSIBILITY

Provide help desk support and specialized technical assistance to system users, escalating issues, as necessary.
Perform hardware, software and peripheral equipment improvements and upgrades to ensure all systems are up to date.
Monitor system performance to ensure that operations are within established standards and develop recommendations for enhancements to improve operations and increase system capabilities.
Administer IT onboarding of new employees, including collecting requirements, setup, and deployment.
Maintain inventory of IT equipment, such as desktops, laptops, mobility devices, etc.
Creates and update documentation of IT processes, policies, licensing, and systems.
Present equipment and policy training to staff and end users.
Plans, develops and implements recovery and backup procedures.
Communicate IT plans, tasks and modifications to relevant stakeholders and employees.
Assist with research and evaluation of new technology, techniques, threats, and industry best practices to optimize efficiency and usability and minimize vulnerabilities.

Requirements

1-2 years experience with M365, Entra and Federated identity concepts
1-2 years' experience with Windows in an Enterprise environment
1-2 years' experience with MacOS and iOS devices in an enterprise environment preferred
Relevant 2-year diploma or greater, or equivalent industry experience
Ability to work independently with minimal supervision
Excellent interpersonal skills with a customer service mindset
1-2 years' experience with Virtualization platforms such as VMWare or Hyper-V
The ability to travel to all the locations that we operate in
Ability to be an authorized individual for controlled goods
Criminal Record Check

ASSETS

Microsoft Certified Azure, CCNA, or other relevant certifications
Cybersecurity certifications","{""role_summary"":""Provide technical support and assistance to system users, perform system upgrades, and maintain IT equipment inventory, ensuring all systems are up to date and running smoothly."",""key_terms"":[{""term"":""M365"",""explanation"":""Microsoft 365, a suite of cloud-based productivity and collaboration tools.""},{""term"":""Entra"",""explanation"":""A cloud-based identity and access management platform.""},{""term"":""Federated identity"",""explanation"":""A system that enables users to access multiple systems or applications with a single set of login credentials.""},{""term"":""Virtualization platforms"",""explanation"":""Software that allows multiple virtual machines to run on a single physical machine, such as VMWare or Hyper-V.""}],""skill_priorities"":{""must_have"":[""M365"",""Entra"",""Federated identity"",""Windows"",""MacOS"",""iOS"",""Virtualization platforms""],""nice_to_have"":[""Microsoft Certified Azure"",""CCNA"",""Cybersecurity certifications""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you troubleshoot a user's issue with accessing a cloud-based application?"",""example_answer"":""I would first ask the user to provide more details about the error message they're seeing, then check the application's system logs to identify the root cause of the issue. If necessary, I would escalate the issue to the IT Administrators at other Wing Group Locations for further assistance.""},{""question"":""Can you explain the concept of federated identity and how it's used in an enterprise environment?"",""example_answer"":""Federated identity allows users to access multiple systems or applications with a single set of login credentials. In an enterprise environment, this is achieved through the use of identity providers and service providers, enabling single sign-on (SSO) capabilities.""}],""red_flags"":[""Lack of experience with M365, Entra, and Federated identity concepts"",""Inability to work independently with minimal supervision"",""Poor interpersonal skills with a customer service mindset""],""confidence_score"":90.0}"
"Regional IT Manager, Ontario and Atlantic Canada","Inspirational, innovative and entrepreneurial - this is how we describe our empowered teams. Combine your passion with purpose and join a culture that is thriving in the face of change.

Make an impact with our Technology – Support Services team as a Manager, Regional Technology. This diverse team of tech-savvy problem solvers embraces digital transformation and the possibilities technology brings to the future of our industry. As a trusted advisor, you’ll support, utilize and maintain MNP’s technology to ensure smooth IT operations, enabling team members to work efficiently and effectively.

MNP is proudly Canadian. Providing business strategies and solutions, we are a leading national accounting, tax and business advisory firm in Canada. Entrepreneurial to our core, our talented team members transcend obstacles into opportunities and are successfully transforming mid-market business practices.

Responsibilities

Manage all aspects of IT support delivery for your region
Develop and foster business relationships with regional business leaders, gaining an understanding of the unique business requirements of your assigned regions and ensure appropriate IT service offerings are being delivered
Ensure asset management and equipment provisioning processes are being followed, and participate in annual IT equipment budgeting for offices within your region
Lead a team of IT Coordinators and work closely with other groups in the IT department to ensure delivery of high-quality IT services, support, and excellent customer service
Conduct regular team meetings to ensure alignment and collaboration
Develop team members' skills and career paths through comprehensive IT career development initiatives and to align their behaviors with the IT strategic plan, mission, and firm’s values
Foster team growth and expertise in customer service etiquette, support best practices, technical knowledge, and SLA adherence
Ensure the appropriate resourcing and technical capabilities of the support team to deliver IT service to the business, ensuring customer service is the forefront of our service offering
Act as the hiring manager for open positions in your region
Manage the lifecycle of all incidents/requests within the region and serve as the escalation point for the business as it relates to incidents, requests, or unresolved issues
Prepare and present metrics, activity reports, and progress updates on projects and support delivery
Perform trend analysis of services and historical incidents to improve overall performance.
Maintain flexibility to travel, as necessary


Skills And Experience

At least 3 years in an IT Manager role leading successful IT support teams
Knowledge of ITSM/ITIL framework and best practices
Strong people management skills
Proven experience in incident management
Capacity to succeed in a changing, rapid growing business that fosters entrepreneurial values


MyRewards@MNP

With a focus on high-potential earnings, MNP is proud to offer customized rewards that support our unique culture and a balanced lifestyle to thrive at work and outside of the office. You will be rewarded with generous base pay, vacation time, 4 paid personal days, a group pension plan with 4% matching, voluntary savings products, bonus programs, flexible benefits, mental health resources, exclusive access to perks and discounts, professional development assistance, MNP University, a flexible ‘Dress For Your Day’ environment, firm sponsored social events and more

Diversity@MNP

We embrace diversity as a core value and celebrate our differences. We believe each team member contributes unique gifts and amplifying their potential makes our business stronger. We encourage people with disabilities to apply!","{""role_summary"":""Manage IT support delivery for a region, leading a team of IT Coordinators to ensure high-quality IT services, support, and excellent customer service."",""key_terms"":[{""term"":""ITSM/ITIL framework"",""explanation"":""A set of best practices for IT service management, focusing on aligning IT services with business needs.""},{""term"":""Incident management"",""explanation"":""The process of identifying, classifying, and resolving IT incidents to minimize business disruption.""}],""skill_priorities"":{""must_have"":[""At least 3 years in an IT Manager role"",""Knowledge of ITSM/ITIL framework and best practices"",""Strong people management skills"",""Proven experience in incident management""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with ITSM/ITIL framework and how you've applied it in a previous role?"",""example_answer"":""In my previous role, I implemented ITIL best practices to improve incident resolution times by 30%. I worked closely with the team to develop a knowledge base and established a clear escalation process, resulting in improved customer satisfaction.""},{""question"":""How do you approach people management, and what strategies do you use to develop your team members' skills?"",""example_answer"":""I believe in regular feedback and coaching. I work closely with my team members to identify areas for growth and develop personalized development plans. I also encourage cross-functional training to ensure my team is well-rounded and equipped to handle various IT support tasks.""}],""red_flags"":[""Lack of experience in leading IT support teams"",""Inability to adapt to a rapidly changing business environment""],""confidence_score"":90.0}"
"Senior Manager, IT Infrastructure and Security","Sterling Crane Canada

Come join a team where People make the difference! As a part of Marmon Holdings, Inc., a highly decentralized organization, we rely heavily on people with the aptitude, attitude, and entrepreneurial spirit to drive our success, and we're committed to attracting and retaining top talent.

We are seeking a Senior IT Infrastructure and Security Manager to oversee service delivery for companies in the US, Canada, and Australia. This is a technical working lead position that requires an individual with experience in managing global infrastructure and security programs. Reporting to the Vice President of Information Technology, a successful candidate in this role will be responsible for overseeing global delivery for the portfolio.

The Senior Manager, IT Infrastructure and Security - Global will play a critical role in ensuring the stability, security, and scalability of the infrastructure and security environment for the organization, while providing technical leadership, people management, and strategic guidance to a global team.

Senior Manager, IT Infrastructure and Security - Global

Edmonton, AB

We are seeking a Senior IT Infrastructure and Security Manager to oversee service delivery for companies in the US, Canada, and Australia. This is a technical working lead position that requires an individual with experience in managing global infrastructure and security programs. Reporting to the Vice President of Information Technology, a successful candidate in this role will be responsible for overseeing global delivery for the portfolio.

The Senior Manager, IT Infrastructure and Security - Global will play a critical role in ensuring the stability, security, and scalability of the infrastructure and security environment for the organization, while providing technical leadership, people management, and strategic guidance to a global team.

Responsibilities:

Provide technical leadership to a global team responsible for infrastructure and security service delivery across multiple countries.
Collaborate and communicate with stakeholders, developers, and technical team members to deliver on business objectives, ensuring that project goals are met within scope, time, and budget.
Develop and maintain documentation for business processes, operational procedures, technical design, solution structure, and functional know-how.
Collaborate with other teams that are often geographically dispersed, to define, plan and oversee projects that your team will own or participate in.
Manage team projects and deliverables utilizing common project management frameworks and delivery methods, while ensuring team collaboration.
Provide 24X7 escalation support to cross-functional teams for critical incidents.
Lead, mentor, and manage a team of technical experts, providing guidance and coaching to ensure their growth and success.
Develop and maintain relationships with key stakeholders, including vendors, partners, and clients.
Manage the technical scope of infrastructure and security service delivery, ensuring that solutions are scalable, secure, and aligned with industry standards.
Develop and maintain a technology roadmap for the infrastructure and security portfolio, ensuring that it aligns with business objectives and is updated on an ongoing basis.
Provide thought leadership on emerging technologies, industry trends, and best practices related to infrastructure and security service delivery.
Lead the design, development, and implementation of complex technical solutions, ensuring that they are robust, scalable, and secure.
Develop and manage budgets for infrastructure and security service delivery, ensuring that resources are allocated appropriately and that expenditures are in line with business objectives.
Ensure that infrastructure and security service delivery comply with relevant legal, regulatory, and industry standards
Manage all infrastructure and monitoring tools to enable ideal performance and ensure that components of the disaster recovery infrastructure and technical plans are maintained.
Foster a culture of innovation and continuous improvement, encouraging team members to experiment, take risks, and challenge the status quo.
Develop and maintain strong working relationships with other teams and departments, including development, operations, and business stakeholders.
Provide expert knowledge and direction in IT infrastructure operations and controls, ensuring reliability of the servers and data storage.
Perform system administration for on-prem and cloud infrastructure resources – AD, Databases, IIS servers, Azure, Hyper-V, and VMware.
Forecast and manage budgets for the portfolio and ensure delivery within budgetary constraints.
Provide regular reporting to senior management on portfolio performance, risks, and opportunities.

Qualifications:

Bachelor's degree in Computer Science or related field; Master's degree is a plus.
Minimum 10 years of experience in IT infrastructure and security.
5+ years of experience in a management position with people leadership responsibilities.
Experience working with managed service providers, SaaS services, and hosted solutions.
Solid analytical skills, experience solving practical issues and engaging cross-functional teams.
Ability to effectively prioritize and execute tasks while handling time-sensitive competing priorities.
Demonstrated analytical, problem-solving, organizational, interpersonal, communication skills.
Ability to lead discussion with business stakeholders and suggest holistic solutions/improvements for both technical strategy and business processes.
Exhibits strong initiative; self-starter that can lead others in ambiguous situations.
Ability to influence and drive others toward common goals.
Leads by example creative and innovative idea generation and influences decisions across different teams.
Experience with leading or participating in the gathering and documenting of business processes and requirements for the system with key business users.
Ability to manage multiple initiatives of innovation and converge them all into common strategic objectives.
Understanding of holistic infrastructure and security designs, including being able to provide consult to how those could apply to application design requirements.

We offer competitive compensation packages, flexible work arrangements, health and wellness benefits, retirement benefits, professional development opportunities, paid time off, and a fantastic work environment that promotes teamwork, safety, and a sense of community. If you are passionate about leading people with integrity and developing a career with an enterprise scale organization, we encourage you to apply for this exciting opportunity. Please submit your resume and cover letter for consideration.

Location:

Canada (Hybrid Role)
The ideal candidate will be based out of Edmonton or willing to relocate to Edmonton for a period of 2 years.

IMPORTANT:

We thank all applicants for their interest; however, only those candidates who are shortlisted will be contacted:

CLOSING DATE: Until Filled

Following receipt of a conditional offer of employment, candidates will be required to complete additional job-related screening processes as permitted or required by applicable law.

If you would like to apply for this position, please submit your resume online via our Applicant Tracking System https://marmon.wd5.myworkdayjobs.com/Marmon_Careers or drop your resume at any of our office locations.

Following receipt of a conditional offer of employment, candidates will be required to complete additional job-related screening processes as permitted or required by applicable law.","{""role_summary"":""Oversee service delivery for global infrastructure and security programs, providing technical leadership, people management, and strategic guidance to a global team."",""key_terms"":[{""term"":""IT Infrastructure"",""explanation"":""The underlying systems and technology used to support an organization's operations, including hardware, software, and networks.""},{""term"":""Security Programs"",""explanation"":""Initiatives and measures implemented to protect an organization's digital assets from unauthorized access, use, disclosure, disruption, modification, or destruction.""},{""term"":""Managed Service Providers"",""explanation"":""Third-party companies that provide IT services, such as infrastructure management, security, and technical support, to organizations.""},{""term"":""SaaS Services"",""explanation"":""Software as a Service, a cloud-based software delivery model where applications are hosted and managed by a third-party provider.""},{""term"":""Hosted Solutions"",""explanation"":""IT services or applications provided over the internet, where the infrastructure and management are handled by a third-party provider.""}],""skill_priorities"":{""must_have"":[""Experience in managing global infrastructure and security programs"",""Technical leadership and people management skills"",""Strong analytical and problem-solving skills"",""Ability to prioritize and execute tasks with competing priorities""],""nice_to_have"":[""Master's degree in Computer Science or related field"",""Experience with leading or participating in gathering and documenting business processes and requirements"",""Knowledge of holistic infrastructure and security designs""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience in managing global infrastructure and security programs?"",""example_answer"":""I have 10 years of experience in IT infrastructure and security, with 5 years of experience in a management position, where I oversaw global delivery for a portfolio of companies.""},{""question"":""How do you prioritize and execute tasks with competing priorities?"",""example_answer"":""I use project management frameworks and delivery methods to manage team projects and deliverables, ensuring collaboration and effective prioritization of tasks.""}],""red_flags"":[""Lack of experience in managing global infrastructure and security programs"",""Inability to prioritize and execute tasks with competing priorities"",""Limited technical leadership and people management skills""],""confidence_score"":90.0}"
Helpdesk Manager,"Hollingsgate Recruitment is partnering with a leading IT Network Management company in Ottawa that specializes in the financial sector. We are on the lookout for a dynamic Helpdesk Manager who is eager to advance their career in a supportive and stimulating environment.

Position: Helpdesk Manager

Location: Ottawa, ON

What You ll Do

Lead and Oversee Projects: Manage and guide various IT projects, ensuring they are completed on time while supervising a dedicated team of service desk professionals.
Hands-On Project Involvement: Play a proactive role in executing IT projects, working alongside your team to implement solutions and achieve project goals.
Mentor and Support Technicians: Provide guidance, training, and support to both junior and senior techs, creating a collaborative and productive team atmosphere.
Manage Schedules and Coverage: Develop effective scheduling practices to ensure the service desk is always adequately staffed, balancing workloads, and minimizing downtime.
Assist with Calls and Tickets: Act as an escalation point for complex technical issues, helping team members troubleshoot and resolve customer inquiries efficiently.
Review Timesheets and Task Progress: Monitor timesheets for accuracy, ensuring compliance with company policies, and track task progress to maintain project timelines.

What We re Looking For

Leadership Skills: Proven ability to lead, inspire, and motivate a team, focusing on high performance and exceptional customer service.
Helpdesk Management Experience: Demonstrated experience managing a helpdesk environment with a deep understanding of IT support processes and best practices.
Multitasking Abilities: Excellent organizational skills and the capability to juggle multiple responsibilities and projects simultaneously, maintaining high efficiency.
Communication Skills: Strong verbal and written communication skills, able to clearly convey technical information to both technical and non-technical audiences.

If you're passionate about leading a team and thriving in a fast-paced environment, we want to hear from you! This role offers a unique chance to make a significant impact within a forward-thinking organization.

Apply Now!","{""role_summary"":""Manage and lead a team of service desk professionals, overseeing IT projects, providing guidance and support, and ensuring efficient customer service."",""key_terms"":[{""term"":""IT projects"",""explanation"":""Information Technology projects, which involve planning, execution, and delivery of technical solutions.""},{""term"":""Helpdesk environment"",""explanation"":""A technical support system where customers can report issues and receive assistance from IT professionals.""},{""term"":""Service desk professionals"",""explanation"":""IT technicians responsible for providing technical support and resolving customer issues.""}],""skill_priorities"":{""must_have"":[""Leadership skills"",""Helpdesk management experience"",""Multitasking abilities"",""Communication skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to lead a team through a complex IT project? How did you ensure its successful completion?"",""example_answer"":""In my previous role, I led a team of 5 technicians through a network migration project. I created a detailed project plan, assigned tasks, and held regular meetings to track progress. We completed the project 2 weeks ahead of schedule, and our customer satisfaction ratings increased by 20%.""},{""question"":""How do you prioritize tasks and manage your time when dealing with multiple projects simultaneously?"",""example_answer"":""I use a task management tool to organize my tasks and prioritize them based on urgency and importance. I also delegate tasks to my team members and set clear deadlines to ensure we're all working efficiently.""}],""red_flags"":[""Lack of experience in managing a helpdesk environment"",""Poor communication skills""],""confidence_score"":90.0}"
IT Manager & Infrastructure Architect,"IT Manager & Infrastructure Architect

Department: Technology (within Marketing & Digital Growth division)
Location: Telecommuting between home office in Ontario, and 985 Adelaide Street S, London, Ontario
Salary: TBD + Benefits
Application Submission: July 3, 2024

SUMMARY
The Information Technology (IT) Manager & Infrastructure Architect will lead Compassion’s informational technology department efforts and drive the development and implementation of innovative technology solutions. Positioned within our Marketing & Digital Growth team, this position is well situated in our on-going digital transformation (developing an agile and learning mindset) pursuit.

Working alongside members of the Marketing & Digital Growth division, and reporting to the Director of Technology, this role will be a key leader in the overall direction of the Information Technology portfolio.

MINISTRY FOCUS
Compassion Canada is a Christian organization, committed to being child-focused, Christ-centered, and church driven. As such, each employee of Compassion Canada shall:
Agree with Compassion Canada’s core documents, including a Statement of Faith.
Conduct themselves in a Christ-like manner at work and outside the workplace.
Participate in regular Staff Gatherings which include spiritual practices like worship, Scripture reading, and prayer.
Pray with staff or supporters when requested or deemed appropriate.

TASKS & RESPONSIBILITIES: WHAT YOU DO MATTERS
Provide leadership oversight to IT department ensuring efficiency, effectiveness, and provision of support and resource allocation to meet the needs of the organization.
Support the Director of Technology in organizational strategy development for Compassion Canada’s multi-year technology plans.
Collaborate with stakeholders to understand business requirements and develop technology strategies aligned with organizational goals and Epic priorities.
Design and architect end-to-end infrastructure solutions that meet business needs, considering factors such as scalability, security, and performance.
Lead the migration of on-premises infrastructure to the cloud, ensuring a seamless transition and optimal utilization of cloud services and cost.
Manage hybrid infrastructure environments, effectively integrating on-premises and cloud resources to maximize efficiency and flexibility.
Develop and implement cyber security strategy, policies, and procedures to protect organizational assets and mitigate cyber security risks.
Mentor and coach team members, fostering a culture of continuous learning and professional development.
Foster a creative and focused environment that models innovation, boldness and ideation.
Provide technical guidance and mentor the IT department ensuring infrastructure cloud solutions are implemented according to best practices and standards.
Manage all infrastructure and monitoring tools to enable ideal performance and ensure that components of the disaster recovery infrastructure and technical plans are maintained.
Manage vendor relationships and third-party service providers, ensuring adherence to service level agreements and quality standards.
Stay informed about industry trends, regulations, and best practices related to IT management, infrastructure cloud architecture, and cyber security, incorporating relevant insights into decision-making processes.
Manage all infrastructure and monitoring tools to enable ideal performance and ensure that components of the disaster recovery infrastructure and technical plans are maintained.
Evaluate emerging technologies and trends, recommending innovative infrastructure cloud solutions to enhance efficiency, effectiveness, and competitiveness.
Collaborate closely with Compassion International to ensure alignment on strategies and explore joint initiatives opportunities.
Support division outcomes and department/team with other duties as requested.

KNOWLEDGE, SKILLS & ABILITIES: WHO YOU ARE MATTERS
Experience working in AWS (Amazon Web Services) and Okta.
Senior level experience with IT infrastructure both on premise and cloud.
Strong background in infrastructure cloud architecture, with expertise in designing and implementing complex, enterprise-level infrastructure cloud solutions.
Experience in migrating on-premises infrastructure to the cloud, end user computing and managing hybrid infrastructure environments.
Demonstrated expertise in developing and implementing disaster recovery, cyber security strategy, policies, and procedures.
Experienced in the implementation of standardized processes, reports, and procedures across large organizations,
Skilled in balancing a long-term project & data roadmap with the real-time needs of an agile and innovative organization,
Demonstrated capacity to collaborate with cross functional teams on multiple projects simultaneously.
Possess strong analytical and problem-solving abilities, with a keen attention to detail.
Excellent written, verbal, and visual presentation skills with capability to interact with all levels within the organization and for multiple external audiences.

EDUCATION & EXPERIENCE REQUIRED: WHAT YOU BRING MATTERS
Post-secondary education or credential in Computer Science, Information Technology or related discipline required or minimum of five (5) years leadership experience in direct or related area.
Experienced ITIL framework
Cloud computing certification (AWS Certified Solutions Architect), continuous learning credentials or education in area of expertise is an asset.

The foregoing statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills.

We appreciate all applications for employment; however, we will only contact those applicants invited for an interview.

Please note, we will accommodate the needs of persons with disabilities in our hiring process. Should you require an accommodation during the hiring process or for this application, please contact Compassion Canada via email at accessibility@compassion.ca or call People & Culture Resources at (519) 668-0224.","{""role_summary"":""The IT Manager & Infrastructure Architect leads Compassion's IT department, driving innovative technology solutions and digital transformation. This role provides leadership oversight, develops technology strategies, and ensures efficient infrastructure solutions."",""key_terms"":[{""term"":""Cloud computing"",""explanation"":""The practice of using a network of remote servers accessed over the internet to store, manage, and process data.""},{""term"":""Cyber security"",""explanation"":""The practice of protecting computer systems, networks, and sensitive information from unauthorized access, use, disclosure, disruption, modification, or destruction.""},{""term"":""Infrastructure cloud architecture"",""explanation"":""The design and implementation of cloud-based infrastructure solutions that meet business needs, considering factors such as scalability, security, and performance.""},{""term"":""ITIL framework"",""explanation"":""A set of best practices for IT service management that focuses on aligning IT services with business needs.""},{""term"":""AWS (Amazon Web Services)"",""explanation"":""A cloud computing platform that provides a range of services including computing power, storage, databases, analytics, machine learning, and more.""}],""skill_priorities"":{""must_have"":[""Experience working in AWS (Amazon Web Services)"",""Senior level experience with IT infrastructure both on premise and cloud"",""Strong background in infrastructure cloud architecture"",""Experience in migrating on-premises infrastructure to the cloud"",""Demonstrated expertise in developing and implementing disaster recovery, cyber security strategy, policies, and procedures""],""nice_to_have"":[""Cloud computing certification (AWS Certified Solutions Architect)"",""Experienced ITIL framework"",""Continuous learning credentials or education in area of expertise""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with migrating on-premises infrastructure to the cloud, and how you ensured a seamless transition?"",""example_answer"":""In my previous role, I led a team that migrated our on-premises infrastructure to AWS, ensuring minimal downtime and optimal utilization of cloud services. We developed a comprehensive migration plan, conducted thorough testing, and provided training to end-users to ensure a smooth transition.""},{""question"":""How do you stay informed about industry trends and best practices in IT management, infrastructure cloud architecture, and cyber security?"",""example_answer"":""I regularly attend industry conferences, participate in online forums and discussion groups, and read relevant publications to stay up-to-date on the latest trends and best practices. I also network with peers and thought leaders in the field to gain insights and share knowledge.""}],""red_flags"":[""Lack of experience with AWS (Amazon Web Services)"",""Inadequate understanding of infrastructure cloud architecture"",""Insufficient experience in migrating on-premises infrastructure to the cloud""],""confidence_score"":90.0}"
National IT Manager,"Are you ready for a new and exciting leadership opportunity with one of the most successful logistics organizations worldwide? Here at Kuehne+Nagel, our Toronto office is looking for a new National IT Manager to join our IT team.

Your Role

As the National IT Manager, your primary objective will be to support the National Management team while ensuring global IT standards and policies are maintained and implemented. You will oversee a team of local IT Specialists with the goal of representing our Canada team, while focusing on our US objectives. You will report directly to the National Finance Manager

Your Responsibilities

To lead a team of IT support engineers through various projects + daily tasks.
To be responsible for all local IT activities within your cluster/country
To take charge as the primary IT contact within area of responsibility supporting all IT demands + engaging with the appropriate supply teams
To ensure that all IT infrastructure is supported + managed appropriately to deliver a highly resilience working platform
To manage + review all local supplier contracts + negotiations
To take responsibility for all IT security + data protection + ensure compliance to the global standards
To manage the budget if local IT as approved by the local, NAM and global management
To identify cost savings, as well as process improvements + best practices on a continuous basis

If you require an accommodation for the recruitment /interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.

Your Skills And Experiences

Bachelor's Degree in Computer Science or similar
5+ Years of experience in similar role with strong leadership experience
Strong knowledge and background in IT Management with stakeholder management experience
Great project management skills, including organization, planning, time management and prioritization
IT Certifications (CCNA,PMP, MSCE, TIA A+) would be an asset

Good Reasons to Join

There has never been a better time to work in logistics. Bring your skills to an industry that offers stability and international career growth. We offer a great compensation and medical/dental benefits package, employee discounts, tuition reimbursement, excellent training programs, and a fun, and interesting global work environment.","{""role_summary"":""Lead a team of IT support engineers, manage local IT activities, and ensure global IT standards and policies are implemented, while supporting the National Management team."",""key_terms"":[{""term"":""IT infrastructure"",""explanation"":""The underlying systems and technology used to support the organization's IT needs.""},{""term"":""Stakeholder management"",""explanation"":""The process of identifying, analyzing, and prioritizing the needs of various groups or individuals impacted by a project or initiative.""},{""term"":""CCNA"",""explanation"":""Cisco Certified Network Associate, a certification for networking professionals.""},{""term"":""PMP"",""explanation"":""Project Management Professional, a certification for project managers.""},{""term"":""MSCE"",""explanation"":""Microsoft Certified Solutions Expert, a certification for IT professionals with expertise in Microsoft solutions.""},{""term"":""TIA A+"",""explanation"":""CompTIA A+, a certification for IT professionals with expertise in computer hardware, software, and networking.""}],""skill_priorities"":{""must_have"":[""Bachelor's Degree in Computer Science or similar"",""5+ Years of experience in similar role with strong leadership experience"",""Strong knowledge and background in IT Management"",""Great project management skills""],""nice_to_have"":[""IT Certifications (CCNA,PMP, MSCE, TIA A+)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with IT infrastructure management and how you ensured high resilience?"",""example_answer"":""In my previous role, I managed a team that implemented a cloud-based infrastructure, which increased our uptime by 99.9%. I worked closely with the supply team to ensure seamless integration and developed a comprehensive disaster recovery plan.""},{""question"":""How do you prioritize and manage multiple projects simultaneously?"",""example_answer"":""I use Agile project management methodologies to prioritize tasks and allocate resources. I also conduct regular status updates with stakeholders to ensure everyone is aligned and informed.""}],""red_flags"":[""Lack of experience in managing local IT activities"",""Inability to prioritize and manage multiple projects""],""confidence_score"":85.0}"
Delivery Manager IT - Permanent Role,"Delivery Manager – IT – Permanent Role On behalf of our client in the Professional Services Sector, PROCOM is looking for a Delivery Manager - IT.
Delivery Manager - IT - Job Description

Our client in Guelph, Ontario is seeking a highly skilled IT Delivery Manager to lead the implementation of IT projects with a focus on cloud migration and on-premises solution delivery
This senior role requires a candidate with a deep understanding of application support management, strong IT service management, and exceptional people management skills
The ideal candidate will have proven experience in migrating legacy applications to modern cloud-based solutions, particularly on the Azure platform


Delivery Manager - IT - Mandatory Skills

4-5 years of experience as a Scrum Master/Delivery Manager
5+ years in software development, project management, or business analysis
Proven experience with cloud platforms, particularly Azure
Expertise in migrating on-premises solutions and legacy applications to modern platforms
Excellent communication skills, both verbal and written, including presentation and facilitation skills
Proficiency in Project Management and team collaboration tools (e.g., JIRA, Confluence, Figma)
Certified Advanced Scrum Master/PMP Certification or equivalent
Ability to adapt quickly to changing priorities and influence others without authority
Outcomes-focused mindset


Delivery Manager - IT- Preferred Skills

Experience with Agile UX Management Framework and Agile techniques (e.g., User Stories, Burndown techniques, A/B Testing, Lean Startup)
UX certifications (e.g., Certified UX Professional, Nielsen Norman Group UX Certification)
Proficiency in cloud infrastructure as code (IaC) tools (Terraform, CloudFormation)
Experience with DevOps tools and practices, including CI/CD pipelines, automation tools (Jenkins, GitLab CI), and containerization (Docker, Kubernetes)
Knowledge of security best practices and compliance standards (ISO 27001, NIST, GDPR)
Strong background in IT Service Management frameworks (ITIL 4, SIAM)
Ability to leverage analytics tools (Power BI, Tableau) for reporting and decision-making


Delivery Manager - IT - Assignment Start Date ASAP – Permanent Role
Delivery Manager - IT - Assignment Location Guelph, ON – Work Hybrid","{""role_summary"":""Lead IT projects with a focus on cloud migration and on-premises solution delivery, requiring strong IT service management, people management, and cloud platform expertise."",""key_terms"":[{""term"":""Cloud migration"",""explanation"":""The process of moving applications and data from on-premises infrastructure to cloud-based infrastructure.""},{""term"":""Azure platform"",""explanation"":""A cloud computing platform and set of services offered by Microsoft.""},{""term"":""Scrum Master"",""explanation"":""A facilitator of Scrum, a framework for managing and completing complex projects.""},{""term"":""IT service management"",""explanation"":""The implementation and management of quality IT services that meet business needs.""},{""term"":""Agile UX Management Framework"",""explanation"":""A framework for managing user experience in Agile development environments.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""ITIL 4"",""explanation"":""A framework for IT service management that provides best practices for delivering high-quality IT services.""}],""skill_priorities"":{""must_have"":[""4-5 years of experience as a Scrum Master/Delivery Manager"",""5+ years in software development, project management, or business analysis"",""Proven experience with cloud platforms, particularly Azure"",""Expertise in migrating on-premises solutions and legacy applications to modern platforms"",""Excellent communication skills"",""Proficiency in Project Management and team collaboration tools"",""Certified Advanced Scrum Master/PMP Certification or equivalent""],""nice_to_have"":[""Experience with Agile UX Management Framework and Agile techniques"",""UX certifications"",""Proficiency in cloud infrastructure as code (IaC) tools"",""Experience with DevOps tools and practices"",""Knowledge of security best practices and compliance standards"",""Strong background in IT Service Management frameworks"",""Ability to leverage analytics tools for reporting and decision-making""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with cloud migration projects, particularly on the Azure platform?"",""example_answer"":""I led a team that successfully migrated a legacy application to Azure, resulting in a 30% reduction in costs and a 25% increase in application performance.""},{""question"":""How do you ensure effective communication and collaboration among team members and stakeholders?"",""example_answer"":""I use agile methodologies and tools like JIRA and Confluence to facilitate collaboration and ensure that all stakeholders are aligned on project goals and objectives.""}],""red_flags"":[""Lack of experience with cloud platforms, particularly Azure"",""Inability to adapt quickly to changing priorities"",""Poor communication and collaboration skills""],""confidence_score"":90.0}"
"Manager, Systems Administration","Ontario Medical Supply is a Leading Distributor of medical equipment, supplies, and services for healthcare organizations and home healthcare clients across Ontario. Specializing in long term care, assisted living, retirement and home health care. Ontario Medical Supply is partnered for success with Royal Drugs. Royal Drugs is a healthcare company providing specialty pharmacy, infusion therapy, and retail pharmacy services. Together, we work towards supporting optimal health outcomes and better quality of life.

Come Join Our Team!

Purpose:
The primary goal of the Manager, Systems Administration is to ensure the company’s IT infrastructure meets the needs of the organization, is secure and dependable. The Manager, Systems Administration plays a critical role, in cooperation with other members of the IT team, in maintaining and constantly improving systems and technologies that support business operations.
The organization’s IT infrastructure currently supports more than 10 locations with additional locations being added due to growth. Our main location in Ottawa includes an on-premises server room.

Location: Ontario Medical Supply (OMS) – Ottawa, ON or Markham, ON
Reports to: Senior Director, Information Technology
No. of Positions: 1
ATR: 4550
Type: Full time, Permanent
Salary: Salary, commensurate with experience
Benefits: Yes

Job Responsibilities:
Define, manage, maintain, and implement IT infrastructure including servers and networks
Manage physical servers and server virtualization (VMWare and Hyper-V)
Server operating systems (primarily Windows, some Linux)
Manage server storage systems
Manage networks including LAN/WAN, firewalls, routers, switches, Wi-Fi, cabling
Configure and administer Active Directory in an M365 environment
Configure and maintain the M365 email system
Work with external vendors and internal IT staff to manage and improve IT security
Manage and implement phone systems across all locations
Participate in various IT projects
Evaluate and recommend hardware and software upgrades, as well as plan and design future infrastructure growth
Backups and disaster recovery solutions
Create and maintain system and network documentation
Ensure standards and procedures are up to date and enforced to support management of IT assets and adhering to compliance requirements
Vendor and contract management

Qualifications:
Minimum 5 years’ experience in IT infrastructure management
An in-depth understanding of a variety of IT systems, hardware, and software is essential
Experience managing IT infrastructure projects
Experience managing and mentoring technical staff
Planning and organizational skills including the ability to plan, coordinate, prioritize and monitor projects and day to day maintenance and support activities
Solid understanding of virtualization technology (VMWare and Hyper-V)
Solid understanding of network and security monitoring tools
Experience working with a SAN (iSCSI and Fiber Channel)
Understanding of network protocols, including TCP/IP, DHCP, DNS, VPN
Excellent problem solving, analytical skills, technical skills and attention to detail
Excellent interpersonal skills working with business team leaders and business users at all levels of the organization
Communicates effectively verbally and in written form
A passion to learn the business and use their skills to improve business outcomes
Understand the business goals and objectives to ensure alignment of IT priorities with business priorities
A desire to make a difference in the growth and success of the organization
A belief in continuous learning and an interest in new technologies

Other:
Must be available for on-call support during evenings and weekends on a rotating schedule
Travel to our various locations will be required

While we thank you for your interest, only select applicants will be contacted regarding the position.

Ontario Medical Supply is an inclusive and equal opportunity employer committed to providing diversity and accommodations for applicants upon request at any stage of the recruitment process in accordance with the Accessibility for Ontarians with Disabilities Act (AODA) and the Ontario Human Rights Code. All applicants must make their requirements known when contacted.","{""role_summary"":""The Manager, Systems Administration ensures the company's IT infrastructure meets organizational needs, is secure, and dependable, maintaining and improving systems and technologies to support business operations."",""key_terms"":[{""term"":""Server virtualization"",""explanation"":""A technology that allows multiple virtual servers to run on a single physical server, improving resource utilization and flexibility.""},{""term"":""M365 environment"",""explanation"":""A suite of Microsoft cloud-based productivity and collaboration tools, including Office 365, SharePoint, and Teams.""},{""term"":""SAN (iSCSI and Fiber Channel)"",""explanation"":""A Storage Area Network that connects storage devices to servers, providing high-speed data transfer and storage consolidation.""},{""term"":""TCP/IP, DHCP, DNS, VPN"",""explanation"":""Fundamental network protocols that enable communication, routing, and security in computer networks.""}],""skill_priorities"":{""must_have"":[""IT infrastructure management"",""Server operating systems (Windows, Linux)"",""Network management (LAN/WAN, firewalls, routers, switches, Wi-Fi)"",""Virtualization technology (VMWare and Hyper-V)"",""Network and security monitoring tools"",""Project management and planning""],""nice_to_have"":[""Experience with M365 environment"",""Knowledge of SAN (iSCSI and Fiber Channel)"",""Understanding of network protocols (TCP/IP, DHCP, DNS, VPN)""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach implementing a new server virtualization solution in our organization?"",""example_answer"":""I would start by assessing our current infrastructure and identifying areas where virtualization can improve resource utilization and reduce costs. Then, I would design and implement a virtualization solution using VMWare or Hyper-V, ensuring seamless integration with our existing systems and minimal downtime.""},{""question"":""Can you describe your experience with network security monitoring tools?"",""example_answer"":""In my previous role, I used tools like Nagios and SolarWinds to monitor network traffic, identify potential security threats, and implement measures to prevent breaches. I'm confident in my ability to set up and maintain a robust network security monitoring system.""}],""red_flags"":[""Lack of experience with server virtualization technologies"",""Inability to manage and mentor technical staff"",""Insufficient understanding of network protocols and security monitoring tools""],""confidence_score"":85.0}"
"IT Service Delivery Manager, NA","Please scroll down for the English version***

Si vous êtes un professionnel de l'informatique possédant de vastes compétences en gestion de projet, ceci est votre opportunité de rejoindre un leader mondial de l’industrie

La décision entourant le choix de votre prochain employeur ne doit pas être prise à la légère. Si vous désirez travailler aux premières lignes du développement de nouveaux procédés et produits qui permettront de façonner diverses industries, continuez votre lecture pour voir ce que nous vous offrons!

Nous avons bâti notre équipe gagnante en investissant continuellement dans le perfectionnement des compétences, le leadership et le mieux-être. Appliquez votre expertise pour faire avancer votre carrière en tant que responsable de la livraison des technologies de l'information (TI) chez Valmet.

Le responsable de la livraison des TI est responsable de la mise en œuvre, de la livraison et du support des solutions informatiques qui font progresser Valmet Business. Vous superviserez la conception, le développement et les tests des systèmes informatiques afin qu'ils répondent aux besoins commerciaux actifs et futurs de l'organisation. Vos responsabilités consisteront notamment à diriger des initiatives stratégiques et à assurer le bon fonctionnement des fonctions quotidiennes. Les responsabilités incluent également l'audit de qualité de ces services et solutions dans la zone Amérique du Nord tout en collaborant étroitement avec l'entreprise et l'équipe informatique mondiale dans le monde entier.

Attentes

Les candidats bien qualifiés posséderont un baccalauréat en informatique ou un diplôme technique connexe combiné à des diplômes et certifications professionnels liés à l’informatique. Solide compétences in leadership et un minimum de 5 ans d'expérience professionnelle dans la fourniture de solutions informatiques grâce à des initiatives d'amélioration continue efficaces avec une expérience avérée dans la mise en œuvre du changement.

La gestion de projet avec les certifications associées, les politiques de pointe et la formation d'un large éventail de publics seront considérées comme un atout majeur.

Ce poste nécessite une excellente maîtrise de la langue anglaise puisqu’il s’agit de notre langue commerciale commune utilisée dans le monde entier. Ce poste nécessite la capacité d'apporter un support à nos clients, tant virtuellement qu'en se déplaçant occasionnellement sur nos sites situés en Amérique du Nord. Il sera nécessaire pour certains projets de s'adapter à la disponibilité de nos collègues situés dans d'autres fuseaux horaires.

Nous offrons

Nous offrons un milieu de travail stimulant valorisant l’innovation, adapté aux personnes avides de perfectionnement, qui aiment travailler dans un environnement rapide et dynamique. Le poste inclut une généreuse rémunération et un ensemble d’avantages sociaux, y compris un Régime de Pension Agréé financé par la Compagnie.

Veuillez noter que toute offre d’emploi est conditionnelle à une vérification des antécédents.

Renseignements supplémentaires

Livrer des technologies et des services compétitifs, c’est ce que nous faisons de mieux. Chez Valmet, nous continuons à avancer et à nous perfectionner, tout en nous concentrant sur la technologie, les services, des pratiques durables, notre présence locale et nos gens.

Pour être inclus dans le processus de recrutement, veuillez nous présenter votre demande directement en ligne. Pour de plus amples renseignements, veuillez contacter Agda Feio par courriel au agda.feio@valmet.com

Veuillez noter que Valmet ne demandera jamais d'informations financières personnelles pendant le processus d'entrevue. Si vous pensez avoir été victime d'une escroquerie en matière d'offre d'emploi en ligne, veuillez en informer la Federal Trade Commission des États-Unis ou le Centre Ant-Fraude du Canda.

Quand tout fonctionne harmonieusement

Valmet est l’endroit où se réunissent les meilleurs talents d’un grand nombre de disciplines. Avec nos 19 000 professionnels partout dans le monde, nous sommes le chef de file mondial des développeurs et fournisseurs de technologies, d’automation et de services pour les industries des pâtes et papiers et de l’énergie. Notre engagement à faire avancer le rendement de nos clients exige de la créativité, des innovations technologiques, du savoir-faire dans le service et, surtout, du travail d’équipe. Joignez-vous à l’équipe!  https://www.valmet.com/fr

Veuillez défiler vers le haut pour la version française***

If you are an IT professional with extensive project management skills, this is your opportunity to join a global industry leader.

Deciding on a new career within Valmet can be an exciting prospect. Every day there are teams of Valmet employees around the world who share the feeling of achieving something great – that feeling when everything works together.

Our winning team is built by continuous investment in skills development, leadership, and well-being. As a global company, we offer many career paths to suit individual needs and aspirations. Apply your expertise to further your career as an Information Technology (IT) Delivery Manager at Valmet.

The IT Service Delivery Manager is responsible for the implementation, delivery and support of IT solutions that drive Valmet Business forward. You will oversee the design, development, and testing of IT systems so that they meet the organization's active and future business needs. Your responsibilities will include leading strategic initiatives and ensuring the smooth operation of daily functions. Responsibilities also include the quality audit of these services and solutions in the North America Area while collaboration closely with the business and the Global IT Team worldwide.

Expectations

Well qualified candidates will possess a Bachelor’s Degree in Computer Science or a related technical degree combined with IT business-related professional degrees and certifications. You have strong leadership skills with minimum of 5 years of work experience in delivering IT solutions through effective continuous improvement initiatives with a proven track record in implementing change.

Project Management with related certifications, leading policies and training a diverse range of audiences will be considered as a strong asset.

This position requires excellent command of the English language since it is our common business language used worldwide. This position requires the ability to provide support to our customers, both virtually and by occasionally traveling to our sites located in North America. It will be necessary for certain projects to accommodate the availability of our colleagues located in other time zones.

Please note that any offer of employment is contingent upon a background check.

We offer

We offer a challenging work environment that values innovation and suits development-minded people who enjoy working in a fast-paced and dynamic setting. Includes a generous wage and benefits package that includes a company-funded pension plan.

Please note that any offer of employment is contingent upon a background check.

Additional Information

Delivering competitive technologies and services is what we do best. At Valmet, we continue to push forward and develop ourselves, concentrating on technology, services, sustainability, local presence, and our people.

To be included in the recruiting process, please apply directly with us online. For more information please reach out to Agda Feio at agda.feio@valmet.com

Please note that Valmet will never ask for personal financial information during the interview process. If you feel you have been a victim of an online job posting scam, please notify the US Federal Trade Commission or the Canadian Anti-Fraud Centre.

When everything works together

Valmet is where the best talent from a wide variety of backgrounds comes together. With 19,000 professionals around the world, we are the leading global developer and supplier of technologies, automation and services for the pulp, paper, and energy industries. Our commitment to moving our customer’s performance forward requires creativity, technological innovations, service know-how – and above all, teamwork. Join the team! www.valmet.com/careers","{""role_summary"":""The IT Delivery Manager is responsible for implementing, delivering, and supporting IT solutions that drive business forward, overseeing design, development, and testing of IT systems to meet business needs."",""key_terms"":[{""term"":""IT Service Delivery"",""explanation"":""The process of planning, designing, delivering, and managing IT services to meet business needs.""},{""term"":""Continuous Improvement"",""explanation"":""A methodology for identifying and implementing opportunities to improve processes, products, or services.""},{""term"":""Project Management"",""explanation"":""The process of planning, organizing, and controlling resources to achieve specific goals and objectives.""}],""skill_priorities"":{""must_have"":[""Bachelor's Degree in Computer Science or related technical degree"",""Minimum 5 years of work experience in delivering IT solutions"",""Strong leadership skills"",""Excellent command of the English language""],""nice_to_have"":[""Project Management certifications"",""Leading policies and training experience"",""Experience in implementing change""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience in delivering IT solutions through continuous improvement initiatives?"",""example_answer"":""In my previous role, I led a team that implemented a new IT system, resulting in a 30% increase in efficiency and a 25% reduction in costs.""},{""question"":""How do you ensure the smooth operation of daily functions in an IT service delivery team?"",""example_answer"":""I prioritize tasks, delegate responsibilities, and establish clear communication channels to ensure that all team members are aligned and working towards common goals.""}],""red_flags"":[""Lack of experience in IT service delivery"",""Inability to work in a fast-paced and dynamic environment"",""Poor command of the English language""],""confidence_score"":90.0}"
Senior IT Systems Administrator,"Saltworks Technologies (Richmond, BC) is a global technology leader in advanced industrial wastewater treatment and lithium refining. Our innovative machines produce clean water from high-strength industrial discharges and refine lithium to support the energy transition. We offer meaningful and exciting work in a collaborative environment, driven by innovation and problem-solving. We're a fast-growing cleantech company offering exceptional career opportunities, driven by major global trends.

The Role

We have an immediate opening for a Senior IT Systems Administrator. In this role, you will be instrumental in ensuring the seamless operation of our IT infrastructure. You will be responsible for managing and maintaining our network, servers, and client systems, while also helping ensure network security to protect our data and operations.

This is an onsite role at our office in Richmond, BC, with limited opportunity for remote work. You must be located in or be willing to relocate to the Lower Mainland.

System Administration

Your primary areas of responsibility are:

Install, configure, deploy, and maintain Windows and Linux client/server systems and virtual machines.

Configure and maintain Microsoft 365 environment.

Administer various software and hardware assets, including on-premise, cloud and hybrid, as well as enterprise software systems.

Install, configure, repair, upgrade, and maintain networking and end-user devices.

Network Security

Ensure network security and stability across local and cloud-based environments.

Implement and oversee security protocols to safeguard data and network operations.

Conduct regular system audits to detect vulnerabilities and mitigate risks.

Maintain data backups to ensure data integrity and availability.

Technical Support

Provide direct technical support for IT infrastructure, ongoing and new projects, and end-user issues.

Resolve technical challenges promptly and efficiently in compliance with company policies.

Project Management

Collaborate with IT Manager and project stakeholders to plan and execute system upgrades, migrations, and new technology deployments.

Coordinate with vendors and service providers to ensure timely delivery of products and services as needed.

You Will Be a Great Fit If You Have

A degree, diploma, or certificate in Information Technology or related field.

Minimum of 5 years of experience in system and network administration on-premise and in the cloud, including but not limited to Microsoft 365, Microsoft VMs, Cloud Services, Hybrid Environments, MDM, Entra, Intune, Web Servers, Clusters, Storage Management, AD, Remote Access, ZTNA, and Linux systems.

Proven experience supporting IT systems in a corporate or other business environment with 50+ users is a must.

Experienced in automating day-to-day IT administration related tasks.

Experience With PowerShell, Bash, And Other Scripting Languages.

Proven hands-on experience in deploying Networks, Equipment, Servers, VMs, Access Control Solutions, GP, device mass deployment and configuration, RMM (Remote Management and Monitoring) systems, Backup Solutions, Ticketing Systems, managing users in Hybrid Environment, SharePoint, etc.

Excellent troubleshooting skills, ability to manage multiple projects simultaneously, exercise critical thinking, and preventative damage control.

Excellent verbal and written communication skills in English.

Ability to lead and deploy assigned projects or tasks independently.

The Following Qualifications Are Preferred But Not Required

Experience with database administration tasks for SQL Server and other databases.

Proficiency in coding and dev-ops tools, especially PHP, Python, SQL, Git, and Docker.

Why join Saltworks?

We have an outstanding team that is passionate about innovation and solving key environmental challenges facing our planet.

Join a team pioneering the future of water. Some of our customers include world-leading electric vehicle makers, semiconductor firms, mining companies, agriculture firms, and more!

We Offer

A collaborative and rewarding work environment.

Opportunities to advance technically or in leadership roles.

A competitive compensation package that includes medical, dental, vision, RRSP matching, life insurance, AD&D coverage, and an education allowance.

A culture that supports safety, innovation, learning, diversity, and teamwork.

Fun social activities and company events.

How To Apply

If you would like to be a part of a globally recognized team, please submit your resume (cover letters are not required).

While we sincerely appreciate all applications, only those candidates selected for an interview will be contacted. All applications are considered confidential.

Kindly, no recruiters.

INDS

0SpDUpKvUI","{""role_summary"":""The Senior IT Systems Administrator is responsible for ensuring the seamless operation of the company's IT infrastructure, including managing and maintaining networks, servers, and client systems, as well as ensuring network security and providing technical support."",""key_terms"":[{""term"":""Microsoft 365"",""explanation"":""A cloud-based productivity suite that includes email, word processing, and collaboration tools.""},{""term"":""Virtual Machines"",""explanation"":""Software that mimics the functionality of a physical computer, allowing multiple operating systems to run on a single machine.""},{""term"":""Cloud Services"",""explanation"":""On-demand computing resources and services provided over the internet, allowing for scalability and flexibility.""},{""term"":""Hybrid Environments"",""explanation"":""A combination of on-premise and cloud-based infrastructure, allowing for flexibility and scalability.""},{""term"":""MDM"",""explanation"":""Mobile Device Management, a set of policies and technologies used to manage and secure mobile devices in an enterprise environment.""},{""term"":""Entra"",""explanation"":""A cloud-based identity and access management platform, providing secure access to applications and resources.""},{""term"":""Intune"",""explanation"":""A cloud-based endpoint management platform, providing secure access to applications and resources.""},{""term"":""Web Servers"",""explanation"":""Software that hosts and serves websites, providing access to web-based applications and resources.""},{""term"":""Clusters"",""explanation"":""A group of computers or nodes that work together to provide high availability, scalability, and performance.""},{""term"":""Storage Management"",""explanation"":""The process of managing and maintaining data storage systems, ensuring data integrity and availability.""},{""term"":""AD"",""explanation"":""Active Directory, a directory service that provides authentication, authorization, and identity management for Windows-based networks.""},{""term"":""Remote Access"",""explanation"":""The ability to access and control a computer or network from a remote location, often using virtual private networks (VPNs) or remote desktop protocols (RDPs).""},{""term"":""ZTNA"",""explanation"":""Zero Trust Network Access, a security approach that assumes no user or device is trusted, and verifies the identity and permissions of all users and devices before granting access to resources.""},{""term"":""PowerShell"",""explanation"":""A task automation and configuration management framework from Microsoft, consisting of a command-line shell and scripting language built on top of .NET.""},{""term"":""Bash"",""explanation"":""A Unix shell and command-line interpreter, used for executing commands and scripting tasks.""}],""skill_priorities"":{""must_have"":[""System and network administration"",""Microsoft 365"",""Microsoft VMs"",""Cloud Services"",""Hybrid Environments"",""MDM"",""Entra"",""Intune"",""Web Servers"",""Clusters"",""Storage Management"",""AD"",""Remote Access"",""ZTNA"",""PowerShell"",""Bash""],""nice_to_have"":[""Database administration"",""Coding and dev-ops tools"",""PHP"",""Python"",""SQL"",""Git"",""Docker""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with Microsoft 365, and how have you implemented it in previous roles?"",""example_answer"":""I have implemented Microsoft 365 in my previous role, and I have experience with configuring and maintaining the environment. I have also worked with Microsoft VMs and Cloud Services, and I am familiar with Hybrid Environments.""},{""question"":""How do you approach network security, and what measures do you take to ensure data integrity and availability?"",""example_answer"":""I approach network security by implementing security protocols and conducting regular system audits to detect vulnerabilities and mitigate risks. I also maintain data backups to ensure data integrity and availability.""},{""question"":""Can you give an example of a time when you had to troubleshoot a technical issue, and how you went about resolving it?"",""example_answer"":""In my previous role, I encountered an issue with a server that was causing downtime for our users. I used my troubleshooting skills to identify the root cause of the issue and implemented a solution that resolved the problem and minimized downtime.""}],""red_flags"":[""Lack of experience with Microsoft 365 and related technologies"",""Inability to work independently and lead projects"",""Poor troubleshooting skills""],""confidence_score"":90.0}"
"Associate Manager, IT - Release Management","Job Description

The Associate Manager Release Management will be a key component of the IT ERP Capabilities Team. The role will implement and report against KHC Release Management principles.

Primary Responsibilities

Develop and maintain release management standards and documentation.
Ensure adherence to Kraft Heinz global IT standards and procedures while employing continuous improvement of Release Management processes, tools and repositories
Manage SAP outages with cross functional global teams and provide appropriate communication including associated impacts
Coordinate cutover through SAP landscape (F/D->Prod)
Facilitate Hypercare for major releases, implementations, and other projects
Leads monthly releases including coordination with Change Management and Test Hub
Perform routine transport management activities including guidance and approvals
Contribute to development of annual and forward planning release calendars including publication and communication of changes
Participate in CAB, GCC, etc. to provide input and guidance as pertains to Release Management, including presentations as applicable.
Maintain relationships and orchestrate work between different teams at different locations during cutover and project release activities.
Provide release reporting metrics and follow-up of over-due / abandoned items.
Maintain release repositories including associated documentation (timelines, build metrics, testing, status reporting, etc.)


Additional contributions, with possibilities to lead, include

Present release status at weekly Leadership meetings
Identifying and reporting upon release risks/issues identified from Release perspective
Identify and define release scope with IT leads and Project Managers
Communicate all key project plans, commitments, and changes including requirements, QA plans, schedule, and scope changes
Report upon and conduct Release Readiness reviews, Milestone Reviews, and Business Go/No-Go reviews
Define, coordinate and facilitate Technical Go-live activities per plans and checklists


Appetite for Success

Project & Process Management
Vendor Relationship Management
Influencing and Negotiating
Acting as an Owner
Problem solving and Critical thinking
Thrive in a results-driven environment
Effective communication and troubleshooting skills, relationship building skills, and work effectively in a team environment with both local and remote teams
Advanced interpersonal, oral, and written communication skills, and able to multitask effectively


Qualifications

Team Leadership and management of cross functional teams
Experiences working in multinational companies operating in the consumer goods environment
Proven track record of successful assignments and positive results
Support through different time zones with geographically dispersed teams and clients
Experience with testing methodology, subject areas and activities, including test planning, preparation, execution and reporting
Strong leadership capabilities and excellent interpersonal, verbal and written communication skills
Experience in handling and leading escalations and managing resolution of critical issues
Experience in coordination with PMO and aligning on methodology and process
Experience in HP Quality Center is highly preferred
SAP S4 and Legacy application knowledge a plus.


Location(s)

Toronto - Queen's Quay - Headquarters

Kraft Heinz is an Equal Opportunity Employer – Underrepresented Ethnic Minority Groups/Women/Veterans/Individuals with Disabilities/Sexual Orientation/Gender Identity and other protected classes. In order to ensure reasonable accommodation for protected individuals, applicants that require accommodation in the job application process may contact NATAI@kraftheinz.com for assistance.","{""role_summary"":""The Associate Manager Release Management is responsible for implementing and reporting against release management principles, ensuring adherence to global IT standards, and managing SAP outages and releases."",""key_terms"":[{""term"":""Release Management"",""explanation"":""The process of planning, coordinating, and controlling the movement of changes to IT systems and services.""},{""term"":""SAP"",""explanation"":""Systems, Applications, and Products in Data Processing, a type of enterprise resource planning software.""},{""term"":""Hypercare"",""explanation"":""A period of intense support and monitoring after a major release or implementation to ensure stability and resolve any issues.""},{""term"":""CAB"",""explanation"":""Change Advisory Board, a group that reviews and approves changes to IT systems and services.""},{""term"":""GCC"",""explanation"":""Global Change Committee, a group that reviews and approves global changes to IT systems and services.""}],""skill_priorities"":{""must_have"":[""Project & Process Management"",""Vendor Relationship Management"",""Influencing and Negotiating"",""Acting as an Owner"",""Problem solving and Critical thinking"",""Effective communication and troubleshooting skills"",""Relationship building skills"",""Team Leadership and management of cross functional teams"",""Experience working in multinational companies operating in the consumer goods environment"",""Proven track record of successful assignments and positive results""],""nice_to_have"":[""Experience with testing methodology"",""Experience in HP Quality Center"",""SAP S4 and Legacy application knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with release management principles and how you would implement them in this role?"",""example_answer"":""I have previously worked on implementing release management principles in a similar IT environment, ensuring adherence to global standards and procedures. I would develop and maintain release management standards and documentation, and ensure continuous improvement of release management processes, tools, and repositories.""},{""question"":""How would you manage SAP outages and releases, and what communication strategies would you use?"",""example_answer"":""I would manage SAP outages and releases by coordinating with cross-functional global teams, providing appropriate communication including associated impacts, and facilitating Hypercare for major releases, implementations, and other projects. I would use clear and concise communication strategies to ensure all stakeholders are informed and aligned.""}],""red_flags"":[""Lack of experience in multinational companies operating in the consumer goods environment"",""Inability to work effectively in a team environment with both local and remote teams"",""Limited experience with testing methodology and subject areas""],""confidence_score"":90.0}"
IT Manager - Manufacturing environment,"Position: IT Manager - Manufacturing environment

Location: Laval

Are you and IT Manager who has previously worked in a manufacturing environment? Are you looking for a role where you can guide and coach a team of IT professionals, if so, please read on.

Our partner is looking to hire an IT Manager to manage a small team. In this role you will be asked to bring your expertise and help select an ERP system as well as work on many projects.

Requirements For This Role

4 years of IT management
Must have worked in a manufacturing environment
Strong knowledge of ERP systems
Ability to work onsite at their Laval location
French communication skills must be excellent.


Advantages For You

Dental insurance
Disability insurance
Supplementary health insurance
Life insurance
Vision insurance
Discounted or free food
Employee assistance program
Group RRSP
On-site parking
Casual dress code


Please send your resume in Word format to Annick Wilson at annick.wilson@quantum-qtr.com .

REFER A PERM HIRE AND EARN $1,000! For more details, click here . Conditions apply.

OUR VIRTUAL DOORS ARE OPEN! We’re also bringing the interviews to you by various web applications, virtually! Contact us today for your next opportunity.

CNESST permit number: AP-2000414","{""role_summary"":""Manage a small team of IT professionals in a manufacturing environment, select an ERP system, and work on various projects."",""key_terms"":[{""term"":""ERP systems"",""explanation"":""Enterprise Resource Planning systems, used to manage and integrate business operations.""}],""skill_priorities"":{""must_have"":[""4 years of IT management"",""Experience in a manufacturing environment"",""Strong knowledge of ERP systems"",""Excellent French communication skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with ERP system implementation in a manufacturing environment?"",""example_answer"":""In my previous role, I led a team to implement an ERP system, which resulted in a 30% increase in operational efficiency.""},{""question"":""How do you approach team management and coaching in an IT team?"",""example_answer"":""I believe in regular feedback and coaching sessions, and I've seen a significant improvement in team performance when I've implemented this approach.""}],""red_flags"":[""Lack of experience in a manufacturing environment"",""Insufficient knowledge of ERP systems""],""confidence_score"":90.0}"
Information Manager,"Company Description

Ferrovial Construction Canada Inc. and VINCI Construction Grands Projects are undertaking the design, build, and finance the Ontario Line Southern Civil, Stations, and Tunnel (South Civil) package.

As Ontario Transit Group, we are now mobilizing our design and construction crews, with major works. The South Civil contract is anticipated to be completed in 2030.

The project will strengthen Ontario’s economy by supporting an estimated 1,500 jobs at the peak of construction.

What is the project?

A six-kilometer tunnel and associated tunnelling works from Exhibition to Don Yard portal (west of the Don River).
Stations:
One above-ground station to be integrated with the existing GO Transit Exhibition Station.
Two underground stations to be integrated with the existing TTC Osgoode and Queen subway stations.
Four new underground stations (King/Bathurst, Queen/Spadina, Moss Park, Corktown).
The benefits to Ontario!

Faster, more frequent, and reliable access to rapid transit with more than 227,500 people will live within a 10-minute walk of an Ontario Line station.

Improve the quality of life for commuters by reducing daily travel time.
Reduce crowding on the existing Line 1 (Yonge-University) subway.
Up to 57,000 more jobs accessible by transit (in 45 minutes or less) for Toronto residents.
Economic and community growth along the future transit line and thousands of job opportunities annually during construction.
Reduction in traffic congestion, greenhouse gases, and fuel consumption by providing an alternative transportation option.

Job Description

Ontario Line South Design & Construction project is a massive project happening in the heart of Toronto for the following 7 years. Along the project duration, large number of processes are happening in parallel, and several digital tools and platforms would be used in the design and construction of the project.

The Information Manager, reporting directly to the Digital Delivery Manager, will lead the information management requirements and processes implementation throughout all the project departments. Among other duties, with a internal strategic consultant approach, the Information Manager will lead a 3 key-steps process:

Identify: work jointly with department managers to detect processes that can be improved in the project
Simplify: work together with them to reduce to the minimum steps and propose a clear flowchart for bringing the process to the rest of the teams
Digitalize: prioritizing the project platforms and solutions, proposed the best approach to bring it into a digital process. From this point, the Information Manager should work together with the Data Management team to propose the best data models and data structure for reporting and data analytics processes.

Asite and Dalux Field are the official EDMS and Operational and Construction Management platforms across the project. The Information Manager will need to get familiar with these platforms and lead the implementation and deployment of the processes happening in them.

Additional Information Manager duties include:

Analyze and document using visual flowcharts for the different processes of the project
Definition of information standards and data models applicable to design and construction projects. Development of use cases and POCs for validating the schemas.
Creation of templates for different design and construction tools, for input and output data schemas, to link information from different processes and tools.
Development of logic schemas linked to existing standards and data ontologies, specially linked to 3D (BIM) and 2D (GIS) geometric references.
Being capable of standardizing initiatives approach, with strategic and analytic vision to understand project needs and providing value from the data that they or other departments generate.
Developing training content, both basic and more advanced levels for different adoption users.

Establish and prepare clear and concise documentation for the different standardized processes

Qualifications

Basic Qualifications

At least 5 years of experience in design and construction of big projects
Civil or Industrial engineering bachelor, or equivalent studies with real experience in design and construction projects
High Analytical Thinking and mindset, Problem Solving and Strategic Vision skills
High communication and meeting leadership skills
High experience with some flowchart, diagram and process visualization (MS Visio, Edraw, Miro)
High experience with Microsoft Office (Office 365, SharePoint, Power Platform)
Experience in EDMS systems administration such as SharePoint, Asite, Aconex, ACC
Experience in Power BI, PowerQuery, DAX and/or SQL
Experience in analysing BIM and GIS requirements of design and construction projects

Preferred Certifications

Any official Certification in any Microsoft Office 365 tools

Additional Information

We Offer:

Competitive Salary
Comprehensive Benefits Package:
Disability Insurance
Dental Insurance
Extended medical insurance
(Optional) RRSP matching
Discretionary Bonus

Why OTG?

Welcome to Ontario Transit Group (OTG), located in the heart of Downtown Toronto, where diversity and passion collide. As we work on the groundbreaking Ontario Line project, we prioritize fostering a positive culture. Join us and be part of a team that celebrates our employees, organizes family events, and promotes health and wellness initiatives. Our commitment to personal and professional growth means annual performance reviews, salary increases, comprehensive health benefits, generous RRSP matching, industry education support, and career development opportunities.

At OTG, we embrace diversity, recognizing that it strengthens us as a team and as a company. We are an equal-opportunity employer, encouraging applications from all interested candidates. We value Indigenous people, racialized people, neurodivergent people, people with disabilities, and individuals from gender and sexually diverse communities with intersectional identities. Reasonable accommodations are available upon request for people with disabilities. If you're ready to be part of our dynamic team in one of the world's most diverse cities, don't wait any longer—apply now!



While we appreciate your interest, only selected candidates will be contacted for interviews. Please note that we do not accept agency submissions.","{""role_summary"":""The Information Manager will lead the information management requirements and processes implementation throughout all project departments, identifying areas for improvement, simplifying processes, and digitalizing them using various platforms and tools."",""key_terms"":[{""term"":""EDMS"",""explanation"":""Electronic Document Management System, used for managing and storing project documents and data.""},{""term"":""BIM"",""explanation"":""Building Information Modelling, a digital representation of physical and functional characteristics of a building or infrastructure project.""},{""term"":""GIS"",""explanation"":""Geographic Information System, a system for capturing, storing, analyzing, and displaying geographically referenced data.""},{""term"":""Asite"",""explanation"":""A cloud-based construction management platform used for collaboration, data management, and project delivery.""},{""term"":""Dalux Field"",""explanation"":""A construction management platform used for operational and construction management, including field data collection and reporting.""}],""skill_priorities"":{""must_have"":[""At least 5 years of experience in design and construction of big projects"",""Civil or Industrial engineering bachelor, or equivalent studies with real experience in design and construction projects"",""High Analytical Thinking and mindset, Problem Solving and Strategic Vision skills"",""High communication and meeting leadership skills"",""High experience with some flowchart, diagram and process visualization (MS Visio, Edraw, Miro)"",""High experience with Microsoft Office (Office 365, SharePoint, Power Platform)""],""nice_to_have"":[""Any official Certification in any Microsoft Office 365 tools""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with EDMS systems administration, specifically with SharePoint, Asite, Aconex, and ACC?"",""example_answer"":""I have worked with SharePoint for 3 years, implementing document management and workflow automation for a large construction project. I'm familiar with Asite's collaboration and data management features, and I've used Aconex for project coordination and ACC for contract management.""},{""question"":""How do you approach process improvement and digitalization in a large-scale construction project?"",""example_answer"":""I identify areas for improvement through stakeholder engagement and process mapping. Then, I simplify the process by reducing unnecessary steps and propose a clear flowchart for implementation. Finally, I prioritize digital solutions and work with the Data Management team to develop data models and structures for reporting and analytics.""}],""red_flags"":[""Lack of experience with construction management platforms such as Asite and Dalux Field"",""Inability to communicate complex technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Information systems Technical Advisor,"Job title: Information systems Technical Advisor

Duration:1 year, extendable up to 3 years

Location: Halifax, Nova Scotia (Onsite)

Responsibilities

Analyze intricate technical challenges and recommend solutions
Provide technical guidance and best practices around solution implementations, upgrades, etc.
Design technical solutions and assist with the development of Detailed Architecture Design Documents
Plan and create the structure for technical solutions
Assist with evaluation and selection of software and hardware solutions
Suggest integration methods with other internal IT systems
Supervise the execution of projects/programs, including conducting code reviews
Gain an understanding of systems and interfaces in place at the client's organization and be able to identify cross impacts.
Lead resolution of technical issues - lead discussion with technical resources, drive to solution, engage project manager as needed, defect resolution, etc.
Guide software development teams and address technical concerns
Translate complex requirements into functional architecture
Offer guidance to technical team members
Ensure the implementation of agreed-upon architecture and infrastructure
Lead development of work effort estimates and plans for technical work (application and infrastructure) in collaboration with project manager
Play lead role in setting up development and test environments
Identify technical cross impacts with other projects or operational work
Identify any technical risks and contribution to risk response strategy
Review vendor engagements (SOW for technical aspects)
Engaged in all phases of the Software Development Life Cycle (SDLC) including client interactions, requirements gathering, application design, development, testing, debugging, deployment, maintenance, and enhancements
Participate in the investigation of opportunities for improvement and make recommendations. May consult technical equipment/software vendors and current users in these evaluations
Stay up-to-date with the latest technology trends and developments
Conduct transition to operations with operational teams
Other duties as required.

Qualifications

Minimum education level of a University Degree or equivalent College diploma with combined work experience
Previous work as a technical architect
Familiarity with coding languages
Understanding of various operating systems
Familiarity with Cloud technologies
Strong leadership and team building skills
Strong decision making and conflict management skills. Ability to coach, motivate, build trust, negotiate and communicate

Whopper Technologies, a minority women-owned enterprise, is at the forefront of digital transformation, technology excellence, and business growth solutions. Specializing in talent mobilization and innovation, we are dedicated to enhancing customer experiences across diverse sectors such as Information Technology, Telecommunications, Healthcare, Engineering, and the Public sector. With a focus on deploying top-tier talent and fostering innovation, we empower businesses to thrive and excel in a rapidly evolving digital landscape, helping them reach new heights of success.

Whopper Technologies is committed to fostering workforce diversity and is proud to be an equal opportunity employer.","{""role_summary"":""The Information Systems Technical Advisor provides technical guidance and solutions to complex technical challenges, leads technical projects, and ensures the implementation of agreed-upon architecture and infrastructure."",""key_terms"":[{""term"":""Detailed Architecture Design Documents"",""explanation"":""A detailed document outlining the technical design of a solution or system.""},{""term"":""Software Development Life Cycle (SDLC)"",""explanation"":""A process used to design, develop, test, and deliver software applications.""},{""term"":""Cloud technologies"",""explanation"":""A model of delivering computing services over the internet, allowing for on-demand access to a shared pool of resources.""}],""skill_priorities"":{""must_have"":[""Technical architecture experience"",""Familiarity with coding languages"",""Understanding of various operating systems"",""Familiarity with Cloud technologies"",""Strong leadership and team building skills"",""Strong decision making and conflict management skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a complex technical challenge you've faced in the past and how you approached solving it?"",""example_answer"":""In my previous role, I encountered an issue with a software integration project. I analyzed the problem, identified the root cause, and proposed a solution that involved rewriting a portion of the code. I worked with the development team to implement the fix, and we were able to deliver the project on time.""},{""question"":""How do you stay current with the latest technology trends and developments?"",""example_answer"":""I regularly read industry publications, attend conferences, and participate in online forums to stay informed about the latest advancements in technology. I also network with peers and colleagues to learn from their experiences and share my own knowledge.""}],""red_flags"":[""Lack of technical architecture experience"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
"Systems Manager, WMS and Integration","Radiant offers a complete range of industry-leading transportation and warehousing solutions to businesses around the globe by leveraging our extensive network of carrier partners across all modes. Radiant provides customized logistics solutions that create value and increase profitability for our customers. 

Radiant Canada is a learning environment in which passion, dedication and a commitment to getting the job done are valued. That’s what being on our team is all about. It’s where you can gain valuable skills and experience, which also helps Radiant grow. If this sounds like the kind of company you are looking for, we would love to hear from you!

We are currently looking for a Manager, WMS and Integration Systems to join Radiant and be part of our dynamic team.
4 DAY ONSITE, 1 DAY REMOTE:  Work in the office at 1280 Courtneypark Drive E, Mississauga Monday to Thursday.  Work from home Fridays.  

What You’ll Do:  
Maintain a productive, high performing team through recruiting, selecting, orienting and training. Develop personal growth opportunities for team members. 
Manage all contractual relationships i.e. source / vet appropriate WMS application and system vendor partners, request and review contracts, approve invoices, etc. 
Lead / coordinate WMS application and integration design for projects. Provide detailed cost estimates, resource plans and schedules to project management teams. 
Engage and ensure effective and timely delivery of deliverables and tasks.
Handle all escalated matters related to the delivery of IT solutions. 
Ensure IT solutions comply with architectural standards. 
Organize and maintain the performance of WMS application issues in accordance with agreed SLA’s.
Determine the operational objectives by studying business functions, gathering information and evaluating outputs.
Design and improve systems by analyzing current practices and suggesting improvements.
Monitor project progress by tracking activity; resolving problems; publishing progress reports and recommending actions.
Maintain system-enforced processes by writing and updating procedures.
Provide references for users by writing and maintaining user documentation and providing support and training for users.
Test and support the QA process.
Document process and system procedures.
Other duties and assignments as required.

What You Bring to the Role:
College or University Degree in Computer Science, Engineering, or related field.
Minimum of 5 years’ experience with WMS in the position of applications support, project management and/or development of which a minimum 2 years’ experience must be in a management / leadership role.
Strong working knowledge of EDI systems and their specifications.
Complete working knowledge of warehouse business processes.
Experience delivering business critical software functionality.
Experience with 3PL distribution customer onboarding
3PL Distribution Supply chain / logistics experience is required. 
Must have the following technical skills:
5 years’ experience using WMS Systems and EDI Integration specifically:
Business analysis and systems analysis in support of technology solutions,
Project co-ordination, Documentation and End-user support,
Report Design,
Integration,
Quality Assurance and Testing,
Customer relationship management,
Distribution management,
Financial management,
Reporting and analytics
Experience with Kober High Jump Advantage System is preferred.
Experience with Biz Talk EDI is preferred.
Dedicated project commitment to providing acceptable and timely deliveries.
Ability to communicate effectively with all levels of the Company inside and outside of IT
Strong interpersonal skills to successfully communicate and collaborate with users, other technical teams, and internal stakeholders to collect requirements and articulate technical strategies. 
Highly organized with the ability to multi-task and prioritize.
High tolerance for stress. 
Strong problem-solving skills and decision-making skills in a team environment.
Team cooperation and respect is required. 
Strong analytical and reasoning skills with attention to detail.
After hours and weekend work as required.  
10% Travel Required

Perks You’ll Get:
·      Health, Dental, Vision, Life and Disability insurance
·      RRSP Contribution Matching
·      Birthday Day Off
·      Paid Sick Days
·      Learning & Development Opportunities
·      Employee Discounts
·      Access to an Employee Assistance Program for services including counseling, financial and legal consultation
·      Wellness Program
·      Safety Shoe Allowance
·      A Supportive and Positive Work Environment

The Fine Print:
Radiant is committed to providing accessible employment practices that are in compliance with the Accessibility for Ontarians with Disabilities Act (AODA). Accommodations are available on request for candidates taking part in all aspects of the recruitment and selection process.

We thank all candidates for applying, however, only those candidates selected for an interview will be contacted.","{""role_summary"":""Manage and lead the Warehouse Management System (WMS) and Integration Systems team, ensuring high performance, and delivering IT solutions that meet business objectives."",""key_terms"":[{""term"":""WMS"",""explanation"":""Warehouse Management System, a software solution that manages and controls warehouse operations.""},{""term"":""EDI"",""explanation"":""Electronic Data Interchange, a standard for exchanging business data between organizations.""},{""term"":""3PL"",""explanation"":""Third-Party Logistics, a service where a company outsources its logistics and distribution operations to a third-party provider.""}],""skill_priorities"":{""must_have"":[""WMS experience"",""EDI knowledge"",""Warehouse business process understanding"",""Project management skills"",""Leadership experience"",""Communication skills"",""Problem-solving skills""],""nice_to_have"":[""Experience with Kober High Jump Advantage System"",""Experience with Biz Talk EDI""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with WMS systems and how you've used them to improve warehouse operations?"",""example_answer"":""I've worked with WMS systems for 5 years, and in my previous role, I implemented a new WMS that increased efficiency by 20%. I worked closely with the warehouse team to design and test the system, and we saw significant improvements in order fulfillment and inventory management.""},{""question"":""How do you ensure that IT solutions meet business objectives, and what metrics do you use to measure success?"",""example_answer"":""I work closely with stakeholders to understand business objectives and develop IT solutions that meet those objectives. I use metrics such as project timelines, budget, and user adoption to measure success. In my previous role, I led a project that implemented a new transportation management system, which resulted in a 15% reduction in transportation costs and a 20% increase in on-time deliveries.""}],""red_flags"":[""Lack of experience with WMS systems"",""Inability to communicate technical information to non-technical stakeholders"",""Poor problem-solving skills""],""confidence_score"":90.0}"
Senior Manager IT,"Our client in the non-profit sector is seeking a Deputy Director, IT to lead IT operations, security, strategy, and infrastructure. This role ensures technology supports organizational goals efficiently and securely.

Location: Hybrid 3d/week Toronto

Key Responsibilities:
• Assist in IT strategy development and implementation.
• Oversee IT budget, policies, and vendor management.
• Lead IT team, fostering innovation and professional growth.
• Manage IT projects using Agile methodologies.
• Maintain and secure IT infrastructure, networks, and cloud services.
• Ensure cybersecurity best practices and conduct security assessments.
• Provide IT support and optimize Microsoft 365 services.

Qualifications:
5+ years experience in IT management
Strong expertise in IT infrastructure, security, and cloud technologies.
Advanced knowledge of Microsoft 365 (Exchange, SharePoint, Teams, Azure AD).
Experience in IT leadership, project management, and team development.","{""role_summary"":""Lead IT operations, security, strategy, and infrastructure to support organizational goals efficiently and securely."",""key_terms"":[{""term"":""Agile methodologies"",""explanation"":""An iterative approach to managing projects, focusing on flexibility and continuous improvement.""},{""term"":""Cloud technologies"",""explanation"":""On-demand computing resources and services provided over the internet, such as storage, servers, and applications.""},{""term"":""Cybersecurity best practices"",""explanation"":""Established guidelines and procedures to protect computer systems, networks, and data from unauthorized access, use, disclosure, disruption, modification, or destruction.""},{""term"":""Microsoft 365"",""explanation"":""A suite of productivity applications, including Exchange, SharePoint, Teams, and Azure AD, providing email, collaboration, and identity management services.""}],""skill_priorities"":{""must_have"":[""IT management experience"",""IT infrastructure expertise"",""Microsoft 365 knowledge"",""IT leadership experience"",""Project management skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure IT infrastructure is aligned with organizational goals?"",""example_answer"":""I assess business objectives and develop an IT strategy that supports those goals, ensuring efficient and secure technology operations.""},{""question"":""Can you describe your experience with Agile project management?"",""example_answer"":""I've led IT projects using Agile methodologies, focusing on iterative development, continuous improvement, and team collaboration to deliver projects efficiently.""}],""red_flags"":[""Lack of experience with Microsoft 365 services"",""Inability to demonstrate IT leadership and team development skills""],""confidence_score"":90.0}"
"Manager, IT Service Manager","Akkodis is seeking a Manager, IT Service Manager for a full-time position with a client in Toronto, ON and ideally looking for experience with ITSM management, ITIL certifications, Management experience, ITSM processes, incidents Management
Position: Manager, IT Service Manager
Location: Toronto, On - Hybrid
Full Time

Key skills:
Extensive experience in introducing, managing, and improving ITSM processes, specifically in Incident, Major Incident, Problem, and Change Management (not looking for configuration management as that will be someone else’s responsibility). Hands-on incident management experience is needed, including at least some major incidents. Will be coaching their direct reports, including the major incident manager.

Have a roadmap in place and need help with tactical work like introducing CAB workbench, and introducing training to support the rollout but want someone who comes with their own experience and ideas and suggestions of how to do things better. They are working on maturing their ITSM processes.
Not looking for any particular industry experience but has to come from a sizeable organization as they are the only ones with formalized ITSM processes.
Needs to have excellent communication skills and will be presenting to the CTO and SVPs every week.
Description,
We are embarking on an important and exciting journey to transform our IT Service Management practices to support the growing services delivered by Moneris that benefit millions of Canadians each day!
As IT Service Management leader, you will oversee the execution of the IT Service Management roadmap and lead the daily operations and execution of all processes within the ITSM program.
Location: You will be based in our Toronto office and will work in a hybrid model.
Reporting Relationship: You will report to the Director, of Production Support and Service Management.

What you'll do
Led IT service management teams responsible for the daily operations of Moneris’ IT Service Management processes including incident management, major incident management, problem management, change management, and configuration management.
Manage the IT service management processes for Incident, Major Incident, Problem, Change, and Configuration management which includes tracking and enforcing any daily process compliance issues with stakeholders.
Support all technology team members on ITSM process and procedural questions and lead training and communication activities.
Take a lead role for the most critical of major incidents, in a 24x7 environment, where senior ITSM leadership is imperative for the successful resolution. Moreover, uses sound judgment and decision-making skills to lead senior technology practitioners and leaders towards the most effective recovery and resolution.
Key contributor to the success of the service improvement process by identifying process deficiencies and recommendations for improvement.
Review operational metrics with senior management to drive awareness, support, and compliance.
Chairs regular operational meetings with stakeholders to review operational KPI’s, and trends and identify improvement opportunities to drive ITSM across the Technology Organization.
Seen as the trusted ITSM expert and partner at Moneris and levers industry and ITSM framework knowledge to improve ITSM processes delivered at Moneris.
Maintain a diverse peer group of other ITSM professionals to share ideas and challenges to the benefit of Moneris’ IT Service Management

What you bring
Bachelor’s degree in information technology, system administration, information systems management, or similar disciplines. A Master’s degree is considered an asset.
Minimum 10 years of experience working in developing, administering, or conducting IT service management work processes and managing senior technical resources.
Minimum 3 years’ experience managing IT service management teams
Expert and experienced in supporting and administering IT service management responsibilities such as incident, problem, and IT change and configuration management.
ITIL V3 or ITIL V4 Intermediate certification, Expert level (considered an asset)
Experience supporting payment systems within a merchant-acquiring business (considered an asset)

What you get
Comprehensive Total Rewards Program including bonuses, flexible benefits starting from day 1, and your choice of either a health spending account (HSA) or personal spending account (PSA)
RRSP matching & defined contribution pension plan
Learning & development programs and resources including unlimited free access to Coursera and an Educational Assistance Program
Holistic approach to your well-being, with an Employee Assistance Program for you and your family, access to 24/7 virtual health care, wellness events, and a supportive workplace culture
A workplace committed to investing in Diversity, Equity, and Inclusion (DEI) through various initiatives including, employee inclusion groups (EIGs), mentorship, DEI learning and workshops, educational events, and various resources including an internal DEI website and newsletter
Company-wide paid year-end closure & personal time off (including religious, personal, and volunteer days)","{""role_summary"":""Manage IT service management teams, oversee daily operations, and lead process improvements to support growing services."",""key_terms"":[{""term"":""ITSM"",""explanation"":""IT Service Management, a set of policies, procedures, and processes to manage IT services.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management.""},{""term"":""CAB"",""explanation"":""Change Advisory Board, a group that assesses and approves changes to IT services.""}],""skill_priorities"":{""must_have"":[""Extensive experience in ITSM management"",""Hands-on incident management experience"",""Excellent communication skills"",""Minimum 10 years of experience working in IT service management""],""nice_to_have"":[""ITIL V3 or ITIL V4 Intermediate certification"",""Experience supporting payment systems within a merchant-acquiring business""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with ITSM process improvements and how you've led teams to achieve them?"",""example_answer"":""In my previous role, I introduced a new incident management process that reduced resolution time by 30%. I worked closely with the team to identify areas for improvement and developed a training program to ensure successful adoption.""},{""question"":""How do you stay current with industry trends and best practices in IT service management?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and network with peers to stay informed about the latest developments in ITSM. I also leverage my experience with ITIL frameworks to identify opportunities for improvement.""}],""red_flags"":[""Lack of experience with ITSM process improvements"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
"Manager, IT Service Management (ITSM)","Why eHealth?

We may be biased, but eHealth Saskatchewan is the place to be right now! As the result of a province wide consolidation of IT services in the health care sector, we have seen substantial growth in our organization that is only going to increase as we aim to meet our expanded mandate and the immense need for our support. This gives our people a unique and rare opportunity to truly create, build, improve, and leave their mark on a growing organization.

We are a Treasury Board Crown Corporation that focuses on digital technologies to enable, support, and enhance high quality health services across the entire province. There is no greater job satisfaction than knowing the work you do is directly related to saving a life or bringing a new one into the world. Although we may not be front facing with patient care, we have a huge role in maintaining and improving IT systems and supporting health care providers and teams throughout Saskatchewan in delivering the best possible care to patients, citizens, and health system users. Programs range from primary care to acute care, and includes laboratories, pharmaceuticals and diagnostics. Additional programs and services that support patient care and information include Virtual Care, MySaskHealthRecord, the Provincial Electronic Health Record, Health Registries (eligibility for health services/distribution of health cards) and vital event records.

Our vision is “Connected healthcare, accessible to everyone, everywhere” with a mission to “Collaborate to transform healthcare through the use of information and innovative technology”. It is a complex environment, constantly evolving and quick to change as we live our values of excellence, integrity, teamwork, courage, resilience and collaboration.

About the Role:

Reporting to the Director, Operational Support Services, the Manager, IT Service Management (ITSM) will oversee day-to-day service management, operational support, quality and standards, and recruitment for Operational Support Services. This includes leading the development of an ITIL Centre of Excellence and maintaining and communicating ITIL processes and standards. This role is responsible for ensuring high-quality IT service management across multiple teams, with a focus on service excellence, ITIL standards, and customer experience.

The individual is part of a management team who collaboratively manages the first point of contact and customer support for critical applications within the Saskatchewan health sector and for MySaskHealthRecord services for Saskatchewan citizens. This position will facilitate communication among health sector stakeholders, including executive management, end users and the public as required, while working collaboratively with technical experts and vendors. With patients and the public at the forefront, the Manager will ensure that eHealth’s programs, technology, and tools remain a top priority and functional for those who need them most.

Key Responsibilities

Manage the requirements, tracking, maintenance, and continual improvement of ITSM tools, ensuring alignment with organizational objectives.
Lead decommissioning tasks of legacy ITSM applications, and work with technical teams to ensuring smooth transition to modern solutions.
Oversee Service Desk standards, ensuring the highest level of customer experience and service delivery.
Develop and lead an ITIL Centre of Excellence, establishing and ensuring ITIL best practices and continuous service improvement.
Lead ITIL process adoption and improvement initiatives in alignment with the organization’s ITSM transformation strategy.
Establish, implement, and communicate quality assurance frameworks, ITIL processes, and governance structures across all teams.
Drive the standardization and optimization of ITSM processes across Service Desk, Knowledge Management, and the IT Operations Centre (ITOC).
Work collaboratively with healthcare stakeholders, end users, and technical experts to ensure seamless IT service management and manage escalations, confidential IT requests, audits and reviews.
Enhance ServiceNow capabilities, leveraging its full potential for automation, reporting, and service improvement.
Establish and monitor service quality metrics, SLAs, and KPIs to ensure performance targets are met.
Advocate and work collaboratively on ITSM process improvements by partnering with IT leadership and business stakeholders.

The ideal candidate will be a resilient leader who demonstrates:

Progressive experience in linking strategy and operations, IT polices, framework and practices;
Superior communication, problem-solving, accountability, systems management skills, and a solid track record in initiating and supporting collaborative work and innovation solutions;
Knowledge of public sector budgeting, forecasting, accountability, and decision-making processes;
Understanding how to advance the strategic and corporate work of the organization and the goals of government overall;
Change agent with a proven track record in leading dynamic and diverse teams through provincial wide changes and times of uncertainty;
Ability to navigate and build strong relationships in a large, complex multi-enterprise environment;
Extensive leadership experience that enables you to lead, direct and manage a team of professionals;
Ability to think critically and view issues and challenges from multiple perspectives; and,
Reputation for integrity and a focus on service excellence.

Experience & Qualifications:

Demonstrated experience managing ITSM tool requirements, tracking, maintenance, development, and continuous improvement tasks and initiatives.
Proven ability to manage decommissioning tasks for legacy ITSM applications.
At least five (5) years of experience in IT services field.
Knowledge of ITIL principles, processes, and frameworks.
Advanced computer skills and knowledge of systems and applications, such as ServiceNow administrator functions, Active Directory and account management systems, and interdependencies of accounts.
Advanced computer skills in Microsoft Office Suite (Word, Excel, PowerPoint, etc.)
Strong leadership skills, writing and presentational skills.

The successful applicant will have a mix of a strategic mindset, relatable educational and/or experienced background in IT Services and knowledge of service level agreements, queue management, and continuous improvement. They will need to be able to paint the strategic picture for those around them, while understanding the operational nuances that drive the business. Curiosity, innovation, and the ability to learn new subjects and apply them into practice, will also be critical.

We offer:

Dynamic work environment with opportunities to create and build;
A competitive salary;
A physical wellness flex benefit program;
A comprehensive benefits package, including pension; and
Paid vacation, scheduled days off and other types of leaves. (maternity/paternity/adoption/family/personal leave, sick leave)

If this role sounds like the opportunity you have been looking for to challenge yourself, make a difference in people’s lives, and display your abilities – we would love to hear from you.

Employment Type

Permanent Full-time

Location(s)

SK

Salary Range

$48.255 - $61.691

We are committed to workplace diversity.

Number of Openings

1

Mar 18, 2025, 11:59:00 PM","{""role_summary"":""The Manager, IT Service Management (ITSM) oversees day-to-day service management, operational support, quality, and standards, ensuring high-quality IT service management across multiple teams, focusing on service excellence, ITIL standards, and customer experience."",""key_terms"":[{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of best practices for IT service management.""},{""term"":""ITSM"",""explanation"":""IT Service Management, a set of policies, procedures, and processes to manage IT services.""},{""term"":""ServiceNow"",""explanation"":""A cloud-based IT service management platform for automating and managing IT services.""}],""skill_priorities"":{""must_have"":[""ITIL principles, processes, and frameworks"",""Experience in IT services field"",""Advanced computer skills"",""Leadership skills"",""Communication skills""],""nice_to_have"":[""Knowledge of public sector budgeting, forecasting, accountability, and decision-making processes"",""Experience with ServiceNow administrator functions, Active Directory and account management systems""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you ensure seamless IT service management across multiple teams?"",""example_answer"":""I would establish clear communication channels, define roles and responsibilities, and implement ITIL best practices to ensure consistency and quality of service delivery.""},{""question"":""Can you describe your experience with ITSM tool requirements, tracking, maintenance, and continuous improvement?"",""example_answer"":""In my previous role, I managed the implementation of an ITSM tool, ensuring alignment with organizational objectives and continuous improvement through regular reviews and updates.""}],""red_flags"":[""Lack of experience in IT service management"",""Inability to communicate technical information to non-technical stakeholders"",""No knowledge of ITIL principles and frameworks""],""confidence_score"":90.0}"
"Senior Manager, IT Operations and Improvements","About Metergy Solutions Inc. (“Metergy”)
As one of North America’s most experienced submetering providers, Metergy Solutions has brought turnkey solutions to clients for over 20 years. Metergy supplies, installs and remotely reads meters to measure individual suite consumption of electricity, water, gas, and thermal energy in multifamily and commercial buildings, and bills and collects the utility consumption.

Our innovative Submetering as a Service (SaaS) model generates long-term recurring revenue and has been proven to reduce in-suite energy consumption by an impressive 40%, significantly advancing our clients' decarbonization efforts. This outstanding performance has enabled Metergy to issue green bonds and secure green financing, fueling our sustained growth and creating extraordinary career opportunities for our team.

As the #1 submeter provider in the New York and Canadian markets, and one of the largest in North America, Metergy boasts over 850,000 contracted meters, issues more than 2 million utility invoices annually, and employs over 400 dedicated team members. Our successful acquisitions have consistently exceeded expectations, unlocking immense growth potential.

Metergy is proudly a portfolio company of Brookfield Infrastructure Partners, one of the world’s largest investors, owners, and operators of infrastructure assets across the utilities, transport, energy, data, and sustainable resources sectors. This partnership provides Metergy with access to substantial capital, infrastructure investment expertise, and a global reach, positioning us for continued success and innovation

Our Mission

Provide building owners and occupants with accurate and reliable utility consumption data through market-leading expertise in turnkey submetering and billing, while fostering a workplace with inspired team members empowered to do more good.

Role Overview
Are you passionate about driving IT excellence and continuous improvement? Do you thrive on analyzing metrics and leading impactful initiatives? Is your IT career pushing you to become a leader? If so, we have an exciting opportunity for you! As the Manager, IT Operations and Improvements at Metergy Solutions, you will play a pivotal role in optimizing our IT operations, ensuring robust reporting, and spearheading improvement projects that drive efficiency and innovation.

Responsibilities

Lead IT Improvement Initiatives: Identify areas for improvement within IT operations, develop strategic plans, and lead initiatives to enhance efficiency, reduce costs, and improve service delivery
Drive Process Optimization: Analyze existing IT processes, identify bottlenecks, and implement best practices to streamline workflows and improve overall performance
Develop and Implement IT Metrics Reporting: Design and maintain comprehensive IT metrics dashboards to track performance, identify trends, and support data-driven decision-making
Financial Analysis and Cost Management: Conduct financial analysis to ensure cost-effective IT operations, manage budgets, and optimize resource allocation
AI and Automation Opportunities: Explore and implement AI and automation solutions to enhance IT operations and drive innovation
Collaboration and Communication: Foster strong collaboration with other departments, ensuring IT initiatives align with business goals and support overall organizational success
Team Development and Leadership: Mentor and develop IT staff, fostering a culture of continuous learning and improvement
Lead the Development of Delivery Models: Spearhead the creation and implementation of IT delivery models based on ITIL, MOE, and DevOps best practices, ensuring they are fit for purpose and aligned with organizational goals
Intranet Ownership and Management: Oversee the management and continuous improvement of the company's intranet, ensuring it meets organizational needs and enhances internal communication



Qualifications

Bachelor's degree in Computer Science, Computer/Electrical Engineering, Information Technology, or a related field
Proven experience in IT operations, process improvements, and financial analysis
Strong knowledge of ITIL, MOE, and DevOps best practices
Excellent analytical and reporting skills
Experience with AI technologies and their application in IT operations
Strong project management and leadership skills
Excellent communication and collaboration abilities
Ability to manage multiple priorities and work effectively in a fast-paced environment



Metergy’s recruitment process includes accommodation for applicants with disabilities. All accommodations will consider the applicant’s accessibility needs due to disability and are available upon request.","{""role_summary"":""The Manager, IT Operations and Improvements will lead IT improvement initiatives, optimize IT operations, and drive innovation to support business goals."",""key_terms"":[{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of best practices for IT service management.""},{""term"":""MOE"",""explanation"":""Management of Engineering, a framework for managing and improving IT services.""},{""term"":""DevOps"",""explanation"":""Development and Operations, a set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""AI"",""explanation"":""Artificial Intelligence, a technology that enables machines to perform tasks that typically require human intelligence.""}],""skill_priorities"":{""must_have"":[""Proven experience in IT operations"",""Strong knowledge of ITIL, MOE, and DevOps best practices"",""Excellent analytical and reporting skills"",""Strong project management and leadership skills""],""nice_to_have"":[""Experience with AI technologies and their application in IT operations""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you identified an area for improvement in IT operations and led an initiative to implement a solution?"",""example_answer"":""In my previous role, I noticed that our IT ticketing system was causing delays in resolving issues. I analyzed the process, identified bottlenecks, and led a team to implement a new system that reduced resolution time by 30%.""},{""question"":""How do you stay current with emerging trends and technologies in IT operations?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read relevant publications to stay informed about the latest developments in IT operations and innovation.""}],""red_flags"":[""Lack of experience in IT operations and process improvements"",""Inability to manage multiple priorities in a fast-paced environment""],""confidence_score"":90.0}"
"Manager, IT Service Management","Manager, IT Service Management

The Opportunity
We are embarking on an important and exciting journey to transform our IT Service Management practices to support the growing services delivered by us that benefit millions of Canadians each day!

As IT Service Management leader, you will oversee executing the IT Service Management roadmap and for leading the daily operations and execution of all processes within the ITSM program.

Location: You will be based in our Toronto office and will work in a hybrid model.

Reporting Relationship: You will report to Director, Production Support and Service Management.
What you'll do
Lead IT service management teams responsible for the daily operations for our IT Service Management processes including incident management, major incident management, problem management, change management and configuration management.
Manage the IT service management processes for Incident, Major incident, Problem, Change and Configuration management which includes tracking and enforcing any daily process compliance issues with stakeholders.
Support all technology team members on ITSM process and procedural questions and leads training and communication activities.
Take a lead role for the most critical of major incidents, in a 24x7 environment, where senior ITSM leadership is imperative for the successful resolution. Moreover, uses sound judgement and decision-making skills to lead senior technology practitioners and leaders towards the most effective recovery and resolution.
Key contributor to the success of service improvement process by identifying process deficiencies and recommendations for improvement.
Review operational metrics with senior management to drive awareness, support and compliance.
Chairs regular operational meetings with stakeholders to review operational KPI’s, trends and identify improvement opportunities to drive ITSM across the Technology Organization.
Maintain diverse peer group of other ITSM professionals to share ideas and challenges to the benefit of our IT Service Management

Your Career - What you bring
Bachelor’s degree in information technology, system administration, information systems management or similar disciplines. Master’s degree considered an asset.
Minimum 10 years of experience working in developing, administering, or conducting IT service management work processes and managing senior technical resources.
Minimum 3 years' experience managing IT service management teams
Expert and experienced in supporting and administering IT service management responsibilities such as incident, problem and IT change and configuration management.
ITIL V3 or ITIL V4 Intermediate certification, Expert level (considered an asset)
Experience supporting payment systems within a merchant acquiring business (considered an asset)","{""role_summary"":""Oversee the execution of IT Service Management roadmap, lead daily operations, and manage ITSM processes to support growing services."",""key_terms"":[{""term"":""IT Service Management"",""explanation"":""A set of practices and processes to manage IT services, ensuring their quality, reliability, and efficiency.""},{""term"":""ITSM"",""explanation"":""Abbreviation for IT Service Management, referring to the practices and processes to manage IT services.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management that provides best practices and guidelines.""}],""skill_priorities"":{""must_have"":[""10+ years of experience in IT service management"",""3+ years of experience managing IT service management teams"",""Expertise in IT service management processes (incident, problem, change, and configuration management)""],""nice_to_have"":[""Master's degree in information technology or similar disciplines"",""ITIL V3 or ITIL V4 Intermediate certification"",""Experience supporting payment systems within a merchant acquiring business""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach leading a team to resolve a critical major incident in a 24x7 environment?"",""example_answer"":""I would prioritize clear communication, assign tasks to team members based on their strengths, and make sound judgment calls to ensure effective recovery and resolution.""},{""question"":""Can you describe your experience with IT service management processes, such as incident, problem, and change management?"",""example_answer"":""I have managed IT service management teams and have hands-on experience with incident, problem, and change management processes, ensuring compliance and identifying areas for improvement.""}],""red_flags"":[""Lack of experience in managing IT service management teams"",""Inadequate knowledge of IT service management processes and best practices""],""confidence_score"":90.0}"
IT Services Manager,"Job Description
Information Technology Services (ITS) Manager

The Manager of IT Services is responsible for ensuring that our Internal IT Systems are secure, consistent and reliable by monitoring, working closely with 3rd party vendors and ensuring we provide excellent customer service to our staff, clients and families. You’ll help develop, maintain, and evaluate organizational IT policies and procedures.

The Manager of IT Managed Services is responsible for overseeing the security, stability, and reliability of external clients and their IT infrastructure. This role involves proactive system consulting, design, management, deployment and monitoring, close collaboration with third-party vendors, and a commitment to delivering exceptional customer service to clients, their staff, and stakeholders. Additionally, the IT Services Manager will develop, implement, and continuously refine IT policies and procedures to enhance operational efficiency, security, and overall service delivery.

Additionally, the IT Services Manager will play a pivotal role in establishing and managing the IT services unit. This role involves planning, coordinating, and executing project-based IT systems and network deployments. It does not include continuous IT support but focuses on delivering exceptional project outcomes.

The successful candidate will work closely with cross-functional teams to ensure the successful implementation of IT projects.

This role requires a highly motivated self-starter with superb attention to detail, solid soft skills, written and verbal acumen, and in the same breath, a willingness to be a student and a teacher. In addition, public speaking skills will be closely assessed to ensure clear and concise communication will be delivered to our partners.

Other responsibilities include overseeing project execution against profit margins, establishing health partnerships with third-party vendors, learning and leading teams deploying the IT catalogue of services, managing day-to-day client engagement requests, and contributing to the organization’s fiscal goals and objectives.

If you’re technical with excellent communication skills and have the ability to juggle multiple priorities and projects while leading a dedicated IT team, we’d like to meet you.


Essential Functions:

Maintain and optimize customer’s IT environment
Responsible for hardware and software life cycle.
Responsible for implementing and enforcing ITIL and security best practices
Build a resource management plan for the IT team.
Establish and structure the IT services unit, defining processes, workflows, and standards for project-based deployments.
Routinely review tools and technologies that will enhance teams’ ability to deliver services cost-effectively.
Provide technical guidance and expertise on IT systems and network deployments, serving as a point of contact for technical queries.
Understanding applicable regulations, guidelines, and industry best practices to manage risk and ensure compliance.
Implement quality control measures to ensure that project outcomes meet or exceed client expectations.
Monitoring internal control effectiveness.
Conducting internal IT assessments to ensure continued compliance.
Reviewing, implementing, updating, and documenting information technology policies and procedures.
Keep abreast of industry IT trends, developments, and applicable government laws and regulations.
Develop and maintain IT Service Catalogue.
Creating and executing strategies to improve the reliability and security of IT projects.
Allocate resources, including internal and external teams, to ensure efficient project delivery.
Maintain effective communication with stakeholders, keeping them informed of project progress and addressing concerns.
Identify potential project risks and develop mitigation strategies to minimize disruptions.
Maintain comprehensive project documentation, including project plans, status reports, and post-project evaluations.
Manage relationships with third-party vendors and suppliers to ensure project requirements are met.
Lead an manage a team of technicians, offering coaching, guidance and technical escalation support
Develop departmental strategy and vision for solutions, go-to market and collaborate with sales to ensure enablement tools are effective and up to date

Required Skills and Experience

Bachelor’s in business administration, Computer Science, or a related field. Cyber Security Degree a plus.
ITIL/CAPM/PMP Certifications are a plus.
5+ years of professional experience in project management or technical project management.
Prior experience and fundamental knowledge of Information Technology are required.
Ability to understand and communicate technical components of a project with associated mitigation strategies.
Proven consultative, conflict resolution, negotiation, and facilitation skills to gain internal and external stakeholder buy-in for onboarding and steady-state stages of the engagement.
Prior experience working with Project Management and Team Collaboration tool.
Excellent verbal and written communication skills.
Exceptional organizational and teamwork skills.
Minimum of three (3) years of management experience as an IT Manager or Information Assurance/Engineering team lead.
Demonstrated experience presenting briefings to senior customer management and customer stakeholders.

Job Type
Full-time

Technical Skills and Experience Nice to Have

Infrastructure & Systems Administration
Infrastructure & Systems Administration
Management and administration of Windows Server (2016/2019/2022) & Active Directory
Experience with Linux-based servers (Ubuntu, CentOS, Red Hat, etc.)
Virtualization technologies: VMware vSphere, Hyper-V, Citrix
Storage solutions: SAN, NAS, iSCSI, RAID configurations
Cloud infrastructure management: Microsoft Azure, AWS, Google Cloud
Backup and disaster recovery solutions: Veeam, Acronis, Datto, Azure Backup
IT asset management and monitoring tools: NinjaOne, Kaseya, SolarWinds, PRTG

Networking & Security
Configuration, administration, and troubleshooting of firewalls, routers, and switches (Cisco, Fortinet, Palo Alto, Ubiquiti, Meraki)
VPN and remote access solutions: IPSec, SSL VPN, RADIUS, Zero Trust
Network troubleshooting using tools like Wireshark, TCPDump, SolarWinds
Wireless network setup, security, and optimization (WAPs, VLANs, SSIDs)
Endpoint security & patch management: Microsoft SCCM, Intune, CrowdStrike, SentinelOne
SIEM & security monitoring tools: Splunk, Microsoft Sentinel, AlienVault
Implementation and enforcement of cybersecurity best practices (NIST, CIS, ISO 27001)

Cloud Services & SaaS Solutions
Microsoft 365 Administration (Exchange, Teams, SharePoint, OneDrive, Intune)
Google Workspace Administration (Gmail, Drive, Google Admin Console)
Identity and access management (Azure AD, Okta, Duo, MFA, SSO)
Cloud migration projects (On-prem to Azure, AWS, M365, Google Cloud)
SaaS application management and integrations

IT Service Management & Automation
ITIL framework knowledge and implementation
IT Service Desk & Ticketing systems: ConnectWise, ServiceNow, Zendesk, Autotask
Automation & scripting: PowerShell, Bash, Python for system administration
Patch management & compliance: WSUS, Intune, Automox
Endpoint Deployment & Imaging: Autopilot, MDT, PXE Boot solutions

Business Continuity & Disaster Recovery (BCDR)
Backup & restore strategies for servers, databases, and cloud environments
Disaster Recovery Planning (DRP) & Business Continuity Planning (BCP)
Incident response & remediation for security breaches and outages


Location
100% Telecommuting

% of Travel Required
0-50%

CyberClan is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran, or disability status.","{""role_summary"":""The ITS Manager is responsible for ensuring the security, consistency, and reliability of internal and external IT systems, providing excellent customer service, and developing IT policies and procedures."",""key_terms"":[{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of best practices for IT service management.""},{""term"":""CAPM/PMP"",""explanation"":""Certifications in project management, demonstrating expertise in planning, executing, and monitoring projects.""},{""term"":""Cyber Security"",""explanation"":""The practice of protecting computer systems, networks, and sensitive information from unauthorized access, theft, or damage.""},{""term"":""Virtualization"",""explanation"":""A technology that allows multiple virtual machines to run on a single physical machine, improving resource utilization and flexibility.""},{""term"":""Cloud Infrastructure"",""explanation"":""A model for delivering IT services over the internet, providing on-demand access to computing resources, storage, and applications.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in Business Administration, Computer Science, or a related field"",""5+ years of professional experience in project management or technical project management"",""Prior experience and fundamental knowledge of Information Technology"",""Ability to understand and communicate technical components of a project with associated mitigation strategies"",""Proven consultative, conflict resolution, negotiation, and facilitation skills"",""Excellent verbal and written communication skills"",""Exceptional organizational and teamwork skills"",""Minimum of three (3) years of management experience as an IT Manager or Information Assurance/Engineering team lead""],""nice_to_have"":[""Cyber Security Degree"",""ITIL/CAPM/PMP Certifications"",""Infrastructure & Systems Administration experience"",""Networking & Security experience"",""Cloud Services & SaaS Solutions experience"",""IT Service Management & Automation experience"",""Business Continuity & Disaster Recovery experience""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with IT service management frameworks, and how have you implemented them in previous roles?"",""example_answer"":""I have experience with ITIL and have implemented it in my previous role as an IT Manager, where I developed and maintained IT policies and procedures to enhance operational efficiency and security.""},{""question"":""How do you stay current with industry IT trends and developments, and how do you apply that knowledge in your work?"",""example_answer"":""I regularly read industry publications and attend conferences to stay current with the latest trends and developments. I apply that knowledge by identifying opportunities to improve our IT services and implementing new technologies and processes to enhance our operations.""}],""red_flags"":[""Lack of experience with IT service management frameworks"",""Inability to communicate technical information to non-technical stakeholders"",""Limited experience with cloud infrastructure management""],""confidence_score"":90.0}"
"Manager, Infrastructure and Cloud Operations","PointClickCare is a leading North American healthcare technology platform enabling meaningful care collaboration and real‐time patient insights. For over 20 years, the company has been focused on realizing its vision: to help create a world in which providers and plans can confidently deliver frictionless care. Since its inception, PointClickCare has grown exponentially, with over 2,200 employees working to impact millions across North America. Recognized by Forbes as one of the top 100 private cloud companies and acknowledged by Waterstone Human Capital as Canada’s Most Admired Corporate Cultures, PointClickCare leads the way in creating cloud-based healthcare software.

At PointClickCare, we offer a wealth of opportunities and a vibrant culture that empowers our employees. Our dynamic environment is the perfect place to advance your career while engaging in meaningful work alongside incredible colleagues. Here, you’ll discover a space where your talents can thrive, your career can grow, and your work will have a lasting impact on healthcare across North America. We believe that work becomes profoundly fulfilling when driven by a higher purpose.

Join us and be part of a team that is making a real impact.

To learn more about us, check out Life at PointClickCare and connect with us on Glassdoor and LinkedIn.

The Manager, Infrastructure and Cloud Operations develops and maintains the design and integrity of all corporate infrastructure and cloud systems/services. This role requires a people leader with extensive knowledge in Azure cloud technology and financial operations, infrastructure management, and demonstrated experience in team management. This manager will have experience successfully finding ways to improve the quality of IT service delivery, focusing on quality, efficiency, productivity, and agility.

This role oversees delivering operational support for all infrastructure services brokered, and managing internal corporate infrastructure and applications that support the organization’s business processes across the enterprise. As a people leader, the role will be to guide and direct the TSS Infrastructure and Operations group including performance reviews and goal setting. As a skilled and experienced technician and infrastructure specialist, this working manager role will manage incidents and request escalations from other groups at PointClickCare for resolution, documentation, and knowledge transfer (where required).

This role will also coordinate and sustain relationships with OCIO counterpart groups and vendors/partners, assist in contract negotiations, take part in operational and security scorecard reviews and budget monitoring

Key Responsibilities

Supervise, guide and collaborate with a diverse technical team of Architects, Analysts, Administrators, DBA’s, and App Admins to comprehend the needs of the workload, design, develop, evaluate, and deploy cloud services that are efficient, cost-effective, and adaptable for architectural flexibility.
Keep the systems secure by following the best guidelines for security and compliance. Maintain clear and detailed system documentation, including infrastructure setup based on observations and modifications.
Regularly enhance and revise Standard Operating Procedures (SOPs) for all operational processes and ensure that all services related to infrastructure function properly and are always available for business use. Work with and maintain good contacts of external vendors and service providers to make sure incidents and problems are addressed quickly and professionally.
Manage the IT roadmap for short-term goals to align with the current needs of the business and security. Take part in planning, implementing, and overseeing projects and budgets related to infrastructure.
Responsible for providing support for infrastructure services, such as LAN/WAN/WLAN, Windows, VMWare, A/D, and services from external partners, in a large-scale network environment. Manage Azure IaaS/PaaS/MI environments and some Microsoft 365 micro-services as listed in the service catalog.
Other duties as assigned.

Qualifications And Skills

At least 5 years of experience managing infrastructure, with 3 or more years in a leading or supervising position that involves cloud-based solutions.
In-depth understanding of cloud platforms, infrastructure technologies, networking, virtualization, and storage solutions.
Demonstrated skill in examining complex problems, designing solutions, and making decisions based on data to optimize service performance.
Strong ability to communicate and collaborate well with teams and stakeholders from diverse backgrounds and functions.
Effective leadership skills with a history of leading and growing successful teams, promoting a culture of teamwork and creativity.
Bachelor’s degree in information technology or computer science; or equivalent experience.

PointClickCare Benefits & Perks

Benefits starting from Day 1!

Retirement Plan Matching

Flexible Paid Time Off

Wellness Support Programs and Resources

Parental & Caregiver Leaves

Fertility & Adoption Support

Continuous Development Support Program

Employee Assistance Program

Allyship and Inclusion Communities

Employee Recognition … and more!

It is the policy of PointClickCare to ensure equal employment opportunity without discrimination or harassment on the basis of race, religion, national origin, status, age, sex, sexual orientation, gender identity or expression, marital or domestic/civil partnership status, disability, veteran status, genetic information, or any other basis protected by law. PointClickCare welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process. Please contact recruitment@pointclickcare.com should you require any accommodations.

When you apply for a position, your information is processed and stored with Lever, in accordance with Lever’s Privacy Policy. We use this information to evaluate your candidacy for the posted position. We also store this information, and may use it in relation to future positions to which you apply, or which we believe may be relevant to you given your background. When we have no ongoing legitimate business need to process your information, we will either delete or anonymize it. If you have any questions about how PointClickCare uses or processes your information, or if you would like to ask to access, correct, or delete your information, please contact PointClickCare’s human resources team: recruitment@pointclickcare.com

PointClickCare is committed to Information Security. By applying to this position, if hired, you commit to following our information security policies and procedures and making every effort to secure confidential and/or sensitive information.","{""role_summary"":""The Manager, Infrastructure and Cloud Operations is responsible for developing and maintaining the design and integrity of all corporate infrastructure and cloud systems/services, overseeing operational support, and managing internal corporate infrastructure and applications."",""key_terms"":[{""term"":""Azure cloud technology"",""explanation"":""A cloud computing platform and set of services offered by Microsoft that allows users to build, deploy, and manage applications and services through Microsoft-managed data centers across the globe.""},{""term"":""Infrastructure management"",""explanation"":""The process of planning, designing, implementing, and maintaining an organization's infrastructure, including hardware, software, and network resources.""},{""term"":""IT service delivery"",""explanation"":""The process of designing, building, and delivering information technology services to meet business needs, focusing on quality, efficiency, productivity, and agility.""},{""term"":""OCIO counterpart groups"",""explanation"":""Groups or teams within an organization that work together to achieve common goals, in this case, related to infrastructure and operations.""}],""skill_priorities"":{""must_have"":[""At least 5 years of experience managing infrastructure"",""In-depth understanding of cloud platforms, infrastructure technologies, networking, virtualization, and storage solutions"",""Demonstrated skill in examining complex problems, designing solutions, and making decisions based on data to optimize service performance"",""Strong ability to communicate and collaborate well with teams and stakeholders from diverse backgrounds and functions"",""Effective leadership skills with a history of leading and growing successful teams""],""nice_to_have"":[""Bachelor's degree in information technology or computer science""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with Azure cloud technology and how you've used it to improve IT service delivery?"",""example_answer"":""I've worked with Azure for over 3 years, and in my previous role, I implemented a cloud-based solution that increased our organization's efficiency by 30%. I worked closely with the development team to design and deploy the solution, ensuring seamless integration with our existing infrastructure.""},{""question"":""How do you approach complex problem-solving in infrastructure management, and can you give an example of a successful solution you've implemented?"",""example_answer"":""I follow a structured approach to problem-solving, involving data analysis, stakeholder input, and solution design. For example, I once identified a network bottleneck that was causing application downtime. I worked with the network team to design and implement a new architecture, which resulted in a 50% reduction in downtime and improved overall system performance.""}],""red_flags"":[""Lack of experience with Azure cloud technology"",""Inability to communicate technical information to non-technical stakeholders"",""No experience in leading or supervising teams""],""confidence_score"":90.0}"
Information Technology Service Management Specialist,"LeverageTek is actively seeking an ITSM Specialist for a 4-month contract with it’s Ottawa based customer.


Work Location
Hybrid – 3/days week onsite at Ottawa HQ


Key Tasks
• Responsible for leading and driving best practices, innovation, and efficiency within the clients IT Service Delivery environment.
• This role requires deep expertise in ITIL frameworks, ITSM tools, and service strategy to enhance IT operations and ensure alignment with business goals.
• Provide expert guidance on ITSM best practices, processes, and frameworks (e.g., ITIL, COBIT, ISO 20000).
• Lead ITSM strategy development and implementation to optimize service delivery.
• Assess current ITSM capabilities and recommend improvements in processes, automation, and tools.
• Support the selection, configuration, and optimization of a new ITSM platform.
• Develop and refine incident, problem, change, and service request management processes.
• Define key performance indicators (KPIs) and service level agreements (SLAs) to measure and improve service performance.
• Collaborate with cross-functional teams, including IT operations, security, and development, to ensure seamless service integration.
• Provide training and mentorship to IT teams to enhance ITSM capabilities and adoption.
• Stay up to date with industry trends, emerging technologies, and ITSM advancements.


Key Qualifications
• Minimum 3-5+ years of experience in ITSM consulting, advisory roles, or IT operations management.
• Hands-on experience with ITSM tools like ServiceNow, BMC Remedy, Cherwell, Zendesk, ServicePRO etc.
• Experience providing advisory/strategic support and guidance within ITSM environments where the organization is considering consolidating from multiple ITSM tools to one common ITSM platform.


Other Qualifications
• Experience participating in and contributing to the Procurement process for new ITSM software.
• ITIL Certification.
• Additional certifications such as COBIT, ISO 20000, PMP, or Agile methodologies.


Assets
• Experience in cloud-based ITSM implementations.
• Knowledge of enterprise architecture frameworks and IT governance.
• Experience in implementing automation and AI-driven ITSM solutions is a plus.
• Hands-on knowledge and experience with Zendesk and ServicePRO ITSM software.


About LeverageTek Staffing Solutions
Founded in 2003, LeverageTek provides end-to-end, cross-functional staffing solutions throughout North America. We are a trusted partner to leading private and public sector organizations and experts in talent solutions that create optimal business outcomes.
Don’t let our name fool you. Our roots are in technology, but we are also a proven leader in accounting and finance, sales and marketing, human resources, supply chain, and legal talent acquisition. We offer contract and permanent staffing, executive search, talent mapping, management consultancy, and contractor payroll management.

LeverageTek is an equal opportunity employer. We offer a welcoming and inclusive environment in service to one another, our customers, the candidates we represent, and the diverse communities we call home. We do all of this with kindness, empathy, and respect for each other. LeverageTek is committed to employment equity and creating a diverse and inclusive workplace. We welcome applications from all qualified individuals regardless of race, religion, gender, national origin, age, disability, and marital status.
Accessibility accommodations are available upon request","{""role_summary"":""Lead and drive best practices, innovation, and efficiency within the client's IT Service Delivery environment, ensuring alignment with business goals."",""key_terms"":[{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of best practices for IT service management.""},{""term"":""ITSM"",""explanation"":""IT Service Management, a set of policies, procedures, and processes for managing IT services.""},{""term"":""COBIT"",""explanation"":""Control Objectives for Information and Related Technology, a framework for IT governance and management.""},{""term"":""ISO 20000"",""explanation"":""International Organization for Standardization standard for IT service management.""}],""skill_priorities"":{""must_have"":[""ITIL frameworks"",""ITSM tools"",""service strategy"",""ITSM consulting"",""IT operations management""],""nice_to_have"":[""cloud-based ITSM implementations"",""enterprise architecture frameworks"",""IT governance"",""automation and AI-driven ITSM solutions"",""Zendesk and ServicePRO ITSM software""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you assess and improve ITSM capabilities in a client's IT Service Delivery environment?"",""example_answer"":""I would conduct a thorough analysis of the current ITSM processes, identify areas for improvement, and develop a strategy to optimize service delivery, including implementing automation and AI-driven solutions.""},{""question"":""Can you explain the importance of ITIL frameworks in IT service management?"",""example_answer"":""ITIL frameworks provide a structured approach to IT service management, ensuring alignment with business goals and improving service quality, efficiency, and customer satisfaction.""}],""red_flags"":[""Lack of experience with ITSM tools and platforms."",""Inability to provide expert guidance on ITSM best practices and frameworks.""],""confidence_score"":90.0}"
Information Technology Infrastructure Manager,"Job Title: IT Infrastructure Manager

Note: This position was previously posted but was placed on hold due to business priorities. We are now actively hiring and encourage previous applicants to reapply.

Starting Salary Range: $90k - $115k (based on experience)

About the Company: Keilhauer

Founded in 1981, Keilhauer is a privately owned, design-focused contract furniture manufacturer. The company produces seating and tables that enhance communication and engagement in various spaces such as meeting rooms, collaboration areas, lobbies, and lunchrooms. Keilhauer is internationally recognized for award-winning design and high environmental standards.

About the Role: We are seeking a proactive and hands-on IT Infrastructure Manager to lead our infrastructure and support team. This role is crucial in ensuring the stability, security, and scalability of our IT systems while overseeing help desk operations. The IT Infrastructure Manager will work closely with the Head of Technology to develop and implement infrastructure strategies, manage a team of skilled professionals, and maintain high availability of systems. The role also includes overseeing IT projects, managing vendor relationships, and ensuring financial accountability within the department. This position requires flexibility to be available during off-hours for system maintenance and emergency support.

Primary Responsibilities:

Business Continuity & Critical Systems

Ensure the availability, performance, and security of business-critical systems (Syteline, Windchill, SQL, O365).
Develop and maintain backup, disaster recovery, and incident response plans (Veeam, Commvault).
Oversee help desk operations, ensuring timely issue resolution and continuous improvement of support processes.
Monitor and refine ticketing system performance to enhance user satisfaction.
Maintain an on-call rotation for critical system support.

Strategic Technology Leadership & Innovation

Assess emerging technologies, industry solutions, and vendor offerings to enhance infrastructure, security, and business operations.
Proactively recommend tools, platforms, and automation strategies to optimize efficiency.
Lead IT infrastructure projects, ensuring they align with business goals, are delivered on time, and within budget.
Provide insights to leadership on infrastructure performance, trends, and investment opportunities.
Manage software licensing and vendor compliance, ensuring adherence to EULA requirements.

Infrastructure Management & Security

Design, implement, and maintain IT infrastructure, including servers, storage, networking, and cloud services.
Optimize system performance and reliability through proactive monitoring and automation.
Lead network security, ensuring protection from internal/external threats, including firewall (FortiGate, Cisco) and security best practices.
Regularly assess vulnerabilities and implement risk mitigation strategies.
Ensure wired/wireless networks and converged infrastructure are secure and scalable.

Team Leadership & Growth Mindset

Manage a team of three, setting expectations, mentoring, and conducting performance reviews.
Foster a culture of continuous learning, innovation, and personal development.
Encourage a proactive mindset, empowering the team to suggest and implement improvements.
Lead by example, providing hands-on support when necessary while developing the team’s technical capabilities.

Qualifications:

2+ years of experience as an IT specialist or in a similar leadership role.
Post-secondary degree or diploma.
PMP certification or equivalent project management experience.
Advanced technical knowledge in server infrastructure, networks, scripting/automation, and cloud systems.
Proven experience with disaster recovery, backup solutions, and incident response.
Familiarity with ERP systems, product lifecycle management tools, and databases.
Certifications such as ITIL, CISSP, or other relevant credentials preferred.
Excellent interpersonal and communication skills in both written and spoken English.
Valid driver’s license, own vehicle, and valid insurance.


Working Conditions: This role is primarily performed in an office environment, with some functions conducted in manufacturing facilities. The position requires frequent interaction through face-to-face contact, email, and phone communications. The candidate must be available during off-hours for urgent system maintenance, upgrades, and incident response.


How to Apply: If this role sounds like a fit for you, please send your resume to careers@keilhauer.com and tell us why you would be a great addition to our team! Please note that only those selected for further consideration will be contacted.","{""role_summary"":""The IT Infrastructure Manager leads the infrastructure and support team, ensuring the stability, security, and scalability of IT systems, overseeing help desk operations, and maintaining high system availability."",""key_terms"":[{""term"":""Syteline"",""explanation"":""An enterprise resource planning (ERP) system used for managing business operations.""},{""term"":""Windchill"",""explanation"":""A product lifecycle management (PLM) tool used for managing product data and collaboration.""},{""term"":""Veeam"",""explanation"":""A backup and disaster recovery software used for ensuring business continuity.""},{""term"":""Commvault"",""explanation"":""A data protection and information management software used for backup and disaster recovery.""},{""term"":""FortiGate"",""explanation"":""A network security appliance used for firewall and security protection.""},{""term"":""CISSP"",""explanation"":""A certification for information security professionals, demonstrating expertise in security and risk management.""},{""term"":""ITIL"",""explanation"":""A framework for IT service management, focusing on aligning IT services with business needs.""}],""skill_priorities"":{""must_have"":[""IT infrastructure management"",""server infrastructure"",""networking"",""cloud services"",""disaster recovery"",""incident response"",""project management"",""leadership and team management""],""nice_to_have"":[""PMP certification"",""ITIL certification"",""CISSP certification"",""experience with ERP systems"",""experience with product lifecycle management tools""]},""proposed_screening_questions_with_answers"":[{""question"":""What strategies would you implement to ensure high availability of our IT systems?"",""example_answer"":""I would focus on proactive monitoring, automation, and regular vulnerability assessments to minimize downtime and ensure business continuity.""},{""question"":""How would you approach leading a team of IT professionals and fostering a culture of continuous learning?"",""example_answer"":""I would set clear expectations, provide regular feedback, and empower the team to suggest and implement improvements, while leading by example and providing hands-on support when necessary.""}],""red_flags"":[""Lack of experience in IT infrastructure management"",""Inability to work during off-hours for system maintenance and emergency support""],""confidence_score"":95.0}"
Information Technology Administrator,"NATURE OF WORK

Provide technical and administrative support for LAN, using Windows and a variety of application software. Maintain adequate knowledge of existing hardware and software in use to maximize efficiency of the network and users' utilization of them. Uses knowledge of operating system and application software to provide high levels of support to users. Assist in server and infrastructure upgrades and expansions.

REPORTING STRUCTURE

The position reports to the Director of IT North America.

EXAMPLES OF WORK

Listed examples are illustrative and representative of the tasks required for this position, and are not intended to be complete or exclusive.

Perform general network maintenance on LAN relating to users, contexts, and network devices.
Monitor cables and ensure reliable connectivity to the network.
Assist with network troubleshooting and maintaining data integrity.
Assist in providing computer/network support relating to software and hardware problems reported by users.
Assist with on-boarding and off-boarding users and sites.
Assist with maintenance of multiple systems and databases.
Assist with developing SQL/Crystal Reports for manager’s staff.
Monitor and evaluate efficiency of software/hardware usage, providing items to be covered in training of users, making them more efficient.
Install new software applications or hardware on the LAN, coordinating assistance from third parties when necessary.
Add and maintain users on the network; assigning application access, ensuring security, and maintaining their configurations are within standards.
Assist in installation of workstations and printers on the LAN.
Participate in team meetings, providing input and suggestions, and prepare minutes of discussion items when necessary.
Assist in gathering bid prices on equipment and supplies as needed.
Provide written document on a monthly basis which defines upcoming needs of network which would require purchase of additional hardware or software.
Monitor and report licenses on applications to ensure compliance on a monthly basis.
Other duties may be assigned.

REQUIRED QUALIFICATIONS

General understanding of the company business. Ability to build and maintain professional employee relations. Excellent oral/written communication skills. Knowledge of MS Office, Windows operating systems, Active Directory, PowerShell, Crystal Reports. Excellent phone etiquette. Able to multi-task. Employee service driven, teamwork and detail orientated, professional, upbeat, energetic, takes initiative, dependable, takes pride in work.
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Bachelor's degree in computer science, information technology or a related field as well as at least 3+ years of experience in networking or equivalent

PHYSICAL REQUIREMENTS

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to stand, walk, sit, talk, listen and hear. The employee is occasionally required to reach with hands and arms, lift, and stoop, kneel or crouch. The employee must occasionally lift, carry and/or move up to 20 pounds.

Specific vision abilities required by this job include close vision, peripheral vision, depth perception, and ability to adjust focus.

Mental Requirements: Ability to read and interpret documents such as safety rules, operating and maintenance instructions, and procedure manuals. Ability to write routine reports and correspondence. Ability to speak effectively before groups of customers or employees of organization. Ability to add, subtract, multiply, and divide in all units of measure, using whole numbers, common fractions, and decimals.

Ability to compute rate, ratio, and percent and to draw and interpret bar graphs. Ability to apply common sense understanding to carry out instructions furnished in written, oral, or diagram form. Ability to deal with problems involving several concrete variables in standardized
situations.","{""role_summary"":""Provide technical and administrative support for LAN, ensuring efficient network and user utilization, and assist in server and infrastructure upgrades and expansions."",""key_terms"":[{""term"":""LAN"",""explanation"":""Local Area Network, a computer network that connects devices in a limited geographical area.""},{""term"":""Active Directory"",""explanation"":""A Microsoft directory service that provides authentication and authorization for Windows domain networks.""},{""term"":""PowerShell"",""explanation"":""A task automation and configuration management framework from Microsoft, consisting of a command-line shell and scripting language.""},{""term"":""Crystal Reports"",""explanation"":""A business intelligence application used to design and generate reports from a wide range of data sources.""},{""term"":""SQL"",""explanation"":""Structured Query Language, a programming language designed for managing and manipulating data in relational database management systems.""}],""skill_priorities"":{""must_have"":[""MS Office"",""Windows operating systems"",""Active Directory"",""PowerShell"",""Crystal Reports""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you troubleshoot a network connectivity issue?"",""example_answer"":""I would first check the physical connections, then verify the network settings and configuration, and finally use tools like ping and tracert to identify the issue.""},{""question"":""Can you explain the concept of Active Directory and its role in a Windows domain network?"",""example_answer"":""Active Directory is a directory service that provides authentication and authorization for Windows domain networks. It stores information about objects on the network, such as users, groups, and computers, and enables administrators to manage access to network resources.""}],""red_flags"":[""Lack of experience with Windows operating systems and MS Office"",""Inability to troubleshoot network issues"",""Limited knowledge of Active Directory and PowerShell""],""confidence_score"":90.0}"
Regional IT Manager,"Tenstorrent is leading the industry on cutting-edge AI technology, revolutionizing performance expectations, ease of use, and cost efficiency. With AI redefining the computing paradigm, solutions must evolve to unify innovations in software models, compilers, platforms, networking, and semiconductors. Our diverse team of technologists have developed a high performance RISC-V CPU from scratch, and share a passion for AI and a deep desire to build the best AI platform possible. We value collaboration, curiosity, and a commitment to solving hard problems. We are growing our team and looking for contributors of all seniorities.

Tenstorrent is growing and we are looking for a RITM of field office information technology systems and operations in alignment with the business objectives of the organization. The RITM will provide technical expertise and manage field office IT staff. The incumbent will travel to various sites that are under this role.

This role is hybrid, based out of Toronto, ON.

We welcome candidates at various experience levels for this role. During the interview process, candidates will be assessed for the appropriate level, and offers will align with that level, which may differ from the one in this posting.

Responsibilities

The RITM will identify, recommend, develop, implement, and support cost-effective technology solutions in line with the organization’s strategic vision
Ensure smooth running of the IT operations in the field, including user support, IT systems, onboarding/offboarding, domain services, communications, and connectivity
Managing crisis situations, which may involve complex technical hardware or software problems
Network configuration assessments, and implementing hardware/software upgrades and improvements
Mentoring and training IT staff in the field
Overseeing IT staff in planning and managing new office build-outs and moves
Providing guidance and support to field office IT as they perform troubleshooting and maintenance tasks on servers, Macs, PCs, and other devices
Partnership across sites on various IT projects
Recommending information technology strategies, policies, and procedures by evaluating organization outcomes; identifying problems’ evaluating trends’ anticipating requirements
This role will have a physical as well as remote administration and support aspects.
Developing, and implementing new IT procedures in the field and reviewing and enhancing existing procedures (Documentation)
Oversee deployment, maintenance, support, and monitoring of our infrastructure, including laptops, WiFi Access points, and AV equipment
Evaluating employees’ performance and progress on a regular basis, providing feedback/coaching/mentoring as needed
Other duties as assigned

Experience & Qualifications

Demonstrated ability to manage IT systems and staff remotely and in-person through appropriate technology
Demonstrated ability to plan and execute technology projects and system implementations effectively
Management Skills with demonstrated experience in managing multiple projects simultaneously
Ability and willingness to travel in the assigned regions
Degree/diploma in Computer Science or equivalent practical experience
Experience with our tech stack: Slack, Zoom, Google Workspace, JIRA, Confluence, Entra, Azure Active Directory, CrowdStrike, Office365, and 1password.
Proficiency with MacOS, iOS, Android, and Windows 10/11
Proven ability to work autonomously with limited direction and oversight while driving impactful IT initiatives

Tenstorrent offers a highly competitive compensation package and benefits, and we are an equal opportunity employer.

Due to U.S. Export Control laws and regulations, Tenstorrent is required to ensure compliance with licensing regulations when transferring technology to nationals of certain countries that have been licensing conditions set by the U.S. government.

As this position will have direct and/or indirect access to information, systems, or technologies that are subject to U.S. Export Control laws and regulations, please note that citizenship/permanent residency, asylee and refugee information and supporting documentation will be required and considered as a condition of employment.

If a U.S. export license is required, employment will not begin until a license with acceptable conditions is granted by the U.S. government. If a U.S. export license with acceptable conditions is not granted by the U.S. government, then the offer of employment will be rescinded.","{""role_summary"":""The RITM is responsible for managing field office IT systems and operations, providing technical expertise, and overseeing IT staff. This role involves identifying and implementing cost-effective technology solutions, ensuring smooth IT operations, and mentoring/training IT staff."",""key_terms"":[{""term"":""RISC-V CPU"",""explanation"":""A type of central processing unit (CPU) architecture that is open-source and customizable.""},{""term"":""IT systems"",""explanation"":""Computer systems and networks used to support business operations.""},{""term"":""Domain services"",""explanation"":""Services related to managing and maintaining domain names and their associated infrastructure.""},{""term"":""Azure Active Directory"",""explanation"":""A cloud-based identity and access management solution.""},{""term"":""CrowdStrike"",""explanation"":""A cybersecurity technology company that provides endpoint security solutions.""}],""skill_priorities"":{""must_have"":[""Experience with IT system management"",""Ability to manage IT staff remotely and in-person"",""Degree/diploma in Computer Science or equivalent practical experience"",""Proficiency with MacOS, iOS, Android, and Windows 10/11""],""nice_to_have"":[""Experience with Slack, Zoom, Google Workspace, JIRA, Confluence, Entra, and 1password"",""Ability to work autonomously with limited direction and oversight""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach managing IT systems and staff in a hybrid remote and in-person environment?"",""example_answer"":""I would prioritize clear communication, establish regular check-ins, and leverage technology to facilitate collaboration and remote support.""},{""question"":""Can you describe a time when you had to troubleshoot a complex technical issue in a field office setting?"",""example_answer"":""In my previous role, I encountered a network connectivity issue at a remote site. I worked with the local IT staff to identify the root cause, developed a plan to resolve the issue, and implemented the solution, resulting in minimal downtime and improved user experience.""}],""red_flags"":[""Lack of experience with IT system management"",""Inability to travel to various sites"",""Limited proficiency with MacOS, iOS, Android, and Windows 10/11""],""confidence_score"":85.0}"
IT Manager - Hotel,"Salary: $90,000
Location: Vancouver, BC

A prestigious hotel in Vancouver is seeking a dedicated IT Manager to oversee all aspects of its information technology infrastructure. The ideal candidate will ensure seamless operations, manage system upgrades, and provide technical support to staff and guests. This role offers an opportunity to maintain and enhance the hotel's IT systems, ensuring exceptional service and security. The IT Manager will play a crucial role in customer service, needing to interact directly with guests to resolve technical issues and enhance their overall experience.

Skills and Experience:
• Proven experience managing IT systems within a hotel or hospitality environment
• Strong technical proficiency with various systems
• Excellent problem-solving skills and ability to manage multiple projects simultaneously
• Effective communication and interpersonal skills to communicate technical information to non-technical staff
• Bachelor’s degree in Information Technology, Computer Science, or related field is a plus but not essential
• Capacity to work independently

If you are keen to discuss the details further, please apply today or send your cv to Nastasija
Note that candidates must have the right to live and work in the USA to be considered. Only shortlisted candidates will be contacted.
COREcruitment are experts in recruiting for the service sector. We currently have live roles across the UK, Middle East, Europe, North America, Southeast Asia, Africa and Australia. To view other great opportunities please check out our website at www.corecruitment.com
Follow COREcruitment on your favorite social networks - Facebook, Twitter, LinkedIn and Instagram","{""role_summary"":""Oversee and maintain the hotel's IT infrastructure, ensuring seamless operations, managing system upgrades, and providing technical support to staff and guests."",""key_terms"":[{""term"":""IT infrastructure"",""explanation"":""The underlying technology systems and networks that support the hotel's operations.""},{""term"":""System upgrades"",""explanation"":""The process of updating and improving existing IT systems to ensure they remain efficient and effective.""}],""skill_priorities"":{""must_have"":[""Proven experience managing IT systems within a hotel or hospitality environment"",""Strong technical proficiency with various systems"",""Excellent problem-solving skills"",""Effective communication and interpersonal skills""],""nice_to_have"":[""Bachelor's degree in Information Technology, Computer Science, or related field""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to troubleshoot a complex technical issue in a fast-paced hospitality environment?"",""example_answer"":""In my previous role, I had to resolve a network outage during peak check-in hours. I worked closely with the hotel team to identify the root cause, implemented a temporary solution, and coordinated with the vendor to resolve the issue within a few hours, minimizing the impact on guests.""},{""question"":""How do you ensure that technical information is communicated effectively to non-technical staff?"",""example_answer"":""I use clear, non-technical language and provide context to help staff understand the technical issue and the solution. I also offer training and support to ensure they feel comfortable using new systems or technologies.""}],""red_flags"":[""Lack of experience in a hotel or hospitality environment"",""Poor communication and interpersonal skills""],""confidence_score"":85.0}"
IT Operations Team Leader,"The House of Commons Administration delivers outstanding services to Members of Parliament and their employees in support of parliamentary democracy. Our success is made possible by our talented and dedicated workforce. We value diversity in all its forms and recognize that everyone has valuable contributions to make and the potential for individual growth. If you dream of joining an organization that is small enough for you to be noticed, but big enough to provide you with a meaningful career, then we want to hear from you!

Job Description
The House of Commons Digital Services and Real Property is currently looking to staff the IT Operations Team Leader position.

As an IT Operations Team Leader within our Digital Infrastructure Products and Services team, you will have the opportunity to leverage your leadership experience to oversee the delivery of key services to both the organization and external partners. This role requires strong leadership skills, a deep understanding of access management processes, and the ability to drive operational efficiency.

Some activities related to this position may require irregular working hours, overtime or on-call assistance to meet operational requirements.

Top Reasons to Join Digital Infrastructure Products and Services Team:
If you're ready to make an impact in a dynamic and fast-paced environment, we invite you to join our team and contribute to the success of our Digital Platforms functional group. Apply now to embark on a rewarding career journey with us!
Training and development opportunities.
Work-life balance /35-hour workweek
4 weeks’ vacation (minimum)

Qualifications
Education :
Graduation from a college or technical institute in the area of information technology, management or an acceptable combination of education, training and experience.

Experience :
Minimum of 5 years of experience in access management or a related field, with at least 2 years in a leadership role;
Experience in leading and managing a team to ensure the timely and accurate delivery of services;
Demonstrated ability to develop and implement strategies to improve access management processes and enhance service delivery;
Experience collaborating with internal and external stakeholders to understand their access management needs and provide effective solutions;
Strong track record of monitoring and reporting on team performance, identifying areas for improvement, and implementing corrective actions as needed;
In-depth knowledge of ensuring compliance with relevant policies, procedures, and regulations;
Experience providing training and support to team members to enhance their skills and knowledge
Proven ability to manage escalations and resolve issues related to access management services.

Assets :
Proficiency in using ServiceNow as a tool for managing IT operations;
Good understanding of access management principles, processes, and technologies.

Additional Information
We are committed to creating an inclusive workplace by providing a barrier-free recruitment and selection process. If you have an accommodation request, require material in an accessible format, or need additional support with the application process, please contact Recruitment and Selection Services at HOCCareers-CarrieresCDC@parl.gc.ca.

Each bilingual position is assigned a linguistic profile that identifies the level of second language proficiency for reading comprehension, written expression and oral interaction required. The profile for this position is CBC. Consideration may be given to candidates with other linguistic profiles.

We invite you to save a copy of the notice of job opportunity. Once the closing date has passed, these documents will no longer be available.

Qualified candidates may be considered for future vacancies for this role or for other similar and/or related roles on an indeterminate and/or fixed term basis.

Learn more about us! Visit Ourcommons.ca.
To learn about our hiring process, visit Eligibility and Selection.","{""role_summary"":""The IT Operations Team Leader oversees the delivery of key services to the organization and external partners, leveraging leadership experience to drive operational efficiency and ensure compliance with relevant policies and regulations."",""key_terms"":[{""term"":""Access Management"",""explanation"":""The process of granting, managing, and revoking access to resources, systems, and data within an organization.""},{""term"":""ServiceNow"",""explanation"":""A software platform used for managing IT operations, including incident management, problem management, and change management.""}],""skill_priorities"":{""must_have"":[""Leadership experience"",""Access management experience"",""Team management skills"",""Operational efficiency skills"",""Compliance knowledge""],""nice_to_have"":[""ServiceNow proficiency"",""Bilingualism (CBC linguistic profile)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to develop and implement a strategy to improve access management processes?"",""example_answer"":""In my previous role, I identified inefficiencies in our access management process and developed a strategy to implement a new access management system, resulting in a 30% reduction in access request processing time.""},{""question"":""How do you ensure compliance with relevant policies, procedures, and regulations in your team's operations?"",""example_answer"":""I ensure compliance by conducting regular audits, providing training to team members, and implementing corrective actions when necessary. I also stay up-to-date with changes to relevant policies and regulations.""}],""red_flags"":[""Lack of leadership experience in an IT operations team"",""Inability to manage escalations and resolve issues related to access management services""],""confidence_score"":90.0}"
"Senior Manager, IT","Location: Pickering, Ontario

Status: Regular, Full – Time

Education level: 4 Year university degree in Information Technology, Computer Science or related field

Deadline to apply: Friday, March 28, 2025

Travel: 10%

Laurentis Energy Partners (LEP) is on a high growth trajectory. We offer an exciting combination of challenging opportunities and career diversity in a work environment where safety is a core value. We seek ambitious and intelligent leaders in the energy industry with the ability to think differently to find new ways to solve problems. Being an Laurentis employee means you can apply your knowledge, broaden your skills, and make a valuable contribution to enhancing Ontario's energy sector. Our values are our strengths, and they are fundamental truths about us that do not change. Safety. Integrity. Excellence. People and Citizenship. Visit our website to know more about our services.

Job Overview

Reporting to the VP Finance and IT, the Senior Manager, IT Services position is responsible for ensuring secure, compliant, and efficient IT systems that support business operations, regulatory requirements, and digital transformation initiatives. The role requires a strategic thinker with strong leadership skills that will collaborate with business to develop and implement IT strategies that drive business growth, efficiency, and security.

Key Accountabilities

Working in accordance with prescribed safety procedures and regulations:

Have a clear and thorough understanding of Laurentis’s business functions, processes and information management priorities as well as the IT systems and resources used to help the business optimize IT expenditures.
Ensure delivery of high-quality and reliable IT services focused on maximizing return on investment for IT investments.
Provide delivery/oversight of IT and telecom services leveraging Laurentis’s outsourcing partners.
Lead Laurentis’s application and infrastructure outsourcing partners to manage the ongoing development, support and maintenance of Laurentis’s applications and infrastructure. This includes infrastructure planning, applications lifecycle planning, asset refresh and applications continuity management.
Work with the business clients to establish and manage on an on-going basis, service level agreements for all information management services.
Be the strategic interface for the business client group for resolution of information management issues with both internal and external IT service providers.
Support the development of information management strategies to meet changing business objectives while maximizing the efficiency and effectiveness of information technology within the business groups.
Maintain awareness of both internal and external trends in IT technology and services that could be used to enable or improve Laurentis’s management of information.
Facilitate the identification and screening of business needs/outcomes and/or solutions and determine if capabilities can be delivered through a modification or enhancement to an existing system, execution of a formal project, or whether a non-technical solution (i.e. status quo, business processes change, etc.) would meet business objectives.
Support the approval process for IT projects and provide technical input in preparation of requirements and business cases as required.
Facilitate the IT decision making and prioritizing process by participating in Laurentis’s line of business management team meetings and/or other line of business forums.
Initiate/support special IT initiatives/projects from time to time.
Maintain the overall Laurentis information systems architecture and adapt as business needs change through design reviews with business and service providers.
Establish and maintain Laurentis's information management policy and associated standards and provide oversight, guidance and support for the corporate document and records management programs.
Establish and manage an IT security framework and a program that protects the confidentiality, integrity and availability of Laurentis's critical systems and data, and enables monitoring, compliance and incident investigation.
Ensure the readiness and testing of the IT Disaster Recovery and Business Continuity Plan.
Identify the threat and associated vulnerabilities of IT operations and work with service-providers to implement cost-effective countermeasures to mitigate the risk.
Work with service providers to establish a governance framework over IT operations to ensure it continues to meet or exceed established service levels and complies with all regulatory requirements.
Maximize the value from our strategic IT vendors and service providers and maintain a strong focus on return on investment.
Maintain a highly skilled, motivated and engaged workforce.

Qualifications

We are seeking dynamic and results-driven professionals who have the following:

10 years of progressive IT services leadership with a track record of delivering high-quality, cost-effective IT solutions in complex, multi-vendor environments.
Proven ability to collaborate with business groups to define and oversee service level agreements that align IT operations with evolving business objectives.
Strong background in developing and executing information management strategies, and IT security frameworks.
Strong understanding of IT infrastructure, cybersecurity, cloud computing, and digital transformation.
Strong leadership, communication, and problem-solving skills

APPLICATION PROCESS

Please submit your resume by Friday, March 28, 2025. Laurentis thanks all those who apply; however, only candidates considered for an interview will be contacted.

ACCOMMODATIONS

Laurentis is committed to fostering an inclusive, equitable, and accessible environment where all employees feel valued, respected, and supported. If you require accommodation during the application or interview process, please advise us as soon as possible so appropriate arrangements can be made.","{""role_summary"":""The Senior Manager, IT Services is responsible for ensuring secure, compliant, and efficient IT systems that support business operations, regulatory requirements, and digital transformation initiatives."",""key_terms"":[{""term"":""Digital transformation"",""explanation"":""The integration of digital technology into all areas of a business, fundamentally changing how it operates and delivers value to customers.""},{""term"":""IT infrastructure"",""explanation"":""The composite hardware, software, network resources, and services required for the existence, operation, and management of an enterprise IT environment.""},{""term"":""Cybersecurity"",""explanation"":""The practices, technologies, and processes designed to protect digital information, computer systems, and networks from unauthorized access, use, disclosure, disruption, modification, or destruction.""},{""term"":""Cloud computing"",""explanation"":""A model for delivering information technology services over the internet, allowing users to access and use computing resources on-demand.""}],""skill_priorities"":{""must_have"":[""10 years of progressive IT services leadership"",""Strong background in developing and executing information management strategies"",""Strong understanding of IT infrastructure, cybersecurity, cloud computing, and digital transformation"",""Strong leadership, communication, and problem-solving skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience in developing and executing information management strategies in a complex, multi-vendor environment?"",""example_answer"":""In my previous role, I led a team in developing an information management strategy that aligned with business objectives, resulting in a 30% reduction in IT costs and a 25% increase in system efficiency.""},{""question"":""How do you stay current with emerging trends in IT technology and services?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and engage with peers to stay informed about the latest developments in IT technology and services.""}],""red_flags"":[""Lack of experience in IT services leadership"",""Inability to collaborate with business groups to define and oversee service level agreements""],""confidence_score"":90.0}"
"Director of IT & Digital Transformation - Edmonton or Calgary, AB","Edmonton, Alberta, Canada .

full-time . March 17, 2025

Description

Director of IT & Digital Transformation (Player-Coach Role)

Reports To: President

About Inline

Inline is a Civil Engineering Field Services firm. With a team of 250+ team members across various departments (Finance, Operations, HR, Sales) and significant field-to-office operations, we are on a journey to modernize and automate our processes using the Microsoft 365 platform and other leading technologies. We’re looking for a hands-on Director of IT & Digital Transformation who can set the strategic technology vision while actively driving day-to-day execution.

Position Overview

As the Director of IT & Digital Transformation at Inline, you will wear multiple hats: you’ll work strategically to align IT initiatives with the company’s long-term goals, but you’ll also be hands-on-rolling up your sleeves to build solutions, troubleshoot issues, and mentor your small IT team (currently one direct report). This is a player-coach role, ideal for someone who loves leading digital transformation but isn’t afraid to dive into technical details.

Core Responsibilities

Strategic Planning & Vision

Develop and execute a multi-year IT roadmap, ensuring alignment with Inline’s growth objectives.
Evaluate emerging technologies (e.g., advanced field data capture tools, AI, IoT) for potential business value.

Hands-On Microsoft 365 & Power Platform Development

Oversee (and, when needed, personally handle) the configuration and administration of Microsoft 365, including SharePoint, Teams, OneDrive, and license management.
Lead the design and implementation of Power Apps, Power Automate (Flow), and Power BI solutions that streamline field-to-office data flows and enhance productivity.

IT Operations & Support

Directly manage day-to-day IT operations, ensuring minimal downtime and prompt resolution of technical issues.
Oversee hardware and software updates, manage user accounts, and maintain system security across the organization.
When necessary, provide hands-on support to fill gaps and address urgent technical needs.

Cybersecurity & Compliance

Develop and enforce company-wide security policies, best practices, and data protection standards.
Conduct regular risk assessments and collaborate with external security partners (if needed) for specialized tasks (e.g., penetration testing).

Team Leadership & Development

Serve as a mentor and coach for your direct report(s), providing guidance on technical tasks, professional growth, and cross-functional collaboration.
Cultivate a learning culture: encourage continuous improvement and upskilling to keep pace with evolving technologies.

Business Analysis & Cross-Functional Collaboration

Partner with key stakeholders in Finance, HR, Sales, and Field Ops to understand process pain points and propose technology solutions.
Lead or support software evaluations, vendor negotiations, and implementation projects, ensuring alignment with business objectives.

Budget & Vendor Management

Own the IT budget, forecast technology expenses, and ensure ROI on major initiatives.
Manage relationships with key vendors and service providers, holding them accountable for deliverables and service quality.

Change Management & Adoption

Develop clear communication plans, training programs, and stakeholder engagement strategies for all IT initiatives.
Champion user adoption, ensuring that new tools and processes deliver measurable productivity gains.

Metrics & Continuous Improvement

Track and report on key performance indicators (KPIs), such as system uptime, support ticket resolution, and user adoption rates.
Use data and user feedback to refine processes, optimize workflows, and prioritize future projects.

What Success Looks Like

Immediate Impact: You seamlessly blend strategic oversight with day-to-day operations. Team members see you as both a leader and a reliable go-to resource for solving complex tech challenges.

Mid-Term (6–12 Months): Key digital transformation projects (e.g., new Power Apps for field data collection, improved SharePoint-based intranet) are successfully implemented, and end-users embrace the new tools.

Long-Term: Inline has a robust, secure, and scalable IT environment that supports growth, efficiency, and innovation; your team expands responsibly as the company’s needs evolve.

Ideal Candidate Profile

Experience

7+ years in IT leadership or management roles (Manager, Senior Manager, or Director) within mid-sized organizations.
Proven track record in player-coach positions where you’ve successfully balanced strategic responsibilities with hands-on tasks.

Technical Proficiency

Expertise in Microsoft 365 administration (SharePoint, Teams, Power Platform).
Familiarity with IT security best practices, network fundamentals, and data protection.
Comfortable with common business applications (ERP, CRM, HRIS, etc.)—experience with field service solutions is a plus.

Leadership & Communication

Strong ability to mentor and motivate a small team, fostering growth and collaboration.
Excellent interpersonal and stakeholder management skills, able to translate complex technical concepts for non-technical audiences.

Strategic & Hands-On Balance

Demonstrable history of crafting IT strategies aligned with business objectives, while staying connected to the “nuts and bolts” of technology.
Ability to shift between executive-level discussions and rolling up your sleeves for direct problem-solving or development.

Education

Bachelor’s degree in Computer Science, Information Systems, or related field (Master’s or MBA a plus, but not mandatory).
Relevant certifications (e.g., Microsoft certifications, PMP, ITIL) are beneficial.

#INDHP2025","{""role_summary"":""The Director of IT & Digital Transformation is a player-coach role that sets the strategic technology vision while actively driving day-to-day execution, leading digital transformation and mentoring a small IT team."",""key_terms"":[{""term"":""Microsoft 365"",""explanation"":""A suite of cloud-based productivity and collaboration tools, including SharePoint, Teams, OneDrive, and Power Platform.""},{""term"":""Power Apps"",""explanation"":""A low-code development environment for building custom business applications.""},{""term"":""Power Automate (Flow)"",""explanation"":""A workflow automation tool for streamlining business processes.""},{""term"":""Power BI"",""explanation"":""A business analytics service for data visualization and business intelligence.""},{""term"":""AI"",""explanation"":""Artificial Intelligence, a technology that enables machines to perform tasks that typically require human intelligence.""},{""term"":""IoT"",""explanation"":""Internet of Things, a network of physical devices, vehicles, and sensors that connect and exchange data.""}],""skill_priorities"":{""must_have"":[""Microsoft 365 administration"",""IT security best practices"",""Data protection"",""Leadership and team management"",""Strategic planning and vision""],""nice_to_have"":[""Field service solutions experience"",""Microsoft certifications"",""PMP or ITIL certifications""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach developing a multi-year IT roadmap for a mid-sized organization?"",""example_answer"":""I would start by aligning with the company's growth objectives, evaluating emerging technologies, and identifying areas for process improvement. Then, I would prioritize initiatives based on business value and develop a phased implementation plan with clear milestones and resource allocation.""},{""question"":""Can you give an example of a Power Apps solution you've designed and implemented to streamline field-to-office data flows?"",""example_answer"":""In my previous role, I built a custom Power App for field data collection that integrated with our CRM system, reducing data entry errors by 30% and increasing field worker productivity by 25%.""}],""red_flags"":[""Lack of hands-on technical experience with Microsoft 365 and Power Platform"",""Inability to balance strategic planning with day-to-day operations"",""Poor leadership and team management skills""],""confidence_score"":90.0}"
"Manager, IT Infrastructure","About The Company

Bosa Properties Inc. (""BPI"") is an end-to-end real estate company offering human-centered solutions for property development and management. Based out of Vancouver, Canada, our team of in-house experts work across residential, commercial and master-planned projects, with a growing residential portfolio that includes more than 22,000 homes that are built or under development, and an income portfolio that includes 5.5 million square feet of retail, industrial, office and rental properties under management.

We are an organization of high achievers and believe what is created in community is always better than what is created in isolation. We set high expectations and support you in achieving excellence. We are building a trusted community to collaborate, learn from each other and deliver results.

About The Role



Reporting to the Director, IT Operations, the IT Infrastructure Manager is responsible for overseeing infrastructure operations and ensuring the availability and security of services across the organization. The IT Infrastructure Manager is responsible for training, managing, and mentoring a team of specialist and generalist IT professionals and will work closely with other IT leaders to define and prioritize projects to enhance and secure the technologies we rely on every day.

The Manager, IT Infrastructure possesses a combination of advanced technical skills and incredible managerial abilities. They are naturally service oriented, passionate about problem solving, and can motivate a team of hybrid/remote work IT professionals. The Manager, IT Infrastructure, will contribute a deep understanding of the continuously changing IT landscape and is a valued partner in the day-to-day operation of a high performing business.

Supporting a user base of 350 hybrid-work users, the Infrastructure Team is a critical component of the overall support structure within Bosa Properties Inc. This is an excellent opportunity for an IT professional to truly take ownership of the IT Infrastructure function at one of the top property developers in the country.

What You'll Do

Manage the Infrastructure team, evaluate performance, and address performance issues
Recruit, train and support multiple roles (e.g. Network/System Administrator, DevOps Engineer)
Establish, measure, and track KPI's for system health and support escalations
Develop weekly and monthly reports on the team's productivity
Work with business units to understand and provide expected service levels
Manage technology projects start to finish
Act as an escalation contact for incidents and manage the escalation process where required
Monitor ticket queues, assign issues, and identify opportunities for improvements and automation
Work with stakeholders on technology adoption, training, and optimizing technology usage
Create training material and conduct training sessions
Utilize contract/consultant resources for specialized skillsets we do not have internally

What You Bring

You are a customer-centric individual with a keen desire to standardize and automate.  Your experience allows you to respond appropriately to critical incidents, and you thrive in an environment that is evolving how technology is used in the business.  Most notably, you enjoy training and developing others - from your own team to technology champions in each department that you partner with.

Our Must Haves:

Diploma in Computer Information Systems Administration or equivalent work experience
Minimum four (4) years of experience leading a team of 3+ direct reports
Minimum eight (8) years of experience with a minimum of four (4) years of experience in a senior IT operational role
A wide breadth of knowledge in the technology space, with direct experience in a Windows-based, M365, AWS/Azure environment
Experience optimizing escalation workflows, and team schedules for both in and after-hours coverage to meet SLA's and KPI's
Experience collecting business and user requirements, and managing technology implementation projects
Experience with event correlation and root cause analysis for infrastructure services and security incidents
Experience managing training schedules and performance of direct reports
Experience with change management and change control processes
Experience with issue tracking systems (e.g. FreshService, JIRA)
Experience working in agile/scrum environments
Excellent communication & documentation skills

Our salary ranges and bonus percentages are determined by job family and level. Base salary is determined by a combination of factors including, but not limited to, education and training, years of relevant experience, and internal equity.

Salary

$134,067—$184,418 CAD

Who You Are

Trustworthy: You lead with trust when interacting with your team and other departments. You proactively build trust by demonstrating credibility, empathy, and sincerity.
Humble: Unpretentious and self-aware, you take responsibility for your mistakes. You know that egos are barriers to doing our best work and always learning.
Community focused: You believe what is created in community is always better than what is created in isolation and excellence is created through collaboration.

How To Apply

We value your interest in Bosa Properties. While we can only respond to shortlisted applicants, we will keep your information on file and consider you for future opportunities as they come available.

You belong here! If your experience and interests match with some of the above, we want you to apply. We are dedicated to building a diverse community, where everyone belongs.

Accommodations will be provided as requested by candidates taking part in all aspects of the selection process.","{""role_summary"":""The IT Infrastructure Manager oversees infrastructure operations, ensuring service availability and security across the organization, while leading and mentoring a team of IT professionals."",""key_terms"":[{""term"":""M365"",""explanation"":""Microsoft 365, a cloud-based productivity suite""},{""term"":""AWS/Azure"",""explanation"":""Cloud computing platforms provided by Amazon Web Services and Microsoft Azure""},{""term"":""DevOps Engineer"",""explanation"":""A professional responsible for ensuring the smooth operation of software systems, from development to deployment""},{""term"":""Event correlation and root cause analysis"",""explanation"":""The process of identifying and analyzing the underlying causes of infrastructure service and security incidents""},{""term"":""Agile/Scrum environments"",""explanation"":""Iterative project management methodologies focused on flexibility and teamwork""}],""skill_priorities"":{""must_have"":[""Diploma in Computer Information Systems Administration or equivalent work experience"",""Minimum four (4) years of experience leading a team of 3+ direct reports"",""Minimum eight (8) years of experience with a minimum of four (4) years of experience in a senior IT operational role"",""Experience with Windows-based, M365, AWS/Azure environment"",""Experience optimizing escalation workflows, and team schedules for both in and after-hours coverage to meet SLA's and KPI's"",""Excellent communication & documentation skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach standardizing and automating IT infrastructure processes?"",""example_answer"":""I would assess current workflows, identify areas for improvement, and implement automation tools to streamline tasks, ensuring consistency and efficiency.""},{""question"":""Can you describe your experience with event correlation and root cause analysis for infrastructure services and security incidents?"",""example_answer"":""In my previous role, I utilized tools like Splunk to analyze log data, identify incident patterns, and implement corrective measures to prevent future occurrences.""}],""red_flags"":[""Lack of experience with cloud-based infrastructure (AWS/Azure) and M365"",""Inability to manage and prioritize multiple projects simultaneously"",""Poor communication and documentation skills""],""confidence_score"":90.0}"
IT Service Manager,"Synopsis of the role :

A Technical Service Management Career is responsible for managing all customer impacting incidents involving the services provided by Equifax. The team’s primary responsibility is to analyze and resolve incidents that arise in our environments ensuring the impact to our customers are minimized. Proactive responsibilities include the building of Incident Trend and Analysis to identify vulnerabilities, change review to minimize customer impacts, and involvement in operational readiness procedures. This team is also responsible for maintaining the Incident Communications process to ensure on-time and accurate notifications are being sent to internal partners and external customers.

What You Will Do

Using your experience and understanding of the ITIL Incident Management processes, you will work in an IT Service Management environment to support a large IT company's ITIL Incident Management Process.
Frequently communicate with internal and external senior level executives; Major Incident communications are required to be submitted within strict SLA guidelines so the ability to quickly understand technical information and be able to translate to non-technical updates are a must.
Responsible for managing major incidents impacting a large number of external customers or internal employees. Must have the ability to perform well under stressful conditions and provide leadership to a large number of technicians to resolve issues in a timely manner. Diligence and attention to detail are key skills along with the ability to multitask and prioritize work appropriately.
Provide oversight of the environment to quickly identify correlating incidents that could evolve to larger events. Provide guidance and leadership to the other members of the TOC team helping to direct an efficient and highly productive Incident Management team.
Troubleshoot IT services and identify opportunities for improvement as well as document preventive measures to ensure issues do not recur; share and discuss these findings with Leadership and the Problem Management team to ensure corrective actions or documented and followed through.

What Experience You Need

Bachelor’s Degree or Associate's Degree/Technical Certification or equivalent job experience required
Minimum 5 years Incident Management experience working on a technical triage team to remediate customer impacting incidents
Work experience in an enterprise 24/7 production environment supporting critical, real-time applications
You've worked in an enterprise 24/7 production environment supporting critical, real-time applications
You possess excellent written and verbal communication skills with the ability to communicate with team members at various levels, including business leaders; providing end-to-end incident communications, both internally and externally
You're experienced working with one or more of the following tools/technologies: ServiceNow, App Dynamics, Apica, Extra Hop, Slack, Pager Duty, or similar tools

What Could Set You Apart

You're capable of assessing business impact and urgency, declaring major incident and trigger business continuity and/or disaster recovery procedures
You've collaborated with Business Services and Change Managers to review change requests, and assist with decisioning and scheduling to minimize the risk of customer impact
You've led and participated in problem management meetings with focus on recent major incidents, Root Cause Analysis, incident trending, and operational issues
You've collaborated with multi-functional teams to ensure new applications and services are in compliance with Technology Operations Center standards, prior to deploying them into production
You have a real passion for and the ability to learn new technologies","{""role_summary"":""Manage customer-impacting incidents, analyze and resolve issues, and minimize customer impact. Proactively identify vulnerabilities, review changes, and ensure operational readiness."",""key_terms"":[{""term"":""ITIL Incident Management"",""explanation"":""A framework for managing IT service incidents, focusing on restoring normal service operation as quickly as possible.""},{""term"":""SLA"",""explanation"":""Service Level Agreement, a commitment between a service provider and its customers that defines the expected service quality.""},{""term"":""TOC"",""explanation"":""Technology Operations Center, a team responsible for monitoring and managing IT services.""},{""term"":""Problem Management"",""explanation"":""A process to identify and resolve the root cause of incidents, preventing future occurrences.""}],""skill_priorities"":{""must_have"":[""ITIL Incident Management experience"",""Technical triage team experience"",""Excellent written and verbal communication skills"",""Experience with enterprise 24/7 production environment""],""nice_to_have"":[""Experience with ServiceNow, App Dynamics, Apica, Extra Hop, Slack, Pager Duty, or similar tools"",""Business impact and urgency assessment"",""Change management experience"",""Problem management experience"",""Passion for learning new technologies""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you handle a major incident impacting multiple customers?"",""example_answer"":""I would quickly assess the situation, communicate with stakeholders, and lead a team of technicians to resolve the issue in a timely manner, ensuring minimal customer impact.""},{""question"":""Can you explain the importance of ITIL Incident Management in a technical service management environment?"",""example_answer"":""ITIL Incident Management provides a structured approach to incident resolution, ensuring efficient and effective communication, and minimizing the impact on customers.""}],""red_flags"":[""Lack of experience in ITIL Incident Management"",""Inability to communicate technical information to non-technical stakeholders"",""Poor problem-solving skills under stressful conditions""],""confidence_score"":90.0}"
Senior Information Technology Administrator,"Adamson Systems Engineering is in an exciting phase, expanding our teams across the organization as we continue to push the boundaries of innovation in the professional audio industry. We are hiring for many new positions to keep up with global demand. As a leader in the design and manufacture of premium loudspeaker systems for live sound and installation markets, our name is celebrated by professionals on stages and in venues & theatres in more than sixty countries. This global presence not only reinforces our reputation for delivering exceptional sound experiences but also protects us from any financial risks that may arise from trade barriers in individual markets.

Recently named Business Of The Year by the North Durham Chamber of Commerce, this recognition reflects the dedication, passion and expertise that drive our success. Join us as continue our rapid growth and shape the future of sound.

For more information about our company, visit www.adamson.ai

We are actively looking for individuals motivated by vision, innovation and challenge: those who will stop at nothing to achieve their goals. Out team values principled engineering combined with diligent execution with each team member striving to make each new product better

We are looking for a Senior IT Administrator who will be responsible for the maintenance and planned upgrades to our network infrastructure, as well as the day-to-day administration of computer hardware.

Responsibilities:

Providing prompt and effective first-level support for network issues, telecommunications, and workstation-related concerns, serving as the initial point of contact for all IT-related inquiries.
Ensuring Distributed Replicated Block Device (DRBD) functions as expected.
Maintaining network performance by monitoring and analyzing system activity, optimizing performance, troubleshooting network issues, and escalating problems as required.
Diagnosing and resolving hardware and software issues, including replacing defective components.
Assisting in the maintenance of all network hardware, software, printers, phones, RF hand scanners, laptops, and other IT equipment.
Ensuring the company’s 3CX phone system remains in optimal working condition.
Preparing users by designing and conducting training programs, as well as providing reference materials and ongoing support.
Staying up to date with industry developments by participating in educational opportunities, reading professional publications, maintaining professional networks, and engaging with industry organizations.
Protecting the organization’s assets by maintaining confidentiality of sensitive information.
Supporting organizational goals by taking ownership of new and diverse requests and exploring opportunities that add value.

Skills and Qualifications:

Degree in Information Technology, Computer Science, or a related discipline.
A minimum of 7 years experience in a similar role.
Industry-standard certifications such as A+, Network+, MCP, etc.
One to three years of experience as a Microsoft Systems Support Technician.
Hands-on knowledge of current Microsoft software, including Windows and Office applications.
Practical understanding of desktop and laptop repair, as well as troubleshooting methods.\
Proficiency in the following systems (considered strong assets): LINBIT DRBD, Open-ERP, ECI M1, Warehouse Management Systems, Anti-virus software (Sophos, Avast), Network security, Office 365, Windows 10, Windows Server 2012 R2, Juniper Networking, Cisco Wi-Fi.
Working knowledge of VoIP phone systems (Yealink).
Exceptional interpersonal skills, written communication abilities, and organizational skills.

Benefits

Casual dress
Company events
Dental care
Disability insurance
On-site parking
Vision care

Accessibility

Adamson Systems is an equal opportunity employer, dedicated to creating a workplace culture of inclusiveness that reflects the diverse residents that we serve.

Adamson Systems is committed to creating an accessible and inclusive organization; we provide barrier-free and accessible employment practices in compliance with the Accessibility for Ontarians with Disabilities Act (AODA). Should you require accommodation through any stage of the recruitment process, please make them known when contacted and we will work to accommodate your needs. Disability-related accommodation during the application process is available upon request.","{""role_summary"":""The Senior IT Administrator is responsible for maintaining and upgrading the company's network infrastructure, providing technical support, and ensuring the smooth operation of IT equipment and systems."",""key_terms"":[{""term"":""Distributed Replicated Block Device (DRBD)"",""explanation"":""A software-based, shared storage system that replicates data across multiple devices for high availability and redundancy.""},{""term"":""3CX phone system"",""explanation"":""A software-based, private branch exchange (PBX) system for managing and directing phone calls within an organization.""},{""term"":""LINBIT DRBD"",""explanation"":""A specific implementation of the DRBD technology, used for data replication and high availability in storage systems.""},{""term"":""Open-ERP"",""explanation"":""An open-source enterprise resource planning (ERP) system for managing business operations and resources.""},{""term"":""ECI M1"",""explanation"":""A specific enterprise resource planning (ERP) system for managing business operations and resources.""},{""term"":""Warehouse Management Systems"",""explanation"":""Software systems used to manage and control warehouse operations, including inventory, shipping, and receiving.""},{""term"":""VoIP phone systems"",""explanation"":""Voice over Internet Protocol (VoIP) systems allow for voice communications over internet protocol networks.""}],""skill_priorities"":{""must_have"":[""Degree in Information Technology, Computer Science, or a related discipline"",""A minimum of 7 years experience in a similar role"",""Industry-standard certifications such as A+, Network+, MCP, etc."",""Hands-on knowledge of current Microsoft software, including Windows and Office applications"",""Practical understanding of desktop and laptop repair, as well as troubleshooting methods""],""nice_to_have"":[""One to three years of experience as a Microsoft Systems Support Technician"",""Proficiency in LINBIT DRBD, Open-ERP, ECI M1, Warehouse Management Systems, Anti-virus software (Sophos, Avast), Network security, Office 365, Windows 10, Windows Server 2012 R2, Juniper Networking, Cisco Wi-Fi"",""Working knowledge of VoIP phone systems (Yealink)""]},""proposed_screening_questions_with_answers"":[{""question"":""What steps would you take to troubleshoot a network issue, and how would you escalate the problem if necessary?"",""example_answer"":""I would first gather information about the issue, then use tools like ping and tracert to identify the source of the problem. If necessary, I would escalate the issue to a senior administrator or a specialized team, providing detailed documentation of the issue and the steps I've taken so far.""},{""question"":""How do you stay current with industry developments and advancements in IT?"",""example_answer"":""I regularly read industry publications, participate in online forums and discussion groups, and attend training sessions and conferences to stay up-to-date with the latest technologies and best practices.""}],""red_flags"":[""Lack of experience with Microsoft software and systems"",""Inability to troubleshoot and resolve technical issues"",""Poor communication and interpersonal skills""],""confidence_score"":90.0}"
IT Help Desk Manager,"Status: Full-time, Permanent Position | Location: Vaudreuil-Dorion, QC

Report To: Director of Information Systems | Service: Information Systems

Overview

Reporting to the Director of Information Systems, the IT Help Desk Manager will oversee the daily operations of our help desk, manage escalations, ensure compliance with service-level agreements (SLAs), and continuously improve processes to enhance end-user support. This role requires a strong leader with a strategic mindset to guide the team, optimize workflows, and implement best practices in IT service management.

In a smaller team environment, this role may also involve hands-on technical work.

Responsibilities

Help Desk Operations & Team Management

Oversee the help desk function, ensuring timely and effective resolution of IT support tickets.
Manage and mentor Help Desk Technicians, providing guidance and professional development opportunities.
Ownership and administration of Fastco’s ITSM platform to streamline ticket management and reporting.
Ensure adequate staffing coverage for IT support during both regular and off-hours using HCM software and other scheduling tools.
Establish and enforce Standard Operating Procedures (SOPs) for help desk workflows, security protocols, and troubleshooting guides.
Analyze ticket data and user feedback to identify areas for service improvement and training opportunities.


IT Service Management & Escalations

Participate in the evaluation of new and existing products/vendors, with the collaboration of the Product Development, Technical Services & Sales departments.
Work with the planning department to identify opportunities to improve forecasting models for better product availability.
Work with Marketing to stay informed of ongoing sales initiatives that could lead to demand peaks and/or stock depletion.
Work with Product Managers and the Master Planner to review the Management forecast on new items.
Provide support in the S&OP cycle.


Security & Compliance

Ensure that all help desk procedures align with company security policies, especially when handling sensitive user data.
Enforce security best practices, including password management, user authentication policies, and access control procedures.
Stay informed about cybersecurity threats and ensure the team follows best practices for data privacy and confidentiality.
Conduct post-incident reviews for major issues and work towards long-term preventative solutions.


Process Improvement & Reporting

Continuously review and refine help desk processes to improve response times, efficiency, and user satisfaction.
Monitor key performance metrics (e.g., ticket resolution time, user satisfaction scores, firstcall resolution rate) and provide reports to senior management.
Provide insights and recommendations for IT budgeting, including technology investments, staff training, and resource allocation.


End-User Support & Training

Ensure end-users receive high-quality technical support and customer service.
Develop user guides, knowledge base articles, and training sessions to empower employees to resolve common IT issues independently.
Gather and analyze user feedback to drive improvements in IT support services.


Required Skills & Qualifications

5+ years of experience in IT support, with at least 2+ years in a leadership or management role.
Strong expertise in IT service management (ITSM) tools like Freshdesk, SeviceNow, or similar platforms.
Experience working in Active Directory, M365, Windows, Linux, and cloud environments.
Hands-on experience in troubleshooting network, hardware, and software issues.
Strong understanding of IT security best practices, compliance standards, and access control policies.
Experience with help desk performance metrics, reporting, and continuous improvement initiatives.
Excellent leadership, strategic planning, and process improvement skills.
Excellent communication and interpersonal skills in French, with a good command of English to facilitate collaboration between teams.
Ability to manage and prioritize multiple tasks, projects, and escalations in a fast-paced environment.


Preferred Qualifications

ITIL certification (or experience with ITIL best practices).
Certifications such as CompTIA, Microsoft, or similar.
Experience with Human Capital Management (HCM) scheduling software or similar workforce management tools.
SAP ByDesign or similar ERP system experience


This position may require minimal travel.","{""role_summary"":""The IT Help Desk Manager oversees daily help desk operations, manages escalations, and ensures compliance with service-level agreements. They lead the team, optimize workflows, and implement best practices in IT service management."",""key_terms"":[{""term"":""ITSM"",""explanation"":""IT Service Management, a set of practices to manage IT services, including incident, problem, and change management.""},{""term"":""SLAs"",""explanation"":""Service-Level Agreements, which define the expected service quality, responsiveness, and resolution times for IT support.""},{""term"":""Fastco's ITSM platform"",""explanation"":""A specific IT Service Management tool used by the company for ticket management and reporting.""},{""term"":""HCM software"",""explanation"":""Human Capital Management software used for scheduling and workforce management.""},{""term"":""SOPs"",""explanation"":""Standard Operating Procedures, which outline step-by-step instructions for help desk workflows, security protocols, and troubleshooting guides.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management best practices.""},{""term"":""CompTIA"",""explanation"":""A certification for IT professionals, covering a range of topics including IT service management, security, and networking.""},{""term"":""SAP ByDesign"",""explanation"":""An Enterprise Resource Planning (ERP) system used for managing business operations and resources.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in IT support"",""Strong expertise in IT service management (ITSM) tools"",""Experience working in Active Directory, M365, Windows, Linux, and cloud environments"",""Strong understanding of IT security best practices, compliance standards, and access control policies"",""Excellent leadership, strategic planning, and process improvement skills"",""Excellent communication and interpersonal skills in French, with a good command of English""],""nice_to_have"":[""ITIL certification (or experience with ITIL best practices)"",""Certifications such as CompTIA, Microsoft, or similar"",""Experience with Human Capital Management (HCM) scheduling software or similar workforce management tools"",""SAP ByDesign or similar ERP system experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach optimizing help desk workflows to improve response times and user satisfaction?"",""example_answer"":""I would analyze ticket data and user feedback to identify bottlenecks, then implement process improvements, such as automating routine tasks and streamlining escalation procedures. I would also establish clear communication channels with the team and stakeholders to ensure seamless collaboration.""},{""question"":""Can you describe your experience with IT service management tools, such as Freshdesk or ServiceNow?"",""example_answer"":""I have hands-on experience with Freshdesk, where I managed ticket workflows, configured custom fields, and generated reports to track key performance metrics. I'm confident in my ability to adapt to similar platforms.""}],""red_flags"":[""Lack of experience in IT service management tools"",""Inability to communicate effectively in French and English"",""Insufficient understanding of IT security best practices and compliance standards""],""confidence_score"":90.0}"
"Manager, IT and Facilities","Who we are YouthLink believes in the potential of every youth, and we are dedicated to providing them with the support, guidance and opportunities they need to make positive life choices. We provide youth with brief and ongoing counselling, in-home wraparound support, shelter, housing, educational support, and safe drop-in spaces. Guided by our mission and inspired by the potential to make a profound impact, Youthlink works closely with youth, families and partners in our community. We come together to highlight and develop strengths, aspirations and positive actions that improve the health and well-being of all who live, work, study and play in our community. As a service delivery organization, we leverage data-driven decision-making and grassroots engagement with youth advisory councils to create an inclusive, innovative, and responsive agency that provides the best fit and most needed services for our communities. If you are seeking a meaningful opportunity and want to play a key role in bringing our vision for a stronger Scarborough where all youth and families thrive, join us. (Full-time 35 hours per week) Non-Bargaining Unit Position IT Systems and Operations 45% Plans, manages and evaluates the operations of information systems and electronic devices. With vendors, develops a systems infrastructure plan for networking a wide-area network for the entire agency, ensures UPS back-up, Security monitoring/ cyber security.Develops system requirements, specifications, costs and timelines. Manages Web contractors for the YouthLink Website ensuring updates are added as needed. Ensures technology is accessible and equipped with current hardware and software. Trouble shoots hardware, software and network operating system for Issues. Negotiates the best cost for staff phones, sets them up, trains staff in use of phones, and troubleshoots. On boards staff with fobes, phones, computers, access to buildings. Maintains photocopiers, negotiates contracts with vendors. Hires and manages contractors for system projects regarding network infrastructure, Telecommunications software, and information systems. Provides orientation, training and support to users Supports off-site employees with the use of laptops, email and other forms of online communication. Installs and maintains AV equipment. Facilities 45% Ensures that the buildings meet all health and safety requirements; Ensures compliance with building and safety codes, hazardous waste disposal, handling hazardous materials, fire alarm systems and fire protection equipment. Plans best allocation and utilization of space and resources; investigates availability and suitability of options; evaluates costs for required goods or services to achieve maximum value for money; plans for future development in line with business objectives. Prepares documents to put out to tender for contractors; manages projects and supervises work of contractors; follows up for completion and payment. Manages all contracts for cleaning, landscaping, elevators, HVAC, and electrical. Maintains a key control system for all locations. Budgets and Planning 10% Maintains current and accurate inventory of technologies, facilities, goods, hardware, software and resources. Monitors the help-desk system daily for reported problems with facilities or IT. Assigns priorities to issues reported. Responds to staff and keeps them informed of progress or problem resolution. Provides help desk statistics and reports. In conjunction with the Senior Director of Finance, Administration manages facility and technology budgets and expenditures. Actively contributes to the Agency’s Strategic Plan by participating in initiatives and committees to support the Plan. May be asked to contribute to the development of a funding proposal. Takes all reasonable and necessary precautions to protect his or her own health and safety and that of co-workers by complying and demonstrating knowledge of the policies, procedures and safe practices established by Youthlink. Highlights of What You Bring Education: Undergraduate degree or diploma in Information Technology or a combination of education and experience. Microsoft Certification (MCSE) required. Experience: Five years experience in an IT environment, computer operations, and technical support Five years experience in project management, facilities and maintenance, preparing RFPs and negotiating contracts. Three years of managerial experience. Experience implementing and managing in a Microsoft Windows platform, Virtualization, Clustering technologies, Exchange, personal computer Office Tools, Virus Scanning, Security, Firewalls, SQL databases Experience in cell phones technologies. Proficient knowledge in computer hardware and software systems and programs, network administration and installation, troubleshooting, viruses and security, email and internet programs and protocols. Skills: Demonstrated ability to manage large scale projects in either IT or facilities and manage contractors. Ability to work as a team and understand team building skills. Exceptional analytical and problem solving skills. Decision making skills. Effective verbal, presentation and listening communications skills, and effective written communications skills Ability to work under stress and assign priorities to work Working conditions This position works normal hours but is required to be on-call for emergencies related to the building, security, or equipment, or systems failure. Travelling between agency sites required. Physical Requirements This position has some physical demands, such as lilting, bending and reaching. Working on a computer screen for long periods of time. Join us. YouthLink's core values define what we stand for and how we operate, helping us to work together in the most fulfilling ways. We value leadership , acting in ways that exemplify what we expect of each other and our clients. We work together, bringing out the best in each other and creating strong working relationships. Our professional ethics are evident in all the work we do and the decisions we make. We value humanity and show consideration for people, their abilities, skills, diversity and perspectives. We create an inclusive workplace that celebrates individual differences and, through our actions, demonstrates empathy, goodwill and honesty. We value innovation , demonstrating flexibility and changeability in adapting to our work and community dynamics. We show courage in developing service initiatives that will improve the well-being of our clients and their families. We value respect for people for who they are and for their knowledge, skills and experience as individuals and team members. We treat clients with respect and fairness and encourage the same in return. We value excellence , demonstrating competence and accountability in delivering client services. We display clear judgment and exhibit clear thinking and reasoning in all situations. We continually strive to accomplish all tasks and provide an outstanding service for our clients. Benefits At YouthLink, we understand the nature of our work and the deep commitment every team member offers. We strive to provide a rewarding compensation and benefits package to support our people. This includes: Comprehensive health and dental coverage for you and your family, with 100% of the premiums fully covered. Annual vacation with pay at 1.66 working days for each calendar month to a maximum of 20 working days per year. 5 ‘authorized absence’ days for family illness or emergency circumstances that prohibit employees from reporting to work. 3 paid agency days every calendar year after 3 calendar months service. Maternity / parental /adoption leave top-up payments (to top-up Canadian government unemployment benefit payments). 100% premium cost for long-term disability coverage paid by employee. Eligibility to participate in the pension plan after 2 years of continuous service with a generous matching employer contribution. Apply now. We welcome applications from candidates who reflect the communities we serve, particularly candidates from Black communities, Indigenous communities, racialized people, persons with disabilities, members of diverse gender identities and people with lived experiences. We are seeking candidates who demonstrably operate and practice from an equity and trauma-informed lens.We encourage applications from passionate professionals who will help us dismantle systemic barriers and embrace working outside of Euro-centric practices. If you meet 70% of the qualifications we are looking for and share 100% of our passion and commitment to supporting youth and their families, please submit your application. We can’t promise to hire you; we can promise to review your lived and learned experiences fully. We are committed to providing equitable employment opportunities and a workplace free from discrimination and harassment. We are equally committed to providing an inclusive and accessible workplace. If you require accommodations at any stage of the interview process, please email us at accessibility@youthlink.ca . Powered by JazzHR","{""role_summary"":""The IT Systems and Operations role is responsible for planning, managing, and evaluating the operations of information systems and electronic devices, as well as ensuring the maintenance and upkeep of facilities, including health and safety requirements."",""key_terms"":[{""term"":""Microsoft Certification (MCSE)"",""explanation"":""A certification that demonstrates expertise in Microsoft systems and technologies.""},{""term"":""Virtualization"",""explanation"":""A technology that allows multiple virtual machines to run on a single physical machine.""},{""term"":""Clustering technologies"",""explanation"":""A technology that allows multiple computers to work together as a single system.""},{""term"":""SQL databases"",""explanation"":""A type of database management system that uses Structured Query Language to manage and manipulate data.""}],""skill_priorities"":{""must_have"":[""Microsoft Certification (MCSE)"",""Experience in IT environment, computer operations, and technical support"",""Experience in project management, facilities and maintenance"",""Managerial experience"",""Proficient knowledge in computer hardware and software systems and programs""],""nice_to_have"":[""Experience implementing and managing in a Microsoft Windows platform"",""Experience with cell phones technologies"",""Ability to work as a team and understand team building skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with Microsoft Certification (MCSE) and how you have applied it in previous roles?"",""example_answer"":""I have held an MCSE certification for the past 5 years and have used it to design and implement Microsoft-based solutions for my previous employers. In my current role, I have used my MCSE skills to troubleshoot and resolve technical issues with our Microsoft systems.""},{""question"":""How do you stay current with the latest developments in IT and facilities management?"",""example_answer"":""I regularly attend industry conferences and seminars, and I also participate in online forums and discussion groups to stay up-to-date with the latest trends and best practices in IT and facilities management.""}],""red_flags"":[""Lack of experience with Microsoft Certification (MCSE)"",""Inability to work independently and manage multiple projects simultaneously"",""Poor communication and interpersonal skills""],""confidence_score"":90.0}"
Technology Manager,"Entity: Doctor Care
Position: Technology Manager
Type: Full Time
Location: Toronto
Salary Range: $140,000 - $160,000CAD


About the Company:

WELL Health Technologies is an innovative technology-enabled healthcare company whose overarching objective is to positively impact health outcomes by leveraging technology to empower and support healthcare practitioners and their patients and is publicly traded on the Toronto Stock Exchange under the symbol ""WELL."" As the largest clinic network in Canada, operating under the WELL Health Clinic Network brand, we currently have 200+ clinics across the country. Our team includes over 3,400 WELL Care Providers, facilitating more than 4.2 million patient interactions each year. Our clinics offer a diverse range of services, including walk-in appointments, family medicine, internal medicine, Kinesiology, sleep apnea treatment, and women’s health services. WELL exists to enable healthcare practitioners with best-in-class technology and services. The company has built a comprehensive practitioner enablement platform which includes digital Electronic Medical Records (EMR), practice management software, practitioner enablement tools, telehealth platforms, digital health apps that extend the features of EMRs, billing and Revenue Cycle Management (RCM) solutions, patient engagement technologies, clinic optimization tools, data protection solutions and more. The platform empowers healthcare providers with digital healthcare products, tools, and services designed to enhance the delivery of care, and improve their patients’ healthcare experience and health outcomes. For more information about the companies, visit; www.well.company, wellclinics.ca

DoctorCare is a group of Canadian healthcare experts making it easier for doctors to get paid. We are a technology solution provider that takes the administrative burden of complex medical billing off of doctors’ plates, enabling them to focus on what really matters: cutting wait times and improving the delivery of care and the patient experience. We are changing the practice of medical billing for all doctors. Our solutions and services are designed to help doctors ensure they are maximizing their revenue, improving patient care, and growing their practice. Our platform delivers innovative, customizable, yet simple solutions that let doctors focus on medicine while we take care of the administration. Patients deserve the best possible care – and we give doctors the tools they need to provide it.

Position Summary:

Reporting to the VP Engineering, the Technology Manager is responsible for leading all technology functions within the DoctorCare organization including engineering (software development, infrastructure, operations, devops) and technology systems (IT helpdesk, Salesforce CRM). You will be responsible for directly managing a team of 6 and providing them day to day prioritization, enablement and coaching. This is a very diverse and challenging role requiring a wide range of technology, people management and business systems experience. The role requires a very hands technology leader that is capable of executing, managing frequent context changes and leading multiple products and functions at the same time.

What you will be doing:

Technical Execution
As the lead of the engineering team, your key responsibilities is the delivery of quality software that delights our customers and meets our strategic objectives.

Success factors:
% of Epics that are delivered on time is greater than 80%
Rate of software bug injections is reducing quarter over quarter
Deployment frequency is increasing quarter over quarter

Talent Development
The DoctorCare engineering team is a youthful and energetic group. As the Technology Manager, you will provide hands on technology coaching, goal setting and personal development support for all levels of the team.

Success factors:
Team members are actively working towards and tracking against stretch goals and learning objectives
Greater than 95% voluntary staff retention rate within your first 12 months

Technical Alignment
Working with your peer, technical leads at sister companies, you will align regularly with other engineering teams to drive enterprise technology re-use and reduce duplication of effort across teams.

Security and Privacy Management
Ensure that all technologies at DoctorCare are managed from the perspective of security and privacy.

Outcomes
Leading the DoctorCare technology team, you will lead deliver the following outcomes within the first 12 months of your tenure as director of engineering:

Automate Billing Care Workflows
Working with the Client Success team, design and implement automation workflows capable of reducing the overall human effort required to deliver the Billing Care product by at least 25%.
Launch ClinicAid Mobile Application
Design and lead the execution of ClinicAid’s greenfield mobile application. This will require a new re-architecting of the entire stack with an eye to developing it in a mobile, FHIR native format leveraging ReactJS and React Native.
Launch ClinicAid’s new API Business
Develop full support for ClinicAid’s newly launched API as a service product line. Develop documentation, sales and support processes, operational processes, etc.
ISO 27001 Certification
Lead DoctorCare’s ISO 27001 certification with a goal of accomplishing certification within the next 18 months.

You have:

As a technical leader, you are expected to have intimate software development experience. You are familiar both with the execution of modern software development tools and practices as well as in building high performing software development culture and teams.
As a leader, you inspire those around you to improve and seek to constantly improve yourself. You do not shy from the hard work of leading from the front and don’t deflect responsibility.

Balance your deep experience in software development with a humility that provides support for those around you to ask questions with comfort and ease. Don’t rush to dismiss. Provide space for all ideas. Promote the best ideas without ego.
You ensure goals and alignment are established and ensure that all teams are actively working towards those goals.
Exhibit a daily drive to results that is thoughtful but values action over perfection.
Demonstrate professionalism in all aspects of software development. Does not cut corners but also doesn’t die on hills of purity and process.
The role requires individuals that have a generally high level of intelligence and a mental toughness for solving problems.
You have experience with Python, ruby or other OOP language, SQL. You have strong standards around testing practices. Experience with React is a plus.
You have a strong mind towards modern architecture including the AWS platform, Identity systems, modern authentication flows, data systems, etc.
Able to communicate clearly in a structured and thoughtful fashion. Provides context (background) and clarity (details) as required and appropriately. Direct.
Is eager to help others. Loves to see the team grow and improve. Recognizes raised hands and provides support with comfort.

The salary offered for this position falls within a specified salary range and will be determined based on a variety of factors, including but not limited to the candidate's experience, qualifications, skills, and the specific needs of the organization.

At WELL, we believe in fair and equitable compensation, and our goal is to offer a competitive salary that reflects the value and expertise of the selected candidate.

WELL is committed to supporting a diverse, inclusive, and accessible workplace. We welcome and celebrate the diversity of applicants and team members across ability, race, gender identity, sexual orientation, and perspective. We strive to create an inclusive workplace where differences are celebrated and fuel our success – this is the WELL Way!

WELL has been independently certified as a Great Place to Work® by Great Place to Work Institute® Canada, an achievement that reflects the company’s strong commitment to creating a workplace culture centered on trust, inclusivity, and employee well-being, aligning with its ‘Healthy Place to Work’ ESG strategy pillar.

Want Read more about us: https://stories.well.company/","{""role_summary"":""The Technology Manager leads the technology functions within DoctorCare, including engineering and technology systems, and is responsible for delivering quality software, developing team members, and ensuring technical alignment and security."",""key_terms"":[{""term"":""FHIR"",""explanation"":""Fast Healthcare Interoperability Resources, a standard for exchanging healthcare information electronically.""},{""term"":""ReactJS"",""explanation"":""A JavaScript library for building user interfaces and can be used for developing web and mobile applications.""},{""term"":""ISO 27001"",""explanation"":""An international standard for information security management systems, ensuring the confidentiality, integrity, and availability of information.""}],""skill_priorities"":{""must_have"":[""Python, Ruby or other OOP language"",""SQL"",""Experience with modern architecture including AWS platform, Identity systems, modern authentication flows, data systems"",""Strong standards around testing practices""],""nice_to_have"":[""Experience with React""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach automating billing care workflows to reduce human effort by at least 25%?"",""example_answer"":""I would analyze the current workflow, identify areas for automation, and design a solution using modern software development tools and practices, ensuring alignment with the company's strategic objectives.""},{""question"":""How do you ensure the security and privacy of technologies within an organization?"",""example_answer"":""I would implement a robust security and privacy management framework, ensuring compliance with industry standards and best practices, and conducting regular security audits and risk assessments.""}],""red_flags"":[""Lack of experience with modern software development tools and practices"",""Inability to communicate technical information clearly and effectively"",""Insufficient experience with team management and leadership""],""confidence_score"":90.0}"
"manager, information systems","Overview

Languages

English

Education

Bachelor's degree

Experience

3 years to less than 5 years

On site

Work must be completed at the physical location. There is no option to work remotely.

Work setting

Hotel, motel, resort

Responsibilities

Tasks

Plan and control budget and expenditures
Recruit staff
Supervise staff
Train staff
Establish and implement policies and procedures for information systems
Manage incidents
Plan, organize, direct, control and evaluate daily operations

Additional information

Work conditions and physical capabilities

Fast-paced environment
Work under pressure
Tight deadlines
Attention to detail
Large workload

Personal suitability

Efficient interpersonal skills
Excellent oral communication
Excellent written communication
Flexibility
Initiative
Judgement
Organized
Reliability
Team player
Values and ethics
Proactive

Employment groups

This employer promotes equal employment opportunities for all job applicants, including those self-identifying as a member of these groups:

Support for persons with disabilities

Provides awareness training to employees to create a welcoming work environment for persons with disabilities

Support for newcomers and refugees

Provides diversity and cross-cultural trainings to create a welcoming work environment for newcomers and/or refugees

Support for youths

Provides awareness training to employees to create a welcoming work environment for youth

Support for Veterans

Provides awareness training to employees to create a welcoming work environment for Veterans

Support for Indigenous people

Provides cultural competency training and/or awareness training to all employees to create a welcoming work environment for Indigenous workers

Support for mature workers

Provides staff with awareness training to create a welcoming work environment for mature workers

Supports for visible minorities

Provides diversity and cross-cultural training to create a welcoming work environment for members of visible minorities","{""role_summary"":""Manage daily hotel operations, including budgeting, staff supervision, and policy implementation, in a fast-paced environment."",""key_terms"":[{""term"":""Information systems"",""explanation"":""Computer systems and technology used to manage and store data in a hotel setting.""}],""skill_priorities"":{""must_have"":[""Leadership skills"",""Budgeting and financial management"",""Communication skills"",""Time management and organization""],""nice_to_have"":[""Experience in the hospitality industry"",""Knowledge of diversity and inclusion practices""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you handle a last-minute staff shortage during peak season?"",""example_answer"":""I would quickly assess the situation, identify available resources, and make adjustments to ensure minimal impact on hotel operations. I would also communicate clearly with staff and guests to maintain a positive experience.""},{""question"":""Can you give an example of a time when you had to implement a new policy or procedure in a previous role?"",""example_answer"":""In my previous role, I introduced a new customer feedback system, which involved training staff and creating procedures for data collection and analysis. The system improved customer satisfaction ratings by 15%.""}],""red_flags"":[""Lack of experience in a fast-paced, deadline-driven environment"",""Inability to work effectively in a team-oriented setting""],""confidence_score"":80.0}"
"Manager, ITSM Process Lead","Akkodis is partnered with a leading FinTech who specialize in payment processing to recruit a Manager, ITSM Process Lead to join an IT Service Management team located in Toronto.

In this role, you will be responsible for overseeing a team of 5 direct reports. Outside your people management responsibilities, you'll play a pivotal role in driving ITSM transformation - enhancing processes, implementing improvements, and ensuring ITSM best practices are embedded across the technology environment.

What you'll do:
Lead & Enhance ITSM Processes – Oversee Incident, Major Incident, Problem, and Change Management, ensuring compliance, efficiency, and continuous improvement.
Drive ITSM Transformation – Execute the ITSM roadmap, introduce new tools like CAB Workbench, and implement training programs to support adoption.
Manage a High-Performing Team – Guide and mentor a team of five direct reports, including a Major Incident Manager, fostering best-in-class ITSM capabilities.
Lead High-Stakes Major Incidents – Take command in 24/7 critical situations when needed, making sound decisions under pressure and coordinating with senior technology leaders.
Be the Trusted ITSM Expert – Present regularly to the CTO and SVPs, leveraging industry knowledge to drive strategic ITSM advancements.
Promote Data-Driven Improvement – Analyze key ITSM metrics, identify trends, and spearhead initiatives to enhance overall service quality.

What You Bring
10+ years in IT Service Management (ITSM), with hands-on experience in Incident, Major Incident, Problem, and Change Management
3+ years of leadership experience, managing ITSM teams in enterprise environments
Strong track record of introducing, managing, and optimizing ITSM processes in large, complex organizations
Exceptional communication & stakeholder management skills—confident presenting to executive leadership
Experience with CAB Workbench implementation and ITSM training programs (a plus)
ITIL V3 or V4 Intermediate certification (Expert level is an asset)


If you are interested in learning more or would like to discuss any other ITSM Process & transformation roles, don't hesitate to apply!","{""role_summary"":""Manage a team of ITSM professionals, drive ITSM transformation, and ensure best practices are embedded across the technology environment."",""key_terms"":[{""term"":""ITSM"",""explanation"":""IT Service Management, a set of policies, procedures, and processes to manage IT services.""},{""term"":""Incident Management"",""explanation"":""The process of restoring normal IT service operation as quickly as possible after an unplanned interruption.""},{""term"":""Major Incident Management"",""explanation"":""The process of managing high-impact incidents that require immediate attention and resolution.""},{""term"":""Problem Management"",""explanation"":""The process of identifying and resolving the root cause of incidents to prevent future occurrences.""},{""term"":""Change Management"",""explanation"":""The process of controlling and managing changes to IT services to minimize risk and disruption.""},{""term"":""CAB Workbench"",""explanation"":""A tool used for Change Advisory Board (CAB) meetings to manage and track changes.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management best practices.""}],""skill_priorities"":{""must_have"":[""10+ years of ITSM experience"",""3+ years of leadership experience"",""Strong communication and stakeholder management skills"",""ITIL V3 or V4 Intermediate certification""],""nice_to_have"":[""Experience with CAB Workbench implementation"",""ITIL V4 Expert certification""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with ITSM process implementation and optimization in a large, complex organization?"",""example_answer"":""In my previous role, I introduced and managed ITSM processes, resulting in a 30% reduction in incident resolution time and a 25% increase in customer satisfaction.""},{""question"":""How do you ensure effective communication and stakeholder management in high-pressure ITSM situations?"",""example_answer"":""I prioritize clear and concise communication, actively listening to stakeholders and providing regular updates to ensure their needs are met, even in critical situations.""}],""red_flags"":[""Lack of leadership experience in ITSM teams"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
"Manager, IT Solutions","Overview

We are seeking a Manager, IT Solutions to join our Vancouver HQ to lead our System Operations and IT Support teams. This role reports the Director, Business Excellence and is involved in overseeing core IT functions (ERP, integrations, retail/wholesale IT) and developing the strategy, design, support, maintenance, and enhancement of the organization’s IT infrastructure.

The successful candidate will be responsible for the performance, security, and reliability of all IT managed systems and will require a strong understanding of cloud technologies, ERP systems, and the ability to effectively manage both internal teams and external partners. Collaboration with our Senior Data Scientist on data storage infrastructure and security may also be required.

We’re a fast-growing retail startup and this is an excellent opportunity to shape how technology serves our teams and customers. If you’re looking to make a big impact on a key area of our business, we want to hear from you!

What You’ll Do:

Leadership & Management: Provide overall leadership and direction for the IT department, including the System Operations and IT Support teams. Foster a collaborative, high-performing team environment.
System Integrations: Oversee the System Operations team's management of integrations between commercial platforms (Shopify, POS, NuOrder B2B, SPS), the ERP system, and third-party logistics providers, leveraging our Celigo iPaaS platform. Ensure seamless data flow via API and EDI integrations and maintain an integration roadmap aligned with business needs.
ERP System Management (Netsuite): Provide strategic oversight of the Netsuite ERP system, ensuring its effective utilization and alignment with business needs. Work with the Netsuite Administrator and System Operations team to ensure smooth ERP operations and integrations.
Retail IT Operations: Provide strategic direction and support for retail IT operations, working closely with the IT Support team and any managed service providers (MSPs). Ensure consistent IT standards and security practices across all locations.
IT Infrastructure Management: Oversee the IT Support team's management of the IT infrastructure, including servers, networks, desktops, telephony, and infrastructure applications. Work with the IT Support lead to ensure optimal performance, security, availability, and reliability.
IT Operations & Support: Provide strategic guidance for IT support operations, ensuring timely and effective technical support for end-users. Oversee the development and maintenance of standard operating procedures for system support and maintenance.
IT Projects & Vendor Management: Oversee IT projects, including the design, procurement, installation, and lifecycle management of IT infrastructure and end-user hardware and software. Manage relationships with infrastructure vendors and external consultants, serving as the primary point of escalation.
Security & Compliance: Develop and enforce IT security policies and procedures. Conduct regular security audits, process audits, and vulnerability assessments. Ensure IT systems comply with security standards and policies and data privacy regulations. Respond to security incidents and implement appropriate remediation measures.
IT Strategy & Planning: Collaborate with the Director of Business Excellence to develop and implement a long-term IT strategy aligned with business objectives. Research and recommend new technologies to drive efficiency and innovation. Manage the IT budget and track technology investments.
Data Infrastructure Collaboration: Collaborate with the Senior Data Scientist on data storage infrastructure and security, as needed.
KPI Reporting & Analysis: Monitor, analyze, and report on key IT performance indicators (KPIs), including system uptime, mean time to resolution (MTTR), and incident reporting. Identify trends and areas for improvement.

What We’re Looking For:

Bachelor's degree in Computer Science, Information Technology, or a related field.
4+ years of experience in IT management
Strong understanding of cloud applications, networking, and security.
Experience with ERP systems (Netsuite strongly preferred) and integration platforms.
Experience in network management and modern telephony systems.
Experience managing third-party service providers.
Strong Google Workspace and/or Microsoft background, specifically the M365 suite.
Proven ability to manage and mentor IT teams.
Excellent communication, problem-solving, and project management skills.

It’s a Bonus If You Have:

Experience managing a SaaS infrastructure
Proven experience in leading projects
Proficient in Information Security
Experience in the retail industry is a significant advantage.
Understanding of data management principles and cloud security best practices.

What You’ll Get:

Opportunity to help build an ever-evolving brand and help us achieve Vessi’s vision which is to inspire happier communities
Competitive salary
3 weeks paid vacation
Professional development opportunities
Extended health benefits package including an EAP and a $500 annual Health & Wellness Spending Account
40% Family & Friends Discount
Free Vessi product and 50% Employee Discount
Dog-friendly office","{""role_summary"":""Lead IT teams, oversee IT infrastructure, and develop strategies for IT operations, security, and innovation to support business growth."",""key_terms"":[{""term"":""ERP systems"",""explanation"":""Enterprise Resource Planning systems, used to manage business operations and resources.""},{""term"":""Cloud technologies"",""explanation"":""On-demand computing resources and services provided over the internet, enabling scalability and flexibility.""},{""term"":""iPaaS platform"",""explanation"":""Integration Platform as a Service, used to integrate applications, data, and APIs across the organization.""},{""term"":""Netsuite ERP system"",""explanation"":""A specific ERP system used by the organization to manage business operations and resources.""},{""term"":""Celigo iPaaS platform"",""explanation"":""A specific integration platform used to integrate applications, data, and APIs across the organization.""},{""term"":""API and EDI integrations"",""explanation"":""Application Programming Interface and Electronic Data Interchange integrations, used to enable seamless data flow between systems.""},{""term"":""IT infrastructure"",""explanation"":""The underlying systems, networks, and applications that support the organization's IT operations.""}],""skill_priorities"":{""must_have"":[""Strong understanding of cloud technologies"",""Experience with ERP systems"",""Strong understanding of IT infrastructure"",""Experience managing IT teams"",""Excellent communication and problem-solving skills""],""nice_to_have"":[""Experience managing a SaaS infrastructure"",""Proven experience in leading projects"",""Proficient in Information Security"",""Experience in the retail industry"",""Understanding of data management principles and cloud security best practices""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach developing a long-term IT strategy aligned with business objectives?"",""example_answer"":""I would collaborate with stakeholders to identify business needs, assess current IT capabilities, and develop a roadmap for IT investments and initiatives that drive efficiency and innovation.""},{""question"":""Can you describe your experience with ERP system management and integration?"",""example_answer"":""I have managed ERP systems, including Netsuite, and have experience with integration platforms like Celigo iPaaS. I understand the importance of seamless data flow and API/EDI integrations.""},{""question"":""How do you ensure IT security and compliance in your organization?"",""example_answer"":""I develop and enforce IT security policies and procedures, conduct regular security audits and vulnerability assessments, and ensure IT systems comply with security standards and data privacy regulations.""}],""red_flags"":[""Lack of experience with ERP systems"",""Inability to manage and mentor IT teams"",""Limited understanding of cloud technologies and IT infrastructure""],""confidence_score"":90.0}"
"Team Lead, End User Computing","The Team Lead, End User Computing is accountable for management and operations of all end user devices and peripheral equipment. Responsibilities include design, architecture, sourcing, and management of the end user computing platform, building and maintaining technology standards based on industry best practices, managing a technology roadmap, and proposing/developing new solutions to support the business strategy. The Team Lead, End User Computing will work with the larger IT organization to deliver solutions, serve as a subject matter expert in end user computing technology, manage governance and compliance, and drive the focus to deliver an optimum customer experience.

Identify end user technologies such as desktop workstation hardware, video conferencing technologies, printers and mobile computers which will improve customer satisfaction, reduce cost and improve efficiency.
Architect, design, implement, test and deploy end user technology solutions
Complete research using vendors, interviews and written materials for new and emerging technologies for input into recommendations around potential use within Husky. Research and analysis is also performed in seeking possible solutions for identified issues and problems in major platform changes and functional software deployments.
Work with other team members to develop and test firm images that are used on the majority of our 5,000+ workstation fleet.
Collaborate with Infrastructure, Security and other teams that interface with the end user technology team. Work with Service Desk and regions/offices to provide second level support on hardware and software environments.
Create/test packages and scripts to be distributed through software distribution systems including SCCM and InTune.
Collaborate with vendors and other staff to troubleshoot issues, identify platforms that meet requirements, and ensure regions/offices receive required support and services to provide end users with a stable, consistent platform.
Create and maintain a standards catalog which lists all core end user device platform standards and/or services provided by the End User Computing team.
Assign personnel to various projects, direct their activities, and evaluate their work to ensure timelines and service levels are met
Monitor ongoing staff performance, identify and communicate opportunities for improvement.
Proactively seek and communicate opportunities for improvement in both the operational and customer satisfaction aspects IT
Establish metrics to measure efficient use of existing systems and resources
Promote a professional environment at all times, acting as a point of escalation for staff and internal teams
Manage the lifecycle of all endpoint devices by establishing duty cycles and coordinating ongoing refresh initiatives
Ensure assigned IT support tickets are triaged and resolved within agreed-to SLAs
Other duties assigned.
Requirements
Comprehensive understanding of, but not limited to, PC hardware, meeting room kits, scan guns, printers, mobile devices, software, operating systems, directory services, etc.
Experience with software distribution systems
Experience with device and asset management required
Experience in hardware and software design, installation, configuration, maintenance, and troubleshooting required
Problem solving skills and ability to work under pressure
10+ years of professional IT experience with increasing supervisory experience.","{""role_summary"":""The Team Lead, End User Computing is responsible for managing and operating end user devices and peripheral equipment, designing and implementing technology solutions, and ensuring customer satisfaction."",""key_terms"":[{""term"":""End User Computing"",""explanation"":""Refers to the technology and systems used to support and manage end-user devices, such as desktops, laptops, and mobile devices.""},{""term"":""Technology Roadmap"",""explanation"":""A plan outlining the technology strategy and direction for an organization, including the adoption and implementation of new technologies.""},{""term"":""SCCM"",""explanation"":""System Center Configuration Manager, a software distribution system used to manage and deploy software applications.""},{""term"":""InTune"",""explanation"":""A cloud-based endpoint management solution used to manage and secure devices.""}],""skill_priorities"":{""must_have"":[""Comprehensive understanding of PC hardware, software, and operating systems"",""Experience with software distribution systems"",""Experience with device and asset management"",""Problem-solving skills and ability to work under pressure""],""nice_to_have"":[""Experience with meeting room kits, scan guns, and printers"",""Knowledge of directory services""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your approach to designing and implementing end-user technology solutions?"",""example_answer"":""I would first assess the business requirements and then design a solution that meets those needs, taking into account industry best practices and emerging technologies.""},{""question"":""How do you stay current with new and emerging technologies in end-user computing?"",""example_answer"":""I regularly research vendors, attend industry conferences, and read written materials to stay informed about the latest developments and trends.""}],""red_flags"":[""Lack of experience with software distribution systems"",""Inability to work under pressure and meet deadlines""],""confidence_score"":90.0}"
IT Technical Manager,"Ready to take your career to the next level? Invest in yourself! MSP Corp is a dynamic and evolving organization. Our team is energetic and multidisciplinary, performing at the highest levels.  We thrive on the diversity of our team and believe that any candidate could be the talent to take us to the next level. We drive technology and performance by providing powerful toolsets, business support and professional services. Our team provides complete, turn-key solutions with one goal in mind — to ensure that we can deliver 100% any day, any time.

As we continue to grow, we are seeking a Technical Services Coordinator at MSP Corp to support one of our clients.

About The Role

The Technical Services Coordinator is responsible for managing client-facing IT staff, ensuring efficient handling of escalated technical issues, and maintaining smooth collaboration with both internal and outsourced resources. This role also involves providing leadership, coaching, and development to team members while working closely with the MSP (Managed Service Provider) to support ongoing IT projects and ensure the security and compliance of the organization’s IT infrastructure.

Role title: Technical Services Coordinator
Location: London
Salary: 80,000$ - 95,000 based on experience
Schedule: Monday to Friday (8-hours) 100% onsite

What You’ll Do

Supervise and guide front-line IT staff, providing mentorship and ensuring smooth operations.
Manage escalated technical issues, collaborating with internal and outsourced resources to determine the best course of action.
Deliver hands-on assistance to resolve complex issues, driving timely resolutions and ensuring high-quality outcomes.
Coach, mentor, and motivate team members, fostering a supportive and productive environment.
Oversee the delegation of tasks, ensuring that the team remains aligned with organizational goals and customer needs.

In collaboration with MSP

Partner with IT staff and MSP team members to support ongoing projects, coordinating efforts with assigned project staff.
Work with the MSP to implement disaster recovery, backup procedures, and ensure information security and control measures are in place.
Ensure compliance with relevant IT legislation, including copyright and privacy regulations, in partnership with the MSP.
Collaborate with vendors and the MSP to negotiate project schedules, deadlines, and deliverables. Ensure all escalated issues are documented, tracked, and resolved efficiently.

What We’re Looking For

Proven experience in IT support and team management, particularly in a technical services or IT coordination role Min.5 years.
Strong problem-solving skills with the ability to handle escalations and complex technical challenges.
Effective communicator with the ability to work cross-functionally with internal teams, vendors, and external partners.
Proficient in Microsoft 365 Administration, including Conditional Access Policies and Intune management.
Experience in Windows 10/11 Deployment and Management.
Strong knowledge of Windows Server Administration.
Familiarity with SQL Server Administration.
Expertise in Virtualization Platforms (VMware, Hyper-V).
Hands-on experience with Hosted Server Environments, Clusters, and SANs.
Proficient in managing Multisite Networks.

Why work at MSP Corp.?

Dental care
Extended health care
Life insurance
On-site parking
Paid time off
Vision care

Ready to make a difference? Join us and shape the future. Apply today!

Diversity, Equity & Inclusion at MSP Corp, we believe that diversity, equity, and inclusion are essential for fostering a healthy and innovative work environment. We are committed to creating a workplace where everyone, regardless of age, gender, ethnicity, sexual orientation, ability, or any other characteristic, feels valued and respected. We encourage applications from individuals of diverse backgrounds and perspectives and ensure a fair and inclusive recruitment process.

Thank you for your interest in this opportunity. We will only contact candidates whose profile closely matches the job requirements.","{""role_summary"":""The Technical Services Coordinator is responsible for managing client-facing IT staff, ensuring efficient handling of escalated technical issues, and maintaining smooth collaboration with internal and outsourced resources."",""key_terms"":[{""term"":""Managed Service Provider (MSP)"",""explanation"":""A company that provides IT services and support to clients.""},{""term"":""Conditional Access Policies"",""explanation"":""Security policies that control access to resources based on user and device conditions.""},{""term"":""Intune management"",""explanation"":""A cloud-based endpoint management solution that helps manage and secure devices.""},{""term"":""Virtualization Platforms (VMware, Hyper-V)"",""explanation"":""Software that creates a virtual environment for running multiple operating systems on a single physical machine.""},{""term"":""Hosted Server Environments, Clusters, and SANs"",""explanation"":""Centralized storage and computing resources provided as a service by a third-party provider.""}],""skill_priorities"":{""must_have"":[""Proven experience in IT support and team management"",""Strong problem-solving skills"",""Effective communication skills"",""Proficient in Microsoft 365 Administration"",""Experience in Windows 10/11 Deployment and Management"",""Strong knowledge of Windows Server Administration""],""nice_to_have"":[""Familiarity with SQL Server Administration"",""Expertise in Virtualization Platforms (VMware, Hyper-V)"",""Hands-on experience with Hosted Server Environments, Clusters, and SANs"",""Proficient in managing Multisite Networks""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you handle an escalated technical issue that requires collaboration with internal and outsourced resources?"",""example_answer"":""I would first assess the issue, then gather relevant information and resources. Next, I would collaborate with internal teams and outsourced resources to determine the best course of action, ensuring timely resolution and high-quality outcomes.""},{""question"":""Can you describe your experience with Microsoft 365 Administration, including Conditional Access Policies and Intune management?"",""example_answer"":""I have hands-on experience with Microsoft 365 Administration, including implementing Conditional Access Policies to control access to resources and managing Intune to secure and manage devices.""}],""red_flags"":[""Lack of experience in IT support and team management"",""Inability to handle complex technical challenges"",""Poor communication skills""],""confidence_score"":90.0}"
Technology Strategy Manager,"TRADER Corporation is a trusted Canadian leader in online media, dealer and lender services. The company is comprised of AutoTrader.ca, AutoSync and Dealertrack Canada. AutoTrader.ca (AutoHebdo.net in Quebec) offers the largest inventory of new cars and used cars in Canada, receiving over 25 million monthly visits to its marketplace. With over 3,500 subscribers and counting, AutoSync is the largest and fastest growing dealer and OEM software provider in Canada. The platform's suite of connected automotive software solutions brings advertising, conversion and operational support together, synchronizing the entire retail process. AutoSync's diverse range of offerings includes: vAuto, EasyDeal, xtime, Motoinsight, Activix, TAdvantage and TRFFK. Dealertrack is Canada’s largest automotive financing portal, enhancing efficiency and profitability for all major segments of the automotive, marine, recreational vehicle, motorcycle and powersport retail industries. Over 6.5 million credit applications are submitted via the Dealertrack Canada portal each year. Collateral Management is a national, end-to-end, managed technology solution that offers industry insight and multi-channel collection strategies to maximize funds recovered. Collateral Management helps you remain compliant in all jurisdictions, alleviating your exposure to reputational and financial risks. Visit tradercorporation.com to learn more.

TRADER Corporation's parent company AutoScout24 is the largest pan-European online car market with over 2 million listings and more than 43,000 dealer customers. With AutoScout24, users can find, finance, buy, subscribe for and sell used and new cars. The marketplace provides inspiration on cars and other vehicles and makes hard decisions easy.

Since 1998 AutoScout24 has been offering private users, car dealers and other cooperation partners from the automotive, financial and insurance services sector a comprehensive digital platform for car trading. The online marketplace includes used and new cars, motorcycles as well as commercial vehicles. AutoScout24 has over 30 million users per month, more than 43,000 dealers and around 500 employees. In addition to Germany, AutoScout24 is also represented in the European core markets of Belgium, Luxembourg, the Netherlands, Italy, France and Austria.

More information on www.autoscout24.de

Experience leveraging AI, Generative AI (GenAI) to enhance engineering productivity, automate repetitive tasks, and optimize workflows. Candidates should demonstrate the ability to integrate AI-driven solutions into their daily work — such as code generation, debugging, reviews, documentation, and decision support—to improve efficiency for themselves and their teams. A proactive approach to exploring and implementing AI tools that drive innovation and streamline development processes is highly valued

We are a leading international tech company with operations across Europe and Canada, seeking a dynamic and strategic Technology Strategy Manager to support our Chief Technology Officer (CTO). This pivotal role is designed for an individual who excels in strategic planning, communication, and program management, and who can drive the effectiveness of our global technology organization. The Technology Strategy Manager will act as a trusted advisor to the CTO, ensuring that strategic initiatives are well-communicated, resources are optimally allocated, and programs are executed efficiently across all locations. The successful candidate will embody a mindset akin to a special operations team, diving into complex topics and providing comprehensive support to ensure the success of our strategic technology initiatives.

Key Responsibilities:

Strategic Planning and Execution:
Collaborate with the CTO and technology leadership to formulate and communicate strategic directions for the technology function.Assist in setting priorities, aligning initiatives with overall business objectives, and monitoring execution.Facilitate strategic planning sessions and workshops.
Strategic Communication and Stakeholder Management:
Develop and produce high-quality communication materials (presentations, emails, reports) for internal stakeholders, technology teams, and external parties, including the supervisory board.
Craft clear and compelling messages that articulate the technology vision, strategy, and progress to diverse audiences.
Program and Project Management:
Ensure global technology programs are delivered on time, effectively communicated, and in alignment with technology leadership expectations.
Monitor program progress, identify risks, and implement mitigation strategies.
Lead or support strategic projects as assigned by the CTO, ensuring they are delivered on time, within scope, and meet quality standards.
Analytical Support:
Provide in-depth analysis of technology function metrics, including employee engagement scores, productivity measures, and operational efficiency indicators. Generate comprehensive reports that highlight trends, successes, and areas for improvement within the technology organization.
Budget, Capacity and Resource Planning:
Oversee technology functional capacity and budget planning.
Work closely with HR and finance teams to align staffing and resources with strategic needs and budget constraints.
Analyze workforce data to forecast future staffing requirements.
Operational Efficiency and Change Management:
Identify opportunities to improve processes within the technology organization to enhance efficiency and effectiveness.
Drive and support change management initiatives, ensuring successful adoption of new technologies and processes.
Implement best practices and ensure compliance with organizational policies.

Qualifications:
Bachelor's degree in Computer Science, Information Technology, Business Administration, or a related field; MBA or advanced degree preferred.
Experience in technology (leadership) roles.
Proven experience in strategic planning, program management, and operational leadership within a global organization.
Exceptional communication and presentation skills, with the ability to convey complex technical concepts to non-technical audiences.
Strong analytical and problem-solving abilities, with a data-driven approach to decision-making.
Experience in change management and driving organizational transformation.
Demonstrated ability to manage multiple priorities in a fast-paced, dynamic environment.
Excellent interpersonal skills and the ability to build relationships across diverse teams and cultures.
Knowledge of current technology trends and their potential impact on business strategies.
Familiarity with risk management and compliance in a technology context.

What We Offer:
A leadership role in a forward-thinking, international tech company.
Opportunity to influence the strategic direction and success of our global technology organization.
A collaborative and innovative work environment that values diversity and inclusion.
Competitive salary and comprehensive benefits package.
Professional development opportunities and support for continuous learning.

What’s in it for you…
-We understand that there is life at work and life outside of work. Here are a few benefits we all benefit from that support us to be our creative best.
Fitness and wellness
-We provide discounts to nation-wide gyms, onsite gyms (when we’re in the office), an Employee and Family Assistance Program, as well as a virtual wellness program.
Benefits from Day 1
-Gym discounts
-Local in-office free gyms
-Employee and Family Assistance program
-Weekly virtual wellness events
-Conferences & training budget
-Regular internal training programs
Financial planning
-Let us help you invest in your future with 3% matching towards your pension and multiple forms of income protection.
Competitive salary
-Annual bonus structure
-3% CPP matching","{""role_summary"":""The Technology Strategy Manager will support the Chief Technology Officer (CTO) in strategic planning, communication, and program management, driving the effectiveness of the global technology organization."",""key_terms"":[{""term"":""AI"",""explanation"":""Artificial Intelligence, used to enhance engineering productivity, automate repetitive tasks, and optimize workflows.""},{""term"":""Generative AI (GenAI)"",""explanation"":""A type of AI that can generate new ideas, code, or solutions, used to improve efficiency and innovation in software development.""},{""term"":""CTO"",""explanation"":""Chief Technology Officer, the senior executive responsible for the technology strategy and direction of the organization.""}],""skill_priorities"":{""must_have"":[""Strategic planning and execution"",""Communication and stakeholder management"",""Program and project management"",""Analytical and problem-solving skills"",""Experience in technology leadership roles""],""nice_to_have"":[""MBA or advanced degree"",""Experience with AI and GenAI"",""Knowledge of current technology trends and their potential impact on business strategies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with strategic planning and execution in a technology organization?"",""example_answer"":""In my previous role, I worked with the CTO to develop a 3-year technology roadmap, which involved aligning business objectives with technology initiatives and allocating resources effectively. We were able to increase operational efficiency by 25% and reduce costs by 15%.""},{""question"":""How do you stay current with emerging technology trends and their potential impact on business strategies?"",""example_answer"":""I regularly read industry publications and attend conferences to stay informed about the latest developments in AI, cloud computing, and cybersecurity. I also network with peers and thought leaders to gain insights into best practices and innovative solutions.""}],""red_flags"":[""Lack of experience in technology leadership roles"",""Inability to communicate complex technical concepts to non-technical audiences"",""No experience with AI and GenAI""],""confidence_score"":90.0}"
"Senior Manager, IT Service Management","For over 50 years, LifeLabs has been Canada’s leading provider of laboratory diagnostic information and digital health connectivity systems, enabling patients and healthcare practitioners to diagnose, treat, monitor and prevent disease. We are passionate about empowering healthier Canadians through accessible, accurate, and innovative diagnostic services.

We are committed innovators, operating Canada's first commercial genetics lab, and the country's largest online patient portal, with more than 8 million Canadians receiving their results online. More than 112 million laboratory tests come through LifeLabs’ laboratories annually, and our team of more than 6,000 passionate, caring, and diverse professionals works together as one to provide high quality testing and results that Canadians can trust.

We know that behind every lab requisition, sample being tested, or investment in technology is an individual and their family counting on us. At LifeLabs, you can make a meaningful impact on Canadians’ lives every day.

Our teams are at the heart of everything we do. We are proud to be recognized as one of Canada’s Best Employers, reflecting our deep commitment to our core values of caring, agility, teamwork, and a customer-centered approach. As part of this commitment, LifeLabs prioritizes the ongoing development of our diversity, equity, and inclusion (DEI) program to better serve the needs of our diverse workforce and the communities we serve. We continue to take steps to challenge ourselves to act with courage and integrity, and to create an environment where people can be their true selves.

These values are not just words on a page, they guide our actions and decisions every day and have come to define our team culture.

Reports to: Vice President, Technology Infrastructure & CISO

Status: Full Time

Schedule: Monday-Friday

Additional Requirements: N/A

Number of Positions: 1

Start Date: ASAP

Internal Application Deadline: March 21, 2025

LifeLabs operates under a Hybrid workforce model. Further details will be provided during the interview stage.

This vacancy is for an existing position.

Purpose of the Role

The Senior Manager, IT Service Management is an essential member of the IT Technology Shared Services leadership team and will define, implement, and maintain the IT Service Management portfolio, processes and procedures across internal organization and external suppliers leveraging the Information Technology Infrastructure Library (ITIL) framework. The ideal candidate will oversee the full scope of IT Service Management (ITSM) delivery across IT and to the business. This person will be responsible for the deployment of IT Service Management and its related processes: Incident management, Request Fulfillment, Problem Management, Configuration Management, Change Management, and Knowledge Management.

This person will lead the IT Service Management vision, strategy, goals, and priorities to achieve best-in-class service delivery. This will include designing service management operations in lockstep with cloud architecture to ensure ITIL objectives continue to be met while progressively pursuing new, modern practices. This role will require a senior leader with broad working knowledge of infrastructure technologies (legacy and modern), operations, architecture, platform delivery, vendor management and partnerships, cloud technologies, hybrid cloud operating models, and Agile infrastructure. Since this function services the broader enterprise, this leader will also need to have a strong background in applications support and operations, particularly the ITSM tool set (BMC Helix). There will be a heightened focus towards process simplification/engineering, automation, self-service capabilities, and advancements in AI operations. This role is also expected to have a significant matrix management responsibility and will be required to manage incident, problem and change across stakeholder organizations (technology & business groups).

They will also follow up and report on the adherence to the ITSM processes in the department and work with IT leadership to ensure coherence. The Senior Manager will lead the design and implementation of projects, policies and processes aimed at improving IT services, systems, and operations. They will lead a small team on strategies for improved services, performance, and reliability.

Your Responsibilities Will Include

Responsible for providing oversight and leadership of ITIL-based IT Service Management processes and policies for Incident, Problem, Change, and Asset management
Develop and maintain documentation and training materials around ITSM policies, processes and standards within the knowledge bases and other collaboration portals
Develop business cases to propose and implement additional ITSM processes and functions to further improve service – Knowledge Management, Release Management, Event Management, Request Management (with self-service capabilities)
Ensure services and tools are consistently deployed, executed, measured, monitored, and improved for Incident Management, Problem Management, Change Management, Asset Management, Configuration Management (CMDB), Capacity Management, Service Catalog, ServiceNow ITSM Platform, etc.
Partner with business stakeholders and transformation office leads to deliver initiatives on target and on budget
Serve as a senior expert on service management to educate, enable, and promote awareness to the Technology organization, service providers and business partners
Drive production stability, performance, and automation
Evaluate new information systems products or services and suggest improvements to existing products or services
Develop and oversee metrics and reporting capabilities
Provide leadership to staff and cross-functional teams to ensure deliverables are met
Develops strategic direction for ITIL based process improvement initiatives
Support increased project and milestone delivery through repeatable and consistent execution of ITIL process
Identify, analyze, and mitigate risk and issues across LifeLabs IT landscape
Own and govern the BMC Helix ITSM development lifecycle
People management duties, such as hiring, performance management, mentoring, running team meetings, timesheet approvals etc.
Annual budgeting, ensuring budget tracking through projections and actuals
Ensure continuity of the team through cross-training and succession planning
Set goals and delivery results – set annual goals for team members using the SMART framework – identity action steps and timelines needed to reach objectives and communicate plans to staff including delegation of work – Track progress to ensure completion of work and set priorities, manage workload for self and staff
Plan and facilitate effective meetings, implement changes and new systems or programs within the department
Conduct performance reviews on a regular basis, deliver ongoing feedback and address performance issues – recognize training needs – collaborate with team members to create and implement development plans – embrace continuous learning and self-development

What You Bring To The Role

Expert knowledge of IT Service Management concepts
7+ years of experience with various technologies relevant to IT Service Management (BMC, Service Now)
7+ years of experience managing and leading teams of technical staff
5+ years of experience with BMC Helix ITSM (Remedy)
Proven ability to effectively collaborate and engage with internal and external business partners at all levels on projects from conceptualization to execution, and plan for short and long-term goals
High attention to details, motivation and commitment to quality and customer service
7+ years of experience coordinating cross-functional work teams toward task completion
5+ years of experience overseeing vendor partners with a proven track record of building, developing, and managing service delivery and support teams
Bachelors degree in information technology, system administration, information systems management or a related discipline
ITIL v4.0 or DevOps Certification an asset
Proven ability to act with a sense of urgency and accountability while achieving quality results and identifying and resolving problems and issues in a context that requires assuming responsibility for decisions which have an impact on people, costs, and the delivery of services
Understanding of all aspects of software development and implementation
Proven ability to act as a thought leader in researching and presenting innovative ways to solve complex infrastructure related issues, including working with Managed Service Providers and other vendor partners with root cause analysis, SLA adherence and outcomes-based results
Proven ability to work in an Agile environment

LifeLabs’ compensation programs are commensurate based on the role, skill, effort, responsibility and working conditions, irrespective of gender, race, ethnicity, beliefs, age or any other personal characteristics. Pay programs are communicated regularly in an accessible and transparent manner.

LifeLabs is also proud to offer resources, opportunities, as well as a collaborative and supportive environment that enables our team members to thrive.

In Addition To a Competitive Compensation Package, LifeLabs Provides a Comprehensive Total Rewards Program, Specific To The Job Position. Your Package May Include

Employee Group Benefits: Competitive coverage for employees and their families to support their overall health and wellness needs, including Extended Health Care, Dental Care, and Life Insurance.
Retirement Savings Plan
Vacation and Wellness Days
Employee Wellness and Giving Programs: Our award winning mental, physical and financial wellness programs aim to address the comprehensive well-being of our team members, including resources like the Employee & Family Assistance Program, financial planning tools, and employee recognition initiatives.
Professional development and membership reimbursement, access to preferred rates and discount programs, including WorkPerks, Home and Auto Insurance, Costco Membership, etc., and optional health-related benefits.

In accordance with LifeLabs’ Accessibility Policy , and the applicable Accessibility Acts within the provinces we operate in, accommodations are available by request for candidates taking part in all aspects of the recruitment and selection process. For a confidential inquiry or to request an accommodation, please contact your recruiter or email careers@lifelabs.com .

Vaccinations are highly encouraged at LifeLabs’. Vaccinations and/or immunization screening may be mandatory for selected employees if regulated by provincial or regional governments, or through employer-led vaccination policies in the facilities we service. Please ensure you ask if this position requires the successful candidate to be vaccinated or undergo immunization screening.

Ready to empower healthier Canadians? Apply today!

Apply Now","{""role_summary"":""The Senior Manager, IT Service Management is responsible for defining, implementing, and maintaining the IT Service Management portfolio, processes, and procedures across internal organizations and external suppliers, leveraging the Information Technology Infrastructure Library (ITIL) framework."",""key_terms"":[{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management that provides best practices for delivering high-quality IT services.""},{""term"":""BMC Helix"",""explanation"":""A software platform that provides IT service management capabilities, including incident, problem, and change management.""},{""term"":""Agile infrastructure"",""explanation"":""An approach to infrastructure management that emphasizes flexibility, collaboration, and rapid delivery of services.""},{""term"":""Hybrid cloud operating models"",""explanation"":""A cloud computing model that combines on-premises infrastructure with public cloud services to provide a flexible and scalable IT environment.""}],""skill_priorities"":{""must_have"":[""Expert knowledge of IT Service Management concepts"",""7+ years of experience with various technologies relevant to IT Service Management"",""7+ years of experience managing and leading teams of technical staff"",""5+ years of experience with BMC Helix ITSM""],""nice_to_have"":[""ITIL v4.0 or DevOps Certification"",""Proven ability to work in an Agile environment""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with ITIL-based IT Service Management processes and how you have implemented them in previous roles?"",""example_answer"":""In my previous role, I was responsible for implementing ITIL-based processes for incident, problem, and change management. I worked closely with stakeholders to develop and maintain documentation and training materials, and ensured that services and tools were consistently deployed and executed.""},{""question"":""How do you stay current with industry trends and developments in IT Service Management?"",""example_answer"":""I regularly attend industry conferences and webinars, and participate in online forums and discussion groups to stay current with industry trends and developments. I also network with peers and thought leaders in the field to stay informed about best practices and new technologies.""}],""red_flags"":[""Lack of experience with BMC Helix ITSM"",""Inability to work in an Agile environment""],""confidence_score"":90.0}"
IT Site Manager,"Aversan Inc. (www.aversan.com) is a trusted multi-service engineering and electronics manufacturing company. Aversan delivers leading-edge and reliable safety-critical electronics and software systems to the aerospace, defence, and space industries.

We are currently seeking a qualified IT Site Manager to join our team.

Location: Victory, BC

Work Arrangement: Hybrid

Responsibilities

Infrastucture Functions
Process assigned tickets in ServiceNow through multiple assignment groups, read architecture diagrams, and construct rules based on those diagrams.
Firewalls and network filters, in both Enterprise, Stores, and cloud networks
Intrusion Prevention policies
Networking Protocols/Concepts (Routing (OSPF, BGP), VLAN, Sub-netting, Load balancing, TCP/IP, DNS, HTTP, TLS, SSH)
Site-to-site and remote-access VPN connectivity
Network Access Control
Authentication, Authorization and Accounting (to include multi-factor authentication)
Web access proxy servers and URL filtering
Network Security policy creation, exception documentation and approval
Provide suggestions to team lead/manager in creating your professional development and training plan.
Work on projects assigned to you, in effort to advance partnership opportunities between Network Security team and other business areas.
Work with senior engineers to define network security requirements for current and future state end-to-end architectures and platforms to advance security controls and the security posture of the business.
Assist senior engineers in collaborating with development and engineering teams to prioritize security risks, provide mitigation or remediation recommendations, and implement compensating controls.
Assist in performing proof-of-concept testing for network security solutions under consideration for purchase and implementation.
Provide 7/24 On-Call support for infrastructure related service incidents and follow internal management escalation procedures when necessary (team rotation).
Assist in developing and maintaining network security policies, standards, processes and workflows.


End User Support Functions
Provide Level 2 customer facing support.
Image, deploy and support all desktop and laptops
Support users by regularly monitoring the ticket queue and executing tickets that are assigned to you.
Instruct users as well as troubleshoot basic and advanced software/hardware issues with internal and external customers via phone, email, chat, and remote control/assist software.
Troubleshoot all inquiries regarding systems, hardware, software, and operator problems.
Work with Workplace team to support necessary tickets.
Route or escalate requests to appropriate functional teams beyond Service Desk Team.
Ability to setup, support and troubleshoot VTC (Video Teleconference) and VOL (Video Online)
Create and maintain knowledge base documents
Collaborate with Engineering and all other supportive roles within the campus. May also require interaction with external vendors and /or customers.
Basic Qualifications

Degree in Computer Science, Computer Engineer or a relevant field
Strong relevant managerial experience in IT domain
Experience in network security policy creation
Experience with ServiceNow
Networking Protocols/Concepts (Routing (OSPF, BGP), VLAN, Sub-netting, Load balancing, TCP/IP, DNS, HTTP, TLS, SSH)
Firewalls and network filters, in both Enterprise, Stores, and cloud networks
Able to setup, support and troubleshoot VTC (Video Teleconference) and VOL (Video Online)","{""role_summary"":""The IT Site Manager is responsible for managing and maintaining the company's IT infrastructure, ensuring network security, and providing level 2 customer support. The role involves process management, network security policy creation, and collaboration with various teams to advance security controls and the security posture of the business."",""key_terms"":[{""term"":""ServiceNow"",""explanation"":""A cloud-based IT service management platform used for incident, problem, and change management.""},{""term"":""OSPF"",""explanation"":""Open Shortest Path First, a routing protocol used to determine the best path for forwarding traffic in a network.""},{""term"":""BGP"",""explanation"":""Border Gateway Protocol, a routing protocol used to exchange routing and reachability information among autonomous systems on the internet.""},{""term"":""VLAN"",""explanation"":""Virtual Local Area Network, a method of dividing a physical network into multiple logical networks.""},{""term"":""Sub-netting"",""explanation"":""The process of dividing an IP address into smaller sub-networks to improve network organization and security.""},{""term"":""Load balancing"",""explanation"":""A technique used to distribute network traffic across multiple servers to improve responsiveness and availability.""},{""term"":""TCP/IP"",""explanation"":""Transmission Control Protocol/Internet Protocol, a suite of communication protocols used to interconnect devices on the internet.""},{""term"":""DNS"",""explanation"":""Domain Name System, a system that translates human-readable domain names into IP addresses.""},{""term"":""HTTP"",""explanation"":""Hypertext Transfer Protocol, a protocol used for transferring data over the internet.""},{""term"":""TLS"",""explanation"":""Transport Layer Security, a cryptographic protocol used to provide secure communication over a network.""},{""term"":""SSH"",""explanation"":""Secure Shell, a cryptographic network protocol used for secure remote access to a computer or network device.""},{""term"":""VTC"",""explanation"":""Video Teleconference, a technology that enables remote video conferencing.""},{""term"":""VOL"",""explanation"":""Video Online, a technology that enables online video conferencing.""}],""skill_priorities"":{""must_have"":[""Degree in Computer Science, Computer Engineer or a relevant field"",""Strong relevant managerial experience in IT domain"",""Experience in network security policy creation"",""Experience with ServiceNow"",""Networking Protocols/Concepts (Routing, VLAN, Sub-netting, Load balancing, TCP/IP, DNS, HTTP, TLS, SSH)"",""Firewalls and network filters, in both Enterprise, Stores, and cloud networks""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with network security policy creation, and how do you stay up-to-date with the latest security threats and trends?"",""example_answer"":""I have created network security policies for my previous organization, and I regularly follow industry blogs and attend webinars to stay current with the latest security threats and trends.""},{""question"":""How do you troubleshoot advanced software/hardware issues with internal and external customers?"",""example_answer"":""I use a structured approach to troubleshoot issues, starting with basic questions to identify the root cause, and then use remote control/assist software to resolve the issue. If necessary, I escalate the issue to senior engineers or other teams.""}],""red_flags"":[""Lack of experience with ServiceNow"",""Inability to setup, support and troubleshoot VTC (Video Teleconference) and VOL (Video Online)""],""confidence_score"":90.0}"
Application Technology Manager,"My client is looking for a Manager Application Technology to lead the development, configuration, and support of enterprise applications, ensuring seamless operations for staff and members. You'll manage vendor relationships, oversee system health, and drive continuous improvement in financial and content management applications.

🔹 Key Responsibilities:
✅ Lead the development & optimization of ECM and finance applications.
✅ Collaborate with teams to enhance system performance & user experience.
✅ Manage vendors & IT change requests, ensuring compliance & efficiency.
✅ Monitor application health, analyze performance, & provide 24/7 support.
✅ Drive digital transformation in banking & financial services.

🔹 What You Bring:
💡 5+ years managing ECM & finance applications (Captiva, Doxim, SharePoint, Sage 500).
🏦 5+ years in technology leadership within banking/financial services.
🔹 Expertise in integrated application ecosystems & digital transformation.
🛠 Strong knowledge of SDLC, Azure DevOps, and financial compliance.
📊 Strategic thinker with risk management & decision-making expertise.
📍 Location: Canada (Remote/Hybrid options)
🚫 No sponsorship – candidates must be eligible to work in Canada.

📩 Interested? Let’s connect! #Hiring #ECM #TechnologyLeadership #BankingTech #DigitalTransformation","{""role_summary"":""Lead the development, configuration, and support of enterprise applications, ensuring seamless operations for staff and members."",""key_terms"":[{""term"":""ECM"",""explanation"":""Enterprise Content Management, a system for managing and integrating content across an organization.""},{""term"":""SDLC"",""explanation"":""Software Development Life Cycle, a process for planning, designing, building, testing, and delivering software.""},{""term"":""Azure DevOps"",""explanation"":""A cloud-based platform for collaborative software development, delivery, and collaboration.""},{""term"":""Digital Transformation"",""explanation"":""The integration of digital technology into all areas of a business, fundamentally changing how it operates and delivers value to customers.""}],""skill_priorities"":{""must_have"":[""ECM and finance applications management"",""Technology leadership in banking/financial services"",""Expertise in integrated application ecosystems"",""Knowledge of SDLC, Azure DevOps, and financial compliance""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach optimizing the performance of ECM and finance applications?"",""example_answer"":""I would analyze system logs, identify bottlenecks, and implement performance tuning techniques to ensure seamless operations.""},{""question"":""Can you describe your experience with digital transformation in banking and financial services?"",""example_answer"":""In my previous role, I led a team that implemented a digital transformation project, resulting in a 30% increase in customer engagement and a 25% reduction in operational costs.""}],""red_flags"":[""Lack of experience in managing ECM and finance applications"",""Inability to demonstrate technology leadership in banking/financial services""],""confidence_score"":90.0}"
"Manager, IT Contracts","Recipe Unlimited Corporation is Canada’s leading full service restaurant company. Home to such iconic brands as Swiss Chalet, Harvey’s, St.Hubert, The Keg, Montana’s, Kelseys, Bier Markt, East Side Mario’s, Landing Group, New York Fries, The Pickle Barrell & Catering, State and Main, Elephant and Castle, Original Joe’s, Fresh Kitchen + Juice Bar, and The Burger Priest. With this diverse portfolio of restaurants our Home Office Teammates have the opportunity to work on a wide variety of some of the most popular, well-loved brands in Canada. Variety isn’t the only thing we offer – we are passionate about our industry, we celebrate and support diversity of thought, we are innately curious and encourage our Teammates to take ownership. Above all else, we believe in doing the right thing for our people, our communities and our planet.

The Manager, IT Contracts role encompasses overseeing the entire lifecycle of IT contracts, ensuring compliance, and tracking performance. It involves precise management of purchase orders, resolving discrepancies, and adhering to policies. The role requires meticulous asset tracking and document management for easy access and organization. As a central communication hub, it necessitates addressing contract-related queries and maintaining strong vendor and stakeholder relationships. Additionally, it entails monitoring vendor performance, analyzing data for improvement opportunities, and coordinating business reviews with cross-functional teams to ensure continuous alignment and efficiency.

What you will do in this role:

IT Contract administration: Overseeing the entire lifecycle of contracts specific to our information technology departments, including tracking deadlines, monitoring performance, and ensuring compliance with terms and conditions
Apply basic financial knowledge, including invoice processing and an understanding of financial statements, to support contract administration and vendor payment accuracy. Including processing of purchase orders and invoices in JD Edwards
Purchase Order Management: Responsible for the accurate and timely processing of invoices against purchase orders, including verifying pricing, quantities, and delivery dates. Working with Recipe Stakeholders and vendors to resolve any discrepancies. Following Recipe's purchase order policy, escalate when appropriate purchase orders have not been created
Asset Tracking: Track and maintain accurate records of IT Assets, including their location, condition, purchase and maintenance history
Document and record management: Organizing and maintaining contract files, correspondence, amendments, and other related documents in a systematic and accessible manner
Communication: Serving as the main point of contact for contract-related queries, documenting and reaching out to the appropriate parties for resolution. Building and maintaining positive relationships with vendors and internal business stakeholders
Vendor performance monitoring: Monitor vendor performance, tracking progress against agreed-upon action plans and performance metrics. Analyzing data to identify trends, areas for improvement, and cost-saving opportunities. Regularly update stakeholders, progress and address emerging issues or challenges
Business review: Collaborate with cross-functional teams to gather relevant data, reports, and insights. Schedule and lead business review meetings with vendors and internal stakeholders. Ensure all participants are invited and resources, such as meeting rooms, technology, and materials, are prepared in advance
Contract renewal and termination: Managing contract renewal or termination processes, working with various business partners, providing notice of renewals

What we are looking for from you:

A University Degree or College Diploma in Finance is preferred
3 years of experience as a Contract Analyst, preferably in the IT Industry
Strong analytical skills with the ability to interpret data and identify trends
Excellent communication and interpersonal skills to effectively collaborate with internal teams and vendor representatives
Strong organizational skills to manage multiple business reviews simultaneously and ensure all necessary preparations are made
Ability to facilitate meetings, manage conflicts, and drive productive discussions
Proven experience in vendor management, performance analysis, or related roles
Proficient in G SUITE for Microsoft Office Products

What’s in it for you?

Flexible/Hybrid work environment
You’d be joining a close-knit, innovative team of creative and energetic go-getters
You’d be a part of Canada’s largest full-service restaurant company that leads the industry in size and innovation
20% associate discount dining card and monthly dining allowance valid at participating Recipe brands
A welcoming, fun and safe work environment founded on respect
Career advancement opportunities with a company that owns some of Canada’s most iconic restaurant brands
Industry-leading benefits, wellness programs, and total rewards programs

Recipe is committed to providing a diverse, equitable and inclusive workplace. Celebrating people, being passionate and curious, owning it, and doing the right thing are the values that guide how we build our teams, support our franchisees and create a company that unlocks the full potential of everyone.

Recipe is dedicated to providing accommodations in accordance with applicable human rights and accommodation legislation. For individuals that require accommodations please contact recruit@recipeunlimited.com.","{""role_summary"":""Oversee the entire lifecycle of IT contracts, ensuring compliance, tracking performance, and maintaining strong vendor and stakeholder relationships."",""key_terms"":[{""term"":""IT Contracts"",""explanation"":""Agreements between Recipe Unlimited Corporation and vendors for information technology services or products.""},{""term"":""JD Edwards"",""explanation"":""An enterprise resource planning software used for processing purchase orders and invoices.""},{""term"":""G SUITE"",""explanation"":""A cloud-based productivity suite that includes Google Drive, Docs, Sheets, and Slides, used for document management and collaboration.""}],""skill_priorities"":{""must_have"":[""Contract administration"",""Financial knowledge"",""Analytical skills"",""Communication skills"",""Organizational skills"",""Vendor management""],""nice_to_have"":[""Experience in the IT Industry"",""Proficiency in G SUITE""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you ensure compliance with contract terms and conditions?"",""example_answer"":""I would create a contract tracking spreadsheet to monitor deadlines and milestones, and regularly review contract terms to ensure Recipe Unlimited Corporation is meeting its obligations.""},{""question"":""Can you give an example of a time when you had to resolve a discrepancy with a vendor?"",""example_answer"":""In my previous role, I identified a pricing error on an invoice. I worked with the vendor to resolve the issue and implemented a process to prevent similar errors in the future.""}],""red_flags"":[""Lack of experience with contract administration"",""Poor analytical skills"",""Inability to communicate effectively with vendors and stakeholders""],""confidence_score"":90.0}"
"Manager, Information Technology","Your difference is the difference

Do you love to develop and share great ideas? Do you believe your insights can drive people forward? Do you appreciate working with others and building on mutual successes? Perfect. We do, too.

As an employee-owned company, we foster a culture where our people can thrive – and by thrive, we mean a place where you can share your ingenuity, express your difference, and grow in your very own way. Whatever your area, no matter your grade, your unique skills and perspective will help drive change from operations to the C-suite, across a wide of range of projects and channels.

Are you ready to build a future that’s uniquely yours? Join our award-winning team and make a difference that defines you.

RVA is a 500-person, Engineering services company that operates in Ontario and Eastern Canada with over 11 locations. We are a fully adopted MS 365 environment with a mix of external cloud, on-prem cloud, and on-prem data sources. We are running Nutanix, Trend Micro, Vectra and InTune for data security. The company has over 75 different specialized Engineering software tools that must be procured, installed and maintained. We have in-house developed, cloud-based workflow tools for project management and client resource management. Our growth targets are aggressive, and the IT Manager must be able to lead and support change.

Reporting to the Vice President of IT and working alongside the Manager, Information Systems Security the IT Manager will undertake have the following duties

Duties

Manage IT staff by recruiting, overseeing, monitoring performance, and training.
Monitor daily performance of all IT systems, including computers, programs, and networks in over 11 locations with significant WFH staff.
Responsible for continuous improvement of the Digital User Experience.
Identify new technologies and opportunities to improve systems and processes while adding value.
Prepare and present the IT budget to Senior Management and maintain cost-effectiveness.
Provide input to Senior Management for strategic planning.
Manage complex internal projects, including, stakeholder need definition, programming oversight, training, roll-out, and ongoing support.
Troubleshoot problems and increase overall efficiency.
Develop data backup systems and disaster recovery contingencies.
Monitor service levels including client satisfaction and perform continuous improvement.
After hours work will be required periodically.

Qualifications

Expert knowledge of MS 365 systems and RVA’s technology stack.
Skilled in interpersonal relationships, teaching, planning and communication.
Problem solving, decision making and sound judgment.
Experience negotiating with software vendors.
Past direct engagement with senior executives on aligning IT with business needs in a professional services company.
Skilled at communicating with various stakeholders and providing assistance with the preparation of business cases.
A background that includes exposure to Engineering software would be advantageous.

Your better starts here

We don’t settle for less, and neither should you. As it happens, offering great benefits to our people is entirely possible: the numbers work out. Happy teams mean happy clients. It’s just that simple. From recruitment to flexibility, learning to leadership, wellness to inclusion, we give our people the tools they need to outperform in their careers and build lasting connections with our clients, our culture, and each other.

Competitive compensation packages and performance-based bonuses
Health, paramedical, vision, and dental coverage
A flexible vacation policy that lets you determine your time off based on your other responsibilities and needs
Top-up plans for new and expecting parents
Firm-paid holidays, summer and winter breaks, and other leaves of absence that cover everything from extra family time, jury duty, or even completing a degree
RVA Group Pension Plan with match
Global Travel Assist Program that provides emergency out-of-country medical protection for you and your eligible family members on personal and business trips
Access to a variety of free services (e.g., employee and family assistance programs, nutrition advice, caregiver support) and employee discounts (e.g., sports and entertainment tickets, major brands, insurance plans)
Flexible and alternative work arrangements around core hours, including telecommuting and work-from-home options

Diversity, Inclusion, And Accommodations

At RVA, we are committed to fostering a workforce that reflects the diversity of the communities in which we operate. RVA is an Equal Opportunity Employer that considers applicants without regard to age, race, colour, national origin, citizenship, sex, sexual orientation, religion, creed, marital status, disability, or any other protected status. If you require any special accommodations, please advise Human Resources. Any information received relating to accommodations will be treated as confidential.

Apply Now","{""role_summary"":""The IT Manager will lead and support change, managing IT staff, monitoring IT systems, and improving the Digital User Experience, while ensuring cost-effectiveness and aligning IT with business needs."",""key_terms"":[{""term"":""MS 365"",""explanation"":""A suite of cloud-based productivity and collaboration tools developed by Microsoft.""},{""term"":""Nutanix"",""explanation"":""A cloud computing software company that provides a hyper-converged infrastructure platform.""},{""term"":""Trend Micro"",""explanation"":""A cybersecurity software company that provides threat defense and cloud security solutions.""},{""term"":""Vectra"",""explanation"":""A cybersecurity company that provides AI-powered network threat detection and response solutions.""},{""term"":""InTune"",""explanation"":""A cloud-based endpoint management solution developed by Microsoft.""}],""skill_priorities"":{""must_have"":[""Expert knowledge of MS 365 systems"",""Skilled in interpersonal relationships, teaching, planning and communication"",""Problem solving, decision making and sound judgment"",""Experience negotiating with software vendors""],""nice_to_have"":[""A background that includes exposure to Engineering software""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with MS 365 systems and how you've utilized them to improve IT operations?"",""example_answer"":""I've worked extensively with MS 365, implementing it across multiple locations and ensuring seamless integration with our existing technology stack. I've also developed training programs to ensure staff are proficient in using the suite.""},{""question"":""How do you approach negotiating with software vendors, and what strategies have you found to be most effective?"",""example_answer"":""I take a collaborative approach, understanding the vendor's goals and needs while also ensuring our organization's requirements are met. I've found that building relationships and being transparent about our needs helps to drive better outcomes.""}],""red_flags"":[""Lack of experience with MS 365 systems"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
End User Computing Operations Lead,"Job Information

Job Title: End User Computing Operations Lead

Job Requisition ID: 67980

Ministry: Technology and Innovation

Location: Remote across Alberta

Full or Part-Time: Full Time

Hours of Work: 36.25 hours per week

Permanent/Temporary: Ongoing

Scope: Open Competition

Closing Date: March 21, 2025

Classification: Systems Analyst 3

Salary: $3,199.50 - $4,237.85/ Bi-weekly ($83,506 - $110,607/year)

The Government of Alberta is committed to a diverse and inclusive public service that reflects the population we serve to best meet the needs of Albertans. Consider joining a team where diversity, inclusion and innovation are valued and supported. For more information on diversity and inclusion, please visit: https://www.alberta.ca/diversity-inclusion-policy.aspx .

The Ministry of Technology and Innovation is responsible for making innovation and technology the driving force behind Alberta’s economic growth and diversification. To learn more about us, please visit: https://www.alberta.ca/technology-and-innovation.aspx .

The Technology Support and Operations Division uses a one-government approach to Information Management and Technology (IMT) governance, decision-making and service delivery across the Government of Alberta (GoA) balanced with individual business partner needs. This broader lens facilitates enhanced data sharing, collaboration, reduction in data duplication and innovation support to ensure effective IMT solutions and service delivery across the government to provide better services to Albertans.

Role Responsibilities

Reporting to the End User Computing (EUC) Manager, the Operations Lead is a critical role in leading the way in how End User Computing services are managed and improved, as a core service, within the GoA. This position plays a critical role in shifting EUC services from a technical service offering to user-centric service offering that provides high-business value and increases user performance within the workplace to enable business partner outcomes.

The Operations Lead provides oversight and guidance to the End User Computing team; works with other Information Management and Technology (IMT) and business teams; provides leadership and direction to cross- functional project teams and contributes in the review, development and implementation of divisional service management processes that ensure consistent service management practices are utilized across government.

Responsibilities

The Operations Lead is responsible for day to day planning, coordination, and prioritization of work assignments within the Operations Team. The Operations Lead has a broad scope of services that reaches across all GoA Users and has a significant impact to government ministries at all levels. The End User Computing Service is comprised of a portfolio of components and supporting services including, but not limited to, desktop hardware, software management, desktop imaging and core application packaging and deployments, VIP support services, mobile computing IT bars, mobile device management, network print support and boardroom support services.

Some of the role’s responsibilities include, but are not limited to:

Staff Leadership
Service Operations Ownership
Service Evolution
Service Level Management
Financial Management

To be successful in this role, you must demonstrate excellent:

Problem/Incident Management skills
Supervisory/leadership/coaching skills
Communication skills
Change Management skills
Attention to Detail/Organizational skills
Enterprise Service Management skills
Relationship/Rapport building skills

Please click on this link to view the job description for this position.

APS Competencies

Competencies are behaviors that are essential to reach our goals in serving Albertans. We encourage you to have an in depth understanding of the competencies that are required for this opportunity and to be prepared to demonstrate them during the recruitment process.

This Link Will Assist You With Understanding Competencies

https://www.alberta.ca/system/files/custom_downloaded_images/psc-alberta-public-service-competency-model.pdf .

Agility: Ability to anticipate, assess, and readily adapt to changing priorities, manage resilience in times of uncertainty and effectively work in a changing environment.
Develop self and others: A commitment to lifelong learning and the desire to invest in the development of the long-term capability of yourself and others.
Build Collaborative Environments: Leads and contributes to the conditions and environments that allow people to work collaboratively and productively to achieve outcomes.
Develop Networks: Proactively building networks, connecting, and building trust in relationships with different stakeholders.
Systems Thinking: The work done within the APS is part of a larger integrated and inter-related environment. It is important to know that work done in one part of the APS impacts a variety of other groups/projects inside and outside the APS. Systems thinking allows us to keep broader impacts and connections in mind.
Creative Problem Solving: Ability to assess options and implications in new ways to achieve outcomes and solutions.

Qualifications

Required:

University degree in Computer Sciences or a related field.
Four (4) years of progressive leadership and technical experience in the IT field, specifically related to the technologies and responsibilities of this position:
Enterprise Service Management
Incident/Problem Management
Leadership/Supervisory/Coaching
Change Management
Equivalencies

Equivalencies are considered on the basis of:

A related two-year diploma in computer technology or a related discipline from a recognized postsecondary institution and six (6) years related experience; or
A related one-year certificate from a recognized post-secondary institution and seven (7) years related experience.

Assets

ITIL Certification.
Service Level/KPI Management experience.
Vendor/Contract Management experience.
Continuous Improvement/Service Evolution experience.
Experience in assessing new opportunities and performing necessary due-diligence around technical, operational and financial impacts.
Superior IT technical aptitude to guide the operations and to define road maps for in scope EUC services.
Experience with Enterprise Service Management.
Experience collaborating with the technical project teams and business partners to collect, clarify, and translate technical details into practical, informative messages and forward direction.

Minimum recruitment standards outline the minimum education and experience required for appointment to a job classification.

Refer to https://www.alberta.ca/alberta-public-service-minimum-recruitment-standards

Notes

Term of Employment: Permanent, Full-time position.

Hours of Work: 36.25 hrs./week - Monday to Friday

Location: Remote across Alberta.

You must reside in Alberta to work remotely.

This competition may be used to fill future vacancies, across the Government of Alberta, at the same or lower classification level.

Final candidate will be required to undergo security screening.

Cover Letter: Applicants are advised to provide a cover letter summarizing information that clearly and concisely demonstrates how their qualifications meet the advertised requirements, including education, experience, and relevant examples of required competencies.

Resume: For Employment Experience, please indicate duration of employment (month, year). Please specify employment status (i.e., Casual, part-time, or full-time)

Ex: Youth Worker, Jan 2006 - June 2009, Part-time (three 8 hr. shifts/week)

For Any Post-Secondary Education

Please specify your major and length of program and the year you graduated.

Ex: Bachelor of Social Work, 4-year Degree (Graduated 2017)

Any costs associated with obtaining the required documents/checks as noted or interview travel expenses, will be the responsibility of the candidate. Out-of-province applicants can obtain the required documents/checks from the province they currently reside in.

Links and information on what the GoA have to offer to prospective employees.

Working for the Alberta Public Service - https://www.alberta.ca/advantages-working-for-alberta-public-service.aspx
Public Service Pension Plan (PSPP) - https://www.pspp.ca
Alberta Public Service Benefit Information - https://www.alberta.ca/alberta-public-service-benefits
Professional learning and development - https://www.alberta.ca/professional-development-support-directive
Research Alberta Public Service Careers tool – https://researchapscareers.alberta.ca
Positive workplace culture and work-life balance
Opportunity to participate in flexible work arrangements such as working from home up to two days per week and modified work schedule agreement
Leadership and mentorship programs

How To Apply

Applicants are advised to provide information that clearly and concisely demonstrates how their qualifications meet the advertised requirements, including education, experience, and relevant examples of required competencies.

Candidates are required to apply for a job online. Please visit https://www.alberta.ca/job-application-resources#before for more information. Please visit Recruitment Principles , for more information.

It is recommended applicants who have completed post-secondary studies from outside of Canada obtain an evaluation of their credentials from the International Qualifications Assessment Service (IQAS)( https://www.alberta.ca/international-qualifications-assessment.aspx ) or from a recognized Canadian Credential Evaluator; please visit the Alliance of Credential Evaluation Services of Canada for more information ( https://canalliance.org/en/default.html ).

It is recommended that applicants include the assessment certificate from IQAS or any other educational assessment service as part of their application.

Closing Statement

This competition may be used to fill future vacancies, across the Government of Alberta, at the same or lower classification level.

We thank all applicants for their interest. All applications will be reviewed to determine which candidates' qualifications most closely match the advertised requirements. Only individuals selected for interviews will be contacted.

If you require any further information on this job posting or require an accommodation during the recruitment process, please contact Michelle Elliott at Michelle.Elliott@gov.ab.ca .","{""role_summary"":""The End User Computing Operations Lead is responsible for leading the way in managing and improving End User Computing services within the Government of Alberta, shifting from a technical service offering to a user-centric service offering that provides high business value and increases user performance."",""key_terms"":[{""term"":""End User Computing (EUC)"",""explanation"":""A service that provides desktop hardware, software management, desktop imaging, and core application packaging and deployments to government users.""},{""term"":""Enterprise Service Management"",""explanation"":""A framework for managing IT services across an organization, focusing on customer-centricity and business value.""},{""term"":""ITIL Certification"",""explanation"":""A certification in IT Service Management that demonstrates knowledge of best practices in IT service delivery and management.""}],""skill_priorities"":{""must_have"":[""University degree in Computer Sciences or a related field"",""Four years of progressive leadership and technical experience in IT, specifically in End User Computing"",""Leadership/Supervisory/Coaching skills"",""Change Management skills"",""Problem/Incident Management skills""],""nice_to_have"":[""ITIL Certification"",""Service Level/KPI Management experience"",""Vendor/Contract Management experience"",""Continuous Improvement/Service Evolution experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach shifting End User Computing services from a technical service offering to a user-centric service offering?"",""example_answer"":""I would start by conducting a thorough analysis of our current service offerings and identifying areas where we can improve the user experience. I would then work with our technical teams to develop a roadmap for implementing user-centric services, and collaborate with business partners to ensure that our services meet their needs.""},{""question"":""Can you give an example of a time when you had to manage a complex IT project with multiple stakeholders?"",""example_answer"":""In my previous role, I managed a project to implement a new desktop imaging solution across the organization. I worked closely with technical teams, business partners, and vendors to ensure that the project was delivered on time and within budget. I also developed a comprehensive communication plan to keep stakeholders informed throughout the project.""}],""red_flags"":[""Lack of experience in leading IT teams"",""Inability to adapt to changing priorities and manage resilience in times of uncertainty""],""confidence_score"":90.0}"
"Manager, IT Production Support","Job Summary

Reporting to the VP, IT Operations, the Manager, IT Production Support is a customer-focused leader responsible for ensuring the reliability and performance of IT systems while partnering with Sales to address technology needs and enhance service delivery. This role oversees a team responsible for managing incident resolution, service optimization, and recurring technical challenges, aligning IT capabilities with enterprise goals.

Responsibilities

Lead, manage, and develop a team of IT professionals responsible for production support and customer success to ensure system reliability, incident resolution, and continuous service improvement.
Partner with National & Regional Sales, Operations, and other business stakeholders to identify and implement technology solutions that address the goals, needs and challenges of our customers.
Develop and maintain strong customer relationships by providing transparency, addressing pain points, and driving innovative IT service enhancements.
Oversee incident management, root cause analysis, and resolution of recurring technical issues to minimize disruptions and improve operational efficiency.
Monitor IT system performance, ensure compliance with industry standards and customer commitments, and drive process improvements to optimize IT operations.
Collaborate with cross-functional teams to plan and execute technology upgrades, system enhancements, and service delivery initiatives.
Create, implement and maintain a customer centric support process and its’ procedures and documentation to ensure compliance with internal KPIs and customer SLAs.
Work within an agile development process, collaboratively across the IT and business functions to iteratively implement strategic IT deliverables and assist with implementation of DevOps SDLC.
Work closely and collaboratively with the IT Leadership on assessment of external technology solutions and services ensuring consistency with business direction and technology sustainability.
Proactively monitor business strategies and MI industry innovations and incorporate into Production Support roadmaps.
Lead and participate in cross functional projects as required.

Skills And Qualifications

Bachelor’s degree in Computer Science, Engineering, Information Technology, Business Administration, or a related field.
5+ years of experience in IT production support or IT operations, with 2+ years in a leadership or managerial role.
Strong understanding of IT service management (ITSM) frameworks, such as ITIL, and experience with incident and problem management.
Proven ability to collaborate with business stakeholders to align technology solutions with customer needs.
Excellent leadership and team management skills, with a track record of building high-performing teams.
Strong problem-solving and analytical skills, with the ability to address complex technical challenges.
Exceptional communication and interpersonal skills, with the ability to translate technical concepts into business terms.
Knowledge of insurance industry systems and regulatory requirements is a plus.
Demonstrated proficiency in principles of Call Center Operations.
DevSecOps experience is an asset.
Superior project management skills and attention to detail with the ability to work with and influence all levels in the organization.
Bilingual in English and French strongly desired.

At Sagen, we offer:

Competitive salary
Annual Performance Bonus Plan
Medical, Dental, Prescription Drug, and EFAP Benefits
Company funded Pension Plan
Company matching RRSP, TFSA and/or Non-registered Savings Plan
Competitive vacation policy
Life Insurance and Accidental Death & Dismemberment
Short Term and Long-Term Disability programs
Reimbursement programs for special occasions, health and wellness, mortgage insurance and tuition
Work from Anywhere Days

Sagen is committed to creating a diverse and inclusive workforce. We welcome, respect and value people from all backgrounds and abilities and create a sense of belonging that inspires our employees to be their authentic self.

We encourage applications from people with disabilities and will provide accommodations upon request throughout the selection and hiring process to meet individual needs.","{""role_summary"":""The Manager, IT Production Support leads a team to ensure IT system reliability, partners with Sales to address customer needs, and enhances service delivery."",""key_terms"":[{""term"":""ITSM"",""explanation"":""IT Service Management, a framework for delivering IT services, including incident and problem management.""},{""term"":""DevOps SDLC"",""explanation"":""DevOps Software Development Life Cycle, a collaborative approach to software development and delivery.""},{""term"":""DevSecOps"",""explanation"":""DevOps with a focus on security, integrating security practices into the software development life cycle.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of best practices for IT service management.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in Computer Science, Engineering, Information Technology, Business Administration, or a related field"",""5+ years of experience in IT production support or IT operations"",""Strong understanding of IT service management (ITSM) frameworks"",""Proven ability to collaborate with business stakeholders"",""Excellent leadership and team management skills"",""Strong problem-solving and analytical skills"",""Exceptional communication and interpersonal skills""],""nice_to_have"":[""Knowledge of insurance industry systems and regulatory requirements"",""Demonstrated proficiency in principles of Call Center Operations"",""DevSecOps experience"",""Bilingual in English and French""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with IT service management frameworks, such as ITIL?"",""example_answer"":""I have worked with ITIL for 3 years, implementing incident and problem management processes that improved our team's efficiency by 25%.""},{""question"":""How do you ensure that your team is aligned with business stakeholders to address customer needs?"",""example_answer"":""I hold regular meetings with stakeholders to understand their needs and develop solutions that meet those needs, resulting in a 90% customer satisfaction rate.""}],""red_flags"":[""Lack of experience in IT production support or IT operations"",""Inability to communicate technical concepts to non-technical stakeholders"",""No experience with IT service management frameworks""],""confidence_score"":90.0}"
"Manager, M365 Centre of Excellence (COE)","About Metergy Solutions Inc. (“Metergy”)
As one of North America’s most experienced submetering providers, Metergy Solutions has brought turnkey solutions to clients for over 20 years. Metergy supplies, installs and remotely reads meters to measure individual suite consumption of electricity, water, gas, and thermal energy in multifamily and commercial buildings, and bills and collects the utility consumption.

Our innovative Submetering as a Service (SaaS) model generates long-term recurring revenue and has been proven to reduce in-suite energy consumption by an impressive 40%, significantly advancing our clients' decarbonization efforts. This outstanding performance has enabled Metergy to issue green bonds and secure green financing, fueling our sustained growth and creating extraordinary career opportunities for our team.

As the #1 submeter provider in the New York and Canadian markets, and one of the largest in North America, Metergy boasts over 850,000 contracted meters, issues more than 2 million utility invoices annually, and employs over 400 dedicated team members. Our successful acquisitions have consistently exceeded expectations, unlocking immense growth potential.

Metergy is proudly a portfolio company of Brookfield Infrastructure Partners, one of the world’s largest investors, owners, and operators of infrastructure assets across the utilities, transport, energy, data, and sustainable resources sectors. This partnership provides Metergy with access to substantial capital, infrastructure investment expertise, and a global reach, positioning us for continued success and innovation

Our Mission

Provide building owners and occupants with accurate and reliable utility consumption data through market-leading expertise in turnkey submetering and billing, while fostering a workplace with inspired team members empowered to do more good.

Role Overview
Are you a Microsoft evangelist and passionate about their M365 products? Can you see yourself leading a COE, helping the business maximize the investment in Microsoft products? Do you see limitless potential with MS CoPilot and want to champion its adoption? If so, we have a fantastic role for you!

The Manager of the Microsoft Center of Excellence (COE) at Metergy will lead the development and implementation of innovative solutions using Microsoft Power Platform. This role is pivotal in driving digital transformation and enhancing business processes across the organization. The Manager will act as a Microsoft evangelist, promoting the effective use of Microsoft 365 tools and staying updated on the latest products. They will oversee a team of professionals, including citizen developers, and ensure the effective use of Microsoft tools to improve efficiency, collaboration, and data governance.

Responsibilities

Lead Power Platform Development: Oversee the agile development of automation solutions using Microsoft Power Platform, including Power Apps, Power BI, and Power Automate
Microsoft Evangelism: Promote the effective use of Microsoft 365 tools across the organization and stay updated on the latest Microsoft products
Training and Development: Develop and implement training programs to enhance the skills of power users and ensure the effective use of Microsoft applications
Data Governance: Ensure data integrity and manage API connections across platforms
Chair AI Committee: Promote proper usage of CoPilot throughout organization with Citizen developers
Collaboration and Communication: Foster a culture of continuous improvement and knowledge sharing among team members and across departments
Innovation and Adoption: Drive the adoption of new Microsoft applications and technologies, including AI and machine learning tools
Performance Monitoring: Monitor and optimize the performance of applications and processes, ensuring alignment with organizational goals



Qualifications

Education: Bachelor's degree in Information Technology, Computer Science, or a related field. Advanced degrees or certifications in Microsoft technologies are a plus
Experience: Minimum of 5 years of experience in managing IT projects and teams, with a focus on Microsoft Power Platform and related technologies
Skills: Strong leadership and project management skills, excellent communication and collaboration abilities, and a deep understanding of Microsoft tools and data governance practices
Certifications: Relevant Microsoft certifications (e.g., Power Platform, Azure) are highly desirable



Metergy’s recruitment process includes accommodation for applicants with disabilities. All accommodations will consider the applicant’s accessibility needs due to disability and are available upon request.","{""role_summary"":""Lead the development and implementation of innovative solutions using Microsoft Power Platform, driving digital transformation and enhancing business processes across the organization."",""key_terms"":[{""term"":""Microsoft Power Platform"",""explanation"":""A low-code development environment that includes Power Apps, Power BI, and Power Automate, used for building custom business applications.""},{""term"":""Microsoft 365"",""explanation"":""A suite of cloud-based productivity and collaboration tools, including Office, Teams, and SharePoint.""},{""term"":""CoPilot"",""explanation"":""An AI-powered tool that assists users in completing tasks and provides suggestions for improvement.""},{""term"":""Citizen developers"",""explanation"":""Non-technical users who create business applications using low-code or no-code development tools.""},{""term"":""Data governance"",""explanation"":""The process of managing data quality, security, and integrity across an organization.""}],""skill_priorities"":{""must_have"":[""Microsoft Power Platform"",""Microsoft 365"",""Leadership and project management skills"",""Excellent communication and collaboration abilities""],""nice_to_have"":[""Advanced degrees or certifications in Microsoft technologies"",""Relevant Microsoft certifications (e.g., Power Platform, Azure)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with Microsoft Power Platform and how you've used it to drive digital transformation in previous roles?"",""example_answer"":""In my previous role, I led a team in developing a custom application using Power Apps, which increased process efficiency by 30%. I also implemented Power Automate to automate workflows, resulting in a 25% reduction in manual errors.""},{""question"":""How do you stay updated on the latest Microsoft products and technologies?"",""example_answer"":""I regularly attend Microsoft conferences and webinars, and participate in online forums and communities to stay current on the latest developments and best practices.""}],""red_flags"":[""Lack of experience with Microsoft Power Platform"",""Inability to demonstrate leadership and project management skills""],""confidence_score"":90.0}"
Manager of IT Clinic and Corporate Applications,"Are you passionate about helping people live their healthiest lives? Do you thrive in a dynamic, supportive environment where your contributions truly matter? If so, Medcan is the place for you!

About Us:

Founded in 1987, Medcan is a leader in transformational proactive and primary care dedicated to helping patients and team members live well, for life. We offer a comprehensive range of services including preventative health assessments, wellness programs, and specialized medical care.

Our core values of excellence, drive, respect and integrity guide everything we do. We’re committed to creating a workplace where everyone can thrive, and we’re proud to support over 1,500 businesses across Canada with our health and wellness solutions.

Medcan is seeking an experienced Manager of IT Clinic and Corporate Applications to provide leadership for planning, implementation, and maintenance of solutions including application support. This individual is responsible for all aspects of the organization's Clinic and Corporate Application portfolio, including an application integration platform. The Manager will collaborate directly with business stakeholders to identify, recommend, develop, implement, and support cost-effective technology solutions to support our business.

Why You’ll Love Working Here:

Hybrid Office Policy: Flexible work-from-home and office options.
Coffee and Snacks: Keep your energy up with our delicious onsite offerings.
Employee Perks: Access to wellness programs like fitness training and other discounted Medcan services and products.
Benefits: Comprehensive health plans, retirement saving matches, educational reimbursement, and so much more!
Engaging Work Environment: Join a team that values collaboration, creativity, and continuous improvement.
Recognition: We celebrate our employees’ contributions through manager recognition and AwardCo prizes.
Career Growth Opportunities: We believe in nurturing talent and providing opportunities for professional development and career advancement.

Key Responsibilities:

Stakeholder Collaboration: Manage application support and delivery while prioritizing team workload and capacity. Partner with the business to continuously improve, optimize, and enhance processes and their use of applications. Continuously assess business needs and opportunities for improvements to leverage existing technology. Be a trusted advisor to business partners and IT colleagues on best practices and application of technology. Work closely with other IT management personnel in identifying, evaluating, selecting, and implementing information technologies that support corporate and IT strategies. Provide and own inputs to financial and capital planning processes.
Team Leadership: Foster a collaborative environment, encourage professional growth, and ensure team members are aligned with the organization’s goals. Delegate responsibilities effectively, ensuring each team member understands their role and contributes to project success. Develop and maintain an effective organizational structure that supports the needs of the business and optimizes the pool of talent. Support and nurture staff, build paths to develop and grow the team, and set and measure performance objectives while providing regular one-on-one feedback to all team members.
Data Accuracy and Reporting: Manage the enterprise application integration platform including governance, development practices, maintenance, and support. Regularly audit data sources, validate data quality, and address any discrepancies promptly. Create clear documentation for application support procedures and data definitions.
Efficiency and Quality: Optimize application support processes by leveraging automation tools and best practices. Implement data validation checks to ensure high-quality application data. Continuously monitor performance metrics and identify areas for improvement. Balance efficiency with data accuracy to drive meaningful insights.
Prioritization: Collaborate with senior management to align application initiatives with overall business priorities. Assess the impact and urgency of different projects and allocate resources accordingly. Communicate trade-offs and make informed decisions based on business value.
Process Improvement: Regularly evaluate existing application processes and identify bottlenecks or inefficiencies. Propose enhancements, such as streamlining workflows, adopting new tools, or refining data models. Encourage a culture of continuous improvement within the team. Manage the application support and maintenance operations for the portfolio, along with other IT operational teams (Service Desk and Infrastructure Services). Ensure the continuous delivery of IT services through oversight of service level agreements with end users and monitoring of systems performance. Review software acquisition and maintenance contracts and assist with establishing master agreements to capitalize on economies of scale.

Qualifications:

Experience: 5+ years managing people, including building and leading teams of high-performing IT professionals.
Education: Post-secondary degree/diploma in Human Resources or a related discipline. Some experience in strategic planning and execution.
Technical Requirements: Experience managing external IT service providers and assessing the risk and cost implications of IT contracts and contract negotiations. Experience with onshore, nearshore, and offshore development and support processes. Experience in designing, building, transforming, and managing applications in cloud and application modernization strategies. Sound knowledge of systems architecture, technical design principles, and software development and integration technology.
Strategic Thinking: Proven ability to design and implement innovative application strategies and build a strong technology portfolio.
Intellectual Curiosity: Consistently seek clarity and ask “How” and “Why” questions to fully acquire necessary knowledge.
Leadership: Exceptional leadership skills to build enthusiastic, high-performing teams while focusing on strategic goals. Strong organizational skills, the ability to perform under pressure, and manage multiple priorities with competing demands for resources. Strong understanding of human resource management principles, practices, and procedures.
Performance Management: Experience designing effective application support and maintenance processes and advanced technology solutions for driving business outcomes.
Analytical Acumen: Strong skills in collecting, organizing, analyzing, and disseminating information with precision. Experience with systems design and development from business requirements analysis through to day-to-day management.
Communication: Excellent verbal, written, and presentation skills, engaging stakeholders across the enterprise with clarity. Strong negotiating skills (internally and externally). Ability to present ideas in a business-friendly and user-friendly language.

Reporting to: Vice President, Information Technology

Work Schedule: Full-time position working 40 hours per week based on business needs between regular office hours Monday to Friday 9-5 PM. Hybrid, with two days in the office per week.

Location: Our downtown Toronto clinic is conveniently located at 150 York Street, nearby St. Andrew station or a 10-minute walk from Union Station!

Ready to Apply? If you’re ready to make a difference and be part of a company that truly cares about its people, we’d love to hear from you! Apply today and let’s inspire wellness together.

Ready to Apply?

If you’re ready to make a difference and be part of a company that truly cares about its people, we’d love to hear from you! Apply today and let’s inspire wellness together.

Diversity, Equity and Accessibility:

Medcan is dedicated to employment equity, diversity and inclusion. We strive to ensure all staff have a fair opportunity to participate and success at work. If contacted for an employment opportunity, please advise your Talent Acquisition Specialist if you require accommodation.","{""role_summary"":""The Manager of IT Clinic and Corporate Applications will lead the planning, implementation, and maintenance of IT solutions, collaborating with business stakeholders to identify and develop cost-effective technology solutions to support the business."",""key_terms"":[{""term"":""Application Integration Platform"",""explanation"":""A platform that enables the integration of multiple applications and systems to improve data flow and functionality.""},{""term"":""Cloud and Application Modernization Strategies"",""explanation"":""Approaches to migrating and modernizing applications to take advantage of cloud computing benefits, such as scalability and cost-effectiveness.""},{""term"":""Onshore, Nearshore, and Offshore Development and Support Processes"",""explanation"":""Different models for outsourcing software development and support to teams located in the same country (onshore), nearby countries (nearshore), or distant countries (offshore).""}],""skill_priorities"":{""must_have"":[""5+ years of experience managing people and IT teams"",""Experience with application integration platforms"",""Knowledge of systems architecture and technical design principles"",""Strong leadership and strategic thinking skills""],""nice_to_have"":[""Post-secondary degree/diploma in Human Resources or a related discipline"",""Experience with onshore, nearshore, and offshore development and support processes"",""Knowledge of cloud and application modernization strategies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with application integration platforms and how you've used them to improve data flow and functionality?"",""example_answer"":""In my previous role, I implemented an application integration platform that increased data accuracy by 30% and reduced manual processing time by 25%. I worked closely with stakeholders to identify business needs and developed a solution that met those needs.""},{""question"":""How do you approach strategic planning and execution in an IT environment?"",""example_answer"":""I use a collaborative approach, working with stakeholders to identify business goals and develop technology solutions that support those goals. I prioritize initiatives based on business value and ensure that my team is aligned with organizational objectives.""}],""red_flags"":[""Lack of experience with application integration platforms"",""Inability to communicate technical information to non-technical stakeholders"",""Poor leadership skills or inability to build high-performing teams""],""confidence_score"":90.0}"
Senior IT Administrator,"WHO WE ARE:
Next Level Games is a wholly owned subsidiary of Nintendo Co., Ltd.
We’ve been passionate about video game development for 20 years now, shipping award-winning games for fans across the world and still going strong. Some of our titles include Super Mario Strikers, Mario Strikers Charged, Punch-Out!!, Luigi’s Mansion: Dark Moon, Metroid Prime Federation Force, Luigi’s Mansion 3 and most recently Mario Strikers™: Battle League.
At NLG, we believe that a project finds success when we collaborate. Therefore, we place careful consideration to build an environment where everyone feels welcome and has fun in the process of achieving our shared goals.
WHAT YOU’LL BE DOING:
We are looking for an IT Administrator to join our team at Next Level Games. At Next Level Games, we work hard to ship the best, most memorable games for our audience. To make that happen, we need a seamless flow of information and technology across the entire company and across all our external partners. As a member of our IT team, you will play a pivotal role in achieving this.
You will be given autonomy and responsibility to solve a wide range of infrastructure and technology problems in the ever-changing landscape of video game production. It’s a challenge which demands all of the skills you have acquired in your previous IT work and an interest in always growing and learning more. Key responsibilities include:
Administer Linux and Windows – both physical and virtual
Monitor and maintain on-prem and cloud infrastructures
Manage networking infrastructure
Maintain end-user equipment, hardware, software, and supplies
Perform installation, implementation and upgrades of internal systems and software
Maintain documentation of procedures, operations and system configurations
Evaluate, implement and maintain cybersecurity best practices across all systems
Help improve company productivity
Take initiative in finding solutions to problems
Knowledge-sharing and collaboration with the team
Participate in technical reviews and help develop best practices
Communicate maintenance and incidents to the company in a customer-focused manner
Communicate and coordinate with external partners
WHO WE’RE LOOKING FOR:
Degree in System Administration or equivalent experience in Computer Information Systems, Computer Science or a related field
5+ years of experience administrating Linux and Windows servers in an IT operations or similar role
Entra and Microsoft 365 administration
Scripting (Python, PowerShell, Linux CLI)
Networking configurations (Firewall, DNS, VPN)
Source Control systems (Git, Perforce)
Highly effective triage, task prioritization and time management skills
Ability to work well both in a team and independently
Excellent verbal and written communication skills
YOU SET YOURSELF ABOVE WITH:
Configuration management tools (ex. Ansible, Salt, Puppet)
Virtualization and cloud platforms (ex. VMware, Proxmox, AWS)
Container technologies (ex. Docker, Kubernetes)
Infrastructure Monitoring (Nagios, Grafana)
Systems hardening best practices
Perforce administration
Storage Area Networks administration (Oracle, TrueNAS)
Database administration (SQL, NoSQL)
Jira and confluence server administration and configuration
Authentication systems (SAML, OAuth)
C, C++ programming
Previous gaming or similar studio environment experience
WHY YOU’LL LOVE WORKING HERE:
Competitive benefits and annual leave, including discretionary performance bonus program, health coverage and RRSP matching
Support for mental health, financial well-being, legal assistance and more through our Employee Assistance Program
Access to our in-studio gym, and an extensive media library filled with games and books
Join a committee – board games, sports, or something else – it’s all here!
Discounted shopping for Nintendo products and merchandise at the online employee store
A workplace that values inclusivity and encourages continuous growth
A chance to be part of Nintendo, creating award winning games that make an impact
Please note this is an on-site position, requiring five days per week at our Vancouver studio.
The hiring range for this position is $ 70,000 - $ 105,000 CAD annually and is subject to change. The final base salary compensation will be based on factors such as skills, education, and/or experience.
We wish to thank all applicants in advance; however, only those under consideration will be contacted. We are currently only considering applicants who already have work eligibility in Canada and can work on-site in Metro Vancouver.
Powered by JazzHR
F1ZxVI42iq","{""role_summary"":""The IT Administrator will ensure seamless flow of information and technology across the company and external partners, solving infrastructure and technology problems, and maintaining systems and equipment."",""key_terms"":[{""term"":""Linux"",""explanation"":""An operating system used in servers and infrastructure.""},{""term"":""Windows"",""explanation"":""An operating system used in servers and infrastructure.""},{""term"":""Cloud infrastructure"",""explanation"":""A model for delivering IT services over the internet.""},{""term"":""Cybersecurity best practices"",""explanation"":""Guidelines for protecting computer systems and data from cyber threats.""},{""term"":""Scripting"",""explanation"":""Writing code in languages like Python, PowerShell, or Linux CLI to automate tasks.""},{""term"":""Source Control systems"",""explanation"":""Tools like Git or Perforce that manage changes to code and collaborate with others.""}],""skill_priorities"":{""must_have"":[""Linux and Windows administration"",""5+ years of experience in IT operations"",""Entra and Microsoft 365 administration"",""Scripting (Python, PowerShell, Linux CLI)"",""Networking configurations (Firewall, DNS, VPN)""],""nice_to_have"":[""Configuration management tools (Ansible, Salt, Puppet)"",""Virtualization and cloud platforms (VMware, Proxmox, AWS)"",""Container technologies (Docker, Kubernetes)"",""Infrastructure Monitoring (Nagios, Grafana)"",""Systems hardening best practices"",""Perforce administration"",""Storage Area Networks administration (Oracle, TrueNAS)"",""Database administration (SQL, NoSQL)"",""Jira and confluence server administration and configuration"",""Authentication systems (SAML, OAuth)"",""C, C++ programming"",""Previous gaming or similar studio environment experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach troubleshooting complex infrastructure issues?"",""example_answer"":""I use a structured approach, identifying the root cause, and then implementing a solution. I also ensure to document the process for future reference.""},{""question"":""Can you explain your experience with cloud infrastructure and how you've managed it in the past?"",""example_answer"":""I've worked with AWS and have experience in setting up and managing cloud-based infrastructure. I ensure scalability, security, and cost-effectiveness in my designs.""}],""red_flags"":[""Lack of experience with Linux and Windows administration"",""Inability to work independently and as part of a team"",""Poor communication and problem-solving skills""],""confidence_score"":90.0}"
Technical Lead,"Technology Lead - ERP /SAP, IAM, Infrastructure (Contract Position)
Number of Positions: 1 Filled: 0 Duration: 15 months
Location: Mississauga, ON, CA
Must be eligible to work in Canada
Hybrid position, 1-2d/w in Mississauga, ON office mandatory

Roles and responsibilities:
Technical Expertise -Serve as a technology expert in the product area and maintains a depth of knowledge in current industry trends for the respective Product business functional area. Guides the team with its technical
deliverables.

Operations & People Management - Manage the day-to-day product activities of the team and integrates work into product backlogs. Ensure proactive and reactive problem management is driven across all the delivery teams. Provide advice and lessons learned, and proactively helps teams improve their ways of working and supporting tools (e.g., Jira). May lead teams in Daily Scrums.

Delivery - Advice and lead product teams on Agile practices, processes, and overall approach to executing product delivery quickly and with quality. Also, leads and coaches the team in DevOps methods and delivery. Raise the performance of product teams through continuous improvement and meeting facilitation.

Design - Advice the team in the development of the solution design based on the business and technology requirements.

Continuous Improvement - Drive improvement using a hypothesis; experimentation; measure; knowledge sharing; and ensure teams are actively seeking out opportunities for improvement. Contribute technical expertise in service of continuously improving applications across their lifecycle and provide ongoing maintenance and support to adapt to changing business requirements. Involved in Release planning &Management.

Stakeholder Engagement & Support - Engage with relevant stakeholders in end-to-end service delivery lifecycle. Ensure the appropriate signoffs are obtained at the correct stage (e.g., Architecture, IT security, infrastructure and Product teams etc.), appropriate operational and support requirements are maintained.

Maintenance & Testing - Ensure the completion of business, technology and operational testing and the definition and optimization of appropriate service maintenance models.

Must skills and experience:
Minimum 10 years of IT experience.
Minimum 5+yrs of technical lead role
Good experience with SAP CDC / Gigya preferred.
Good experience with Identity and Access Management required.
Strong leadership and people management skills.
Solid understanding of the infrastructure and application landscape.
Proven track record in Service, Demand, Change and Release Management.
Excellent understanding and awareness of ITIL processes and tools.
Expert knowledge of concepts and tools behind the design of the relevant area of expertise e.g., business
processes or systems and underlying information technologies.
Business acumen coupled with good understanding and awareness of the technology enabling the Team’s
business functional area.
Negotiation Skills.
Agile or Scrum certification (nice to have).","{""role_summary"":""The Technology Lead - ERP/SAP, IAM, Infrastructure is responsible for guiding teams in technical deliverables, managing day-to-day product activities, and ensuring proactive problem management. They will also lead teams in Agile practices, DevOps methods, and delivery, and drive continuous improvement."",""key_terms"":[{""term"":""ERP"",""explanation"":""Enterprise Resource Planning, a type of software that helps organizations manage their business operations.""},{""term"":""SAP"",""explanation"":""Systems, Applications, and Products in Data Processing, a type of ERP software.""},{""term"":""IAM"",""explanation"":""Identity and Access Management, a system that manages digital identities and access to resources.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""Agile"",""explanation"":""A project management approach that emphasizes flexibility, collaboration, and continuous improvement.""},{""term"":""Scrum"",""explanation"":""A framework for implementing Agile principles in software development.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of best practices for IT service management.""}],""skill_priorities"":{""must_have"":[""Minimum 10 years of IT experience"",""Minimum 5+yrs of technical lead role"",""Good experience with Identity and Access Management"",""Strong leadership and people management skills"",""Solid understanding of the infrastructure and application landscape"",""Proven track record in Service, Demand, Change and Release Management"",""Excellent understanding and awareness of ITIL processes and tools"",""Expert knowledge of concepts and tools behind the design of the relevant area of expertise""],""nice_to_have"":[""Good experience with SAP CDC / Gigya"",""Agile or Scrum certification""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with Identity and Access Management systems?"",""example_answer"":""I have worked with IAM systems for over 5 years, implementing and managing access controls for multiple applications and infrastructure components.""},{""question"":""How do you approach continuous improvement in software development and delivery?"",""example_answer"":""I use a hypothesis-driven approach, experimenting with new methods and measuring their impact. I also facilitate knowledge sharing and encourage teams to seek out opportunities for improvement.""}],""red_flags"":[""Lack of experience with SAP CDC / Gigya"",""No Agile or Scrum certification"",""Limited experience with ITIL processes and tools""],""confidence_score"":90.0}"
"Manager, Cloud Technology and Systems","Bookmark this Posting Print Preview | Apply for this Job

Position Details

Position Information

Position Title Manager, Cloud Technology and Systems Who We Are

At BCIT, putting people at the core of everything we do is paramount. This idea is the foundation of BCIT’s People Vision, which describes the Institute’s goals and priorities in respect to our people. In a complex and uncertain world, it’s vital our people feel valued, supported and connected. BCIT champions a culture of innovation and global progress through people’s imagination and creativity. With a competitive compensation package, great work-life balance, and career advancement opportunities, see why we’ve earned the title of one of BC’s Top Employers for over ten years running.

Position Summary

BCIT’s Information Technology Services department is seeking a regular, full-time (1.0 FTE) Manager, Cloud Technology and Systems. This position participates as a member of the ITS management team, and contributes as a senior member of the Cloud Technology & Infrastructure Services team, assisting in development of strategies, plans and policies. Leads Enterprise Cloud Technology and Enterprise Systems teams in delivery of industry-leading foundation services across the Institute, including cloud technology and architecture, enterprise systems, IaaS management, integration services and identity and access management. Leads cross-functional teams in delivery of user services such as security operations, integration services and monitoring. Provides strategic contribution aimed at driving optimized and secure connectivity and systems for the campus community.

Duties & Responsibilities

Key Accountabilities

Participates as a member of the ITS management team, and contributes as a senior member of the Cloud Technology & Infrastructure Services team, assisting in development of strategies, plans and policies to support the service delivery model and the Institute’s current and future business needs. Develops and implements standards, processes, procedures, tools and metrics.
Develops high performance IT operations teams with capacity to provide state-of-the art support across the Institute. Ensures teams are utilizing optimal techniques, tools and practices to operate technology and software. Fosters an environment of learning, balanced with rapid delivery of quality solutions.
Leads Enterprise Cloud Technology and Enterprise Systems teams in delivery of industry-leading foundation services across the Institute, including cloud technology and architecture, integration services, enterprise systems, and identity and access management.
Manages the delivery of user services such as cloud security operations, linux systems, identity and access management, integration services and monitoring of services. Supports various cross-functional teams across IT services including cyber security operations (SecOps) and their requirements.
Leads the planning and implementation of the enterprise cloud technology and systems roadmap and plans, ensuring the required budget support, associated resources and service ownership. Incorporates improvements, ongoing updates, lifecycle management into roadmaps to ensure currency of plans.
Keeps the Director apprised of relevant issues as they arise and ensures adequate closure in a timely fashion. Collaborates across ITS management to support strategic priorities for BCIT, IT Services and Cloud Technology & Infrastructure Services.
Participates in managing the Institute’s IT infrastructure lifecycle. Develops resource allocation plans and supports project managers by ensuring projects are optimally resourced for success.
Leads support and operations of key ITS service environments, including disaster recovery and high availability. Implements, supports and maintains monitoring capabilities, ensuring computer, storage and cloud service availability, system performance, and intrusion detection.
Collaborates with the other ITS departments to ensure work is aligned with division and Institute objectives, and to foster practices for optimal support of service requests. Delivers project communications and facilitates meetings/workshops to advance technology operations.
Represents the Institute on Provincial committees/initiatives. Undertakes special and ad hoc projects for the advancement of ITS Enterprise Technology portfolio.
Manages staff, overseeing and participating in selection, coaching, mentoring, development, performance management and other people-management practices. Promotes an environment of growth by working with staff to create learning plans, identify training and development opportunities, and ensure the team receives support for growth.

Qualifications

Qualifications & Requirements

Bachelor’s degree in computer science, information systems, business administration or a related field.
Eight years of experience in Enterprise Architecture, System Environment management, software development, network maintenance, technology infrastructure, continuous improvement and leading matrix organizations at progressive levels of responsibility.
An equivalent combination of education and experience may be considered.
Broad knowledge of current and emerging technologies, technology directions and strategic application to business needs; cloud technology adoption, includes familiarity with traditional IT practices, as well as emerging methods such as DevOps and Agile.
Exceptional people management and coaching skills with excellent oral and written communication skills, including the ability to explain technology solutions in business terms, establish rapport and persuade others.
Strong progressive leader and change agent; passionate about delivering high quality projects for ITS clients, with a sharp focus on user impact.
Excellent business acumen and planning skills, with ability to establish processes and manage achievements against key metrics.
Experience working in an Information Technology environment within a large, complex and unionized environment will be preferred.

Additional Information

Benefits – Why You’d Love Working With Us

Competitive pay
Minimum of twenty-five days of vacation
Competitive employer-paid extended health and dental plan including access to a Health Care Spending Account of up to $500 if eligible!
Defined benefit pension plan with employer contributions
Flexible hybrid work arrangements available
Professional Development funds and resources
Access to most BCIT Flexible Learning courses free of charge
Wellness and Employee Assistance programs
Complimentary membership with free access to the Fitness Centre, Gymnasium, and more
For more information on our generous benefits, click here!

BCIT is committed to the principles of equity, diversity & inclusion and to promoting opportunities in hiring for systemically oppressed groups who have been excluded from full participation at BCIT and the larger community. This includes Indigenous Peoples, women, racialized persons, persons with disabilities and those who identify as 2S/LGBTQIA+. All qualified candidates are encouraged to apply; however, Canadian citizens and permanent residents will be given priority.

Persons with disabilities who require accommodation for any part of the application or hiring process should contact RecruitmentAssistant@bcit.ca. Please note that all applications must be submitted via the careers page portal. Email applications will not be accepted.

The British Columbia Institute of Technology acknowledges that our campuses are located on the unceded traditional territories of the Coast Salish Nations of xwməθkwəy̓əm (Musqueam), Sḵwx̱wú7mesh (Squamish), and səl̓ilwətaɁɬ (Tsleil-Waututh).

Position Details

Posting Category Management Salary Range $123,820-$177,992, with a control point of $154,775 per annum Additional Salary Information

The Compensation Range is the span between the minimum and the maximum base salary for a position. The control point of the range represents an employee that possesses full job knowledge, qualifications, and experience for the position. In the normal course, employees will be hired, transferred, or promoted between the minimum and the control point of the salary range for a job, taking internal equity into account. Salaries above the control point may be considered for extenuating circumstances and must be approved by an external governing body.

Department 2 Cloud Tech & Infrastructure Serv Campus Location Burnaby campus Bargaining Unit Management Job Status Regular Full-Time/Part-Time Full-Time Number of Vacancies 1 Anticipated Start Date 04/07/2025 Anticipated End Date

Competition Information

Competition Number 25M191 Competition Open Date 02/05/2025 Competition Close Date Open Until Filled? Yes Quicklink for Posting https://careers.bcit.ca/postings/9258

Supplemental Questions

Required fields are indicated with an asterisk (*).

* What is the highest level of education attained?
GED
High School Diploma
Certificate
Diploma
Associates Degree
Bachelors Degree
Masters Degree
PHD
* How many years of experience do you have in this type of position?
0-1
1-2
3-5
6-9
10+
* All positions at BCIT require on campus presence at the applicable campus location(s). This means the successful candidate must be able to and willing to relocate to the Lower Mainland. Please select from the following that best describes your situation:
I currently reside in the Lower Mainland
I do not currently reside in the Lower Mainland, however I am willing and able to relocate if found to be the successful candidate
I do not currently reside in the Lower Mainland and I am unwilling to relocate
* Given the posted salary range for this position, please indicate your salary expectation should you be the successful candidate for this position. (Open Ended Question)
Documents Needed to Apply

Required Documents

Resume
Cover Letter

Optional Documents","{""role_summary"":""The Manager, Cloud Technology and Systems leads the Enterprise Cloud Technology and Enterprise Systems teams in delivering industry-leading foundation services across the Institute, including cloud technology and architecture, enterprise systems, IaaS management, integration services, and identity and access management."",""key_terms"":[{""term"":""Cloud Technology"",""explanation"":""The use of cloud computing to deliver scalable and on-demand access to a shared pool of computing resources.""},{""term"":""Enterprise Systems"",""explanation"":""Large-scale computer systems that support the operations and management of an organization.""},{""term"":""IaaS Management"",""explanation"":""Infrastructure as a Service management involves the management of virtualized computing resources over the internet.""},{""term"":""Integration Services"",""explanation"":""The integration of different systems, applications, or data sources to enable seamless communication and data exchange.""},{""term"":""Identity and Access Management"",""explanation"":""The process of managing digital identities and access to resources, ensuring secure authentication and authorization.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and speed up the delivery of software applications and services.""},{""term"":""Agile"",""explanation"":""An iterative approach to project management and software development that emphasizes flexibility, collaboration, and rapid delivery.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in computer science, information systems, business administration or a related field"",""Eight years of experience in Enterprise Architecture, System Environment management, software development, network maintenance, technology infrastructure, continuous improvement and leading matrix organizations"",""Broad knowledge of current and emerging technologies, technology directions and strategic application to business needs"",""Exceptional people management and coaching skills"",""Strong progressive leader and change agent""],""nice_to_have"":[""Experience working in an Information Technology environment within a large, complex and unionized environment""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with cloud technology adoption, and how have you applied it to meet business needs?"",""example_answer"":""I have led the implementation of cloud-based solutions in my previous role, resulting in a 30% reduction in IT costs and a 25% increase in system uptime. I worked closely with stakeholders to understand their needs and developed a cloud strategy that aligned with the organization's goals.""},{""question"":""How do you approach people management and coaching, and what strategies have you used to develop high-performing teams?"",""example_answer"":""I believe in empowering team members to take ownership of their work and providing regular feedback and coaching. I have used techniques such as agile methodologies and continuous improvement to develop high-performing teams that are adaptable to changing business needs.""}],""red_flags"":[""Lack of experience in leading matrix organizations"",""Inability to explain technical solutions in business terms"",""Poor people management and coaching skills""],""confidence_score"":90.0}"
"Manager, Technical Operations","Who We Are

Jolera offers MSPs & IT solution providers next-generation managed services, enabling them to create world-class experiences for their clients. Our clients receive award-winning solutions built on over 25 years of experience servicing businesses worldwide.

We’ve helped transform hundreds of MSPs & solution providers worldwide! With our collection of tenured experts, we provide an elevated managed service experience for a variety of clients. At Jolera, we treat each MSP partner with specialized care and uniquely organize our products for your individual business needs.

Who You Are

Jolera seeks an energetic and experienced Technical Operations Manager to join our team in a full-time, permanent capacity.

What You Will Do

Provide leadership and oversight to a team of technical resources delivering infrastructure and service delivery projects.
Liaise with clients and internal leadership to manage daily operational aspects and lead high-priority projects.
Ensure all initiatives are effectively managed to guarantee program success.
Maintain the overall health of the program by working with the IT Service Management (ITSM) team for quick and efficient incident resolution.
Improve process performance, efficiency, and productivity to meet business and client needs.
Manage, develop, motivate, and coach technical staff.
Take ownership of outstanding issues and drive them to resolution.
Produce SLA and KPI metrics and reports.
Serve as the point of contact or escalation for support teams regarding client services.
Collaborate with the ITSM team to identify opportunities for improvement based on metrics and data.
Be flexible and willing to take on challenges beyond the job description.
Identify and address potential concerns to maintain a strong environment.


Qualifications

Bachelor’s degree in information technology or a recognized equivalent.
5-10 years of related work experience in a similar role.
Comprehensive knowledge of a broad range of IT services, including Service Desk, NOC, Field Services, and Systems Engineering.
Strong knowledge and experience with system and network architectures.
Ability to make tough decisions confidently.
Strong project management and leadership skills.
Excellent prioritization abilities.
Experience in process development and improvement with a growth mindset.
Experience in a Service Delivery function, dealing with clients, internal teams, and vendors.
Ability to maintain a high level of confidentiality.
Strong interpersonal skills.
Capability to work independently on simple to moderately complex tasks.
Knowledge of IT Infrastructure projects and strategies, preferably gained through various project roles.
Flexibility to work overtime when required.


Preferred Hands-On Experience:

Windows Administration
Linux/UNIX Systems Administration
Network Engineering
Storage Management
Backup & Recovery
Virtualization
ServiceNow


What We Offer

Competitive compensation package
Competitive benefits package
Company Perks, and various brand discounts
Company events, recognitions, and celebrations
Career development and growth opportunities","{""role_summary"":""The Technical Operations Manager will lead a team of technical resources, manage daily operations, and ensure program success by improving process performance, efficiency, and productivity to meet business and client needs."",""key_terms"":[{""term"":""ITSM"",""explanation"":""IT Service Management, a set of policies, procedures, and processes for managing IT services.""},{""term"":""NOC"",""explanation"":""Network Operations Center, a centralized location for monitoring and managing IT networks.""},{""term"":""SLA"",""explanation"":""Service Level Agreement, a contract between a service provider and its clients that defines the expected service quality.""},{""term"":""KPI"",""explanation"":""Key Performance Indicator, a measurable value that indicates how well an organization is achieving its objectives.""},{""term"":""Service Desk"",""explanation"":""A single point of contact for customers to report IT incidents and request services.""}],""skill_priorities"":{""must_have"":[""Project management"",""Leadership skills"",""IT service management"",""Process development and improvement"",""Strong interpersonal skills""],""nice_to_have"":[""Windows Administration"",""Linux/UNIX Systems Administration"",""Network Engineering"",""Storage Management"",""Backup & Recovery"",""Virtualization"",""ServiceNow""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach improving process performance and efficiency in a technical operations team?"",""example_answer"":""I would analyze the current processes, identify bottlenecks, and implement changes to streamline workflows, automate tasks, and enhance team collaboration.""},{""question"":""Can you describe a time when you had to make a tough decision confidently in a previous technical operations role?"",""example_answer"":""In my previous role, I had to decide on a new IT service management tool. I gathered data, consulted with stakeholders, and made an informed decision that improved our incident resolution time by 30%.""}],""red_flags"":[""Lack of experience in IT service management"",""Inability to make tough decisions confidently"",""Poor project management skills""],""confidence_score"":90.0}"
IT Infrastructure Manager,"We’re looking for a strategic and proactive IT Infrastructure Manager to join our IT Infrastructure team in Winnipeg.

As the IT Infrastructure Manager, you will lead a team of 12 experts managing a complex, multi-site infrastructure across North America. Overseeing Windows, Linux, networking, and virtualization, you’ll ensure system resilience, security, and high performance. Collaborating with European counterparts, you’ll guide cross-functional teams and maintain strong communication. Success in this role requires strategic leadership, hands-on expertise, and proficiency in budgeting and vendor management, particularly with Microsoft 0365, Palo Alto Networks, and Dell equipment.

Who We Are

At Pollard Banknote Limited, we've been a leader in instant lottery ticket manufacturing and services for over a century, delivering innovation and quality. Our diverse, talented team drives creativity and collaboration. Alongside our traditional products, we lead in digital lottery solutions, enhancing player engagement with cutting-edge technology. Join us in impacting millions of lives with exciting lottery experiences and help shape the future of gaming!

What We Offer

Competitive compensation
Profit sharing program – every role plays a part in our success!
Company Pension
Health & Extended Benefits
Opportunities for professional development
Tuition Reimbursement
On-Site Cafeteria & Outdoor Patio
On Site Gym
A variety of committee-driven employee engagement activities
Free Parking
Hybrid Work Environment

What You'll Do

Lead and manage a team of 12 IT professionals, providing direction, mentorship, and support.
Take ownership of the organization’s IT infrastructure, focusing on Windows, Linux, networking, and virtualization technologies.
Ensure the infrastructure is properly maintained, patched, and aligned with security standards.
Manage vendor relationships and contracts, specifically for Microsoft 0365, Palo Alto Networks, and Dell hardware.
Oversee and manage the IT infrastructure budget, ensuring efficient resource allocation and cost management.
Collaborate with teams across North America and Europe to ensure consistency and best practices in infrastructure management.
Oversee and maintain network security in alignment with industry standards and organizational security policies.
Manage data center operations across multiple North American locations, ensuring uptime, efficiency, and security.
Take a proactive role in monitoring systems, identifying potential issues before they escalate.
Collaborate with development teams in a large-scale development shop to ensure infrastructure needs are met, and the systems can support ongoing projects.
Plan and implement infrastructure projects, upgrades, and migrations with minimal disruption to business operations.
Maintain compliance with industry regulations and best practices for IT infrastructure and security.
Support the organization's long-term IT strategy by researching and recommending new technologies to enhance infrastructure capabilities.

Who You Are

Strategic and hands-on individual who thrives in complex, multi-site IT environments.
Skilled in collaboration and communication, working effectively across teams and geographies.
Proactive in identifying and solving infrastructure challenges while ensuring security and performance.
A supportive leader who mentors and empowers teams to deliver results.

What You'll Bring

Bachelor's degree in Information Technology, Computer Science, or a related field.
5+ years of experience in IT infrastructure management, including Windows, Linux, networking, and virtualization.
Proven experience leading teams and managing large-scale infrastructure environments.
Strong communication skills, with the ability to collaborate effectively with both technical and non-technical stakeholders.
Experience working in or managing large development environments.
In-depth knowledge of security standards and practices.
Experience in multi-site infrastructure management and data center operations.
Proficiency in budgeting and vendor management, particularly with Microsoft 0365, Palo Alto Networks, and Dell equipment.
Ability to take ownership of systems, ensuring they are well-maintained and secure.
Strong problem-solving skills with a proactive approach to identifying and resolving infrastructure issues.

Pollard Banknote Limited is an equal opportunity employer, committed to promoting and maintaining a diverse and inclusive workforce. Reasonable accommodations are available upon request.

Employment is contingent upon a satisfactory response from a Criminal Record Search.","{""role_summary"":""Lead a team of IT professionals to manage and maintain a complex, multi-site infrastructure across North America, ensuring system resilience, security, and high performance."",""key_terms"":[{""term"":""Microsoft 0365"",""explanation"":""A cloud-based productivity suite used for collaboration and communication.""},{""term"":""Palo Alto Networks"",""explanation"":""A cybersecurity company providing network security solutions.""},{""term"":""Dell equipment"",""explanation"":""Hardware components used in IT infrastructure, such as servers and storage devices.""},{""term"":""Virtualization"",""explanation"":""A technology that allows multiple virtual machines to run on a single physical machine, improving resource utilization and flexibility.""}],""skill_priorities"":{""must_have"":[""Windows"",""Linux"",""Networking"",""Virtualization"",""Budgeting"",""Vendor management"",""Microsoft 0365"",""Palo Alto Networks"",""Dell equipment""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach ensuring system resilience and security in a complex, multi-site infrastructure?"",""example_answer"":""I would implement a layered security approach, including firewalls, intrusion detection, and access controls, and ensure regular security audits and penetration testing to identify vulnerabilities.""},{""question"":""Can you describe your experience with budgeting and vendor management in an IT infrastructure context?"",""example_answer"":""In my previous role, I managed a budget of $X and worked with vendors to negotiate contracts and ensure cost-effective solutions that met our infrastructure needs.""}],""red_flags"":[""Lack of experience in managing large-scale infrastructure environments"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Manager of Information Technology,"VACANCY STATUS: FULL TIME

Position Purpose

The Manager of Information Technology is responsible for overseeing the implementation, integration, and ongoing management of Windsor Regional Hospital’s Information Systems. This role ensures that these systems meet the needs of WRH, improve patient care, and ensures adherence to governance and security standards. The Manager will work closely with TransForm, a shared service organization, to align strategies and operations across five hospitals in the region. Collaboration with these hospitals is essential to improve system issues, policies and procedures.

There are no direct reports

Duties And Responsibilities

Represent WRM in all respects with TransForm (TSSO) account management to ensure the Information Technology needs of WRH are delivered in a timely manner within established budgeted Capital and Expense limits.
Identify and coordinate via hospital leadership all WRH IT ongoing and new project and service needs including provincially mandated requirements.
Within WRH, Implement security frameworks, conduct risk assessments, vulnerability assessments and incident response planning.
Development of internal information security polices, with
Ensure training and compliance of all security polices and governance. Coordinate and implement WRH wide audit requirements
Provide TransForm with updates on key hospital led initiatives and their status changes, through regular scheduled meetings with the account manager.
Participation in regional committees such as Regional Intake Committee (RIC), Regional Change Management and Adoption Team (RCMAT), and Regional Data Governance. This would include bringing any TransForm produced materials, requests for action, dissemination, or request for decision, and follow up within the hospital to achieve the necessary response back to TransForm.
Coordinate the prioritization, awareness, identification of accountability and responsibility for all Intake requests and/or Projects.
Responsible for monitoring all initiatives, engagement for intake submission process and reporting internally to key stakeholders and executives within WRH.
Serve as the site operational lead for all IS projects working in partnership with TransForm Shared Service Organization (TransForm), Mohawk Medbuy (MMC), hospitals in Erie St. Clair (ESC), provincial partners, and vendors. The role provides collaborative oversight for the coordination of digital services, including systems and infrastructure at WRH.
Other duties as assigned.

Skills/Capabilities

Strong knowledge of clinical workflows and healthcare regulations.

Proven experience in project management and stakeholder engagement.

Experience in establishing and maintaining relationships with technology vendors, ensuring service level agreements are met and managing vendor performance

In-depth understanding of cloud computing concepts and technologies

French Language proficiency an asset

Qualifications

Bachelor’s degree in Information Technology with a preference in Health Informatics, Information Technology, Healthcare Management, or a related field.

Minimum of 10 years Leadership comprising of Service Desk, Networking/Infrastructure and Security/GRC (Governance Risk and Compliance)

Cybersecurity experience implementing

Certified Professional in Healthcare Information and Management Systems – Canada (CPHIMS-CA) preferred

#yqg

Windsor Regional Hospital is an equal opportunity employer. In accordance with the Accessibility for Ontarians with Disabilities Act, 2005, upon request, accommodation will be provided by WRH throughout the recruitment, selection and/or assessment process to applicants with disabilities.","{""role_summary"":""The Manager of Information Technology oversees the implementation, integration, and management of Windsor Regional Hospital's Information Systems, ensuring they meet the hospital's needs, improve patient care, and adhere to governance and security standards."",""key_terms"":[{""term"":""Governance Risk and Compliance (GRC)"",""explanation"":""A framework for managing an organization's overall governance, risk, and compliance activities.""},{""term"":""Cloud Computing"",""explanation"":""A model for delivering computing services over the internet, allowing users to access and store data remotely.""},{""term"":""Health Informatics"",""explanation"":""The application of information technology to healthcare, focusing on the acquisition, storage, and use of healthcare data.""},{""term"":""Cybersecurity"",""explanation"":""The practice of protecting computer systems, networks, and sensitive information from unauthorized access, use, disclosure, disruption, modification, or destruction.""}],""skill_priorities"":{""must_have"":[""Strong knowledge of clinical workflows and healthcare regulations"",""Proven experience in project management and stakeholder engagement"",""Experience in establishing and maintaining relationships with technology vendors"",""In-depth understanding of cloud computing concepts and technologies"",""Minimum of 10 years Leadership experience in Service Desk, Networking/Infrastructure and Security/GRC""],""nice_to_have"":[""French Language proficiency"",""Certified Professional in Healthcare Information and Management Systems – Canada (CPHIMS-CA)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with implementing security frameworks and conducting risk assessments in a healthcare setting?"",""example_answer"":""In my previous role, I developed and implemented a comprehensive security framework that included risk assessments, vulnerability assessments, and incident response planning. This framework ensured compliance with governance and security standards, and improved patient care.""},{""question"":""How do you stay current with emerging trends and technologies in healthcare information systems?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and engage with professional networks to stay informed about the latest developments in healthcare information systems. This enables me to identify opportunities for improvement and innovation in our hospital's systems.""}],""red_flags"":[""Lack of experience in healthcare information systems"",""Inability to demonstrate project management skills"",""Limited understanding of cloud computing concepts and technologies""],""confidence_score"":90.0}"
IT Process Manager,"We are seeking an experienced IT Process Manager to oversee and improve our IT service delivery processes. The ideal candidate will be responsible for ensuring the efficiency and effectiveness of our IT operations, aligning processes with industry best practices, and enhancing client satisfaction.

Key Responsibilities

Process Development and Improvement: Design, implement, and refine IT service delivery processes. Ensure alignment with industry standards and best practices.
Quality Assurance: Monitor and evaluate IT processes to ensure they meet quality standards and client requirements. Implement continuous improvement strategies.
Team Leadership: Manage and mentor a team of IT professionals. Foster a collaborative and efficient work environment.
Client Interaction: Work closely with clients to understand their needs and ensure that IT processes are tailored to meet these requirements.
Project Management: Lead and coordinate IT projects, ensuring timely and within-budget delivery.
Compliance and Standards: Ensure all IT processes comply with relevant laws, regulations, and industry standards.
Reporting and Analysis: Develop and present regular reports on process performance, improvements, and challenges.
Vendor Management: Collaborate with vendors and partners to optimize service delivery.
Technology Integration: Oversee the integration of new technologies into existing processes, ensuring minimal disruption and maximum efficiency.

Qualifications

Bachelor’s or Master’s degree in Information Technology, Business Administration, or a related field.
Proven experience in IT process management, preferably in an MSP environment.
Strong understanding of ITIL, Lean, or other process improvement frameworks.
Excellent leadership and team management skills.
Strong analytical and problem-solving abilities.
Exceptional communication and interpersonal skills.
Project management experience and certifications (e.g., PMP) are a plus.

Work Environment

Office-based with occasional visits to client sites.
Standard work hours with flexibility to meet project deadlines and client needs.

Encompass Solutions: Encompass Solutions, renowned for its robust IT services, champions the principle of aligning technology with business goals for consistent, reliable outcomes. With a mission to deliver top-tier IT processes and strategies, Encompass is committed to excellence in customer service, enhancing business performance, and managing technology costs effectively. Leveraging a history of large infrastructure support, our experienced teams excel in solving complex challenges efficiently, ensuring optimal business-aligned IT solutions.","{""role_summary"":""Oversee and improve IT service delivery processes, ensuring efficiency, effectiveness, and client satisfaction."",""key_terms"":[{""term"":""ITIL"",""explanation"":""A set of best practices for IT service management, focusing on aligning IT services with business needs.""},{""term"":""Lean"",""explanation"":""A process improvement methodology that aims to minimize waste, maximize value, and optimize workflows.""},{""term"":""MSP"",""explanation"":""Managed Service Provider, a company that provides outsourced IT services to clients.""},{""term"":""PMP"",""explanation"":""Project Management Professional, a certification for project managers that demonstrates expertise in project planning, execution, and delivery.""}],""skill_priorities"":{""must_have"":[""IT process management experience"",""Strong understanding of ITIL, Lean, or other process improvement frameworks"",""Excellent leadership and team management skills"",""Strong analytical and problem-solving abilities"",""Exceptional communication and interpersonal skills""],""nice_to_have"":[""Project management experience and certifications (e.g., PMP)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you improved an IT service delivery process, and what steps you took to achieve it?"",""example_answer"":""In my previous role, I identified an inefficient process that was causing delays in service delivery. I worked with the team to redesign the process, implementing automation and streamlining workflows. As a result, we reduced service delivery time by 30% and improved client satisfaction ratings.""},{""question"":""How do you ensure that IT processes comply with relevant laws, regulations, and industry standards?"",""example_answer"":""I conduct regular audits and assessments to identify areas of non-compliance. I then work with the team to develop and implement corrective actions, ensuring that our processes meet the required standards.""}],""red_flags"":[""Lack of experience in IT process management"",""Inability to demonstrate understanding of process improvement frameworks"",""Poor leadership and team management skills""],""confidence_score"":90.0}"
Incident Manager,"Incident Manager (3 Positions) – Montreal Airport
Location: Montreal, QC (On-site)
Language Requirement: French
Citizenship: Must be a Canadian Citizen
Availability: On-call required

Role Overview:
We are seeking three experienced Incident Managers to oversee and coordinate critical Networking/Server/Storage incident management at Montreal-Trudeau International Airport (YUL). The role involves managing and monitoring IT infrastructure incidents, ensuring efficient resolution, and maintaining service level commitments across multiple business processes and vendor applications.

Key Responsibilities:
Incident Coordination: Oversee all activities related to critical incidents, ensuring swift and effective resolution.
Process Management: Manage, coordinate, and monitor daily activities related to the Incident Management process within the assigned service domain.
Workload Balancing: Assign resources efficiently to meet service level agreements.
Escalation & Resolution: Identify incidents at risk of missing SLAs, escalate as needed, and drive resolution efforts.
Stakeholder Liaison: Act as the primary interface for the Process Account Lead and High Priority Incident Manager.
Performance Management: Monitor and evaluate team performance to ensure adherence to incident management processes.
Service Delivery Oversight: Track service performance for all customers supported within the environment.
Data Analysis: Analyze process efficiency and delivery metrics to drive improvements.

Environment & Scope:
The role involves supporting critical IT infrastructure and business processes, including:
Server management, storage, backup/recovery, disaster recovery, Active Directory, database management, and web servers.
Over 100 vendor applications used within the airport environment.
Coordination with SITA Global Services (SGS) for the management of SITA kiosks at YUL, ensuring communication with key stakeholders.

Qualifications & Requirements:
Prior experience in major incident management and IT service delivery.
Strong understanding of IT infrastructure and airport technology environments.
Ability to work on-call and respond to high-priority incidents as needed.
Fluency in French is required.
Must be a Canadian Citizen due to security and compliance requirements.","{""role_summary"":""Oversee and coordinate critical IT infrastructure incident management at Montreal-Trudeau International Airport, ensuring efficient resolution and maintaining service level commitments."",""key_terms"":[{""term"":""Incident Management"",""explanation"":""The process of identifying, containing, and resolving IT incidents to minimize business impact.""},{""term"":""SLA"",""explanation"":""Service Level Agreement, a commitment to deliver a certain level of service quality.""},{""term"":""SITA kiosks"",""explanation"":""Self-service kiosks used at the airport for check-in, baggage drop-off, and other passenger services.""},{""term"":""Active Directory"",""explanation"":""A Microsoft directory service that manages access to network resources.""}],""skill_priorities"":{""must_have"":[""Prior experience in major incident management and IT service delivery"",""Strong understanding of IT infrastructure and airport technology environments"",""Ability to work on-call and respond to high-priority incidents as needed"",""Fluency in French""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you handle a critical incident that affects multiple business processes?"",""example_answer"":""I would immediately assess the impact, notify stakeholders, and coordinate with the team to contain and resolve the incident, ensuring minimal business disruption.""},{""question"":""Can you describe your experience with IT service delivery and incident management?"",""example_answer"":""In my previous role, I managed a team that resolved IT incidents, ensuring SLA adherence and improving process efficiency by 25%.""}],""red_flags"":[""Lack of experience in IT infrastructure and airport technology environments"",""Inability to work on-call and respond to high-priority incidents as needed""],""confidence_score"":90.0}"
IT Applications Manager,"Visier is the leader in people analytics and we believe in a 'people-first' approach to business strategy. Our innovative technology transforms the way that organisations make decisions, allowing them to elevate their employees and drive better business outcomes. Embarking on an exciting new chapter in our growth story, we are looking for talented individuals who can help both Visier and our customers grow, evolve and win!

Visier Inc. is seeking a highly motivated and strategic IT Applications Manager to lead the architecture, development, and execution of our application enablement roadmap. This role is crucial in ensuring Visier's internal use of cloud applications are robust, scalable, and aligned with our evolving business needs. You will be a key driver in shaping the future of our internal application ecosystem, fostering innovation, and maximizing the value derived from our technology investments.

What You’ll Be Doing…

Strategic Roadmap Development:

Develop and maintain a comprehensive, multi-year strategic roadmap for application enablement, aligned with Visier's overall business objectives.
Conduct thorough assessments of current application landscape, identifying gaps, opportunities, and areas for improvement.
Collaborate with stakeholders across departments (e.g., Engineering, Product, Finance, HR) to understand their application needs and translate them into actionable plans.
Research and evaluate emerging technologies and industry best practices to inform roadmap development.

Application Architecture & Design:

Define and enforce application architecture standards, ensuring scalability, security, and maintainability.
Lead the design and implementation of application integrations and data flows.
Evaluate and select appropriate application platforms and technologies.
Ensure applications are designed to support business continuity and disaster recovery requirements.

Team Leadership & Collaboration:

Provide technical leadership and mentorship to application development and support teams.
Foster a collaborative and innovative work environment.
Communicate effectively with stakeholders at all levels of the organization.
Manage projects, budgets and timelines.

Security and Compliance:

Ensure all applications adhere to security and compliance standards, including data privacy regulations.
Implement and maintain security best practices for application development and deployment.
Participate in security audits and risk assessments.

What You’ll Bring To The Table…

Bachelor's degree in Computer Science, Information Technology, or a related field.
Proven experience (5+ years) as an IT Applications Manager or similar role.
Strong understanding of application architecture, design, and development principles.
Experience with a variety of application technologies, including cloud-based solutions, SaaS, and on-premise systems.
Excellent analytical, problem-solving, and decision-making skills.
Strong communication, interpersonal, and leadership skills.
Experience managing IT projects and budgets.
Relevant certifications (e.g., ITIL, PMP) are a plus.
The ideal candidate will have significant experience with ServiceNow.

Most importantly, you share our values...

You roll up your sleeves
You make it easy
You are proud
You never stop learning
You play to win

The base pay range for this position in Canada is $93k - 139k / year + commission/bonus

The compensation offered will be determined by factors such as relevant qualifications, experience, knowledge and skills. Many of our positions are eligible for additional types of compensation (e.g., commission plans, bonus, etc.) which our Talent Acquisition team will share with you if you interview for the role.

See the #VisierLife in action

Instagram - @visierlife

Linkedin - https://www.linkedin.com/company/visier-analytics/

Visier Candidate Privacy Notice and Recruiter Policy","{""role_summary"":""Lead the architecture, development, and execution of application enablement roadmap, ensuring Visier's internal use of cloud applications are robust, scalable, and aligned with business needs."",""key_terms"":[{""term"":""Cloud applications"",""explanation"":""Software applications delivered over the internet, allowing users to access and use them remotely.""},{""term"":""Application enablement roadmap"",""explanation"":""A strategic plan outlining the development and implementation of applications to support business objectives.""},{""term"":""SaaS"",""explanation"":""Software as a Service, a software delivery model where applications are hosted and managed by a third-party provider.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of best practices for IT service management.""},{""term"":""PMP"",""explanation"":""Project Management Professional, a certification for project managers.""}],""skill_priorities"":{""must_have"":[""Proven experience as an IT Applications Manager or similar role"",""Strong understanding of application architecture, design, and development principles"",""Experience with a variety of application technologies, including cloud-based solutions, SaaS, and on-premise systems"",""Excellent analytical, problem-solving, and decision-making skills"",""Strong communication, interpersonal, and leadership skills""],""nice_to_have"":[""Relevant certifications (e.g., ITIL, PMP)"",""Significant experience with ServiceNow""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with application architecture and design? How do you ensure scalability and security?"",""example_answer"":""I have worked on several projects where I had to design and implement application architectures that were scalable and secure. I ensured this by following industry best practices, conducting thorough risk assessments, and implementing robust security measures.""},{""question"":""How do you stay up-to-date with emerging technologies and industry trends in application development?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read relevant publications to stay current with the latest developments in application development.""}],""red_flags"":[""Lack of experience with cloud-based solutions"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Information Technology Audit Manager,"Job Title: IT Audit Manager
Candidate Summary:
We are seeking an experienced IT Audit Manager with over 15 years of expertise in IT governance, data governance, and internal audit within the financial services industry. This candidate has a proven track record of delivering independent assurance on the design and operation of IT systems, internal controls, and data governance practices, ensuring compliance with evolving regulatory frameworks.

Key Responsibilities:
Provide senior-level support for IT governance and data governance audits, collaborating with senior leaders to ensure effective audit planning, reporting, and issue remediation.
Engage with key stakeholders including Director, US Functions IT, Managing Director US IT, and Deputy US CAE to provide updates on audit findings and track open audit issues.
Coordinate responses to US regulatory examinations, working with external auditors and regulators such as FRBNY, OCC, SEC, and FINRA to address and verify regulatory issues.
Develop and implement audit approaches for IT and data governance, ensuring adequate coverage of emerging risks, proprietary technologies, and compliance needs.
Collaborate with Risk Management and Compliance teams to assess and enhance risk management strategies across platforms.
Lead efforts to shift the organization toward a predictive insights-driven approach, enhancing the data analysis capabilities and tools within the audit function.

Qualifications:
Bachelor’s Degree in a relevant field.
Over 15 years of experience in IT governance, data governance, and internal audit, with a strong focus on financial services.
In-depth understanding of IT risks, audit methodologies, and regulatory compliance across Capital Markets, Retail/Commercial Banking, and Enterprise Applications.
Proven ability to engage with senior stakeholders, influence audit strategy, and drive successful issue remediation.
Extensive experience with regulatory bodies such as FRBNY, OCC, SEC, and FINRA.
Excellent communication skills with a focus on relationship-building, problem-solving, and delivering impactful insights.

Preferred Qualifications:
5+ years of experience in IT Internal Audit.
Professional certifications in audit or technology (e.g., CISA, CISSP).

Why Join Us?
As an IT Audit Manager, you will play a critical role in shaping and executing the audit strategy for IT and data governance, ensuring compliance with regulatory standards and strengthening internal controls. This position offers the opportunity to work with senior leaders and make a tangible impact on the organization’s risk management strategies, driving security, productivity, and competitive advantage through data-driven insights.","{""role_summary"":""Lead IT governance and data governance audits, ensuring compliance with regulatory frameworks and strengthening internal controls."",""key_terms"":[{""term"":""IT governance"",""explanation"":""The process of overseeing and managing an organization's IT systems to ensure they align with business objectives and comply with regulations.""},{""term"":""Data governance"",""explanation"":""The process of managing and overseeing an organization's data to ensure its quality, security, and compliance with regulations.""},{""term"":""Internal audit"",""explanation"":""An independent evaluation of an organization's internal controls, risk management, and governance processes to ensure they are effective and compliant with regulations.""},{""term"":""Regulatory frameworks"",""explanation"":""A set of rules, guidelines, and standards that organizations must comply with to ensure they are operating legally and ethically.""},{""term"":""FRBNY"",""explanation"":""The Federal Reserve Bank of New York, a regulatory body that oversees and regulates financial institutions.""},{""term"":""OCC"",""explanation"":""The Office of the Comptroller of the Currency, a regulatory body that oversees and regulates national banks and federal savings associations.""},{""term"":""SEC"",""explanation"":""The Securities and Exchange Commission, a regulatory body that oversees and regulates the securities industry.""},{""term"":""FINRA"",""explanation"":""The Financial Industry Regulatory Authority, a regulatory body that oversees and regulates the securities industry.""},{""term"":""CISA"",""explanation"":""Certified Information Systems Auditor, a professional certification for IT auditors.""},{""term"":""CISSP"",""explanation"":""Certified Information Systems Security Professional, a professional certification for IT security professionals.""}],""skill_priorities"":{""must_have"":[""15+ years of experience in IT governance, data governance, and internal audit"",""In-depth understanding of IT risks, audit methodologies, and regulatory compliance"",""Proven ability to engage with senior stakeholders, influence audit strategy, and drive successful issue remediation"",""Extensive experience with regulatory bodies such as FRBNY, OCC, SEC, and FINRA""],""nice_to_have"":[""5+ years of experience in IT Internal Audit"",""Professional certifications in audit or technology (e.g., CISA, CISSP)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with IT governance and data governance audits in the financial services industry?"",""example_answer"":""I have over 15 years of experience leading IT governance and data governance audits in the financial services industry, ensuring compliance with regulatory frameworks and strengthening internal controls.""},{""question"":""How do you stay current with evolving regulatory frameworks and emerging risks in IT and data governance?"",""example_answer"":""I regularly review industry publications and attend conferences to stay current with evolving regulatory frameworks and emerging risks in IT and data governance, and I collaborate with cross-functional teams to ensure our audit approaches are adequate and effective.""}],""red_flags"":[""Lack of experience with regulatory bodies such as FRBNY, OCC, SEC, and FINRA"",""Inability to engage with senior stakeholders and influence audit strategy""],""confidence_score"":95.0}"
Technology Lead,"Location:- Montreal OR Toronto, Canada

Relevant:
5+ years of experience in pipeline design and development (Batch and Streaming) using Azure/snowflake cloud services, primarily on Azure Datalake Gen2, Azure Data Factory, Azure Event Hub, Databricks, and Snowflake.
 Must Skills:
Databricks, Snowflake, Pyspark, SQL, Data Modeling
 Responsibilities:
Excellent communication, work closely with Customer
Expertise in above skills
Complete the user stories in the assigned sprint, highlight the risks at right time
 JD:
Collaborate with stakeholders to understand requirements, data solutions, data models and mapping documents.
Lead the design, development, and implementation of data solutions using Azure Data Lake Storage (ADLS), Azure Data Factory, Event Hub, Databricks, and Snowflake.
Oversee the end-to-end data pipeline, ensuring data quality, integrity, and security.
Lead the deployment activities including the Dev test approval, PR approval, Collaboration with DevOps team, Release mgmt. for deployment into all environments including production and provide knowledge sharing to Data operations team
Assist data analysts with technical input.
Provide data engineering inputs to the data solution architect.
Lead the effort estimates/story point estimates for the sprint.
Mentor and guide a team of data engineers.
Foster a collaborative environment to encourage knowledge sharing and continuous improvement.
Conduct code reviews and ensure adherence to coding standards and best practices.","{""role_summary"":""Lead the design, development, and implementation of data solutions using Azure cloud services, ensuring data quality, integrity, and security, and collaborating with stakeholders to understand requirements."",""key_terms"":[{""term"":""Azure Datalake Gen2"",""explanation"":""A cloud-based data storage solution for storing and processing large amounts of data.""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service for creating, scheduling, and managing data pipelines.""},{""term"":""Azure Event Hub"",""explanation"":""A cloud-based event streaming service for ingesting and processing large volumes of events.""},{""term"":""Databricks"",""explanation"":""A cloud-based Apache Spark platform for data engineering, data science, and data analytics.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and processing large amounts of data.""},{""term"":""Pyspark"",""explanation"":""A Python library for Apache Spark, used for data processing and analytics.""},{""term"":""Data Modeling"",""explanation"":""The process of creating a conceptual representation of data structures and relationships.""}],""skill_priorities"":{""must_have"":[""Databricks"",""Snowflake"",""Pyspark"",""SQL"",""Data Modeling""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data quality and integrity in a data pipeline?"",""example_answer"":""I use data validation and data quality checks at each stage of the pipeline, and also implement data testing and monitoring to ensure data accuracy and completeness.""},{""question"":""Can you explain the difference between batch and streaming data processing?"",""example_answer"":""Batch processing involves processing large datasets in batches, whereas streaming processing involves processing data in real-time as it is generated. I use Azure Data Factory for batch processing and Azure Event Hub for streaming processing.""}],""red_flags"":[""Lack of experience with Azure cloud services"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Responsable de la transformation des TI,"Offre d'emploi : Responsable de la transformation des TI
Localisation : Montréal
Durée du mandat : 1 an
Mode de travail : Hybride
Début : 1er avril

Pourquoi nous rejoindre ?

Astek est un leader mondial en conseil technologique. Avec 9 600 experts dans le monde, nous guidons nos clients dans leur transformation numérique en développant des solutions innovantes.

Au Canada, nous excellons en TI et ingénierie. Nous collaborons avec des entreprises de premier plan pour relever des défis technologiques majeurs, en plaçant l’innovation, la collaboration et l’excellence au cœur de nos actions.

Rejoignez une équipe passionnée et engagée, prête à concrétiser vos idées.

À propos du poste

Pour le compte de notre client dans le secteur Bancaire, Astek Canada recherche un(e) Responsable de la transformation des TI motivé(e) et prêt(e) à relever de nouveaux défis.

Vos responsabilités

En tant que Responsable de la transformation des TI, vous serez amené(e) à :
Élaborer des stratégies de transformation des entreprises adaptées.
Guider les dirigeants tout au long des changements transformationnels.
Diriger des projets de gestion du changement et définir les résultats souhaités en matière de changement pour l'organisation.
Diriger l'engagement avec les parties prenantes pour surmonter les obstacles au changement.
Évaluer l'organisation des équipes afin d'éliminer les obstacles internes au changement.
Travailler avec les fournisseurs de services informatiques et élaborer des propositions conjointes de programmes de transformation, évaluer leur faisabilité et gérer l'exécution des projets qui ont été validés.
Suivre les résultats des projets de transformation par rapport à leurs résultats/objectifs.
Mettre en place un changement de processus et une gestion du changement dans l'ensemble de l'organisation.
Examiner les modèles, méthodes, processus et outils opérationnels et proposer des modifications si nécessaire.
Conformité au système de gestion de la qualité convenu.
Se concentrer en permanence sur les gains de productivité, l'efficacité et les économies de coûts.
Respecter toutes les exigences légales, réglementaires et internes en matière de conformité.

Vos atouts pour réussir

Formation/Expérience :
Baccalauréat et/ou maîtrise ou équivalent en informatique, technologie et gestion.
10 ans d'expérience pertinente.

Compétences clés :
Expérience approfondie des projets de transformation des technologies de l'information.
Connaissance des applications et de l'infrastructure informatique d'un centre de prestation de services informatiques.
Connaissance de la sécurité informatique.
Excellentes compétences en matière de communication, d'analyse et d'organisation.
Connaissance du domaine bancaire.
Compétences de présentation efficaces devant la direction.

Qualités personnelles :
Esprit analytique et orienté solutions.
Collaboration et travail en équipe.
Autonomie et rigueur dans la gestion des priorités.

Les avantages Astek
Plan CARE sur mesure pour nos employés
Activités sociales (5@7, team buildings)
Charte diversité & inclusion

Prêt(e) à relever le défi ?
Postulez dès maintenant en envoyant votre CV et découvrez une carrière enrichissante chez Astek Canada.","{""role_summary"":""Lead the transformation of IT services for a banking client, developing strategies, guiding leaders, and managing projects to achieve desired outcomes."",""key_terms"":[{""term"":""Transformation des TI"",""explanation"":""Transformation of IT services, referring to the process of changing or improving IT systems and processes to meet business needs.""},{""term"":""Gestion du changement"",""explanation"":""Change management, referring to the process of planning, implementing, and monitoring changes to minimize disruption and ensure successful adoption.""},{""term"":""Sécurité informatique"",""explanation"":""Information security, referring to the practices and technologies designed to protect digital information and systems from unauthorized access, use, disclosure, disruption, modification, or destruction.""}],""skill_priorities"":{""must_have"":[""10 years of relevant experience"",""Deep experience in IT transformation projects"",""Knowledge of IT applications and infrastructure"",""Information security knowledge"",""Excellent communication, analysis, and organizational skills"",""Presentation skills""],""nice_to_have"":[""Knowledge of the banking domain""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you led a successful IT transformation project? What were the key challenges and how did you overcome them?"",""example_answer"":""In my previous role, I led a team to migrate our client's IT infrastructure to the cloud. We faced resistance from stakeholders, but I worked closely with them to understand their concerns and developed a phased approach to minimize disruption. We achieved a 30% reduction in costs and improved system uptime by 25%.""},{""question"":""How do you stay current with emerging trends and technologies in IT transformation?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read relevant publications to stay informed about the latest developments in IT transformation. I also network with peers and thought leaders to learn from their experiences and share my own insights.""}],""red_flags"":[""Lack of experience in IT transformation projects"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Senior Manager - IT /Cloud FinOps and Governance,"Job Description

Senior Manager - IT /Cloud FinOps and Governance – Job Description

Job Title: Senior Manager - IT /Cloud FinOps and Governance

Location: Canada

Company: Kaleris

About Us: Kaleris is a leading provider of transportation and asset management software for accelerated supply chain execution. Kaleris delivers leading cloud-based transportation and asset management solutions to accelerate supply chain execution for industrial and finished goods shippers and carriers to connect logistics and inventory at yards, terminals, and distribution centers and manage shipments via rail, truck, and multi-mode transportation.

Job Summary: We are seeking a highly skilled and experienced Senior Manager to lead our IT and Cloud FinOps and Governance team. The ideal candidate will have a strong background in financial operations, cloud cost management, and IT governance. This role is critical in ensuring the efficient and effective use of cloud resources, optimizing costs, and maintaining robust governance frameworks.

Key Responsibilities

Lead and manage the IT/Cloud FinOps and Governance team.
Develop and implement strategies for cloud cost optimization and financial management.
Establish and maintain governance frameworks to ensure compliance with industry standards and best practices.
Collaborate with cross-functional teams to align cloud financial operations with business objectives.
Monitor and analyze cloud spending, identifying opportunities for cost savings and efficiency improvements.
Provide regular reports and insights to senior leadership on cloud financial performance and governance.
Drive continuous improvement initiatives in cloud financial operations and governance processes.
Stay up-to-date with industry trends and advancements in cloud technology and financial operations.

Qualifications

Bachelor's degree in Finance, Information Technology, or a related field. A Master's degree or relevant certifications (e.g., FinOps Certified Practitioner, AWS Certified Solution Architect - Associate) is a plus.
Minimum of 7-10 years of experience in IT operations, cloud operations/management, and governance.
Strong understanding of cloud platforms (e.g., AWS, Azure, Google Cloud) and their financial management tools.
Proven track record of leading and managing teams.
Excellent analytical, problem-solving, and decision-making skills.
Strong communication and interpersonal skills, with the ability to collaborate effectively with stakeholders at all levels.
Experience with financial reporting and analysis tools.

Knowledge of industry standards and best practices in IT governance

Kaleris is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.","{""role_summary"":""Lead and manage the IT/Cloud FinOps and Governance team to ensure efficient and effective use of cloud resources, optimize costs, and maintain robust governance frameworks."",""key_terms"":[{""term"":""FinOps"",""explanation"":""Financial Operations, a set of practices that combines technology, business, and financial disciplines to manage and optimize cloud costs.""},{""term"":""Cloud Governance"",""explanation"":""The process of establishing policies, procedures, and standards for the use of cloud computing resources to ensure compliance with industry standards and best practices.""},{""term"":""Cloud Cost Optimization"",""explanation"":""The process of reducing and controlling cloud computing costs through efficient resource allocation, right-sizing, and cost-effective solutions.""}],""skill_priorities"":{""must_have"":[""Cloud cost management"",""IT governance"",""Financial operations"",""Cloud platforms (e.g., AWS, Azure, Google Cloud)"",""Financial reporting and analysis tools""],""nice_to_have"":[""FinOps Certified Practitioner"",""AWS Certified Solution Architect - Associate"",""Master's degree""]},""proposed_screening_questions_with_answers"":[{""question"":""What strategies would you implement to optimize cloud costs and improve financial management?"",""example_answer"":""I would analyze cloud spending patterns, identify areas of inefficiency, and implement cost-saving measures such as rightsizing, reserved instances, and optimized resource allocation. I would also establish a cloud cost governance framework to ensure accountability and transparency.""},{""question"":""How would you ensure compliance with industry standards and best practices in IT governance?"",""example_answer"":""I would establish a governance framework that aligns with industry standards such as COBIT, ITIL, or ISO 27001. I would also conduct regular risk assessments, implement controls, and monitor compliance to ensure the organization meets regulatory requirements.""}],""red_flags"":[""Lack of experience in cloud cost management and optimization"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Cloud DevOps Engineer,"We are seeking a talented and experienced Cloud DevOps Engineer with a strong background in cloud technologies, particularly AWS/GCP, to join our dynamic and innovative team. The ideal candidate will play a critical role in designing, developing, and maintaining scalable, secure, and highly reliable cloud-based solutions. This role offers the opportunity to collaborate with cross-functional teams, mentor peers, and make impactful decisions in a fast-paced, customer-oriented environment.

Responsibilities

Work with the Infrastructure and Engineering teams to maintain products, keeping them secure, bug-free and compliant with platform policies
Support our Customer Success team to troubleshoot customer issues and fix/patch software as needed
Familiarize yourself with end-to-end architecture for both products. Reverse engineer and document system architecture which can be shared across the team
Manage cloud infrastructure and drive DevOps best practices for maintaining our CI/CD pipeline for these products
Perform regular patching, security updates and performance tuning of software products

Minimum Qualifications

BS Degree in Computer Science or similar
5+ years' experience in software development
Experience with full stack models, services, and cloud deployment
Comfortable with GCP or AWS, and proficient in either one
Comfortable with understanding full stack software using Go, JavaScript, and React
Proficiency in Databases, specifically NoSQL like DynamoDB and MongoDB
Comfortable with C# for desktop applications
Experience with either Jenkins or BuildKite
Experience with DevOps tools like – Docker, Terraform, Linux
Proficient in Git and GitHub knowledge
Excellent communication skills
Ability to be a self-starter

Preferred Qualifications

Proficiency in gRPC and Protobuf
Basic game engine experience with Unity
Experience with TestFlight
Knowledge of installers
Knowledge of Electron","{""role_summary"":""Design, develop, and maintain scalable, secure, and reliable cloud-based solutions as a Cloud DevOps Engineer, collaborating with cross-functional teams and mentoring peers in a fast-paced, customer-oriented environment."",""key_terms"":[{""term"":""Cloud technologies"",""explanation"":""Refers to the use of cloud computing platforms such as AWS or GCP to build and deploy applications.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""CI/CD pipeline"",""explanation"":""A set of practices and tools that automate the build, test, and deployment of software applications.""},{""term"":""Full stack"",""explanation"":""Refers to the development of complete web applications, including front-end, back-end, and database components.""},{""term"":""NoSQL"",""explanation"":""A type of database that does not use the traditional table-based relational model, such as DynamoDB or MongoDB.""},{""term"":""gRPC"",""explanation"":""A high-performance RPC framework developed by Google.""},{""term"":""Protobuf"",""explanation"":""A data serialization format developed by Google.""}],""skill_priorities"":{""must_have"":[""AWS or GCP experience"",""Full stack development experience"",""DevOps experience"",""Databases (NoSQL)"",""Git and GitHub knowledge"",""Excellent communication skills""],""nice_to_have"":[""gRPC and Protobuf experience"",""Basic game engine experience with Unity"",""Experience with TestFlight"",""Knowledge of installers"",""Knowledge of Electron""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing and implementing a scalable cloud-based solution?"",""example_answer"":""I would start by identifying the requirements of the solution, then select the appropriate cloud services and architecture to meet those requirements. I would also ensure that the solution is secure, reliable, and scalable, and that it can be easily maintained and updated.""},{""question"":""Can you explain the importance of DevOps in a cloud-based environment?"",""example_answer"":""DevOps is critical in a cloud-based environment because it enables teams to collaborate and work together more efficiently, which leads to faster time-to-market, higher quality, and lower risk. It also enables automation, continuous integration and delivery, and monitoring, which are essential for maintaining scalable and reliable cloud-based solutions.""}],""red_flags"":[""Lack of experience with cloud technologies (AWS or GCP)"",""Inability to work collaboratively in a fast-paced environment""],""confidence_score"":90.0}"
Associate Cloud Engineer,"Requisition ID: 216068

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

Scotiabank has embarked on the journey to modernize both development practices and tools. One of the main areas of transformation is the public cloud and the various platform technologies that support both development and operations on the cloud. The aim is to provide a streamlined process and framework which will allow the development teams to focus on building business logic. The platform is used by development teams globally to host hundreds of applications. We are building our development team with influencers, makers, creators and industry leaders who will drive us forward. The role of the Associate Cloud Engineer operates within the Cloud Platform Engineering team. This valuable member of the team will be responsible for creating platform components and services for the broad enterprise use.

Is this role right for you? In this role, you will:

Key accountabilities include development and maintenance of cloud platforms, services and components to enable safe enterprise-wide use of cloud common functionality.
Level 3 support responsibilities are required.
Designing, implementing and refactoring code.
Participating in design discussions focused on scalability and design and implementation best practices.
Ensuring software, programs and applications are developed and/or configured to meet high availability, integrity and reliability requirements.
Working with other engineers and architects on breaking-down, scoping and estimating tasks.
Participating in planning and retrospective sessions, attending stand-ups, etc.
Build and operate the highly available and scalable software and infrastructure.
Supporting application teams on the use of the platform including providing guidance on design patterns, best practices, and security considerations.
Our teams are flexible and fast – you will be asked to provide peer review and quality control on a daily basis.

Skills

Do you have the skills that will enable you to succeed in this role? We’d love to work with you if you have:

Enthusiasm for cloud transformation and cloud platform/components/services development.
Strong development experience and breadth of language experience (e.g. Hashicorp DSL (HCL), Go, Rego).
Experience with Terraform and module development
Understanding of software development life cycle as well as related technologies.
Experience in cloud platform features and capabilities is an asset (Azure, GCP).
Experience with config management tools and Scripting Languages (Ansible, Bash, Groovy)
Understanding of infrastructure and networking is a benefit.
Self-sufficient, works under the supervision of a more senior engineer.
Knowledgeable in software design patterns, infrastructure architecture, DevOps, or security considerations is an asset.
Understanding of software release process (environments, binary repositories, CI/CD).
Desire to learn, grow yourself and your team.
Writing and maintaining related documentation.
Investigating, analyzing, and resolving system problems.
Experience within Canadian financial institutions is a benefit.
Experience with Kubernetes or containerized applications is a benefit.
Bachelor (equivalent or higher) degree in computer science or engineering/mathematics discipline.

What's in it for you?

Diversity, Equity, Inclusion & Allyship - We strive to create an inclusive culture where every employee is empowered to reach their fullest potential, respected for who they are, and are embraced through bias-free practices and inclusive values across Scotiabank. We embrace diversity and provide opportunities for all employee to learn, grow & participate through our various Employee Resource Groups (ERGs) that span across diverse gender identities, ethnicity, race, age, ability & veterans.
Accessibility and Workplace Accommodations - We value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. Scotiabank continues to locate, remove and prevent barriers so that we can build a diverse and inclusive environment while meeting accessibility requirements.
Upskilling through online courses, cross-functional development opportunities, and tuition assistance.
Competitive Rewards program including bonus, flexible vacation, personal, sick days and benefits will start on day one.
Community Engagement- no matter where you choose to work from; we offer opportunities for community engagement & belonging with our various programs such as hackathons, contests, cooking with friends, Humans of Digital and much more!

Work arrangements: Hybrid

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","{""role_summary"":""The Associate Cloud Engineer role is responsible for creating platform components and services for the broad enterprise use of cloud common functionality, ensuring high availability, integrity, and reliability requirements."",""key_terms"":[{""term"":""Cloud Platform Engineering"",""explanation"":""The process of designing, building, and operating cloud-based systems and applications.""},{""term"":""Hashicorp DSL (HCL)"",""explanation"":""A domain-specific language used for infrastructure as code and configuration management.""},{""term"":""Terraform"",""explanation"":""An infrastructure as code tool used for building, changing, and managing infrastructure.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""}],""skill_priorities"":{""must_have"":[""Cloud transformation and cloud platform/components/services development experience"",""Strong development experience and breadth of language experience (e.g. Hashicorp DSL (HCL), Go, Rego)"",""Experience with Terraform and module development"",""Understanding of software development life cycle and related technologies""],""nice_to_have"":[""Experience in cloud platform features and capabilities (Azure, GCP)"",""Experience with config management tools and Scripting Languages (Ansible, Bash, Groovy)"",""Understanding of infrastructure and networking"",""Knowledgeable in software design patterns, infrastructure architecture, DevOps, or security considerations"",""Experience with Kubernetes or containerized applications""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a scalable cloud platform component?"",""example_answer"":""I would follow a modular design approach, using Terraform to define infrastructure as code, and ensure scalability by using load balancers and auto-scaling groups. I would also consider security and compliance requirements, and implement monitoring and logging to ensure high availability and reliability.""},{""question"":""How do you stay up-to-date with the latest developments in cloud platform engineering?"",""example_answer"":""I regularly follow industry blogs and news, attend conferences and meetups, and participate in online forums and communities to stay current with the latest trends and best practices in cloud platform engineering.""}],""red_flags"":[""Lack of experience with cloud transformation and cloud platform/components/services development"",""Inability to work in a fast-paced and flexible environment"",""Limited understanding of software development life cycle and related technologies""],""confidence_score"":90.0}"
DevOps Cloud Engineer,"We're Hiring!

Job Title: DevOps Cloud Engineer

Location:

Employment Type: Contract Opportunity

Job Description

Minimum 10 years of experience in WebLogic V12, WebSphere V9, Informatica V10 configuration, customization, upgrading
Minimum 5 years of experience in DevOps toolsets in Azure Cloud, including but not limited to, Docker, Ansible, Packer, Terraform, Azure DevOps Pipelines, OpenShift.
Working knowledge and experience in git, including branching and merging strategies (e.g. git-flow), collaborating via pull request and practicing GitOps
Working knowledge and experience of designing and implementing infrastructure as code build automation using Terraform and immutable infrastructure with Ansible and Packer
Minimum 10 years of experience in systems, data communications and telecommunication technology including experience with RedHat Enterprise Linux V7+, UNIX Solaris V10 and Mainframe IMS Connect, system software and System tools
Working knowledge and experience of implementing instances/applications performance tuning, storage/capacity management, DB migration/upgrade, Backup/Disaster Recovery (DR) strategies
Working knowledge and experience of clustering Load Balancers, and Firewall configuration and accomplishing the same in Azure cloud
Experience with technologies (J2EE, Java) and web technologies (Node.js, Azure Functions, Serverless, Pub/Sub event driven systems, Azure App Gateway)
Experience with Informatics Power Centre tools, Designer, Workflow Manager, Workflow
Experience on application monitoring and support
Highly skilled analysis and problem-solving skills

Must Haves

10+ years of experience in systems, data communications and telecommunication technology including experience with RedHat Enterprise Linux V7+, UNIX Solaris V10 and Mainframe IMS Connect, system software and System tools","{""role_summary"":""The DevOps Cloud Engineer is responsible for designing, implementing, and maintaining cloud-based infrastructure and applications, ensuring high performance, scalability, and reliability. This role requires expertise in DevOps toolsets, cloud computing, and system administration."",""key_terms"":[{""term"":""WebLogic V12"",""explanation"":""A version of Oracle's WebLogic Server, a Java-based application server.""},{""term"":""WebSphere V9"",""explanation"":""A version of IBM's WebSphere Application Server, a software framework for building, deploying, and managing web applications.""},{""term"":""Informatica V10"",""explanation"":""A version of Informatica's PowerCenter, a data integration platform for extracting, transforming, and loading data.""},{""term"":""Ansible"",""explanation"":""An open-source automation tool for configuration management, application deployment, and task automation.""},{""term"":""Packer"",""explanation"":""An open-source tool for creating identical machine images for multiple platforms from a single source configuration.""},{""term"":""Terraform"",""explanation"":""An open-source infrastructure as code tool for building, changing, and managing infrastructure.""},{""term"":""Azure DevOps Pipelines"",""explanation"":""A continuous integration and continuous deployment (CI/CD) tool for automating the build, test, and deployment of software applications.""},{""term"":""OpenShift"",""explanation"":""A container application platform for deploying and managing containerized applications.""},{""term"":""GitOps"",""explanation"":""A set of practices that combines Git version control with infrastructure automation to manage infrastructure and application configurations.""},{""term"":""RedHat Enterprise Linux V7+"",""explanation"":""A version of the Red Hat Enterprise Linux operating system.""},{""term"":""UNIX Solaris V10"",""explanation"":""A version of the Solaris operating system, a Unix-based OS developed by Sun Microsystems.""},{""term"":""Mainframe IMS Connect"",""explanation"":""A mainframe integration platform for connecting and integrating mainframe applications with other systems.""},{""term"":""J2EE"",""explanation"":""A version of the Java Platform, Enterprise Edition, a set of APIs and tools for building enterprise-level applications.""},{""term"":""Azure Functions"",""explanation"":""A serverless compute service for running event-driven code in the cloud.""},{""term"":""Serverless"",""explanation"":""A cloud computing model where the cloud provider manages the infrastructure and dynamically allocates computing resources as needed.""},{""term"":""Pub/Sub event driven systems"",""explanation"":""A messaging pattern where publishers send messages to a topic, and subscribers receive messages from the topic.""},{""term"":""Azure App Gateway"",""explanation"":""A web application firewall and load balancer for securing and routing web traffic.""}],""skill_priorities"":{""must_have"":[""10+ years of experience in systems, data communications and telecommunication technology"",""Experience with RedHat Enterprise Linux V7+, UNIX Solaris V10 and Mainframe IMS Connect"",""Experience with DevOps toolsets in Azure Cloud"",""Experience with WebLogic V12, WebSphere V9, Informatica V10 configuration, customization, upgrading""],""nice_to_have"":[""Experience with Docker"",""Experience with Packer"",""Experience with Terraform"",""Experience with Azure DevOps Pipelines"",""Experience with OpenShift"",""Experience with git, including branching and merging strategies"",""Experience with designing and implementing infrastructure as code build automation"",""Experience with clustering Load Balancers, and Firewall configuration"",""Experience with technologies (J2EE, Java) and web technologies (Node.js, Azure Functions, Serverless, Pub/Sub event driven systems, Azure App Gateway)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach infrastructure as code build automation using Terraform and Ansible?"",""example_answer"":""I use Terraform to define the infrastructure configuration and Ansible to automate the deployment and management of the infrastructure. I also implement immutable infrastructure with Ansible and Packer to ensure consistency and reproducibility.""},{""question"":""Can you explain your experience with clustering Load Balancers and Firewall configuration in Azure cloud?"",""example_answer"":""I have experience configuring Load Balancers and Firewalls in Azure cloud using Azure Load Balancer and Azure Firewall. I understand the importance of clustering for high availability and scalability, and I have implemented clustering solutions using Azure Load Balancer and Azure Firewall.""}],""red_flags"":[""Lack of experience with DevOps toolsets in Azure Cloud"",""Limited knowledge of infrastructure as code build automation using Terraform and Ansible"",""Inability to design and implement clustering Load Balancers and Firewall configuration in Azure cloud""],""confidence_score"":90.0}"
DevOps Infrastructure Engineer,"We are seeking a talented and experienced DevOps Infrastructure Engineer with a strong background in cloud technologies, particularly AWS/GCP, to join our dynamic and innovative team. The ideal candidate will play a critical role in designing, developing, and maintaining scalable, secure, and highly reliable cloud-based solutions. This role offers the opportunity to collaborate with cross-functional teams, mentor peers, and make impactful decisions in a fast-paced, customer-oriented environment.

Responsibilities

Work with the Infrastructure and Engineering teams to maintain products, keeping them secure, bug-free and compliant with platform policies
Support our Customer Success team to troubleshoot customer issues and fix/patch software as needed
Familiarize yourself with end-to-end architecture for both products. Reverse engineer and document system architecture which can be shared across the team
Manage cloud infrastructure and drive DevOps best practices for maintaining our CI/CD pipeline for these products
Perform regular patching, security updates and performance tuning of software products

Minimum Qualifications

BS Degree in Computer Science or similar
5+ years' experience in software development
Experience with full stack models, services, and cloud deployment
Comfortable with GCP or AWS, and proficient in either one
Comfortable with understanding full stack software using Go, JavaScript, and React
Proficiency in Databases, specifically NoSQL like DynamoDB and MongoDB
Comfortable with C# for desktop applications
Experience with either Jenkins or BuildKite
Experience with DevOps tools like – Docker, Terraform, Linux
Proficient in Git and GitHub knowledge
Excellent communication skills
Ability to be a self-starter

Preferred Qualifications

Proficiency in gRPC and Protobuf
Basic game engine experience with Unity
Experience with TestFlight
Knowledge of installers
Knowledge of Electron","{""role_summary"":""Design, develop, and maintain scalable, secure, and reliable cloud-based solutions as a DevOps Infrastructure Engineer, collaborating with cross-functional teams and mentoring peers in a fast-paced, customer-oriented environment."",""key_terms"":[{""term"":""Cloud technologies"",""explanation"":""Refers to the use of cloud computing platforms such as AWS or GCP to build and deploy scalable and reliable solutions.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency in the development and deployment of software systems.""},{""term"":""CI/CD pipeline"",""explanation"":""A set of practices and tools that automate the build, test, and deployment of software code changes, ensuring continuous integration and delivery.""},{""term"":""Full stack models"",""explanation"":""Refers to the development of complete web applications, including front-end, back-end, and database components.""},{""term"":""NoSQL databases"",""explanation"":""A type of database that does not use the traditional table-based relational model, instead using a variety of other models such as key-value, document, or graph databases.""}],""skill_priorities"":{""must_have"":[""AWS or GCP experience"",""DevOps experience"",""Full stack development experience"",""NoSQL database experience"",""Git and GitHub knowledge""],""nice_to_have"":[""gRPC and Protobuf experience"",""Unity game engine experience"",""TestFlight experience"",""Knowledge of installers"",""Knowledge of Electron""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing and implementing a scalable and secure cloud-based solution?"",""example_answer"":""I would start by assessing the requirements of the solution and identifying the most suitable cloud services to use. I would then design a scalable architecture that takes into account security best practices, and implement it using infrastructure as code tools such as Terraform.""},{""question"":""Can you explain the importance of CI/CD pipelines in DevOps and how you would implement one?"",""example_answer"":""CI/CD pipelines are essential in DevOps as they automate the build, test, and deployment of software code changes, ensuring continuous integration and delivery. I would implement a CI/CD pipeline using tools such as Jenkins or BuildKite, and automate the deployment of code changes to the cloud using Docker and Terraform.""}],""red_flags"":[""Lack of experience with cloud technologies"",""Inability to work with cross-functional teams"",""Poor communication skills""],""confidence_score"":90.0}"
Cloud Operations Engineer,"Who we are
iTMethods has grown to become a market leader in enabling Enterprise DevOps. Our&#8239;Managed DevOps&#8239;SaaS Platform enables global enterprises to securely integrate, migrate, and modernize their complex, multi-cloud, multi-vendor DevOps environments leveraging our partnerships with industry leaders like: Atlassian, CloudBees, GitHub, GitLab, Sonatype and Jenkins. iTMethods helps companies build better software, faster and more securely. We play a critical role in helping organizations capitalize on their growth opportunities by using DevOps to accelerate their pace of innovation.
We're a Canadian company with headquartersin Toronto and havea flexible work policy that willallowus to grow our team remotely. We offer the excitement and agility of a start-up and the security of a profitable, well-established company serving fortune 500 clients.Every day, everyone at iTMstrives to be an active part of the best DevOps platform and delivery teams our clients have ever worked with. We ask for your ideas, expertise, and commitment. In return, we give you access to intelligent people, an opportunity to further your knowledge, and the chance to build innovation for the real world.
The Opportunity
Reporting to the Director of Platform Operations, we are adding a Cloud Operations Engineer to the team. In this position, you will play a critical role in eliminating vulnerabilities and optimizing uptime for our enterprise clients by implementing resilient and robust solutions leveraging automation for fault detection and a laser focus on automatically recovering when a fault is detected and continuously looking to deploy solutions which avoid previously identified faults from being generated.
Responsibilities
Address root causes and identify solutions. You will focus on problem-solving, automation, and ensuring a sustained focus on engineering. You will:
Architect and implement monitoring alarms and logging solutions
Identify issues proactively, and mitigate them to improve the customer experience
Audit, test, and review solutions to ensure we deliver a resilient, monitored, highly secure, and complete solution
Demand forecasting and capacity planning. You will create and maintain good visibility of the demand for AWS resources, planning, and usage. You will plan and execute efficient use of resources
Optimize through automation. You will eliminate manual, repetitive, tactical solutions with no enduring value. You will implement automation for a more sustained and scalable solution, services, and processes, contributing to the continuous improvement of all operations to efficiently manage and maintain deployments
Plan and deploy upgrade, configuration changes and security patches
Drive continuous improvement. You will research and implement best practices in DevOps. You will explore and evaluate new and emerging software tools and technologies
Be on call on a rotation basis
Take ownership of not only your deliverables but the platform and drive resiliency on the platform as per an SRE mindset
Be hands-on. You will:
Assist in the configuration and support of customer environments
Code deployments, optimization, and various tools
Troubleshoot and resolve escalated software and infrastructure-related issues and challenges, acting as a customer-facing escalation point
Review new tools and software prior to implementation
Qualifications
Education/qualifications and experience You have a Bachelor's Degree in Computer Science, Computer Engineering, Software Engineering, and preferably certification in AWS, Ansible and Terraform and have worked on DevOps tools Git and Jenkins
Exceptional communication and problem solving skills
Have worked with collaboration tools like Jira, Confluence and Jira ServiceDesk
You’re driven, collaborative and motivated.You thrive on developing solutions to open-ended business problems
Ability to write code
Passion for automation and efficiency
Ability to work autonomously and as part of a team
Our Commitment to You
Flexible work environment
Competitive compensation and benefits package
Learning and Development
Career Progression
Culture – One team environment founded on respect and collaboration where we do not take shortcuts and are customer obsessed
Join us
Apply here or learn more on ourwebsite,MediumorLinkedIn.
iTMethods is committed to fostering an inclusive and accessible environment where employees feel valued and respected, and where every employee has the opportunity to realize their potential. We are committed to providing reasonable accommodations, if required, and will work with you to meet your needs.
Powered by JazzHR
f1Au1Ufnr4","{""role_summary"":""The Cloud Operations Engineer is responsible for ensuring the uptime and security of our enterprise clients' DevOps environments by implementing resilient and robust solutions, leveraging automation for fault detection and recovery."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""SaaS Platform"",""explanation"":""A software as a service platform that enables global enterprises to securely integrate, migrate, and modernize their complex DevOps environments.""},{""term"":""Automation"",""explanation"":""The use of technology to perform tasks without human intervention, increasing efficiency and reducing manual errors.""},{""term"":""SRE mindset"",""explanation"":""A set of principles and practices that focuses on ensuring the reliability and efficiency of software systems, with an emphasis on automation and continuous improvement.""}],""skill_priorities"":{""must_have"":[""AWS"",""Ansible"",""Terraform"",""Git"",""Jenkins"",""Automation"",""Problem-solving skills"",""Communication skills""],""nice_to_have"":[""Jira"",""Confluence"",""Jira ServiceDesk"",""CloudBees"",""GitHub"",""Sonatype""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach identifying and mitigating potential vulnerabilities in a DevOps environment?"",""example_answer"":""I would use a combination of monitoring tools and automation to detect potential issues, and then implement solutions to mitigate them. I would also focus on continuous improvement, researching and implementing best practices in DevOps.""},{""question"":""Can you give an example of a time when you had to troubleshoot and resolve a complex technical issue?"",""example_answer"":""In my previous role, I encountered an issue with a code deployment that was causing errors. I used my problem-solving skills to identify the root cause, and then worked with the team to implement a solution. I also automated the process to prevent similar issues in the future.""}],""red_flags"":[""Lack of experience with AWS, Ansible, and Terraform"",""Inability to write code"",""Poor communication and problem-solving skills""],""confidence_score"":90.0}"
DevOps Engineer,"As our DevOps Engineer, you will be helping us build and maintain blockchain networks and protocols. You will work on improving our current infrastructure including security, automation, and monitoring among other things. You will also have the chance to dive deep into new blockchain protocols, run testnets, build secure and scalable infra and maintain it.

What will you do?

Build secure and reliable infrastructure to monitor, detect and mitigate performance and security issues
System administration activities for Linux servers, which includes routine, proactive daily management of the health, stability, and availability of system infrastructure
Create and maintain system procedural and technical documentation
Stay up to date and build on peer-to-peer networking security best practices
Create, maintain and communicate threat models + risk assessments for all systems we operate

What excites us about you?

You have experience as DevOps/SRE/Infrastructure engineer
You have the ability to program in one or more languages like Python, GoLang, Bash or Javascript
You have experience managing server infrastructures with high availability requirements
You had designed secure networks, systems, and application architectures
You had set up and maintained software in both data centers and cloud environments
You have a deep understanding of sockets, full networking stack, and Linux security
You possess the knowledge of building automation and CI/CD processes and tools
You are experienced with Docker, Kubernetes, and other cloud deployment technologies
You have flexibility, teamwork, and you are comfortable with ambiguity, able to take charge and get things done despite the unknowns

What will be great to have?

You have an understanding of the blockchain space and blockchain technology
You possess knowledge of cryptography and security best practices
You have contributions to open source communities

If those describe you, this is the right opportunity for you!

Why are we awesome you ask?

We are truly at the forefront of the crypto ecosystem as maintainers of the infrastructure layer of blockchain networks! We practice the crypto team mentality by assembling a truly global and diverse team.

We collectively represent more than 12 different countries and are united in a single mission: building out the future of decentralization. Crypto is here to stay, having introduced novel ideas such as DeFi, NFTs and DAOs. At the core of all this are teams like us working relentlessly to build the necessary tools and applications that help run and secure blockchains.

Here are some other reasons you should join us:

We have employees from over 10 countries across the globe, and you will be able to meet interesting people from different backgrounds and cultures. Distributed and remote work is baked into our culture
We are one of the top staking service providers with over $3B of assets staked across our validators. We actively explore and develop new products related to staking. You will work on high-impact engineering projects building exciting new products in a startup environment
We have a capable and passionate team. You will find teammates who are power DeFi users, intense NFT collectors, Bitcoin & Ethereum knowledge nerds, etc. You can learn and debate everything on crypto with our teammates
We are not backed by VC funding, and we are already profitable. Our financial independence means that we can make decisions independent of VCs, and we prioritize our ideals of decentralization, user sovereignty, and user privacy over simply making a profit. It also means that, unlike most other startups, stakefish can provide you with a stable low-risk employment opportunity without fundraising concerns","{""role_summary"":""As a DevOps Engineer, you will build and maintain blockchain networks and protocols, improving infrastructure security, automation, and monitoring, and diving into new blockchain protocols."",""key_terms"":[{""term"":""Blockchain protocols"",""explanation"":""Decentralized systems that enable secure, transparent, and tamper-proof data exchange and storage.""},{""term"":""Testnets"",""explanation"":""Experimental blockchain networks used for testing and development before deploying on the main network.""},{""term"":""CI/CD processes"",""explanation"":""Continuous Integration and Continuous Deployment processes that automate testing, building, and deployment of software applications.""},{""term"":""Docker"",""explanation"":""A containerization platform that enables packaging, shipping, and running applications in isolated environments.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system that automates deployment, scaling, and management of containerized applications.""}],""skill_priorities"":{""must_have"":[""Experience as DevOps/SRE/Infrastructure engineer"",""Programming skills in Python, GoLang, Bash, or Javascript"",""Experience managing server infrastructures with high availability requirements"",""Knowledge of sockets, full networking stack, and Linux security"",""Experience with Docker, Kubernetes, and other cloud deployment technologies""],""nice_to_have"":[""Understanding of the blockchain space and blockchain technology"",""Knowledge of cryptography and security best practices"",""Contributions to open source communities""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure high availability and scalability in your infrastructure design?"",""example_answer"":""I use load balancing, auto-scaling, and containerization to ensure high availability and scalability in my infrastructure design.""},{""question"":""Can you explain the importance of threat modeling and risk assessments in DevOps?"",""example_answer"":""Threat modeling and risk assessments help identify potential security vulnerabilities and prioritize mitigation efforts, ensuring the security and integrity of our systems.""}],""red_flags"":[""Lack of experience with blockchain technology"",""Inability to work with ambiguity and uncertainty"",""Limited knowledge of Linux security and networking""],""confidence_score"":90.0}"
DevOps Engineer (Entry level),"DevOps Engineer

Hybrid Position - Minneapolis or Toronto only!

The DevOps Enablement Team at Thomson Reuters is responsible for delivering comprehensive DevOps solutions to the company's technology teams.

As a DevOps Engineer, you will play a crucial role in advancing infrastructure and processes with a focus on automation, reliability, and efficiency.

This involves working closely with development and operations teams to architect, implement, and maintain scalable and resilient systems, leveraging the latest in cloud technologies and DevOps practices.

About the Role:

In this opportunity, as a DevOps Engineer, you will:

Turn new requirements into code, including unit testing, deployment, and ongoing monitoring.
Work with team members through practices and tools enablement including a focus on automation and defining new ways of working, along with a modern development toolset.
Partner with delivery teams through a DevOps transformation of the product lifecycle from requirements definition, through development, and operations.
Collaborate with peers to identify priorities for enablement measured by an increase in developer efficiency.
Drive innovation with a willingness to explore and learn AI technologies, applying them to enhance DevOps solutions and processes.


About You:

This role is designed for individuals who are passionate about leveraging cutting-edge technologies to drive efficiency and innovation within our DevOps & Cloud automation practices.

If you have a proactive mindset, a passion for learning, and a desire to work in a dynamic, collaborative environment, we encourage you to apply.

Here are the skillsets required:

1-2 years of experience with public cloud (AWS, Azure) and strong Automation experience with Python, Bash, PowerShell etc - Must have
Understand and build automated tests to fit into the bigger picture of software delivery for building CI/CD pipelines, optimizing the execution of tests, and ensuring that the tests are regularly providing fast and reliable feedback.
Demonstrated proficiency in utilizing public cloud platforms (AWS/Azure/OCI)
Experience with Generative AI, AI assisted Developer tools like GitHub CoPilot, AWS Code Whisperer etc.


What’s in it For You?

Join us to inform the way forward with the latest AI solutions and address real-world challenges in legal, tax, compliance, and news. Backed by our commitment to continuous learning and market-leading benefits, you’ll be prepared to grow, lead, and thrive in an AI-enabled future. This includes:

Industry-Leading Benefits: We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.
Flexibility & Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, and hybrid model, empowering employees to achieve a better work-life balance.
Career Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow’s challenges and deliver real-world solutions. Our skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.
Culture: Globally recognized and award-winning reputation for inclusion, innovation, and customer-focus. Our eleven business resource groups nurture our culture of belonging across the diverse backgrounds and experiences represented across our global footprint.
Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.
Social Impact: Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives.


In the United States, Thomson Reuters offers a comprehensive benefits package to our employees. Our benefit package includes market competitive health, dental, vision, disability, and life insurance programs, as well as a competitive 401k plan with company match. In addition, Thomson Reuters offers market leading work life benefits with competitive vacation, sick and safe paid time off, paid holidays (including two company mental health days off), parental leave, sabbatical leave. These benefits meet or exceeds the requirements of paid time off in accordance with any applicable state or municipal laws. Finally, Thomson Reuters offers the following additional benefits: optional hospital, accident and sickness insurance paid 100% by the employee; optional life and AD&D insurance paid 100% by the employee; Flexible Spending and Health Savings Accounts; fitness reimbursement; access to Employee Assistance Program; Group Legal Identity Theft Protection benefit paid 100% by employee; access to 529 Plan; commuter benefits; Adoption & Surrogacy Assistance; Tuition Reimbursement; and access to Employee Stock Purchase Plan.

Thomson Reuters complies with local laws that require upfront disclosure of the expected pay range for a position. The base compensation range varies across locations.

For any eligible US locations, unless otherwise noted, the base compensation range for this role is $70,000 - $130,000.

This role may also be eligible for an Annual Bonus based on a combination of enterprise and individual performance.

Base pay is positioned within the range based on several factors including an individual’s knowledge, skills and experience with consideration given to internal equity. Base pay is one part of a comprehensive Total Reward program which also includes flexible and supportive benefits and other wellbeing programs.

Do you want to be part of a team helping re-invent the way knowledge professionals work? How about a team that works every day to create a more transparent, just and inclusive future? At Thomson Reuters, we’ve been doing just that for almost 160 years. Our industry-leading products and services include highly specialized information-enabled software and tools for legal, tax, accounting and compliance professionals combined with the world’s most global news services – Reuters. We help these professionals do their jobs better, creating more time for them to focus on the things that matter most: advising, advocating, negotiating, governing and informing.

We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments that celebrate diversity and inclusion. At a time when objectivity, accuracy, fairness and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward.

Accessibility

As a global business, we rely on diversity of culture and thought to deliver on our goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity/Affirmative Action Employer providing a drug-free workplace.

We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law.

Protect yourself from fraudulent job postings click here to know more.

More information about Thomson Reuters can be found on https://thomsonreuters.com.","{""role_summary"":""As a DevOps Engineer, you will advance infrastructure and processes with a focus on automation, reliability, and efficiency, working closely with development and operations teams to architect, implement, and maintain scalable and resilient systems."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""Cloud Technologies"",""explanation"":""On-demand access to a shared pool of computing resources, such as servers, storage, and applications, over the internet.""},{""term"":""Automation"",""explanation"":""The use of technology to perform tasks without human intervention, increasing efficiency and reducing errors.""},{""term"":""CI/CD Pipelines"",""explanation"":""A series of automated processes that integrate code changes into a larger system, ensuring continuous integration and delivery.""},{""term"":""Generative AI"",""explanation"":""A type of artificial intelligence that generates new content, such as code or text, based on patterns and algorithms.""}],""skill_priorities"":{""must_have"":[""Public cloud experience (AWS, Azure)"",""Automation experience with Python, Bash, PowerShell"",""Understanding of automated tests and CI/CD pipelines""],""nice_to_have"":[""Experience with Generative AI, AI-assisted developer tools""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach automating testing and deployment in a DevOps environment?"",""example_answer"":""I use a combination of tools like Jenkins, Docker, and Kubernetes to automate testing and deployment, ensuring efficient and reliable delivery of software applications.""},{""question"":""Can you explain how you would optimize the execution of tests in a CI/CD pipeline?"",""example_answer"":""I would use techniques like parallel testing, test prioritization, and caching to optimize the execution of tests, reducing the overall testing time and improving feedback loops.""}],""red_flags"":[""Lack of experience with public cloud platforms"",""Inability to explain the importance of automation in DevOps""],""confidence_score"":90.0}"
SRE / DevOps Engineer,"Canada / Remote

6+ Months Contract

Position Requirements

Collaborate closely with Development teams to improve services and operational targets.
Implement and maintain CI/CD practices using tools like Sonar.
Manage application integration and monitoring using DataDog, SumoLogic, and alert systems like MS Teams.
Identify vulnerabilities using tools like JFrog Xray and Veracode.
Design infrastructure automation and deployment systems with Docker/Kubernetes.
Improve system reliability through telemetry and security best practices in cloud deployments.

Required Skills & Experience

Overall 8+ years experience in DevOps
2+ years with AWS (EC2, S3, Lambda, etc.).
5+ years with Windows, Linux, IIS/.NET, and Java.
Strong Git, Jenkins/Bamboo, APM, and telemetry knowledge.
Experience with Chef, Puppet, Ansible, and scripting (PowerShell, Python, Bash).
Expertise in cloud security, networking, storage, and DNS.
Excellent communication, problem-solving, and collaboration skills.
Familiarity with Agile methodologies.

Preferred: Bachelor's Degree in Computer Science or equivalent experience.","{""role_summary"":""Work closely with development teams to improve services and operational targets by implementing and maintaining CI/CD practices, managing application integration and monitoring, identifying vulnerabilities, and designing infrastructure automation and deployment systems."",""key_terms"":[{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a practice that automates testing, building, and deployment of software applications.""},{""term"":""Sonar"",""explanation"":""A tool used for continuous code quality inspection and reporting.""},{""term"":""DataDog"",""explanation"":""A monitoring and analytics platform used to track application performance and identify issues.""},{""term"":""SumoLogic"",""explanation"":""A cloud-based log analysis and monitoring platform used to track application performance and identify issues.""},{""term"":""JFrog Xray"",""explanation"":""A tool used to identify vulnerabilities in software applications.""},{""term"":""Veracode"",""explanation"":""A tool used to identify vulnerabilities in software applications.""},{""term"":""Docker/Kubernetes"",""explanation"":""Containerization tools used to automate deployment, scaling, and management of applications.""},{""term"":""Telemetry"",""explanation"":""The process of collecting and transmitting data from remote sources to monitor and analyze system performance.""},{""term"":""Agile methodologies"",""explanation"":""Iterative and incremental approach to project management and software development.""}],""skill_priorities"":{""must_have"":[""DevOps"",""AWS"",""Windows"",""Linux"",""IIS/.NET"",""Java"",""Git"",""Jenkins/Bamboo"",""APM"",""Telemetry"",""Chef"",""Puppet"",""Ansible"",""Scripting (PowerShell, Python, Bash)"",""Cloud security"",""Networking"",""Storage"",""DNS""],""nice_to_have"":[""Bachelor's Degree in Computer Science or equivalent experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you implement CI/CD practices in a DevOps environment?"",""example_answer"":""I use tools like Jenkins and Git to automate testing, building, and deployment of software applications, ensuring continuous integration and delivery.""},{""question"":""How do you identify and mitigate vulnerabilities in software applications?"",""example_answer"":""I use tools like JFrog Xray and Veracode to identify vulnerabilities, and then implement security best practices and patches to mitigate them.""},{""question"":""How do you design infrastructure automation and deployment systems?"",""example_answer"":""I use containerization tools like Docker and Kubernetes to automate deployment, scaling, and management of applications, ensuring efficient use of resources.""}],""red_flags"":[""Lack of experience with AWS or cloud security"",""Inability to work collaboratively with development teams""],""confidence_score"":90.0}"
(f2pool) DevOps Engineer,"As our DevOps Engineer, you will be helping us build and maintain blockchain networks and protocols. You will work on improving our current infrastructure including security, automation, and monitoring among other things. You will also have the chance to dive deep into new blockchain protocols, run testnets, build secure and scalable infra and maintain it.

What will you do?

Build secure and reliable infrastructure to monitor, detect and mitigate performance and security issues
System administration activities for Linux servers, which includes routine, proactive daily management of the health, stability, and availability of system infrastructure
Create and maintain system procedural and technical documentation
Stay up to date and build on peer-to-peer networking security best practices
Create, maintain and communicate threat models + risk assessments for all systems we operate

What excites us about you?

You have experience as DevOps/SRE/Infrastructure engineer
You have the ability to program in one or more languages like Python, GoLang, Bash or Javascript
You have experience managing server infrastructures with high availability requirements
You had designed secure networks, systems, and application architectures
You had set up and maintained software in both data centers and cloud environments
You have a deep understanding of sockets, full networking stack, and Linux security
You possess the knowledge of building automation and CI/CD processes and tools
You are experienced with Docker, Kubernetes, and other cloud deployment technologies
You have flexibility, teamwork, and you are comfortable with ambiguity, able to take charge and get things done despite the unknowns

What will be great to have?

You have an understanding of the blockchain space and blockchain technology
You possess knowledge of cryptography and security best practices
You have contributions to open source communities

If those describe you, this is the right opportunity for you!

Why are we awesome you ask?

We are a truly global team! We are digital nomads coming from more than 12 different countries, working from wherever we want. We have a collective mission, to provide meaningful services and bring a unique value to users within the crypto space.

We are looking for fun, curious, and committed individuals to swim with us!

Requirements

A BSc/BA degree in Computer Science or a relevant field","{""role_summary"":""The DevOps Engineer will build and maintain blockchain networks and protocols, improving infrastructure security, automation, and monitoring, and ensuring system reliability and scalability."",""key_terms"":[{""term"":""Blockchain"",""explanation"":""A decentralized, distributed ledger technology used for secure and transparent data storage and transfer.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a set of practices that automate and streamline the build, test, and deployment of software applications.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""Testnets"",""explanation"":""A testing environment for blockchain networks, allowing developers to test and refine their applications before deploying them on the main network.""}],""skill_priorities"":{""must_have"":[""DevOps/SRE/Infrastructure engineering experience"",""Programming skills in languages like Python, GoLang, Bash, or Javascript"",""Experience with high-availability server infrastructures"",""Knowledge of Linux security and networking"",""Experience with Docker and cloud deployment technologies""],""nice_to_have"":[""Understanding of blockchain technology and space"",""Knowledge of cryptography and security best practices"",""Contributions to open-source communities""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure the security and scalability of a blockchain network?"",""example_answer"":""I would implement robust access controls, encryption, and monitoring tools to prevent unauthorized access and detect potential security threats. I would also design the network architecture to scale horizontally and vertically to handle increased traffic and user demand.""},{""question"":""Can you explain your experience with CI/CD pipelines and how you've used them to improve deployment efficiency?"",""example_answer"":""In my previous role, I set up a CI/CD pipeline using Jenkins and Docker, which automated the build, test, and deployment process for our application. This reduced deployment time by 50% and improved code quality by 30%.""}],""red_flags"":[""Lack of experience with blockchain technology and security best practices"",""Inability to work with ambiguity and uncertainty in a fast-paced environment""],""confidence_score"":85.0}"
DevOps/SecOps Engineer,"As one of Canada's largest and fastest growing cryptocurrency trading platforms, NDAX has set the bar high for the country's fintech industry and is constantly leading the way in terms of security and innovation. We're on a mission to empower more Canadians to unlock the full potential of digital finance. To address the various needs in the Canadian cryptocurrency space, NDAX has assembled a multidisciplinary team with diverse backgrounds, including finance, technology, engineering, compliance, marketing, and more.

We're proud to have been recognized as one of Canada's Best Workplaces by Great Place to Work®.

NDAX is currently looking to hire a DevOps / SecOps engineer. As a DevOps / SecOps engineer, your responsibilities will include supporting the team in developing current products and in launching products in the pipeline. Using your experience, you will ensure the integrity of our system and support with the developing our technical foundations and system security.

Requirements

Possess extensive knowledge of networking, infrastructure, and applications through a DevOps lens, with a strong emphasis on security
Be a versatile technologist with a knack for swiftly learning and utilizing various technologies, particularly cloud platforms and protective monitoring systems
Demonstrate software development and scripting expertise
Have a comprehensive understanding of security control techniques applicable to both traditional IT environments and cloud-based systems
Have a deep understanding of technical attack methods and their detection in digital landscapes
Be equipped to assess and analyze diverse information to derive conclusions for enhancing system security
Stay informed about information security concepts, along with the latest trends and principles in IT security, data protection, and information risk management.
Posses deep knowledge of security monitoring, prevention and control systems including anti-virus, web proxies and security software


Responsibilities

Execute automation strategies, robust monitoring, and infrastructure-as-code methodologies
Manage and enhance essential applications within a dynamic cloud-native microservices framework
Implement and oversee CI/CD pipelines across diverse environments
Collaborate with a cross-functional engineering team, exploring cutting-edge technologies
Continuously refine best practices to boost deployment quality and speed
Promote and enhance the culture of knowledge sharing within the engineering team
Participate in a rotating on-call schedule with the engineering team
Effectively communicate risks in a nuanced way to support informed business decisions


Benefits

Supercharged Health Plan: Coverage for medical, disability, dental, and vision!
Chill Time: Paid time off plus 2 personal days just for you!
Level Up: Training and development opportunities to boost your skills!
Extra Goodies: Bonuses, awards, and surprise gifts!
Future Investment: Stock option plan to share in the company's success!
Amazing Team: Work with great people and be part of an awesome team!","{""role_summary"":""Support the development of current and pipeline products as a DevOps/SecOps engineer, ensuring system integrity and security while promoting knowledge sharing within the engineering team."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""SecOps"",""explanation"":""A practice that integrates security into DevOps to ensure the secure operation of software systems.""},{""term"":""Cloud-native microservices framework"",""explanation"":""An architecture that builds applications as a collection of small, independent services that can be developed, deployed, and scaled independently.""},{""term"":""CI/CD pipelines"",""explanation"":""A set of practices that automates the build, test, and deployment of software applications to improve efficiency and quality.""},{""term"":""Infrastructure-as-code"",""explanation"":""A practice that manages and provisions infrastructure resources through code and configuration files.""}],""skill_priorities"":{""must_have"":[""DevOps"",""SecOps"",""Cloud platforms"",""Security monitoring"",""Scripting expertise""],""nice_to_have"":[""Knowledge of security control techniques"",""Understanding of technical attack methods"",""Experience with protective monitoring systems""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure the integrity of a system in a cloud-native microservices framework?"",""example_answer"":""I would implement robust monitoring and infrastructure-as-code methodologies to ensure the system's integrity and security.""},{""question"":""Can you explain how you would assess and analyze diverse information to derive conclusions for enhancing system security?"",""example_answer"":""I would use my knowledge of security control techniques and technical attack methods to analyze the information and identify potential security risks, then develop strategies to mitigate those risks.""}],""red_flags"":[""Lack of experience with cloud platforms"",""Inability to communicate technical risks effectively""],""confidence_score"":90.0}"
Cloud Engineer,"Requisition ID: 206977

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture. Scotiabank has embarked on the journey to modernize both development practices and tools. One of the main areas of transformation is the public cloud and the various platform technologies that support both development and operations on the cloud. The aim is to provide a streamlined process and framework which will allow the development teams to focus on building business logic. We are looking to build our development team with influencer, makers, creators, and industry leaders who will drive us forward.

The role of the Cloud Engineer operates within the Cloud File Storage Engineering team. This valuable member of the team will be responsible for creating platform components and services for the broad enterprise use.

Is this role right for you? In this role, you will:

Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems, and knowledge.
Key accountabilities include development and maintenance of cloud platforms, services, and components to enable safe enterprise-wide use of public cloud offerings
Knowledge of a component of a larger product.
Assisting in implementing, and refactoring code.
Assisting in ensuring software, programs and applications are developed and/or configured to meet high availability, integrity and reliability, security, and compliance requirements.
Working with other engineers and architects on breaking-down, scoping and estimating tasks.
Working with application teams for successful onboarding onto the Platform
Participating in planning and retrospective sessions, attending stand-ups, etc.
Be able to build and operate the highly available and scalable software and infrastructure.

Skills

Do you have the skills that will enable you to succeed in this role? We'd love to work with you if you have:

3+ years of experience with Google Cloud Platform (GCP)
3+ years of experience with Cloud Managed Development/Services such as Google Cloud Storage
3+ years of experience in using Infrastructure as Code tooling Like Terraform.
3+ years of experience with development languages (Go, Python, etc)
3+ years of experience with container-based technologies (Docker, Kubernetes)
3+ years of experience in the use of CI/CD Tools
3+ years of experience with config management tools and Scripting Languages (Ansible, Bash, Groovy)
Good oral and written communication skills

Nice To Have

Bachelor (equivalent or higher) degree in computer science or engineering/mathematics discipline.
Understanding of Cloud Native Platforms, particularly Kubernetes, and associated technologies (e.g., Istio, Envoy, Anthos, Kustomize).
Experience working with monitoring tools such as Dynatrace, Prometheus, Grafana, etc.
Understanding of software development lifecycle and release process (container-native workflow for job orchestration, Git/GitOps, CI/CD, environments, code repositories).
Understanding of different database technologies (e.g. CloudSQL, NoSQL, Relational databases)
Focus on scalable, enterprise-level software system design (both on code and infrastructure levels)
Passion for driving teams towards high performance and a deep pride in quality craftsmanship.
Unix administration skills.

What's in it for you?

Diversity, Equity, Inclusion & Allyship - We strive to create an inclusive culture where every employee is empowered to reach their fullest potential, respected for who they are, and are embraced through bias-free practices and inclusive values across Scotiabank. We embrace diversity and provide opportunities for all employee to learn, grow & participate through our various Employee Resource Groups (ERGs) that span across diverse gender identities, ethnicity, race, age, ability & veterans.
Accessibility and Workplace Accommodations - We value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. Scotiabank continues to locate, remove and prevent barriers so that we can build a diverse and inclusive environment while meeting accessibility requirements.
Upskilling through online courses, cross-functional development opportunities, and tuition assistance.
Competitive Rewards program including bonus, flexible vacation, personal, sick days and benefits will start on day one.
Community Engagement - no matter where you choose to work from; we offer opportunities for community engagement & belonging with our various programs such as hackathons, contests, cooking with friends, Humans of Digital and much more!

Work arrangements: Hybrid

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","{""role_summary"":""The Cloud Engineer role is responsible for creating platform components and services for the broad enterprise use, focusing on public cloud offerings and ensuring high availability, integrity, and reliability."",""key_terms"":[{""term"":""Google Cloud Platform (GCP)"",""explanation"":""A cloud computing platform provided by Google that enables users to build, deploy, and manage applications and workloads.""},{""term"":""Infrastructure as Code (IaC) tooling"",""explanation"":""A practice that involves managing and provisioning infrastructure resources through code and configuration files, rather than through graphical user interfaces.""},{""term"":""Container-based technologies"",""explanation"":""Technologies that enable packaging, shipping, and running applications in containers, such as Docker and Kubernetes.""},{""term"":""CI/CD Tools"",""explanation"":""Tools that automate the build, test, and deployment of software applications, such as Jenkins and GitLab CI/CD.""},{""term"":""Cloud Native Platforms"",""explanation"":""Platforms that are designed to take advantage of cloud computing principles, such as scalability, flexibility, and on-demand resources.""}],""skill_priorities"":{""must_have"":[""3+ years of experience with Google Cloud Platform (GCP)"",""3+ years of experience with Cloud Managed Development/Services"",""3+ years of experience with Infrastructure as Code tooling"",""3+ years of experience with development languages"",""3+ years of experience with container-based technologies"",""3+ years of experience with CI/CD Tools""],""nice_to_have"":[""Bachelor's degree in computer science or engineering/mathematics discipline"",""Understanding of Cloud Native Platforms"",""Experience with monitoring tools"",""Understanding of software development lifecycle and release process"",""Understanding of different database technologies"",""Focus on scalable, enterprise-level software system design"",""Passion for driving teams towards high performance"",""Unix administration skills""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure high availability and scalability in cloud-based applications?"",""example_answer"":""I use Infrastructure as Code tooling like Terraform to manage and provision infrastructure resources, and container-based technologies like Docker and Kubernetes to ensure scalability and high availability.""},{""question"":""Can you explain your experience with CI/CD tools and how you've used them to automate the build, test, and deployment of software applications?"",""example_answer"":""I've used Jenkins and GitLab CI/CD to automate the build, test, and deployment of software applications, ensuring faster time-to-market and improved quality.""}],""red_flags"":[""Lack of experience with Google Cloud Platform (GCP)"",""Inability to work with container-based technologies"",""Limited understanding of CI/CD tools and automation""],""confidence_score"":90.0}"
DevOps and Cloud Engineer,"DevOps and Cloud Engineer

Purpose

Our customers demand the highest quality and reliability for their services and we look for innovative ways to meet that demand through product development and innovation. Our cloud presence and cloud management systems are a key component to providing world-class customer experiences via solution engagements or self-serve portals by conveying the optimal data to feed process automation workflows, and business analytics in the most efficient, resilient and scalable manner. Operational efficiencies are critical to the white-glove treatment CentriLogic strives to maintain. To that end, customer facing and internal systems must offer self-serve capabilities, single pane of glass experiences, optimize transactions and automate repeatable processes.

The ideal candidate will be an experienced cloud DevOps engineer with strong experience on Azure and CI/CD.

This position reports to Head of DevOps practice and it can be based in any one of our GTA locations but is expected to travel as needed.

Primary Responsibilities

• Providing thought leadership on both process and technical matters; become a real champion and trusted advisor to our clients on all facets Continuous Delivery
• Designing and enabling automated delivery strategies for core bet-the-company applications – on premises and in the cloud
• Assisting production teams to understand the new paradigm of infrastructure-as-code
• Mentoring and educating development teams to keep them up to speed with the latest approaches, tools and skills

Skills

• Code and configure CI/CD in public cloud setting
• Firm grasp of internet, cloud and network security concepts
• Containerization and orchestration
• Understanding of distributed systems and microservices architecture
• Extensive experience with infrastructure as code provisioning (PowerShell/Bash Scripting/Terraform/Ansible/Salt)
• Experience with Azure and AWS
• Experience with SCM Tools like GitHub

Qualifications

• Source Control expertise (Git/TFS/Subversion)
• Experience with public cloud (Azure preferred)
• Strict adherence to process and procedures
• Understanding and hands on expertise with the SDLC lifecycle
• Experience with different deployment tools – Azure DevOps, Github, GitLab, Jenkins
• Languages: Terraform, Powershell, Bash, Bicep, Ansible, Salt
• 3+ years of experience with CI/CD Pipelines (Azure DevOps/Github, Jenkins, Git)
• 1+ years of experience with Containers and orchestration (Docker Swarm/Kubernetes) in a production environment
• Experience working in an Agile environment
• Excellent communication skills, both oral and written
• Mastery of design patterns and anti-patterns
• Strong analytical and troubleshooting skills
• Superior oral/written communication and time management skills
• Ability to work in a high growth, fast paced environment

Desirable

• Recent public cloud (Azure and/or AWS) certifications
• Maintenance of Industry certifications
• Skills in Windows and Unix environments a plus","{""role_summary"":""Design and implement cloud-based solutions, ensuring efficient, resilient, and scalable systems for customer-facing and internal systems, while providing thought leadership and mentoring to development teams."",""key_terms"":[{""term"":""Infrastructure-as-code"",""explanation"":""A practice of managing and provisioning infrastructure through code and configuration files, rather than through graphical user interfaces.""},{""term"":""Containerization"",""explanation"":""A method of packaging software applications and their dependencies into a single container that can be run consistently across different environments.""},{""term"":""Microservices architecture"",""explanation"":""A software development approach that structures an application as a collection of small, independent services that communicate with each other.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a practice of automating the build, test, and deployment of software applications to improve efficiency and reliability.""}],""skill_priorities"":{""must_have"":[""Azure experience"",""CI/CD experience"",""Infrastructure as code provisioning"",""Containerization and orchestration"",""Distributed systems and microservices architecture""],""nice_to_have"":[""AWS experience"",""Public cloud certifications"",""Windows and Unix environments skills""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a CI/CD pipeline for a cloud-based application?"",""example_answer"":""I would use Azure DevOps to create a pipeline that automates the build, test, and deployment of the application, leveraging infrastructure as code provisioning and containerization.""},{""question"":""What are some best practices for implementing infrastructure as code?"",""example_answer"":""I would use version control systems like Git to manage infrastructure code, and tools like Terraform to provision and manage infrastructure resources.""}],""red_flags"":[""Lack of experience with Azure or CI/CD"",""Inability to explain infrastructure as code concepts"",""No experience with containerization and orchestration""],""confidence_score"":90.0}"
Senior Devops Engineer,"Join a Challenger

Being a traditional bank just isn’t our thing. We are big believers in innovating the banking experience because we believe Canadians deserve better options, and we challenge ourselves and our teams to creatively transform what’s possible in banking. Our team is made up of inquisitive and agile minds that find smarter ways of doing things. If you’re not afraid of taking on big challenges and redefining the future, you belong with us. You’ll get to work with people who will encourage you to reach new heights. We like to keep things fun, ask questions and learn together.

We are a big (and growing!) family. Overall we serve more than 670,000 people across Canada through Equitable Bank, Canada's Challenger Bank™, and have been around for more than 50 years. Equitable Bank's wholly-owned subsidiary, Concentra Bank, supports credit unions across Canada that serve more than six million members. Together we have over $125 billion in combined assets under management and administration, with a clear mandate to drive change in Canadian banking to enrich people's lives. Our customers have named our EQ Bank digital platform (eqbank.ca) one of the top banks in Canada on the Forbes World's Best Banks list since 2021.

Purpose of Job

EQ Bank’s IT team is starting to evolve and Needs a talented Senior DevOps Engineer with a solid passion in this space. Experienced and knowledgeable about the end to end software build chain, operations and automated build and release process.

Main Activities

Design, improve and implement build and release pipelines
Provide subject matter expertise to developers and testers on the current and future technology of DevOps tools chain
Work and collaborate with the larger team to exchange knowledge, solutions and practices to build a more consistent, robust approach to development approaches
Research and analyze existing and emerging technologies to identify products, tools to support the DevOps team
Continuously improve performance and proactively identify and resolve bottlenecks that will reduce time to build and deliver our software
Build and Maintain high availability Continuous Integration/Continuous Delivery infrastructure
Engage as a lead in DevOps capacity planning, software performance analysis and system tuning
Review and provide feedback on product functional specifications, design specifications
Perform formal Code Review, static and security analysis, design and implement Unit Tests and perform code coverage analysis



Knowledge/Skill Requirements

Subject Matter expert with minimum 5 years’ experience in Continuous Integration and Continuous Deployment orchestration
Champion cloud deployments to Azure, AWS or GCP - 2 year solid hands-on experience
Expertise in platform as a service using Pivotal CF or IBM Bluemix - 2+ year experience
Good trouble shooting skills and practical usage of various source control systems (Git, SVN) - 5+ years of experience
Solid understanding of Software Delivery Lifecycle
Good to have SecOps experience
Architecture and design understanding behind containers and work with Docker, Kubernetes or similar technologies - 3+ years of experience
Working knowledge of programming/scripting in one or more of the following languages: Java, C, C++, groovy, Python, Shell
Bachelor's degree or equivalent in the field of Computer Science, Systems or Engineering
Five or more years of similar professional experience



Job Complexities / Thinking Challenges:

Strong organizational skills; demonstrated ability to manage time and adhere to tight deadlines
Must be flexible to adapt to a dynamic environment, make quick and sound decisions under pressure
Ability to communicate technical information and ideas effectively
Must be reliable, proactive, results-oriented, and attentive to details
Ability to design high quality, scalable and supportable technology solutions that could be re-used by other areas of the bank
Team player who mentors and helps fellow team members whenever required
Self-starter who is able to work independently and lead a team if required
Ability to prioritize assignments, projects and handle multiple competing priorities (multi-tasking) within restricted time constraints
Problem solver with sound judgment who takes initiative, accepts ownership and accountability
Ability to help the team in interviewing process
Independent, self-motivated and enthusiastic



Accountability

The Senior Dev Ops Engineer will help development teams (in house and external vendor suppliers) build, integrate, manage and deploy releases into all environments using a hybrid methodology (Agile + Waterfall). This role requires collaboration with all participants across the SDLC: software developers, Quality Assurance, Automated Testing, Infrastructure, Production Owners, Operations, Channels, and Business Units representatives as they continuously develop, deploy, test and implement technology changes
The incumbent will be accountable to continuously improve the Software Development processes to drive measurable efficiency and productivity improvements for technology delivery teams
The Senior Dev-Ops Engineer will liaise with Technology and Project leadership teams to ensure project changes, enhancements, fixes, and emergency patches are implemented to production environments using secure and controlled procedures. Responsibilities also include, acting as point of contact for planning and securing lower environments, addressing cross-projects linkages and dependencies, tracking and communicating of changes as they are implemented



What we offer [For full-time permanent roles]

💰 Competitive discretionary bonus

✨ Market leading RRSP match program

🩺 Medical, dental, vision, life, and disability benefits

📝 Employee Share Purchase Plan

👶🏽 Maternity/Parental top-up while you care for your little one

🏝 Generous vacation policy and personal days

🖥 Virtual events to connect with your fellow colleagues

🎓 Annual professional development allowance and a comprehensive Career Development program

💛 A fulfilling opportunity to join one of the top FinTechs and help create a new kind of banking experience

The incumbent will be working hybrid and in office time will be spent working from Equitable Bank’s additional office space located at 351 King Street East, Toronto, ON.

Equitable Bank is deeply committed to inclusion. Our organization is stronger and our employees thrive when we honour and celebrate everyone’s diverse experiences and perspectives. In tandem with that commitment, we support and encourage our staff to grow not just in their career path, but personally as well.

We commit to providing a barrier-free recruitment process and work environment for all applicants. Please let us know of any accommodations needed so that you can bring your best self to the application process and beyond. All candidates considered for hire must successfully pass a criminal background check and credit check to qualify for hire. While we appreciate your interest in applying, an Equitable recruiter will only contact leading candidates whose skills and qualifications closely match the requirements of the position.

We can’t wait to get to know you!","{""role_summary"":""Design, improve, and implement build and release pipelines as a Senior DevOps Engineer, providing subject matter expertise to developers and testers, and collaborating with the larger team to exchange knowledge and solutions."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve the speed and quality of delivering software applications and services.""},{""term"":""Continuous Integration/Continuous Delivery"",""explanation"":""A software development practice where code changes are automatically built, tested, and deployed to production, ensuring faster and more reliable delivery of software applications.""},{""term"":""Cloud deployments"",""explanation"":""The process of deploying applications and services on cloud computing platforms such as Azure, AWS, or GCP, providing scalability and flexibility.""},{""term"":""Platform as a Service (PaaS)"",""explanation"":""A cloud computing model that provides a complete platform for developing, running, and managing applications, such as Pivotal CF or IBM Bluemix.""},{""term"":""Containers and Docker"",""explanation"":""A lightweight and portable way to deploy applications, using containers such as Docker, to ensure consistency and reliability across different environments.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in Continuous Integration and Continuous Deployment orchestration"",""2+ years of experience in cloud deployments to Azure, AWS, or GCP"",""2+ years of experience in platform as a service using Pivotal CF or IBM Bluemix"",""5+ years of experience in troubleshooting and source control systems (Git, SVN)"",""Solid understanding of Software Delivery Lifecycle"",""Bachelor's degree or equivalent in Computer Science, Systems or Engineering""],""nice_to_have"":[""SecOps experience"",""Experience with containers and Docker, Kubernetes or similar technologies"",""Programming/scripting skills in one or more languages: Java, C, C++, groovy, Python, Shell""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing and implementing build and release pipelines?"",""example_answer"":""I follow a hybrid approach, combining Agile and Waterfall methodologies, to ensure efficient and reliable delivery of software applications. I also consider the entire software development lifecycle, from development to production, to identify areas for improvement.""},{""question"":""Can you explain the benefits of using containers and Docker in DevOps?"",""example_answer"":""Containers provide a lightweight and portable way to deploy applications, ensuring consistency and reliability across different environments. Docker, in particular, allows for easy management and orchestration of containers, making it an essential tool in DevOps.""}],""red_flags"":[""Lack of experience in cloud deployments to Azure, AWS, or GCP"",""Inability to design high-quality, scalable, and supportable technology solutions"",""Poor communication and collaboration skills""],""confidence_score"":90.0}"
Cloud Engineer (AWS),"Employment Type: Full-Time, Experienced

Department: Information technology

We are seeking a Cloud Engineer (AWS) who will be responsible for supporting the development of all required documentation necessary to support the engineering, security, and operational processes for a large federal agency. The ideal candidate will possess a strong grasp of cloud computing SaaS, PaaS, and IaaS fundamentals.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:


Design solutions that ensure maximum flexibility and scalability, while meeting all required security controls
Support the development of all required documentation necessary to support the engineering, security, and operational processes
Perform business and technical alternative analysis for any/all aspects of the solution, aiding the customer is making decisions along the way
Facilitate the transition of the solution to operations, initially and ongoing ensuring at all times the system is operating within the anticipated operating boundaries
Strong grasp of cloud computing SaaS, PaaS and IaaS fundamentals with experience designing and implementing solutions




Qualifications:


Bachelor's Degree in Computer Science, Engineering, or other Engineering or Technical discipline or equivalent relevant experience
At least four (4-7) years of professional IT experience performing duties in support of federal government agencies
4+ years design, implementation and/or support of highly distributed applications demonstrating strong architectural skills to ensure availability, reliability, etc
Hands-on experience with AWS (Required) or other cloud services reinforced with architectural design experience
Experience designing and delivering large-scale solutions, most of which that have advanced to the production state
Strong grasp of cloud computing SaaS, PaaS and IaaS fundamentals with experience designing and implementing solutions. Develop cloud base solution designs and implementation plans based on customer needs
Familiar with lift-and-shift migrations and migration methodologies for cloud migration
Experience in Cloud computing, Networking, Storage, and Identity Management AWS Certification or Cloud Architect Certification (or desire to obtain certification)




Ideally, you will also have:


Hands-on experience with AWS (required) or other cloud services reinforced with architectural design experience designing and delivering large-scale solutions, most of which that have advanced to the production state
Develop cloud base solution designs and implementation plans based on customer needs
Familiar with lift-and-shift migrations and migration methodologies for cloud migration
Experience in Cloud Compute, Networking, Storage, and Identity Management AWS Certification or Cloud Architect Certification (or desire to obtain certification)




Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package.


Health, Dental, and Vision
Life Insurance
401k
Flexible Spending Account (Health, Dependent Care, and Commuter)
Paid Time Off and Observance of State/Federal Holidays




Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com","{""role_summary"":""Support the development of documentation for engineering, security, and operational processes for a federal agency as a Cloud Engineer (AWS), ensuring maximum flexibility and scalability while meeting security controls."",""key_terms"":[{""term"":""Cloud computing"",""explanation"":""The practice of using a network of remote servers accessed over the internet to store, manage, and process data.""},{""term"":""SaaS, PaaS, and IaaS"",""explanation"":""Cloud service models: Software as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service (IaaS) provide different levels of control and management to users.""},{""term"":""Lift-and-shift migrations"",""explanation"":""A cloud migration strategy that involves moving an application or workload from on-premises to the cloud without making significant changes to the application or its architecture.""}],""skill_priorities"":{""must_have"":[""AWS experience"",""Cloud computing fundamentals"",""Designing and implementing cloud solutions"",""Strong grasp of SaaS, PaaS, and IaaS""],""nice_to_have"":[""AWS Certification or Cloud Architect Certification"",""Experience with lift-and-shift migrations"",""Familiarity with cloud migration methodologies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the differences between SaaS, PaaS, and IaaS cloud service models?"",""example_answer"":""SaaS provides software applications over the internet, PaaS offers a platform for developing and deploying applications, and IaaS provides virtualized computing resources. Each model offers varying levels of control and management to users.""},{""question"":""How would you design a cloud-based solution to ensure maximum flexibility and scalability while meeting security controls?"",""example_answer"":""I would consider the customer's needs and design a solution using a combination of cloud services, such as AWS, to ensure scalability and flexibility while implementing security controls to meet the required standards.""}],""red_flags"":[""Lack of hands-on experience with AWS or other cloud services"",""Inability to design and implement cloud solutions"",""Insufficient understanding of cloud computing fundamentals""],""confidence_score"":90.0}"
Sr DevOps Engineer,"Firework is the world’s leading unified video commerce platform that empowers its global partners to personalize the customer experience and engagement at scale. Firework bridges the offline and online for a robust omnichannel immersive brand experience cultivating a deeper emotional human connection between our partners and their end consumers. We are customer-centric and inspired to win together offering total solutions with endless possibilities to help our customers increase purchases and conversions using the power of video. At the heart, we are a global and diverse team of “SuperSpark” creators, entrepreneurs, life-long learners, and data geeks driven by the future of authenticity to transform commerce. Firework has raised over $235M to date, with its latest Series B round led by SoftBank Vision Fund 2. Come reimagine the online customer experience with us.

Summary
Our engineering team is growing! We’re looking for a talented DevOps Engineer to join our global team and build scalable systems that will shape the future of our cloud infrastructure for our customer-facing and internal systems.

What You'll Be Doing

Work across multiple functional teams to assess, design, build and maintain a highly fault-tolerant, elastic infrastructure of tools and automation on cloud
Create deployments, services, and other resources on Kubernetes clusters
Design, build, test, deploy, and automate stable/scalable services for the internal engineering team and end users
Champion for a flawless Service Level Agreement (SLA). Shoot for the 5 9s target
Be available on-call during your shift to handle any P0 incidents and help bring the systems back online
Create and manage CI/CD pipelines for automated testing, deployment, and any other use cases
Continuously monitor all the services and drive performance tuning
Maintain and improve our existing software engineering tools with upgrades and installations
Integrate secure solutions and compliance management including identity and access management role-based access control systems
Debug, troubleshoot, and resolve system level scale, performance, and automation problems
Provide multi-tier levels of support to engineering and non-engineering stakeholders
Check in code to Github repositories and perform code reviews for your fellow team members




What You Should Have

Bachelor’s degree in computer programming, computer science, or a related field
5+ years experience in a DevOps or Site Reliability Engineer role.
Mix of consumer technology and SaaS technology is ideal
Working and maintaining production experience of Kubernetes deployments and services
Kubernetes (k8s) and Docker production experience
Built out continuous integration and continuous deployment pipelines
Able to write Bash and/or Python scripts
Ability to own and be responsible for the projects you will be working on




We'll Be Excited If You Have

Experience working with AWS cloud infrastructure and their various services
Fluent in Terraform/Terragrunt and writing Infrastructure as Code (IaC)
Experience and thorough understanding of the Linux operating systems
Experience with high-traffic monitoring systems.
Implementation of logging (Grafana/Prometheus), telemetry (New Relic), and tracing is ideal
Experience with Nginx deployments.Closely work with SQL and NoSQL databases and experience executing zero-downtime database upgrades
Excellent eye for security and creating bulletproof secure systems
Excellent and effective verbal, written, interpersonal communication skills
Comfortable with fast-paced change: ability to demonstrate comfort with ambiguity, adapt quickly and be effective in new situations in a highly dynamic setting
Data-driven but also imaginative and intuitive in coming up with ideas and solutions
Proven ability to balance multiple priorities in a collaborative team environment




This role may be hybrid and based in our San Mateo office or may be remote in Canada or Latin America.The following represents the expected range of compensation for this role: The estimated pay range for San Mateo is CAD140,000-160,000. Other factors that impact compensation may include stock options.The posted pay range represents the anticipated low and high end of the compensation for this position and is subject to change based on business need. To determine a successful candidate’s starting pay, we carefully consider a variety of factors, including primary work location, an evaluation of the candidate’s skills and experience, market demands, and internal parity. Candidates may receive more information from the talent partner.

Don’t hold back
We understand some candidates may see the above and not apply because they don’t meet all the qualifications. We encourage you to apply anyway; we often find talented candidates that fit many other opportunities we have and look for potential too, not just what you did in the past. As an equal employment opportunity employer, we are a diverse team that strives for an inclusive environment for all. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, age, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws.

By submitting your application, you acknowledge that you have read and understood Firework's Applicant Privacy Policy located at: https://firework.com/legal/applicantpolicy/.","{""role_summary"":""Join Firework's engineering team as a DevOps Engineer to build and maintain scalable cloud infrastructure, ensuring high availability and performance for customer-facing and internal systems."",""key_terms"":[{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""CI/CD pipelines"",""explanation"":""Continuous Integration and Continuous Deployment pipelines automate testing, deployment, and other processes to improve software development efficiency.""},{""term"":""SLA (Service Level Agreement)"",""explanation"":""A formal agreement between a service provider and its customers that defines the expected service quality, availability, and responsiveness.""},{""term"":""IaC (Infrastructure as Code)"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files, rather than manual processes.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in DevOps or Site Reliability Engineer role"",""Kubernetes (k8s) and Docker production experience"",""Ability to write Bash and/or Python scripts"",""Experience with continuous integration and continuous deployment pipelines""],""nice_to_have"":[""Experience working with AWS cloud infrastructure and their various services"",""Fluent in Terraform/Terragrunt and writing Infrastructure as Code (IaC)"",""Experience with high-traffic monitoring systems"",""Implementation of logging (Grafana/Prometheus), telemetry (New Relic), and tracing""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a scalable and fault-tolerant infrastructure for a cloud-based application?"",""example_answer"":""I would use Kubernetes to orchestrate containerized applications, implement load balancing and auto-scaling, and ensure redundancy across multiple availability zones.""},{""question"":""Can you explain the importance of CI/CD pipelines in DevOps and how you would implement them?"",""example_answer"":""CI/CD pipelines automate testing, deployment, and other processes, ensuring faster time-to-market and improved quality. I would implement pipelines using tools like Jenkins, GitLab CI/CD, or CircleCI, and integrate them with version control systems like GitHub.""}],""red_flags"":[""Lack of experience with Kubernetes and Docker"",""Inability to write Bash and/or Python scripts"",""No experience with continuous integration and continuous deployment pipelines""],""confidence_score"":90.0}"
DevOps Engineer Canada,"Benefits:

Bonus based on performance
Competitive salary
Home office stipend
Paid time off
Training & development


We are seeking a DevOps Engineer to join our growing team and take ownership of our cloud infrastructure, CI/CD pipelines, system reliability, observability, and scalability. The ideal candidate is passionate about automation, cloud technologies, and security best practices, ensuring seamless deployment and high availability of our applications.

Responsibilities

Design, implement, and manage CI/CD pipelines to streamline software development and deployment.
Maintain and optimize cloud infrastructure (AWS, Azure) to ensure scalability, security, and cost-effectiveness.
Automate infrastructure provisioning, monitoring, and management using Infrastructure as Code (IaC) tools (Terraform, Ansible, etc.).
Monitor system performance, troubleshoot issues, and ensure high availability and reliability.
Collaborate with software engineers to enhance deployment strategies and improve development workflows.
Implement security best practices to safeguard infrastructure and applications.
Manage containerization and orchestration tools like Docker and AWS ECS.
Optimize logging, monitoring, and alerting systems (ELK stack, etc.).
Stay up to date with the latest DevOps trends, tools, and best practices.


Requirements

3+ years of experience in a DevOps or Site Reliability Engineering (SRE) role.
Strong proficiency in cloud platforms (AWS, GCP, Azure) and cloud-native services.
Experience with CI/CD tools (GitHub Actions, GitLab CI/CD, etc.).
Proficiency in Infrastructure as Code (IaC) tools like Terraform, CloudFormation, or Ansible.
Strong scripting skills in Bash, Python for automation.
Hands-on experience with Docker and AWS ECS for container orchestration.
Knowledge of monitoring and logging tools (ELK stack, Datadog, etc.).
Experience with database management and performance optimization (SQL, NoSQL).
Understanding of security best practices, networking, and system administration.
Experience working in an agile startup environment is a plus.


Nice-to-Have Skills

Development experience with Django
Hands-on experience with Kubernetes for container orchestration.
Exposure to AI/ML workloads.


Who we are

Remarcable is a cloud based platform that helps electrical contractors and distributors streamline purchasing processes to save time and money.

Dedicated to the Electrical Contractor Industry, Remarcable provides cloud-based Procurement & Tool Management Software nationwide. With multiple workflows, two applications in one software, and direct contractor accounting integrations, Remarcable significantly, and efficiently, increases communication, streamlines workflows, and provides visibility for all users.

Our team is composed of contractor and distribution experts located coast to coast. Through collaborations with industry leaders, we've gained insight into the struggles they face. Together, we believe in providing a solution that brings efficiency, visibility, and better communication to streamline the relationship between the contractor and distributor partners.

Our Mission

To advance the adoption of technology in the construction industry and bring better efficiency, visibility, and communication to our customers.

Salary Range Disclaimer

The base salary range represents the low and high end of the Remarcable salary range for this position. Actual salaries will vary depending on factors including but not limited to location, experience, and performance. The range listed is just one component of Remarcable’s total compensation package for employees. Other components may include: PTO and a Bonus plan.

Work remote temporarily due to COVID-19.","{""role_summary"":""A DevOps Engineer responsible for managing cloud infrastructure, CI/CD pipelines, system reliability, observability, and scalability, ensuring seamless deployment and high availability of applications."",""key_terms"":[{""term"":""CI/CD pipelines"",""explanation"":""Continuous Integration and Continuous Deployment pipelines automate software development and deployment, ensuring efficient and reliable delivery of applications.""},{""term"":""Infrastructure as Code (IaC) tools"",""explanation"":""Tools like Terraform, Ansible, and CloudFormation allow for infrastructure provisioning, monitoring, and management through code, enabling version control and automation.""},{""term"":""Containerization and orchestration"",""explanation"":""Technologies like Docker and AWS ECS enable packaging, deployment, and management of applications in containers, ensuring scalability and reliability.""},{""term"":""ELK stack"",""explanation"":""A collection of tools (Elasticsearch, Logstash, Kibana) for logging, monitoring, and alerting, providing insights into system performance and issues.""}],""skill_priorities"":{""must_have"":[""Cloud platforms (AWS, Azure, GCP)"",""CI/CD tools (GitHub Actions, GitLab CI/CD)"",""Infrastructure as Code (IaC) tools (Terraform, Ansible)"",""Scripting skills in Bash, Python"",""Container orchestration (Docker, AWS ECS)"",""Monitoring and logging tools (ELK stack, Datadog)""],""nice_to_have"":[""Development experience with Django"",""Hands-on experience with Kubernetes"",""Exposure to AI/ML workloads""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach automating infrastructure provisioning and management using IaC tools?"",""example_answer"":""I use Terraform to define infrastructure configurations and Ansible for automation, ensuring version control and consistency across environments.""},{""question"":""Can you explain your experience with containerization and orchestration using Docker and AWS ECS?"",""example_answer"":""I've used Docker to package applications and AWS ECS for container orchestration, ensuring scalability and reliability in our production environment.""}],""red_flags"":[""Lack of experience with cloud platforms (AWS, Azure, GCP)"",""Inadequate scripting skills in Bash, Python""],""confidence_score"":90.0}"
Cloud Infrastructure Engineer,"Cloud Infrastructure Engineer
📍 Location: Remote | Full-time
📅 Availability: As soon as possible
About Exposant 3 (E3)
Exposant 3 (E3) is a consulting firm specializing in management and information technology. With team members based in Canada and Europe, we support both public and private organizations in their digital and organizational transformations, placing innovation and people at the heart of our projects. As part of our growth, we are looking for a Cloud Infrastructure Engineer to support the day-to-day operations of our clients current cloud platforms. They assist and participate in implementing the Cloud Engineering backlog of platform enhancements and optimizations. The Cloud Engineer also works closely with our Application Development and DevOps teams to remove roadblocks and solve problems during their implementation. They will also assist our partners in Network, Storage and Security Engineering with their cloud-specific projects.
Main Responsibilities
Under the supervision of the leadership team, you will be responsible for various tasks aimed at optimizing the company’s daily operations:
Job Accountabilities
Handle day-to-day operations in the cloud including closing support tickets and incidents.
Support the Senior and Principal Engineers in implementing United Cloud Strategy efforts
Code solutions and build automations to answer complex problems or address cumbersome processes.
Build skills and knowledge in Cloud Foundations and Solution Architecture.
Assist in the testing of resiliency patterns and practices for our App Workloads.
Interacts frequently with the team through meetings, 1:1s with their leader, and Teams chat discussions to discuss overall team strategy, engage in problem solving, and share best practices and knowledge.
🎯 Required Skills and Qualities:
Bachelors or Masters Degree in related field such as Computer Science
If you have a Bachelors degree - 10+ years of experience in cloud infrastructure engineering with a focus on cloud infrastructure automation.
Experience writing and maintaining CI/CD pipeline templates and infrastructure code.
If you have a Masters Degree -7+ years of hands-on experience with AWS, including expertise in compute, containers, and serverless infrastructure
Certified AWS Cloud Practitioner or AWS Solutions Architect Associate
Knowledge of one or more Cloud providers (i.e., AWS, Azure)
hands-on experience with AWS, including in-depth knowledge of core services (e.g., EC2, S3, RDS, Lambda, CloudWatch, Config, Control Tower, DynamoDB) and multi-account governance using AWS Organizations.
Skilled in security scanning tools such as Wiz and coded remediations
Expertise in Infrastructure as Code (IaC) using CDK,CFT or Terraform, YAML, JSON.
Experienced with Azure functions, AWS Lambda's event bridge, Azure event Hub.
Proficient in programming language (Python, Go, or similar)and Bash/Powershell for scripting and automation tasks.
Knowledge of troubleshooting systems
Skills in business acumen
Skills in persuasion
Skills in effective verbal and written communication
Ability to be creative and innovative","{""role_summary"":""The Cloud Infrastructure Engineer is responsible for optimizing daily operations in the cloud, implementing platform enhancements, and collaborating with development and DevOps teams to solve problems."",""key_terms"":[{""term"":""Cloud Foundations"",""explanation"":""The fundamental architecture and design principles of cloud computing, including infrastructure, security, and governance.""},{""term"":""Solution Architecture"",""explanation"":""The design and implementation of comprehensive solutions that meet specific business needs, often involving multiple cloud services and technologies.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""The practice of managing and provisioning cloud infrastructure using code and configuration files, rather than manual processes.""},{""term"":""CI/CD pipeline"",""explanation"":""A set of automated processes for building, testing, and deploying software applications, ensuring continuous integration and delivery.""}],""skill_priorities"":{""must_have"":[""AWS experience"",""Cloud infrastructure automation"",""CI/CD pipeline templates"",""Infrastructure as Code (IaC)"",""Programming language (Python, Go, or similar)""],""nice_to_have"":[""Azure experience"",""Certified AWS Cloud Practitioner or AWS Solutions Architect Associate"",""Experience with security scanning tools"",""Business acumen"",""Persuasion skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of multi-account governance using AWS Organizations?"",""example_answer"":""AWS Organizations allows us to centrally manage multiple AWS accounts, providing a hierarchical structure for governance, security, and compliance. This enables us to implement consistent policies and access controls across all accounts, ensuring a unified cloud strategy.""},{""question"":""How would you approach automating a complex cloud infrastructure task using IaC?"",""example_answer"":""I would use a tool like Terraform or CDK to define the infrastructure as code, and then leverage automation scripts in Python or Bash to execute the deployment. This approach ensures consistency, repeatability, and version control of the infrastructure.""}],""red_flags"":[""Lack of hands-on experience with AWS or Azure"",""Inability to write infrastructure code or automate cloud tasks"",""Limited knowledge of cloud security and governance""],""confidence_score"":90.0}"
DevOps Engineer (AWS),"Join a leading multinational Fortune 500 company in Canada as a DevOps Engineer (AWS). Contribute to cutting-edge solutions and drive technological innovation. Be a key player in a dynamic team by applying today! This hybrid role, based in Toronto, Ontario, provides the flexibility of working both on-site and remotely.

Responsibilities

Assist in designing and implementing new service offerings on a robust cloud foundation.
Support development teams in utilizing machine learning operations (MLOps) frameworks.
Contribute to the development and maintenance of observability infrastructure, staying updated with emerging technologies.
Participate in incident response, postmortems, and production improvements to support business growth.
Collaborate with software development and infrastructure teams to maintain and enhance multiple business offerings.
Help automate infrastructure deployment, scaling, and management using modern DevOps tools.
Monitor and optimize system performance, troubleshoot issues, and assist in implementing solutions.
Contribute to managing and securing cloud-based environments (AWS).
Support infrastructure as code (IaC) development and maintenance using Terraform.
Collaborate on implementing security best practices throughout development and deployment pipelines.
Participate in on-call responsibilities with team members.
Document and share best practices across DevOps processes.


Minimum Qualifications

Bachelor's degree in Computer Science, Engineering, or a related field.
3+ years of experience in DevOps or a related field.
Hands-on experience with AWS (Amazon Web Services).
Familiarity with container technologies like Docker and Kubernetes.
Experience with infrastructure as code tools such as Terraform or CloudFormation.
Understanding of networking and security concepts.
Basic knowledge of CI/CD processes and related tools.
Proficiency in a programming language such as Java or Python.
Experience in Linux system administration, scripting, and troubleshooting in production environments.
Exposure to monitoring and logging tools (e.g., Prometheus, ELK Stack, Grafana) is a plus.
Relevant certifications (e.g., AWS Certified Cloud Practitioner) are advantageous.


APPLY NOW!

NearSource Technologies values diversity and is committed to equal opportunity. All qualified applicants will be considered regardless of their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as protected veterans.","{""role_summary"":""As a DevOps Engineer (AWS), contribute to cutting-edge solutions, drive technological innovation, and support business growth by designing and implementing new service offerings, collaborating with development teams, and maintaining cloud-based environments."",""key_terms"":[{""term"":""MLOps"",""explanation"":""Machine Learning Operations, a framework for managing machine learning workflows.""},{""term"":""Observability infrastructure"",""explanation"":""A set of tools and systems that provide visibility into application performance and behavior.""},{""term"":""IaC"",""explanation"":""Infrastructure as Code, a practice of managing and provisioning infrastructure through code and configuration files.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a set of practices for automating and streamlining software development and delivery.""}],""skill_priorities"":{""must_have"":[""AWS (Amazon Web Services)"",""Container technologies like Docker and Kubernetes"",""Infrastructure as code tools such as Terraform or CloudFormation"",""Networking and security concepts"",""CI/CD processes and related tools"",""Programming language such as Java or Python"",""Linux system administration, scripting, and troubleshooting""],""nice_to_have"":[""Exposure to monitoring and logging tools (e.g., Prometheus, ELK Stack, Grafana)"",""Relevant certifications (e.g., AWS Certified Cloud Practitioner)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach implementing security best practices throughout development and deployment pipelines?"",""example_answer"":""I ensure that security is integrated into every stage of the pipeline, from code review to deployment, using tools like AWS IAM and Terraform. I also collaborate with the development team to implement secure coding practices and conduct regular security audits.""},{""question"":""Can you describe your experience with infrastructure as code tools like Terraform?"",""example_answer"":""I have used Terraform to manage and provision infrastructure in AWS, including setting up VPCs, subnets, and EC2 instances. I have also used Terraform to automate infrastructure deployment and scaling.""}],""red_flags"":[""Lack of hands-on experience with AWS"",""Inability to work collaboratively with development and infrastructure teams"",""Limited understanding of networking and security concepts""],""confidence_score"":90.0}"
Junior DevOps Engineer,"Are you ready to embark on a career that truly affects people around the world? Trulioo invites you to be a catalyst for change in the dynamic realm of digital identity verification. As the global front-runner in our industry, we are redefining how businesses grow, innovate and comply online.

Picture yourself at the forefront of innovation, contributing to our award-winning platform that enables organizations worldwide to quickly onboard customers, optimize costs and combat fraud. Fueled by Silicon Valley support, Trulioo stands as the trusted platform that can verify more than 5 billion people and 700 million business entities spanning 195 countries.

But Trulioo is more than a tech company. We are a united force of dedicated experts committed to establishing trust online.

Headquartered in Vancouver and with strategic hubs in San Diego and Dublin, we foster a culture of collaboration and open communication. Our offices support a hybrid model and staff typically work three days per week at a hub location. Join us where excitement meets innovation and contribute to a world where trust and technology unite.

What We Offer

Comprehensive Benefits: Health, dental, vision, retirement plans with company match, PTO, parental leave and an education & training fund ($1,000 local currency annually). Benefits vary by geography and will be discussed in more depth during the interview process.
Flexible Hybrid Working Environment: Our offices provide weekly lunches, delicious coffee and frequent social events. Dedicated parent rooms, gyms (in some locations), lounge spaces and flexible workstations create an environment that supports your well-being.
Wellness: We provide a variety of workshops, wellness events and a free subscription to the Headspace app to help our team members perform at their best.
Employee Resource Groups: Belonging is an important part of doing your best work. Our ERGs provide an inclusive space, support and community for employees of diverse backgrounds and allies. We host informative, fun sessions and celebrations that are often open to the entire organization.

Position Summary:

We are looking for a Junior DevOps Engineer to join our team and help us maintain and improve the reliability and performance of our cloud infrastructure. In this role, you’ll work alongside our DevOps team to ensure our systems are highly available, scalable, and performant. You’ll be helping to monitor our infrastructure, troubleshoot issues, and implement best practices to improve system reliability. As part of our 24/7 operations, you’ll also participate in the on-call rotation to assist with any technical incidents.

What you’ll be doing:

Help implement monitoring, logging, and alerting solutions to ensure the health of our systems.
Work with the team to troubleshoot and resolve issues across development, staging, and production environments.
Participate in efforts to improve security and performance across our platform.
Join the on-call rotation to help provide after-hours support for critical incidents.
Collaborate with engineers to ensure observability and reliability practices are embedded throughout the development lifecycle.

You have:

2+ years of experience with DevOps, SRE, or cloud infrastructure.
Hands-on experience with Linux or Windows systems in a production environment.
Basic experience with cloud platforms, preferably AWS.
Familiarity with scripting or programming (Python, Bash, Go, or similar).
Exposure to monitoring and logging tools (e.g., Prometheus, Grafana, New Relic, or similar).
Familiarity with version control systems (e.g., GitHub, GitLab).
A desire to learn and improve your skills in cloud infrastructure, automation, and system reliability.
Familiarity with CI/CD pipelines and tools (e.g., GitHub Actions, Jenkins, Gitlab Pipelines) is a bonus.
Exposure to Infrastructure as Code (e.g., Terraform, CloudFormation) is a bonus.

This is a great opportunity for someone looking to grow in the field of DevOps and/or Site Reliability Engineering. If you’re excited about working with cloud infrastructure, observability tools, and system reliability, we’d love to hear from you!

Pay Transparency (Vancouver)

We take a market-based and data-driven approach to compensation. We leverage data from trusted third-party compensation sources to help us understand the market value of a role based on function, level, location, and scope.

Please view the base salary range for this role below. The range listed is our expected compensation for the role. However, the pay offered may vary depending on a variety of factors including qualifications, job-related knowledge, skills, experience, and location.

Annual Salary

$75,000—$90,000 CAD

Thriving at Trulioo

At Trulioo, you’re not just an employee. You’re a valued member of our Trulicrew on a journey of professional and personal growth with a world-class organization. With Trulioo, you have the power to revolutionize the intersection of technology, digital trust and online identity to open the global economy to everyone. Together, we can shape the digital future.

We’re on the lookout for exceptional people to empower with trust, autonomy and the freedom to cultivate their potential. Your curiosity, meticulous attention to detail and passion to contribute are highly valued. If that resonates with you, apply today to become a part of our team. Join us in shaping a future where your career isn’t just a journey but also a boundless exploration into the possibilities of technology and digital identity verification.

If you don’t see yourself fully reflected in every job requirement listed on the posting above, we still encourage you to reach out and apply. Research has shown that minorities and underrepresented groups often only apply when they feel 100% qualified. We are committed to creating a more equitable, inclusive and diverse company and we strongly encourage applicants of all genders, ages, ethnicities, cultures, abilities, sexual orientations, and life experiences to apply.

Trulioo welcomes applications from people with disabilities. Support is available upon request for candidates taking part in all aspects of the selection process. Finally, we know from time-to-time emergencies happen and you may need to reschedule an interview - we understand and encourage you to be in communication without worrying about losing the opportunity or your credibility.

Privacy Notice

As part of our job application process, Trulioo collects, processes, and discloses personal data for the purpose of identifying suitable candidates for our job openings. For more detail, please visit Trulioo’s Website Privacy Policy in the section “When you apply for a job”.","{""role_summary"":""A Junior DevOps Engineer responsible for maintaining and improving the reliability and performance of Trulioo's cloud infrastructure, ensuring high availability, scalability, and performance."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""Cloud infrastructure"",""explanation"":""A model for delivering computing services over the internet, where resources are provided as a service.""},{""term"":""Observability"",""explanation"":""The ability to measure and understand the internal state of a system, enabling better monitoring and troubleshooting.""},{""term"":""CI/CD pipelines"",""explanation"":""A series of automated processes that integrate code changes, build, test, and deploy software applications.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files.""}],""skill_priorities"":{""must_have"":[""2+ years of experience with DevOps, SRE, or cloud infrastructure"",""Hands-on experience with Linux or Windows systems in a production environment"",""Basic experience with cloud platforms, preferably AWS"",""Familiarity with scripting or programming (Python, Bash, Go, or similar)""],""nice_to_have"":[""Familiarity with CI/CD pipelines and tools (e.g., GitHub Actions, Jenkins, Gitlab Pipelines)"",""Exposure to Infrastructure as Code (e.g., Terraform, CloudFormation)""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach monitoring and logging in a cloud-based infrastructure?"",""example_answer"":""I would implement a monitoring solution using tools like Prometheus and Grafana to collect metrics and logs, and set up alerting mechanisms to notify the team of any issues. I would also ensure that logging is centralized and easily accessible for troubleshooting purposes.""},{""question"":""Can you explain the importance of observability in a DevOps environment?"",""example_answer"":""Observability is crucial in a DevOps environment as it allows us to understand the internal state of the system, identify bottlenecks, and troubleshoot issues efficiently. This enables us to improve system reliability, reduce downtime, and increase overall performance.""}],""red_flags"":[""Lack of experience with cloud infrastructure"",""Inability to work in a 24/7 on-call rotation""],""confidence_score"":90.0}"
Infrastructure/DevOps Engineer,"Landbase leverages the experience of 100+ world class sales professionals and AI to deliver targeted, high-quality leads on autopilot. Our mission is to achieve GTM automation so humans no longer need to work for their software so they can reclaim their day. We're building GTM-1 Omni - the world's first action model purpose built for lead generation.

About The Role

We're looking for an Infrastructure Engineer to help scale our cloud platform and automate our deployment processes.

Key Responsibilities

Design and implement cloud infrastructure on GCP
Manage Kubernetes clusters and containerized applications
Implement and maintain CI/CD pipelines
Monitor system performance and reliability
Implement security best practices
Automate infrastructure provisioning

Required Skills & Experience

4+ years of DevOps/Infrastructure experience
Expert knowledge of Google Cloud Platform
Experience with Kubernetes and container orchestration
Strong background in infrastructure as code
Knowledge of monitoring and observability tools
Experience with security compliance (SOC2, GDPR)

Benefits & Perks

Competitive compensation
Comprehensive health benefits
Flexible work arrangements
Professional development opportunities
Exciting work with cutting-edge AI technology
Collaborative and innovative work environment
Regular team events and gatherings","{""role_summary"":""Design and maintain cloud infrastructure to support lead generation automation, ensuring scalability, reliability, and security."",""key_terms"":[{""term"":""GCP"",""explanation"":""Google Cloud Platform, a cloud computing service used for infrastructure deployment.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""CI/CD pipelines"",""explanation"":""Continuous Integration and Continuous Deployment pipelines, a set of practices for automating testing, building, and deployment of software applications.""},{""term"":""Infrastructure as Code"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files, rather than through graphical user interfaces.""},{""term"":""SOC2"",""explanation"":""Service Organization Control 2, a compliance standard for managing customer data based on five trust service principles: security, availability, processing integrity, confidentiality, and privacy.""},{""term"":""GDPR"",""explanation"":""General Data Protection Regulation, a European Union regulation for data protection and privacy in the European Union and the European Economic Area.""}],""skill_priorities"":{""must_have"":[""DevOps/Infrastructure experience"",""Google Cloud Platform"",""Kubernetes"",""Infrastructure as Code"",""Monitoring and observability tools"",""Security compliance (SOC2, GDPR)""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach infrastructure provisioning and management in a cloud environment?"",""example_answer"":""I use infrastructure as code tools like Terraform or CloudFormation to manage and provision infrastructure resources. This approach allows for version control, reproducibility, and automated deployment of infrastructure changes.""},{""question"":""What is your experience with Kubernetes, and how do you handle container orchestration?"",""example_answer"":""I have experience with Kubernetes and have used it to deploy and manage containerized applications. I understand how to configure and manage Kubernetes clusters, as well as implement rolling updates and self-healing deployments.""}],""red_flags"":[""Lack of experience with Google Cloud Platform"",""Inadequate knowledge of Kubernetes and container orchestration""],""confidence_score"":90.0}"
DevOps Engineer – Intermediate,"Job Title: DevOps Engineer – IntermediateThe DevOps Engineer position is an intermediate-level role focused on contributing to the development, implementation, and optimization of new or updated application systems in collaboration with the Technology team. This role involves participating in system analysis, programming, and ensuring applications meet business requirements.Key Responsibilities:

Participate in feasibility studies, time/cost assessments, IT planning, risk management, and application development, ensuring new or revised systems align with specific business or user needs.
Oversee all stages of the development lifecycle, from design and construction to testing and implementation, while providing ongoing user and operational support for business applications.
Apply specialized knowledge in application development to analyze complex issues, evaluate business and system processes, and compare industry standards to offer well-informed recommendations.
Develop and suggest security measures during post-implementation reviews to ensure systems are functional and secure.
Collaborate with end-users, clients, and other tech teams to resolve issues and provide advanced programming solutions.
Ensure adherence to procedures, define operational standards, and help establish efficient processes.
Mentor or provide guidance to junior analysts.
Operate with a degree of independence, exercising sound judgment and autonomy.
Act as a subject matter expert (SME) for senior stakeholders and team members.
Assess and manage risks in business decisions, ensuring compliance with relevant laws, regulations, and company policies, and promoting ethical conduct.

Qualifications:

5-8 years of relevant experience with systems analysis and software application programming
Proven experience in DevOps, Site Reliability Engineering (SRE), or similar roles in a large-scale enterprise environment.
Strong hands-on experience with CI/CD tools (e.g., Jenkins, GitLab, GitHub Actions, CircleCI).
Expertise in scripting and automation languages such as Python, Shell, Bash, or similar.
Experience with cloud platforms (AWS, Azure, or GCP) and containerization technologies (Docker, Kubernetes).
Experience with monitoring, logging, and alerting tools such as Prometheus, Grafana, ELK Stack, or Splunk.
Strong understanding of version control systems (Git) and collaboration tools (JIRA, Confluence).
Experience with Infrastructure as Code (IaC) tools such as Terraform, CloudFormation, or Ansible.
Solid understanding of networking, security, and system administration.
Excellent problem-solving, troubleshooting, and analytical skills.
Strong communication skills with the ability to collaborate effectively across teams.
Strong background in systems analysis and software application programming.
Proven experience in successfully managing and implementing projects.
Expert in at least one area of application development.
Ability to adapt to shifting priorities and changing circumstances.
Demonstrated leadership and project management capabilities.
Excellent written and verbal communication skills, with the ability to express complex ideas clearly.

Education:

Bachelor’s degree or equivalent experience
See All Jobs","{""role_summary"":""The DevOps Engineer role contributes to the development, implementation, and optimization of new or updated application systems, ensuring they meet business requirements and collaborating with the Technology team."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a practice that automates testing, building, and deployment of software applications.""},{""term"":""Site Reliability Engineering (SRE)"",""explanation"":""A discipline that combines software and systems engineering to build and operate large-scale, distributed systems.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice that manages and provisions infrastructure resources through code and configuration files.""}],""skill_priorities"":{""must_have"":[""DevOps"",""CI/CD tools"",""scripting and automation languages"",""cloud platforms"",""containerization technologies"",""version control systems"",""collaboration tools"",""Infrastructure as Code (IaC) tools"",""problem-solving and analytical skills"",""communication skills""],""nice_to_have"":[""Site Reliability Engineering (SRE)"",""project management capabilities"",""leadership skills""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure the security and functionality of a system during post-implementation reviews?"",""example_answer"":""I develop and suggest security measures during post-implementation reviews to ensure systems are functional and secure. This includes evaluating business and system processes, comparing industry standards, and offering well-informed recommendations.""},{""question"":""Can you explain how you would collaborate with end-users, clients, and other tech teams to resolve issues and provide advanced programming solutions?"",""example_answer"":""I would work closely with stakeholders to understand their needs, provide guidance and support, and develop solutions that meet their requirements. This includes communicating technical information effectively, providing training and documentation, and ensuring that solutions are scalable and maintainable.""}],""red_flags"":[""Lack of experience with cloud platforms and containerization technologies"",""Inability to adapt to shifting priorities and changing circumstances"",""Poor communication skills and inability to collaborate effectively across teams""],""confidence_score"":90.0}"
Senior DevOps Engineer,"Role Title: Senior DevOps Engineering Specialist
Hybrid: 3 Days / Toronto, Winnipeg, London
Salary: CAD 90,000 - 110,000

Any specific tools/skillset:
Min 5+ years of multi-disciplinary experience in a large, complex organization
Bachelors’ degree in Computer Science and/or Software Engineering or equivalent experience
Ability to build and maintain collaborative stakeholder relationships across multiple geographies and business functions
Ability to effectively communicate high-level concepts and solutions with technology and business teams
You value simplicity and are unafraid to challenge technical constraints to utilize an iterative and agile approach
Strong knowledge of infrastructure solutions, specifically in relation to cloud programs, platform migration, system security, enterprise directories, and cloud technologies
Kubernetes Expertise: Design, deploy, and maintain scalable and secure Kubernetes clusters, ensuring high availability, fault tolerance, and optimal performance for containerized applications
Experience working with technologies such as Docker, Kubernetes, Terraform, Ansible or other Infrastructure as Code (IaC) tools
Extensive experience with AWS EKS and Service Mesh
Expertise with CI/CD tooling such as Git, Jenkins, SonarQube, Nexus, Vault etc..
Experience working with at least one of the major public cloud providers (Azure, GCP or AWS) and a willingness to continue to expand your knowledge
A self-starter with the ability to comfortably operate in ambiguity
Monitoring and Troubleshooting: Monitor system performance, proactively identify issues, and implement measures for improvement to ensure system reliability and stability

Role profile description:
Reporting to the Product Owner, the DevOps Engineer is responsible for the monitoring, maintenance, and support of systems, services and tools, as well as deploying net-new capabilities aligned to Canada Life’s DevOps principles. The DevOps Engineer will leverage technical knowledge and experience across a variety of business units including, infrastructure, development, operations, and quality assurance, ensuring emerging trends and new technologies stay top of mind.

Ensure all solutions meet security and risk standards and comply with regulatory requirements as documented
Ensure all functional and non-functional requirements are met and measurable in all environments
Execute on the DevOps framework as defined by the Principal DevOps Engineer
Proactively identify areas of friction in current deployment processes and drive technical solution to remove impediments
Migrate existing services to new and existing digital stacks, while managing solutions by monitoring systems and events to avoid costly downtime
Ensure technology capabilities align with current and future business needs
Ensure alignment and adherence to enterprise technology, vendor management, and risk standards
Respond to critical and non-critical incidents based on priority and level of complexity
Work to validate and triage issues, and resolve where applicable
Manage ticket process from start to finish, interacting with other teams as necessary to identify and implement potential solutions.","{""role_summary"":""The Senior DevOps Engineering Specialist is responsible for monitoring, maintaining, and supporting systems, services, and tools, while deploying new capabilities aligned with the company's DevOps principles."",""key_terms"":[{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files, rather than through graphical user interfaces.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a set of practices that automate the build, test, and deployment of software applications.""},{""term"":""Cloud programs"",""explanation"":""A set of cloud computing services and solutions that enable organizations to build, deploy, and manage applications and workloads in the cloud.""},{""term"":""Service Mesh"",""explanation"":""A configurable infrastructure layer for microservices applications that makes it easy to manage service discovery, traffic management, and security.""}],""skill_priorities"":{""must_have"":[""Kubernetes expertise"",""Experience with cloud providers (AWS, Azure, GCP)"",""CI/CD tooling experience"",""Infrastructure as Code (IaC) tools experience"",""Strong knowledge of infrastructure solutions""],""nice_to_have"":[""Experience with Docker"",""Experience with Terraform"",""Experience with Ansible"",""Experience with Jenkins"",""Experience with SonarQube"",""Experience with Nexus"",""Experience with Vault""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach building and maintaining collaborative stakeholder relationships across multiple geographies and business functions?"",""example_answer"":""I prioritize open communication, active listening, and empathy to understand the needs of different stakeholders. I also establish clear goals and expectations to ensure alignment and collaboration.""},{""question"":""Can you explain how you would design and deploy a scalable and secure Kubernetes cluster?"",""example_answer"":""I would start by assessing the application requirements and defining the cluster architecture. Then, I would use Kubernetes deployment tools like kubeadm or kops to create the cluster, and configure security features like network policies and secret management.""},{""question"":""How do you ensure system reliability and stability in a cloud-based environment?"",""example_answer"":""I monitor system performance using tools like Prometheus and Grafana, and proactively identify issues using log analysis and alerting. I also implement measures for improvement, such as autoscaling and load balancing, to ensure high availability and fault tolerance.""}],""red_flags"":[""Lack of experience with Kubernetes or cloud providers"",""Inability to communicate technical concepts to non-technical stakeholders"",""No experience with CI/CD tooling or Infrastructure as Code (IaC) tools""],""confidence_score"":90.0}"
Site Reliability Engineer,"PointClickCare is a leading North American healthcare technology platform enabling meaningful care collaboration and real‐time patient insights. For over 20 years, the company has been focused on realizing its vision: to help create a world in which providers and plans can confidently deliver frictionless care. Since its inception, PointClickCare has grown exponentially, with over 2,200 employees working to impact millions across North America. Recognized by Forbes as one of the top 100 private cloud companies and acknowledged by Waterstone Human Capital as Canada’s Most Admired Corporate Cultures, PointClickCare leads the way in creating cloud-based healthcare software.

At PointClickCare, we offer a wealth of opportunities and a vibrant culture that empowers our employees. Our dynamic environment is the perfect place to advance your career while engaging in meaningful work alongside incredible colleagues. Here, you’ll discover a space where your talents can thrive, your career can grow, and your work will have a lasting impact on healthcare across North America. We believe that work becomes profoundly fulfilling when driven by a higher purpose.

Join us and be part of a team that is making a real impact.

To learn more about us, check out Life at PointClickCare and connect with us on Glassdoor and LinkedIn.

About The Team (Team Overview)

The Infrastructure SRE Team at PointClickCare is a group of dedicated professionals who specialize in designing, implementing, and maintaining efficient systems at scale for our client-facing services, hosted in multiple cloud service providers. With a strong emphasis on automation, repeatability, and consistency, our team supports a wide range of technologies and production services. We bring expertise in cloud-based solutions, programming languages, and configuration management tools to provide architectural guidance that improves resiliency, efficiency, and performance of PointClickCare’s products. Our team is composed of like-minded individuals who share a passion for the technology we support and are driven to deliver exceptional results.

About The Role

As a talented and experienced Site Reliability Engineer (SRE), you will play a critical role within our Infrastructure SRE team at PointClickCare. Your primary responsibility will be to apply SRE practices to our operations at scale. This entails monitoring and reporting on service level objectives, collaborating with business and product owners to establish key performance indicators. With a strong focus on automation, repeatability, and consistency, you will find opportunities and drive the team’s reduction in toil. Leveraging Infrastructure as Code principles, you will create and maintain the infrastructure of our multi-cloud environments and enhance visibility into application performance and business metrics while effectively managing the operational workload. Collaborating with security engineers, you will also develop plans and automation for proactive responses to new risks and vulnerabilities.

If you thrive in a dynamic and collaborative environment and are passionate about applying software engineering practices, including Infrastructure as Code, to enhance operations at scale, we would love to hear from you. Join our team as an SRE and make a significant impact on PointClickCare's success.

Key Responsibilities

Provide technical guidance and support for a wide range of technologies and services, with a focus on increasing automation, repeatability, and consistency.
Create and maintain monitoring technologies (i.e. AppDynamics, DataDog) and processes to improve visibility into application performance and business metrics, while ensuring manageable operational workload.
Actively drive and implement strategies to reduce toil and improve operational efficiency through automation and process improvements.
Collaborate with security engineers to develop plans and automation for proactive response to new risks and vulnerabilities.
Actively contribute to technical training events, game day scenarios, and engineering spikes.
Participate in an on-call rotation on a weekly basis, ensuring prompt response and resolution to incidents and maintaining system availability.

Your Key Strengths

Bachelor’s degree in computer science, Computer Engineering, Software Engineering, MIS, or related discipline.
Prior relevant software development/architecture experience.
Hands-on experience in containerization technologies (i.e. Docker) and container orchestration platforms (i.e. Kubernetes, AKS/EKS)
Experience building and supporting cloud-native solutions in multiple cloud platforms, such as Azure, AWS or GCP.
Proficiency in one or more programming languages such as C, C++, Java, Python, Go, Perl, or Ruby.
Experience with configuration management and deployment automation tools like Chef, Terraform, Puppet, or Ansible.
Strong knowledge and experience with Windows (2019/2022) and Linux administration.

Bonus Skills

Troubleshooting experience with diverse hosting technologies, such as web server platforms, Java application platforms, network components (load balancers, firewalls), virtualization technologies, and database platforms.
Proficiency in Linux, including experience compiling your own kernel, tracing syscalls, understanding TCP, and familiarity with sysvinit/runit/systemd.
Knowledge of Open Source software and contributions to the open-source community.

PointClickCare Benefits & Perks

Benefits starting from Day 1!

Retirement Plan Matching

Flexible Paid Time Off

Wellness Support Programs and Resources

Parental & Caregiver Leaves

Fertility & Adoption Support

Continuous Development Support Program

Employee Assistance Program

Allyship and Inclusion Communities

Employee Recognition … and more!

It is the policy of PointClickCare to ensure equal employment opportunity without discrimination or harassment on the basis of race, religion, national origin, status, age, sex, sexual orientation, gender identity or expression, marital or domestic/civil partnership status, disability, veteran status, genetic information, or any other basis protected by law. PointClickCare welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process. Please contact recruitment@pointclickcare.com should you require any accommodations.

When you apply for a position, your information is processed and stored with Lever, in accordance with Lever’s Privacy Policy. We use this information to evaluate your candidacy for the posted position. We also store this information, and may use it in relation to future positions to which you apply, or which we believe may be relevant to you given your background. When we have no ongoing legitimate business need to process your information, we will either delete or anonymize it. If you have any questions about how PointClickCare uses or processes your information, or if you would like to ask to access, correct, or delete your information, please contact PointClickCare’s human resources team: recruitment@pointclickcare.com

PointClickCare is committed to Information Security. By applying to this position, if hired, you commit to following our information security policies and procedures and making every effort to secure confidential and/or sensitive information.","{""role_summary"":""As a Site Reliability Engineer (SRE), you will apply SRE practices to operations at scale, focusing on automation, repeatability, and consistency, and collaborate with business and product owners to establish key performance indicators."",""key_terms"":[{""term"":""Infrastructure as Code"",""explanation"":""A practice that involves managing and provisioning infrastructure through code and configuration files, rather than through graphical user interfaces.""},{""term"":""Containerization"",""explanation"":""A technology that allows multiple applications to run on a single host operating system, improving resource utilization and deployment efficiency.""},{""term"":""Cloud-native solutions"",""explanation"":""Applications and services designed to take advantage of cloud computing principles, such as scalability, flexibility, and on-demand resources.""}],""skill_priorities"":{""must_have"":[""Hands-on experience with containerization technologies (e.g., Docker)"",""Experience building and supporting cloud-native solutions in multiple cloud platforms"",""Proficiency in one or more programming languages (e.g., C, C++, Java, Python, Go, Perl, or Ruby)"",""Experience with configuration management and deployment automation tools (e.g., Chef, Terraform, Puppet, or Ansible)""],""nice_to_have"":[""Troubleshooting experience with diverse hosting technologies"",""Proficiency in Linux, including experience compiling your own kernel, tracing syscalls, understanding TCP, and familiarity with sysvinit/runit/systemd"",""Knowledge of Open Source software and contributions to the open-source community""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would implement Infrastructure as Code principles in a multi-cloud environment?"",""example_answer"":""I would use tools like Terraform or CloudFormation to define infrastructure configurations as code, and then deploy and manage them across multiple cloud platforms. This would allow for version control, consistency, and automation of infrastructure provisioning and management.""},{""question"":""How do you approach troubleshooting complex issues in a cloud-native application?"",""example_answer"":""I would start by analyzing logs and monitoring data to identify the root cause of the issue. Then, I would use tools like Docker and Kubernetes to inspect and debug the application, and finally, I would implement a fix and deploy it to the production environment.""}],""red_flags"":[""Lack of experience with containerization technologies"",""Inability to work in a dynamic and collaborative environment"",""Insufficient knowledge of cloud-native solutions and their deployment""],""confidence_score"":90.0}"
Cloud Engineer (AWS & Azure),"Our client, a pioneer in Digital Health is looking for a Cloud Engineer to join on a contract basis, with the opportunity to go full-time. The Cloud Engineer is tasked with designing, implementing, automating, deploying, and managing production-grade services across multiple cloud providers and infrastructure platforms for the organization, its clients, and partners. This role collaborates with different teams to ensure infrastructure requirements are met for various departments, including Information Services, Privacy & Security, Engineering, Product, Client Support, and Delivery.Responsibilities:

Design, implement, automate, deploy, and operate production-grade services on various cloud platforms and infrastructure vendors.
Collaborate with multiple teams to ensure infrastructure needs are met across various departments such as Information Services, Privacy & Security, Engineering, Product, Client Support, and Delivery.
Provide expertise and recommendations related to cloud and platform provisioning to support internal and external projects.
Participate in infrastructure deployments, offering subject matter expertise on cloud components.
Develop and maintain infrastructure code for different solutions, providing support to clients and partners as needed.
Maintain technical documentation, standard operating procedures, implementation plans, and root cause analyses to support business needs.
Participate in planning for technology implementations and transformations, including assessments, proof of concepts, and technology roadmaps.
Leverage innovative cloud technologies to improve operations, security, and maintenance.
Take part in on-call rotations for application and infrastructure support, incident management, and troubleshooting as needed.
Accurately track and report working hours, ensuring proper usage of the project management tool for both billable and non-billable tasks.
Comply with privacy, security, and confidentiality policies.

Requirements:

5+ years of experience in IT, DevOps, infrastructure maintenance, system administration, cloud development, platform engineering, and/or automation development.
3+ years of experience supporting and developing templates and code for Kubernetes services, including HELM, Kustomize, and Kubernetes manifests.
2+ years of experience in a role supporting and maintaining critical infrastructure, troubleshooting escalations, and ensuring key performance metrics are met.
Deep knowledge of cloud services and hands-on experience building critical infrastructure from scratch.
Proven experience with Kubernetes and serverless infrastructure, including building new clusters and migrating applications.
Proficiency in scripting and programming languages like Powershell, Python, and Bash.
Experience translating architecture and technical requirements into cloud infrastructure.
Intermediate certifications in Cloud services (AWS, Azure, GCP) required; professional-level certifications preferred.
Kubernetes-related certifications such as CKA, CKD, and CKS.
Broad experience with core infrastructure technologies, including security, networking, databases, data streaming, deployment automation, monitoring, logging, alerting, and observability.
Strong communication and collaboration skills, with the ability to work closely with clients.
Demonstrated experience in maintaining comprehensive technical documentation, procedures, and standards.
See All Jobs","{""role_summary"":""Design, implement, and manage production-grade cloud services across multiple platforms, collaborating with various teams to meet infrastructure requirements."",""key_terms"":[{""term"":""Cloud Engineer"",""explanation"":""A professional responsible for designing, implementing, and managing cloud-based infrastructure and services.""},{""term"":""Production-grade services"",""explanation"":""High-quality, scalable, and reliable services that meet the needs of an organization, its clients, and partners.""},{""term"":""Infrastructure code"",""explanation"":""Code used to manage and provision infrastructure resources, such as cloud platforms and infrastructure vendors.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""Serverless infrastructure"",""explanation"":""A cloud computing model where the cloud provider manages the infrastructure, and the user only writes and runs code without worrying about the underlying infrastructure.""}],""skill_priorities"":{""must_have"":[""Cloud engineering"",""Kubernetes"",""Cloud services (AWS, Azure, GCP)"",""Scripting and programming languages (Powershell, Python, Bash)"",""Infrastructure maintenance and system administration""],""nice_to_have"":[""DevOps"",""Platform engineering"",""Automation development"",""Serverless infrastructure"",""Intermediate certifications in Cloud services""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing and implementing production-grade cloud services across multiple platforms?"",""example_answer"":""I follow a structured approach, considering factors such as scalability, reliability, and security. I also collaborate with various teams to ensure infrastructure requirements are met.""},{""question"":""Can you explain your experience with Kubernetes and serverless infrastructure?"",""example_answer"":""I have hands-on experience building critical infrastructure from scratch using Kubernetes and serverless infrastructure. I've also migrated applications and built new clusters.""}],""red_flags"":[""Lack of experience with Kubernetes and serverless infrastructure"",""Insufficient knowledge of cloud services and infrastructure maintenance"",""Poor communication and collaboration skills""],""confidence_score"":90.0}"
Cloud Infrastructure engineer,"Job Responsibilities:

We are looking for a Cloud Infrastructure engineer who is proficient in Terraform and Azure and has at least 10+ years of building enterprise infrastructure in the cloud.

The Cloud Infrastructure Engineer will be part of a team of engineers which works on automation and configuration as code for foundational architecture related to connectivity across multiple Cloud Service Providers.

They should have a strong background in infrastructure and Public Cloud technologies. They will be a part of the global team and will be responsible for connecting complex, multi-tier applications from on-prem to the Public Cloud.

They will be closely working with Product Management and Vendors to develop and deploy Cloud services to meet customer expectations.

Skills Required:
-Sound experience with Infrastructure as Code (Terraform)
-Experience in any of the following cloud service providers - Azure / AWS (Preference is Azure)
-Experience in Kubernetes and Container-based technologies
-Develop tooling and self-service capabilities
-Strong development skills in Python, Java or Golang.
-Sound experience in a scripting language such as Shell Scripting.
-Experience of leading development in projects in a distributed enterprise environments
-Experience of setting up a new development project using modern tools and practices including git, Jenkins, test-driven development, and continuous integration in a Linux-based environment
-Sound knowledge of infrastructure and cloud computing
-Ability to mentor and develop more junior programmers, including participating in constructive code reviews
-Collaborate with developers and infrastructure teams to enhance the developer experience

Desired:
10+ years’ experience of working in Azure and/or AWS.
-Working with teams using scrum, kanban or other agile practices.
-Proficiency with standard Linux command line and debugging tools.
-Experience of working with RESTful APIs, especially managing and configure compute and storage infrastructure.
-Knowledge of how to write comprehensive unit tests, including the mocking of external utilities and APIs.","{""role_summary"":""Design, build, and maintain cloud infrastructure, focusing on automation, configuration, and connectivity across multiple cloud service providers."",""key_terms"":[{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning infrastructure through code and configuration files, rather than through graphical user interfaces.""},{""term"":""Terraform"",""explanation"":""An open-source IaC tool that enables users to define and manage cloud and on-premises infrastructure using a human-readable configuration file.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating the deployment, scaling, and management of containerized applications.""},{""term"":""Container-based technologies"",""explanation"":""A method of deploying applications in containers, which are lightweight and portable, providing isolation and consistency across environments.""},{""term"":""Scrum/Kanban"",""explanation"":""Agile project management methodologies that emphasize iterative development, continuous improvement, and team collaboration.""},{""term"":""RESTful APIs"",""explanation"":""An architectural style for designing networked applications based on the use of representational state of resources, which can be manipulated using a fixed set of operations.""}],""skill_priorities"":{""must_have"":[""Terraform"",""Azure"",""Infrastructure as Code (IaC)"",""Kubernetes"",""Container-based technologies"",""Python, Java, or Golang"",""Shell Scripting"",""Cloud computing""],""nice_to_have"":[""AWS"",""Scrum/Kanban"",""RESTful APIs"",""Git"",""Jenkins"",""Test-driven development"",""Continuous integration""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach infrastructure automation using Terraform?"",""example_answer"":""I use Terraform to define infrastructure configurations in code, leveraging modules and workspaces to manage complexity and promote reusability.""},{""question"":""Can you explain the benefits of using container-based technologies in a cloud environment?"",""example_answer"":""Containerization provides isolation, portability, and consistency across environments, enabling efficient deployment and scaling of applications in the cloud.""},{""question"":""How do you ensure scalability and high availability in a cloud-based infrastructure?"",""example_answer"":""I design infrastructure with scalability and high availability in mind, using load balancers, auto-scaling, and distributed architectures to ensure seamless user experiences.""}],""red_flags"":[""Lack of experience with Terraform or Azure"",""Inability to work with distributed teams and agile methodologies"",""Limited understanding of cloud computing and infrastructure as code""],""confidence_score"":90.0}"
DevOps Engineer - Remote,"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start Caring. Connecting. Growing together.

The DevOps Engineer is a member of the DevOps Engineering Team and is responsible for the development and rollout of automated infrastructure-as-code and continuous delivery mechanisms which support Optum Insight’s Stratus Imaging solution in cloud environments. Reporting to the Senior Manager, DevOps Engineering, you will work closely with application development and SRE teams.

You’ll enjoy the flexibility to work remotely * from anywhere within Canada (expect for the Saskatchewan province) as you take on some tough challenges.

Primary Responsibilities

Develop new, update existing and support application infrastructure in Google Cloud environments
Develop new, update existing, and support reusable infrastructure as code (IaC) components
Automate the deployment, configuration, and scaling, of the applications that run on the above infrastructure
Automate the cybersecurity requirements and controls for deployed environments and software applications
Assist with the set up and maintenance of all test environments
Assist with the set up and maintenance of the production environment infrastructure and automation
Create and maintain documentation as required for maintenance and rollout of deliverables
Create and exercise test plans as required for deliverables
Analyze data from production monitoring tools and recommend changes
Assist in the development and implementation of DevOps policies and procedures
Work closely and collaboratively in an Agile environment with our product development, operations, and support teams

You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Required Qualifications

4+ years of experience in software development
2+ years of experience with continuous delivery of cloud infrastructure and applications for enterprise SaaS or PaaS companies in public clouds such as AWS, GCP, Azure
2+ years programming and scripting, particularly Bash and Python
2+ years proven working experience with cloud infrastructure, particularly Kubernetes
2+ years proven working experience with Terraform

Preferred Qualifications

2+ years of Linux and Windows administration
1+ years of experience with HIPAA compliance and the security of PHI data
1+ years of automation and configuration tools (e.g., Ansible, Kustomize)
1+ years of experience with software containers, preferably Docker
1+ years of experience with network implementation, configuration, and monitoring
1+ years of experience with Healthcare IT standards as well as with healthcare workflows
Demonstrated English communication skills (verbal and written) to interact effectively with peers and stakeholders
All employees working remotely will be required to adhere to UnitedHealth Group’s Telecommuter Policy.

Canada Residents Only: The salary range for Canada residents is $61,400 to $127,500 per year. Pay is based on several factors including but not limited to education, work experience, certifications, etc.

At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone-of every race, gender, sexuality, age, location and income-deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes — an enterprise priority reflected in our mission.

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.","{""role_summary"":""The DevOps Engineer develops and rolls out automated infrastructure-as-code and continuous delivery mechanisms to support Optum Insight's Stratus Imaging solution in cloud environments."",""key_terms"":[{""term"":""Infrastructure-as-Code (IaC)"",""explanation"":""A practice of managing and provisioning infrastructure through code and configuration files, rather than through graphical user interfaces.""},{""term"":""Continuous Delivery"",""explanation"":""A software development practice where code changes are automatically built, tested, and deployed to production after passing automated tests.""},{""term"":""Cloud Environments"",""explanation"":""Virtualized computing environments that provide on-demand access to a shared pool of computing resources over the internet.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating the deployment, scaling, and management of containerized applications.""},{""term"":""Terraform"",""explanation"":""An infrastructure as code tool that allows users to define and manage infrastructure on various cloud and on-premises environments.""}],""skill_priorities"":{""must_have"":[""4+ years of experience in software development"",""2+ years of experience with continuous delivery of cloud infrastructure and applications"",""2+ years programming and scripting, particularly Bash and Python"",""2+ years proven working experience with cloud infrastructure, particularly Kubernetes"",""2+ years proven working experience with Terraform""],""nice_to_have"":[""2+ years of Linux and Windows administration"",""1+ years of experience with HIPAA compliance and the security of PHI data"",""1+ years of automation and configuration tools (e.g., Ansible, Kustomize)"",""1+ years of experience with software containers, preferably Docker"",""1+ years of experience with network implementation, configuration, and monitoring"",""1+ years of experience with Healthcare IT standards as well as with healthcare workflows""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach infrastructure-as-code development for cloud environments?"",""example_answer"":""I use Terraform to define and manage infrastructure on cloud environments, ensuring consistency and reproducibility across different environments.""},{""question"":""Can you explain your experience with Kubernetes and how you've used it in previous roles?"",""example_answer"":""I've used Kubernetes to automate the deployment, scaling, and management of containerized applications in cloud environments, ensuring high availability and scalability.""}],""red_flags"":[""Lack of experience with cloud infrastructure, particularly Kubernetes and Terraform"",""Inability to work collaboratively in an Agile environment""],""confidence_score"":90.0}"
Cloud Platform Engineer,"Cloud Platform Engineer
📍 Location: Remote | Full-time
📅 Availability: As soon as possible
About Exposant 3 (E3)
Exposant 3 (E3) is a consulting firm specializing in management and information technology. With team members based in Canada and Europe, we support both public and private organizations in their digital and organizational transformations, placing innovation and people at the heart of our projects. As part of our growth, we are looking for a Cloud Platform Engineer  who will be responsible for developing hardened, scalable automated systems and platforms for the creation of cloud application workloads. The ideal candidate will need to enact an engineering mindset to tactically design and operationalize solutions which will enable developers and devops engineers across the entire organization. 

The platform engineer will appropriately assess and implement coding, IAC, pipeline, tooling, or process solutions to make a measurable impact on our end users. Solutions will need to be well rounded, easy to adopt, and built with the customer in mind through frequent engagement and discovery. Supplemental key responsibilities include contributing to enterprise standards, peer reviewing solutions, clearly communicating solutions, participating in planning ceremonies, and innovating on opportunities to enhance the developer experience
Main Responsibilities
Under the supervision of the leadership team, you will be responsible for various tasks aimed at optimizing the company’s daily operations:
Job Accountabilities
Create enterprise grade Infrastructure as Code solution frameworks for delivering secure, standardized architectures (Terraform, CloudFormation, CDK)
Design and develop coding solutions for integrating platforms, automating the cloud, or developing custom utilities. (Python, Boto3, Bash, JavaScript)
Contribute towards knowledge sharing initiatives through documentation, training and knowledge sharing sessions.
Provide integration support and troubleshooting to end users through the appropriate channels.
Seamlessly integrate multiple tools into a single platform ecosystem – Kong, AWS, Artifactory, Dynatrace
Collaborate with partner teams to design, review, and plan initiatives. Engage with stakeholders to shape the product roadmap.
Embody a custom first mindset to deliver innovative solutions and improve the developer experience
Required Skills and Qualities:
Bachelors or Masters Degree in related field such as Computer Science
If you have a Bachelors degree - 8+ years of experience in software engineering or DevOps roles with a focus on cloud infrastructure automation
Certified AWS Cloud Practitioner or AWS Certified DevOps Professional
Demonstrated experience designing and managing highly available, scalable, and secure cloud-based infrastructure.
Solid understanding of networking, security best practices, and monitoring tools.
Architect and implement scalable, secure, and resilient infrastructure platforms in the cloud (e.g., AWS, Azure, GCP).
Strong proficiency in one or more IaC tools (CloudFormation, Terraform, AWS CDK).
Proficient in programming language (Python, Go, or similar) and Bash/Powershell for scripting and automation tasks.
Experience designing, implementing, and maintaining CI/CD pipeline templates and infrastructure as code.
Hands on experience developing and standardizing an automation platform, Harness is preferred.
Extensive experience with AWS services (ECS Fargate, EKS, Lambda, IAM).
Prior experience in implementing enterprise-wide standardized secure patterns is preferred.
Experienced with Agile/SDLC methodologies.
Excellent communication and collaboration skills.
Experience with monitoring and observability tools (Dynatrace)
Deep understanding of containerization and orchestration technologies (Docker, Kubernetes)
Hands on experience in Harness, It hub Actions, Artifactory is preferred","{""role_summary"":""Design and develop scalable, secure, and resilient cloud-based infrastructure platforms, ensuring seamless integration with multiple tools and improving the developer experience."",""key_terms"":[{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning infrastructure through code and configuration files, rather than through graphical user interfaces.""},{""term"":""CloudFormation"",""explanation"":""A service offered by AWS that allows users to use templates to define and deploy infrastructure as code.""},{""term"":""Terraform"",""explanation"":""An open-source infrastructure as code tool that enables users to define and manage infrastructure across multiple cloud and on-premises environments.""},{""term"":""CI/CD pipeline"",""explanation"":""A set of practices that combines continuous integration and continuous delivery to improve the speed and quality of software releases.""},{""term"":""Kong"",""explanation"":""An open-source API gateway that enables users to manage API traffic, authentication, and security.""},{""term"":""Dynatrace"",""explanation"":""A software intelligence company that provides application performance monitoring and digital experience management solutions.""}],""skill_priorities"":{""must_have"":[""AWS Cloud Practitioner or AWS Certified DevOps Professional certification"",""8+ years of experience in software engineering or DevOps roles with a focus on cloud infrastructure automation"",""Solid understanding of networking, security best practices, and monitoring tools"",""Strong proficiency in one or more IaC tools (CloudFormation, Terraform, AWS CDK)"",""Proficient in programming language (Python, Go, or similar) and Bash/Powershell for scripting and automation tasks""],""nice_to_have"":[""Experience with Harness, It hub Actions, Artifactory"",""Prior experience in implementing enterprise-wide standardized secure patterns"",""Experience with monitoring and observability tools (Dynatrace)"",""Deep understanding of containerization and orchestration technologies (Docker, Kubernetes)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of Infrastructure as Code and how it improves the development and deployment of cloud-based infrastructure?"",""example_answer"":""Infrastructure as Code allows us to manage and provision infrastructure through code and configuration files, rather than through graphical user interfaces. This approach enables version control, reproducibility, and consistency across environments, reducing errors and improving collaboration between teams.""},{""question"":""How would you design and implement a scalable, secure, and resilient cloud-based infrastructure platform?"",""example_answer"":""I would start by assessing the requirements and constraints of the project, then select the appropriate IaC tool and cloud provider. I would design a modular, layered architecture that incorporates security best practices, monitoring, and logging. I would also implement automated testing, deployment, and rollback strategies to ensure high availability and scalability.""}],""red_flags"":[""Lack of experience with cloud infrastructure automation"",""Inability to design and implement scalable, secure, and resilient infrastructure platforms"",""Limited understanding of IaC tools and cloud providers""],""confidence_score"":90.0}"
DevOps Engineer 3,"About Behavox

Behavox is shaping the future for how businesses harness their most important raw material - data. Our mission is bold: Organize enterprise data into actionable information that protects and promotes the business growth of multinational companies around the world.

From managing enterprise risk and compliance to maximizing revenue and value, our data operating platform presents a widespread opportunity to build multilingual, AI/ML-based solutions that activate data for every function within a global enterprise.

Our approach is unique, and it’s validated by our customers who tell us to keep forging ahead because no one else is aggregating, analyzing, and acting on data to uncover opportunities or solve problems quite the way we are.

We are looking for fearless innovators who have an insatiable appetite for building what no one has built before.

About The Role

At Behavox, we are at the forefront of transforming how businesses utilize data. As a DevOps Engineer 3, you will play a critical role in enhancing our security measures ensuring the integrity, availability, and confidentiality of our systems. You will be responsible for designing, implementing, and managing the Security Information and Event Management (SIEM) infrastructure, deploying and configuring SIEM components across multi-account cloud environments, and optimizing the performance and cost-efficiency of our security operations.

Your role will also encompass integrating security into our CI/CD pipelines and implementing advanced security practices such as Static Application Security Testing (SAST) and Dynamic Application Security Testing (DAST). Your expertise in SIEM systems, cloud platforms (AWS and GCP), and log data analysis will be instrumental in detecting and responding to security threats swiftly and effectively. You will work closely with SIEM Infrastructure Engineers, Cloud Platform Engineers, and Security Analysts to ensure a seamless and secure data flow.

Work on the critical business area that will have a big impact on the company
Have freedom in implementing your ideas in an environment that is looking to constantly improve
Create a process of releasing hundreds of well-tested releases on demand

What You'll Bring

5+ years experience in a DevOps/DevSecOps/SRE engineering role, with interest and/or experience in integrating security practices into DevOps process
Hands-on experience with automation tools (e.g., Ansible, SaltStack, or Terraform with a focus on security)
Development and scripting skills (Python and Golang are preferred), with an emphasis on secure coding practices
Hands-on experience with AWS/GCP, including securing cloud environments and services
Experience in building secure CI/CD pipelines, incorporating security scans, and vulnerability assessments

What You'll Do

Participate in the building observability (metrics, logs, etc) for the product(s), along with contributing to the implementation and maintenance of security automation and tooling
Automate and streamline deployment, configuration, and maintenance processes (Ansible/Salt/Terraform)
Create tooling to automate operations (Python/Golang)
Manage and secure infrastructure in AWS/GCP
Build CI/CD pipelines, with a focus on security scans and vulnerability assessments, if possible

What We Offer

A truly global mission with a passionate community in locations all over the world
Huge impact and learning potential as our aspirations require bold innovation
Highly competitive compensation with 100% bonus pay already integrated
Benefits include great health coverage for employee and family
Generous time-off policy and flexible work schedule

About Our Process

We take Talent very seriously and we are building a community of extraordinary individuals working together in very high-performing teams. We also know that the best Talent always has options so we believe that the process has to be a two way assessment - the company AND the candidate assessing the business needs alignment, the career next step alignment, and the cultural alignment.

During the process we will begin by exploring the core factors regarding salary and location along with core experience and skills and values alignment. We will then deep dive explore the critical technical competencies we have identified for the role, and then we will deep dive in behavioral competencies.

The most aligned candidate will then be asked to do a practical work task simulation activity so we can make sure that you will enjoy the kind of work the role requires, and this task will typically be presented and discussed with a group of colleagues and managers.","{""role_summary"":""As a DevOps Engineer 3, you will enhance security measures, design and implement SIEM infrastructure, and optimize security operations, ensuring the integrity and confidentiality of systems."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a system that monitors and analyzes security-related data from various sources.""},{""term"":""DevSecOps"",""explanation"":""A practice that integrates security into DevOps processes, ensuring secure and efficient software development and deployment.""},{""term"":""SAST"",""explanation"":""Static Application Security Testing, a method of analyzing code for security vulnerabilities without executing the code.""},{""term"":""DAST"",""explanation"":""Dynamic Application Security Testing, a method of analyzing code for security vulnerabilities by executing the code.""}],""skill_priorities"":{""must_have"":[""5+ years experience in DevOps/DevSecOps/SRE engineering"",""Hands-on experience with automation tools (Ansible, SaltStack, or Terraform)"",""Development and scripting skills (Python and Golang)"",""Hands-on experience with AWS/GCP, including securing cloud environments and services""],""nice_to_have"":[""Interest and/or experience in integrating security practices into DevOps process"",""Experience in building secure CI/CD pipelines, incorporating security scans, and vulnerability assessments""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design and implement a SIEM infrastructure in a multi-account cloud environment?"",""example_answer"":""I would start by assessing the current security posture and identifying the necessary SIEM components. Then, I would design a scalable and secure architecture, ensuring data confidentiality and integrity. Finally, I would implement and configure the SIEM components, integrating them with existing security tools and processes.""},{""question"":""Can you explain how you would integrate security into a CI/CD pipeline?"",""example_answer"":""I would start by identifying the critical security components, such as SAST and DAST. Then, I would integrate these components into the pipeline, ensuring that security scans and vulnerability assessments are performed at each stage. Finally, I would implement automated remediation and reporting to ensure timely and effective security responses.""}],""red_flags"":[""Lack of experience with SIEM systems or cloud platforms (AWS and GCP)"",""Inability to integrate security practices into DevOps processes""],""confidence_score"":90.0}"
DevOps cloud Engineer 8297-1212,"HM Note: This hybrid contract role is three (3) days in office

Responsibilities

Design, build and support cloud environments to create digital products

Monitor and assess the performance of applications in a cloud environment to ensure solutions are available

Create, test and implement safeguards to maintain data integrity and protect against unauthorized access

General Skills

Experience in one of the leading cloud platforms such as AWS, Azure or Google Cloud, etc

Experience in maintaining complex Linux cloud environments, like CentOS, Ubuntu, or CoreOS, to support modern web technologies: LAMP, MEAN, Drupal and Elasticsearch

Experience setting up development environments and mechanism using tools such as JIRA, Confluence, Maven and Jenkins or similar tools

Experience in scripting languages like Python, Bash, PHP, Java, JavaScript, Node, etc.

Experience in build tools like Git, Ansible, Chef, Puppet etc. for continuous integration

Knowledge of container-based virtualization technology like Docker

Integration experience in building and using APIs

Experience applying industry web, architectural and security standards and best practices

Experience in mobile device management for various versions of cellular and tablets

Skills

Experience and Skill Set Requirements

Technical Knowledge and Skills: 30%

You are a seasoned expert in Azure among other cloud platforms.
You have experience in production environments such as Kubernetes (AKS).
You are familiar with container-based virtualization technology.
Experience with microservice based architectures
You have knowledge of DevOps tools and techniques, and in-depth technical knowledge of system architectures, including technical, data, application and network architectures.
You have experience implementing software engineering practices for full software development life cycles (SDLC), including coding standards, code reviews, source code management, build processes, and testing.
You have experience working independently with high-level direction to build and maintain complex Linux cloud

environments, like CentOS, Ubuntu or CoreOS, to support modern web technologies.

You have extensive knowledge and demonstrated experience in open source search and analytics engines like Elasticsearch (Setup, configuration, watcher, and alerts).
You have fluency in scripting languages like Python, Bash, C#, Java, React, JavaScript, Node, and others.
You have experience in build tools like Git, Ansible, Chef, Puppet, Terraform, and others for continuous integration.
You have integration experience using and building APIs.
You have worked with relational and non-relational databases like MySQL, MongoDB, and others.

Standards and Best Practices Skills: 25%

You have experience applying industry cloud and security standards and best practices to your work that can be adopted by others.
You have designed, implemented and maintained DevOps continuous delivery pipelines to manage from build to deployment and cloud infrastructure using Infrastructure as code practices.
You have knowledge of common authentication technologies, security controls, and standard application security tools.
You have experience securing environments using offensive and defensive approaches.
You have shared best practices and tools with your peers across the organization.
You can research industry best practices to support DevOps standards and apply them to your work.

Communication and Collaboration Skills: 15%

You are a strong communicator who collaborates on your work within a multi-disciplinary team.
You have strong leadership skills to support and guide team members.
You have experience influencing others by persuasion rather than authority â making your case through excellent communication, speaking clearly to be easily understood, and persuasive writing skills.
Your responsibilities include working closely with internal and external partners and team members.
You are comfortable leading discussions and selling your ideas to technical and non-technical colleagues, and senior management.

Project And Digital Expertise

You can articulate methods for build/buy decisions on project components, identify common IT risks and address them with contingency plans and back-out options.
You can analyze designs and determine coding, programming and integration activities to identify issues and provide product solutions.
You have worked on an established environment, balancing the need to address technical debt with new enhancements through continuous iterations.
You are adept at navigating complex issues, handling partners and stakeholder interactions.
You have worked with partners to establish relationships with their security, operations, and IT teams.
You have experience providing production support for multiple cloud environments with a focus on quality, security, reliability and scalability.

Must Haves

You are a seasoned expert in Azure among other cloud platforms.
You have experience in production environments such as Kubernetes (AKS).","{""role_summary"":""Design, build, and support cloud environments to create digital products, ensuring data integrity and security, and collaborating with teams to deliver high-quality solutions."",""key_terms"":[{""term"":""Cloud environments"",""explanation"":""Virtual computing environments that provide on-demand access to a shared pool of computing resources.""},{""term"":""Container-based virtualization technology"",""explanation"":""A method of virtualizing applications by packaging them with their dependencies into containers, ensuring consistency across environments.""},{""term"":""Microservice-based architectures"",""explanation"":""A software architecture that structures an application as a collection of small, independent services, each responsible for a specific business capability.""},{""term"":""DevOps tools and techniques"",""explanation"":""A set of practices that combines software development (Dev) and IT operations (Ops) to improve collaboration, automation, and delivery speed.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files, rather than graphical user interfaces.""}],""skill_priorities"":{""must_have"":[""Experience with Azure and other cloud platforms"",""Experience with Kubernetes (AKS) in production environments""],""nice_to_have"":[""Experience with Linux cloud environments (CentOS, Ubuntu, CoreOS)"",""Knowledge of container-based virtualization technology (Docker)"",""Experience with DevOps tools and techniques"",""Experience with microservice-based architectures"",""Knowledge of open source search and analytics engines (Elasticsearch)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data integrity and security in cloud environments?"",""example_answer"":""I implement safeguards such as access controls, encryption, and regular backups to maintain data integrity and protect against unauthorized access.""},{""question"":""Can you explain your experience with container-based virtualization technology?"",""example_answer"":""I have used Docker to package and deploy applications, ensuring consistency across environments and improving deployment efficiency.""}],""red_flags"":[""Lack of experience with Azure and other cloud platforms"",""Inability to work independently with high-level direction""],""confidence_score"":90.0}"
Cloud Engineer III,"OnX is a leading technology solution provider that serves businesses, healthcare organizations, and government agencies across Canada. OnX combines deep technical expertise with a full suite of flexible technology solutions—including Generative AI, Application Modernization, Managed Hybrid Cloud, Cybersecurity, Unified Communications, and Infrastructure solutions. From developing and deploying modern applications and the secure, scalable platforms on which they run, to managing, monitoring, and optimizing their operations, OnX delivers comprehensive technology solutions for its clients’ transformative business initiatives. For more information, please visit www.onx.com.

Overview

In today's rapidly evolving environment, organizations need to make data-driven decisions that deliver enterprise value. Our OnX Cloud and Artificial Intelligence practitioners design, develop, and implement large-scale data ecosystems, leveraging cloud-based platforms to integrate structured and unstructured data. We utilize automation, cognitive, and science-based techniques to manage data, predict scenarios, and prescribe actions. By continuously optimizing our cloud infrastructure and providing As-a-Service offerings, we ensure ongoing insights and improvements to enhance operational efficiency. We assist clients in transforming their businesses by developing organizational intelligence programs and strategies, enabling them to stay ahead in their markets.

Our Team Works With Clients To

Implement large-scale data ecosystems, including data management, governance, and the integration of structured and unstructured data to generate insights using cloud-based platforms.
Use automation, cognitive, and science-based techniques to manage data, predict scenarios, and prescribe actions.
Enhance operational efficiency by maintaining data ecosystems, sourcing analytics expertise, and providing As-a-Service offerings for continuous insights and improvements.

Responsibilities

As a Cloud Engineer, you will:

Design, develop, and implement large-scale data ecosystems: Collaborate with cross-functional teams to ensure seamless integration and deployment of data ecosystems in a DevOps environment, utilizing CI/CD, Docker, and Kubernetes.
Automate infrastructure provisioning and management using Infrastructure as Code (IaC) practices: Employ automation, cognitive, and science-based techniques to manage data, predict scenarios, and prescribe actions.
Support the technical implementation of cloud solutions: Troubleshoot and resolve technical issues to maintain operational efficiency. Provide technical guidance and support during the implementation and maintenance phases.
Optimize cloud infrastructure: Stay updated with the latest cloud technologies and best practices to ensure the infrastructure remains cutting-edge and provide solutions to complex data-related challenges. Maintain data ecosystems, source analytics expertise, and provide As-a-Service offerings for continuous insights and improvements.

Requirements

Required:

3-5 Years of Industry Experience
Hands-on experience with CI/CD pipelines, Docker, and Kubernetes.
Proven experience in cloud engineering or a similar role.
Strong understanding of cloud platforms (e.g., AWS, Azure, GCP).
Proficiency in Infrastructure as Code (IaC) tools, especially Terraform.
Solid understanding of networking, security, and DevOps practices.
Excellent problem-solving skills and the ability to troubleshoot complex technical issues.
2+ years of experience in Java, .NET or Python
Effective communication skills, written and oral

Nice To Have

Experience in Git, Redhat OpenShift, VMWare, Databricks, Snowflake, Python, OpenSearch, ElasticSearch, Oracle or MS SQL DBs
Familiarity with other IaC tools such as CloudFormation or Ansible.
Experience with monitoring and logging tools (e.g., Prometheus, Grafana, ELK stack).
AWS, Microsoft Azure or Google Cloud certifications

Education

Four years of College resulting in a Bachelor's Degree or equivalent Bachelor's in Business, Computer Science, Engineering, or related field

Due to U.S. Government requirements applicable to foreign-owned telecommunications providers, non-US citizens may be required to submit to an extensive government agency background check which will necessitate disclosure of sensitive Personally Identifiable Information.

The Pay Range For This Role Is

90,000 - 130,000 CAD per year(Remote - Toronto, CA)","{""role_summary"":""Design, develop, and implement large-scale data ecosystems as a Cloud Engineer, ensuring seamless integration and deployment of data ecosystems in a DevOps environment."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a practice that automates the build, test, and deployment of software applications.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice that manages and provisions infrastructure resources through code and configuration files, rather than manual processes.""},{""term"":""Cloud platforms"",""explanation"":""Cloud computing services provided by vendors such as AWS, Azure, and GCP, offering on-demand access to a shared pool of computing resources.""}],""skill_priorities"":{""must_have"":[""Hands-on experience with CI/CD pipelines, Docker, and Kubernetes"",""Proven experience in cloud engineering or a similar role"",""Strong understanding of cloud platforms"",""Proficiency in Infrastructure as Code (IaC) tools, especially Terraform"",""Solid understanding of networking, security, and DevOps practices"",""Excellent problem-solving skills and the ability to troubleshoot complex technical issues"",""2+ years of experience in Java, .NET or Python"",""Effective communication skills, written and oral""],""nice_to_have"":[""Experience in Git, Redhat OpenShift, VMWare, Databricks, Snowflake, Python, OpenSearch, ElasticSearch, Oracle or MS SQL DBs"",""Familiarity with other IaC tools such as CloudFormation or Ansible"",""Experience with monitoring and logging tools (e.g., Prometheus, Grafana, ELK stack)"",""AWS, Microsoft Azure or Google Cloud certifications""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a large-scale data ecosystem using cloud-based platforms?"",""example_answer"":""I would start by assessing the client's requirements and identifying the necessary data sources. Then, I would design a data ecosystem that integrates structured and unstructured data using cloud-based platforms such as AWS or Azure. I would also ensure seamless integration and deployment of the data ecosystem in a DevOps environment using CI/CD pipelines and IaC tools.""},{""question"":""How do you stay updated with the latest cloud technologies and best practices?"",""example_answer"":""I regularly follow industry blogs and attend webinars to stay updated on the latest cloud technologies and best practices. I also participate in online forums and communities to learn from others and share my own experiences.""}],""red_flags"":[""Lack of hands-on experience with CI/CD pipelines, Docker, and Kubernetes"",""Inability to troubleshoot complex technical issues"",""Poor communication skills, written and oral""],""confidence_score"":90.0}"
DevOps Engineer (Vancouver),"Gauss Labs is a leading innovator in AI solutions for the semiconductor industry. We are seeking an experienced DevOps Engineer to join our dynamic team. The ideal candidate will have 5-10 years of experience in DevOps, focusing on building and maintaining infrastructure, managing CI/CD pipelines, deploying cloud-native, and bare-metal applications, and supporting large-scale distributed systems.

Responsibilities

Build, deploy, and manage containerized applications using Docker and Kubernetes, ensuring scalability, reliability, and fault tolerance
Design, implement, and maintain CI/CD pipelines using GitHub Actions, Jenkins, and ArgoCD to ensure efficient and reliable software delivery
Ensure compliance with security standards such as NIST, SOC, and SEMI by implementing best practices and controls to maintain data security and integrity
Develop Infrastructure as Code (IaC) using Terraform to manage AWS environments, including network configurations, security groups, and resource provisioning
Optimize cloud infrastructure costs and performance by evaluating resource usage, identifying inefficiencies, and implementing solutions to reduce expenses while maintaining performance standards
Provide guidance and mentorship to engineers across the company, offering best practice advice on Kubernetes, deployment strategies, scalability solutions, and observability techniques


Basic Qualifications

Computer Science or related degree
5-10 years of experience in DevOps or Software Engineering roles, with a proven track record of supporting Kubernetes environments
Ability to write applications and tooling, contributing to development efforts and automating processes","{""role_summary"":""DevOps Engineer responsible for building, deploying, and managing containerized applications, ensuring scalability, reliability, and fault tolerance, while maintaining data security and integrity."",""key_terms"":[{""term"":""CI/CD pipelines"",""explanation"":""Continuous Integration and Continuous Deployment pipelines, which automate the build, test, and deployment of software applications.""},{""term"":""Containerized applications"",""explanation"":""Applications packaged with their dependencies and libraries into a single container, making them portable and easy to deploy.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files, rather than manual processes.""},{""term"":""Terraform"",""explanation"":""An open-source tool for managing and provisioning infrastructure resources, such as AWS environments, through Infrastructure as Code (IaC).""}],""skill_priorities"":{""must_have"":[""Kubernetes"",""CI/CD pipelines"",""Containerization (Docker)"",""Infrastructure as Code (Terraform)"",""Cloud computing (AWS)""],""nice_to_have"":[""GitHub Actions"",""Jenkins"",""ArgoCD"",""Security standards (NIST, SOC, SEMI)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure scalability and fault tolerance in a containerized application?"",""example_answer"":""I would use Kubernetes to orchestrate the containers, implement load balancing, and configure auto-scaling to ensure the application can handle increased traffic. Additionally, I would implement rolling updates and self-healing mechanisms to ensure fault tolerance.""},{""question"":""Can you explain how you would optimize cloud infrastructure costs and performance?"",""example_answer"":""I would use Terraform to manage AWS resources and implement cost optimization strategies such as rightsizing instances, reserved instances, and spot instances. I would also monitor resource usage and identify inefficiencies to reduce expenses while maintaining performance standards.""}],""red_flags"":[""Lack of experience with Kubernetes or containerization"",""Inability to write applications and tooling"",""No experience with Infrastructure as Code (IaC) or Terraform""],""confidence_score"":90.0}"
DevOps Data Engineer,"Dev Op's Engineer required downtown Toronto, for a Hybrid position working 3 days a week on-site

Responsibilities & tasks include
Data lake management (BQ)
Data analytics & processing
Execution and understanding of our Cloud infrastructure, to be able to design (GCP Cloud)
Individual contributor
Coding experience (programming fundamentals)
ServiceNow (good to have)
IAC
Familiarity with Terraform, Ansible and pipelines
Scripting and system administration experience
Splunk work
Database expertise in Clickhouse
Familiarity with building queries and materialized views
Experience with Grafana integration, PromQL, building dashboards and alerting
Splunk
Expertise in Splunk
Experience in data migration, Splunk query language and log based metrics
Understanding Splunk and build automation to migrate data and indexes
Fluent bit
Familiarity with regex, fluentbit, Ansible, networking, syslog configuration
Experience with fluentbit agent installation, configuration and distribution
IAC
Familiarity with Terraform, Ansible and pipelines
Scripting and system administration experience

Please apply directly via LinkedIn and suitable candidates will be contacted.","{""role_summary"":""A DevOps Engineer is required to manage data lakes, perform data analytics, and maintain cloud infrastructure, while also contributing to automation and scripting tasks."",""key_terms"":[{""term"":""Data lake management"",""explanation"":""Managing large repositories of raw, unprocessed data to facilitate analytics and reporting.""},{""term"":""IAC"",""explanation"":""Infrastructure as Code, a practice of managing and provisioning infrastructure through code and configuration files.""},{""term"":""Terraform"",""explanation"":""An open-source tool for infrastructure automation, allowing users to define and manage infrastructure as code.""},{""term"":""Ansible"",""explanation"":""An automation tool for configuring and managing infrastructure, applications, and services.""},{""term"":""Fluentbit"",""explanation"":""A lightweight, open-source log processor and forwarder for collecting and processing log data.""},{""term"":""Splunk"",""explanation"":""A data analytics and monitoring platform for machine-generated data, used for log analysis and incident response.""},{""term"":""GCP Cloud"",""explanation"":""Google Cloud Platform, a suite of cloud computing services offered by Google.""},{""term"":""BQ"",""explanation"":""BigQuery, a fully-managed enterprise data warehouse service offered by Google Cloud Platform.""},{""term"":""Clickhouse"",""explanation"":""A column-store database management system for analytics and data warehousing.""},{""term"":""Grafana"",""explanation"":""An open-source platform for building observability dashboards, used for data visualization and monitoring.""},{""term"":""PromQL"",""explanation"":""A query language used for Prometheus, a monitoring system and time series database.""}],""skill_priorities"":{""must_have"":[""Data lake management"",""Cloud infrastructure"",""Coding experience"",""Scripting and system administration experience"",""Familiarity with Terraform, Ansible and pipelines"",""Splunk expertise"",""Database expertise in Clickhouse"",""Experience with Grafana integration, PromQL, building dashboards and alerting""],""nice_to_have"":[""ServiceNow experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach data lake management, and what tools do you use for this task?"",""example_answer"":""I use BigQuery for data lake management, and I'm familiar with data warehousing concepts. I'd design a data lake that's scalable, secure, and optimized for analytics.""},{""question"":""Can you explain your experience with Splunk, and how you've used it for log analysis and incident response?"",""example_answer"":""I've used Splunk for log analysis, and I'm familiar with its query language and data visualization capabilities. I've also used it for incident response, creating dashboards and alerts to identify and respond to security threats.""},{""question"":""How do you stay up-to-date with the latest developments in cloud infrastructure, and what tools do you use for automation and scripting?"",""example_answer"":""I follow industry blogs and attend conferences to stay current with cloud infrastructure developments. I use Terraform and Ansible for automation and scripting, and I'm familiar with IAC principles.""}],""red_flags"":[""Lack of experience with Splunk or data lake management"",""Inability to write scripts or automate tasks"",""Limited understanding of cloud infrastructure or IAC principles""],""confidence_score"":90.0}"
DevOps Engineer (Canada Remote),"Company Overview

At Motorola Solutions, we believe that everything starts with our people. We’re a global close-knit community, united by the relentless pursuit to help keep people safer everywhere. Our critical communications, video security and command center technologies support public safety agencies and enterprises alike, enabling the coordination that’s critical for safer communities, safer schools, safer hospitals and safer businesses. Connect with a career that matters, and help us build a safer future.

Aperçu de l’entreprise

Chez Motorola Solutions, nous pensons que tout commence par nos employés. Nous sommes une communauté mondiale soudée, unie par la volonté incessante de contribuer à la sécurité des personnes partout dans le monde. Nos technologies de communication, de sécurité vidéo et de centre de commandement essentielles soutiennent les agences de sécurité publique et les entreprises, permettant une coordination essentielle pour des communautés, des écoles, des hôpitaux et des entreprises plus sécuritaires. Connectez-vous à une carrière qui compte et aidez-nous à bâtir un avenir plus sûr.

Department Overview

Rave Mobile Safety, a Motorola Solutions company, makes complex emergency response simple by building easy to use, trustworthy critical communication and collaboration software. Rave’s platform helps 9-1-1 call centers serve their communities, schools create a safe learning environment, and corporations protect their global workforce by helping them prepare better, respond faster, and communicate effectively during emergencies. Rave’s solutions were utilized in 40 million incidents representing billions of individual communications in 2022 alone. This is your opportunity to become a key contributor in a rapid growth SaaS company while representing a product suite that makes an impact on people’s lives.

Job Description

We’re looking for a highly skilled AWS DevOps Full-Stack Engineer with expertise in IaC (Terraform), Helm, MySQL, Kubernetes, and CI/CD Pipelines. You will play a key role in building, maintaining, securing and deploying scalable cloud infrastructure and systems.

Responsibilities:

Design, develop, and maintain scalable cloud infrastructure
Automate deployment, scaling and monitoring of systems on that infrastructure
Collaborate with cross-functional teams to define and implement CI/CD pipelines
Build and manage containerized applications
Provision and support configuration of relational databases with an emphasis on high availability, security and reliability
Monitor, troubleshoot, and optimize system performance and reliability
Contribute to the creation and operation of robust disaster recovery and backup strategies
Manage developer tooling
Ensure compliance with regulatory, compliance and security frameworks
(Optionally) develop and support full stack Java-based applications

Required Skills:

Experience designing and deploying solutions to cloud environments (AWS)
Experience with IaC tooling (Terraform or similar)
Experience with containers and container orchestration tooling (Kubernetes / Helm / Docker)
Experience with CI/CD tooling (GitHub, BitBucket, Azure DevOps)
Experience with DVCS tooling (Git, GitHub, BitBucket, Azure DevOps)
Experience with RDBMS systems including managing schema evolution, migration, replication and disaster recovery (MySQL or similar)
Experience with Linux including scripting (Bash)

Preferred Skills:

Familiarity with TCP/IP networking and troubleshooting tools (WireShark, TCPDump, SNGrep, nslookup)
Awareness of compliance frameworks (e.g. FedRAMP, CCCS)
Experience with SIP/RTP
Experience with developer tooling (Artifactory, Sonar, Gradle)
Familiarity with observability tooling (Prometheus/Grafana, ELK Stack or similar)
Knowledge of secure coding practices, security frameworks, and tooling (e.g., OWASP, NIST, CIS, Prisma Cloud/Twistlock, Mend/WhiteSource)

Soft Skills:

Strong problem-solving and analytical skills
Effective communication and teamwork abilities
Self-motivated with a passion for continuous learning
Ability to take ownership of problems and deliver complete solutions

Note: Candidate can reside anywhere in Canada.

Basic Requirements

10+ years of software engineering/development experience
AND 5+ years of cloud infrastructure experience

Travel Requirements

None

Relocation Provided

None

Position Type

Experienced

Referral Payment Plan

Yes

EEO Statement

Motorola Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion or belief, sex, sexual orientation, gender identity, national origin, disability, veteran status or any other legally-protected characteristic.

We are proud of our people-first and community-focused culture, empowering every Motorolan to be their most authentic self and to do their best work to deliver on the promise of a safer world. If you’d like to join our team but feel that you don’t quite meet all of the preferred skills, we’d still love to hear why you think you’d be a great addition to our team.

We’re committed to providing an inclusive and accessible recruiting experience for candidates with disabilities, or other physical or mental health conditions. To request an accommodation, please email ohr@motorolasolutions.com.

Motorola Solutions adopte, favorise et promeut les principes de diversité, d’équité et d’inclusion. Nous encourageons et accueillons les candidatures de toutes les personnes qualifiées, quelles que soient leur race, origines ethnique, religion ou croyance, orientation sexuelle, identité et expression sexuelle, statut d’anciens combattants ou tout autre statut protégé par la Loi.

Nous sommes fiers de notre culture axée sur les personnes et les communautés, encourageant ainsi chaque Motorolan d’être la version la plus authentique de lui-même dans ses responsabilités afin de tenir la promesse d’un monde plus sécuritaire.

Si vous souhaitez vous joindre à notre communauté mais croyez que vous ne possédez pas toutes les exigences requises pour le poste convoité, nous aimerions tout de même connaître les raisons pour lesquelles vous pensez être un excellent candidat pour notre équipe.

Nous offrons également des mesures d’adaptation pendant toutes les étapes du processus d’embauche afin de favoriser l’inclusion des personnes vivant avec un handicap physique et/ou mental. Si vous avez besoin de mesures d’adaptation, svp nous faire parvenir un courriel à ohr@motorolasolutions.com.","{""role_summary"":""Design, develop, and maintain scalable cloud infrastructure as an AWS DevOps Full-Stack Engineer, ensuring high availability, security, and reliability."",""key_terms"":[{""term"":""IaC (Terraform)"",""explanation"":""Infrastructure as Code, a practice of managing infrastructure configuration through code, using tools like Terraform.""},{""term"":""Helm"",""explanation"":""A package manager for Kubernetes, used to manage and deploy applications.""},{""term"":""CI/CD Pipelines"",""explanation"":""Continuous Integration and Continuous Deployment pipelines, automating the build, test, and deployment of software.""},{""term"":""Kubernetes"",""explanation"":""A container orchestration system, automating deployment, scaling, and management of containerized applications.""},{""term"":""MySQL"",""explanation"":""A relational database management system, used for storing and managing data.""}],""skill_priorities"":{""must_have"":[""AWS"",""IaC (Terraform)"",""Helm"",""Kubernetes"",""CI/CD Pipelines"",""MySQL"",""Linux"",""Git""],""nice_to_have"":[""TCP/IP networking"",""Compliance frameworks (e.g. FedRAMP, CCCS)"",""SIP/RTP"",""Developer tooling (Artifactory, Sonar, Gradle)"",""Observability tooling (Prometheus/Grafana, ELK Stack)""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a scalable cloud infrastructure for a high-traffic application?"",""example_answer"":""I would use Terraform to define the infrastructure as code, and then use Helm to deploy and manage the application on Kubernetes. I would also ensure that the infrastructure is scalable, secure, and reliable, with proper monitoring and logging in place.""},{""question"":""How do you handle database schema evolution, migration, replication, and disaster recovery in a cloud environment?"",""example_answer"":""I would use MySQL to manage the relational database, and then use tools like Terraform and Helm to automate the deployment and management of the database. I would also ensure that the database is properly backed up and replicated, with a disaster recovery plan in place.""}],""red_flags"":[""Lack of experience with cloud infrastructure (AWS)"",""Inability to work with containerized applications"",""Insufficient knowledge of security frameworks and compliance""],""confidence_score"":90.0}"
DevOps Engineer 3 (Platform),"About Behavox

Behavox is shaping the future for how businesses harness their most important raw material - data. Our mission is bold: Organize enterprise data into actionable information that protects and promotes the business growth of multinational companies around the world.

From managing enterprise risk and compliance to maximizing revenue and value, our data operating platform presents a widespread opportunity to build multilingual, AI/ML-based solutions that activate data for every function within a global enterprise.

Our approach is unique, and it’s validated by our customers who tell us to keep forging ahead because no one else is aggregating, analyzing, and acting on data to uncover opportunities or solve problems quite the way we are.

We are looking for fearless innovators who have an insatiable appetite for building what no one has built before.

About The Role

At Behavox, we're exploring the concept of an Internal Development Platform (IDP) to empower product developers with self-service capabilities.

This involves providing clear 'golden paths' to guide developers effectively through each stage of the development lifecycle.

As an SRE Engineer 3 (Platform Team), you will play a critical role in the design and implementation of such IDP.

You will collaborate with stakeholders across various products to understand their requirements, identify common needs, and incorporate these into the IDP.

We already support:

Self-service addition of new services
Self-service cloud configuration using developer-friendly syntax
Easy onboarding of new products, with a complete set of ready-to-use building blocks (build, test, deploy)
Support for both multi-tenant and single-tenant products
Fully automated CI/CD pipeline - from developer commits to production deployment

With more products on the way, we need your help to scale the platform further, enhance developer convenience, and make 'golden paths' more 'golden'

What You'll Bring

A deep and genuine interest in Behavox as demonstrated by a connection to its mission, marketplace and/or technologies
5+ years of experience in a DevOps/SRE/Platform engineering role
Development and scripting skills in Python and Golang
Experience with GCP/AWS Infrastructure as a Code (IaaC)
Hands-on experience in building CI/CD systems using GitLab and Jenkins

What You'll Do

Design, build, and maintain internal DevOps and platform microservices
Automate operational tasks using Python or Golang
Manage infrastructure across GCP and AWS
Design and implement CI/CD pipelines
Debug complex distributed systems and software products

What We Offer

A truly global mission with a passionate community in locations all over the world
Huge impact and learning potential as our aspirations require bold innovation
Highly competitive compensation with 100% bonus pay already integrated
Benefits include great health coverage for employee and family
Generous time-off policy and flexible work schedule

About Our Process

We take Talent very seriously and we are building a community of extraordinary individuals working together in very high-performing teams. We also know that the best Talent always has options so we believe that the process has to be a two way assessment - the company AND the candidate assessing the business needs alignment, the career next step alignment, and the cultural alignment.

During the process we will begin by exploring the core factors regarding salary and location along with core experience and skills and values alignment. We will then deep dive explore the critical technical competencies we have identified for the role, and then we will deep dive in behavioral competencies.

The most aligned candidate will then be asked to do a practical work task simulation activity so we can make sure that you will enjoy the kind of work the role requires, and this task will typically be presented and discussed with a group of colleagues and managers.","{""role_summary"":""Design and implement an Internal Development Platform (IDP) to empower product developers with self-service capabilities, providing 'golden paths' to guide developers through each stage of the development lifecycle."",""key_terms"":[{""term"":""Internal Development Platform (IDP)"",""explanation"":""A platform that empowers product developers with self-service capabilities, providing guided paths for development lifecycle stages.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development (Dev) and IT operations (Ops) to improve collaboration and efficiency.""},{""term"":""SRE Engineer"",""explanation"":""A Site Reliability Engineer responsible for ensuring the reliability and performance of software systems.""},{""term"":""GCP/AWS Infrastructure as Code (IaaC)"",""explanation"":""A practice that manages and provisions cloud infrastructure using code and configuration files.""},{""term"":""CI/CD pipeline"",""explanation"":""A continuous integration and continuous deployment pipeline that automates the build, test, and deployment of software.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in a DevOps/SRE/Platform engineering role"",""Development and scripting skills in Python and Golang"",""Experience with GCP/AWS Infrastructure as a Code (IaaC)"",""Hands-on experience in building CI/CD systems using GitLab and Jenkins""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design and implement a self-service cloud configuration system for developers?"",""example_answer"":""I would use Infrastructure as Code (IaaC) tools like Terraform or CloudFormation to create a modular and reusable cloud infrastructure. I would also implement a developer-friendly syntax for easy configuration and deployment.""},{""question"":""Can you explain how you would automate operational tasks using Python or Golang?"",""example_answer"":""I would use Python or Golang to write scripts that automate tasks such as backups, deployments, and monitoring. I would also use tools like Ansible or SaltStack for automation and orchestration.""}],""red_flags"":[""Lack of experience with cloud infrastructure and IaaC"",""Inability to write scripts in Python or Golang"",""No experience with CI/CD pipelines and automation""],""confidence_score"":90.0}"
Cloud Devops Engineer,"Proficiency in containerization technologies such as Docker and Kubernetes.
Hands-on experience with front-end framework like React, Vue.js, Next.js or Angular.js
Experience in infrastructure as code (IaC) using Terraform, particularly with AWS provider
Strong Coding skills in Python, Java or Scala for data processing task.
Proficient in integrating Single Sign-On (SSO) with Microsoft Azure AD using OAuth, OpenID Connect (OIDC) and SAML protocols.
Solid Understanding of relational and NoSQL database, such as PostgreSQL, MySQL, DynamoDB or MongoDB.
Familiarity with data pipelines orchestration tools such as Airflow or Flask.
Proficiency in data transformation and ETL process, including tools like Apache Spark or Glue.
Strong experience with cloud platforms, especially AWS, including services like Lambda, S3, RDS and Glue
Familiarity with big data technologies, including Hadoop, Hive or Redshift
Experience with user authentication and authorization using AWS Cognito.
Expertise in API development, security and implementing best practices for scalable solutions.
Experience with monitoring and logging tools, such as Prometheus, Grafana or ELK Stack to ensure system reliability and application performance.
Strong understanding of DevOps principles, CI/CD pipelines and best practices.
Experience with core AWS technologies such as EC2, ELB, Auto Scaling, S3, EFS, Lambda, API Gateway, Step Functions, CloudWatch, VPC, Route 53, ACM.
Experience with BI tools like Tableau, AWS Quick Sight","{""role_summary"":""A software engineer responsible for developing scalable solutions using cloud platforms, containerization technologies, and various programming languages, with a focus on data processing, integration, and security."",""key_terms"":[{""term"":""Containerization"",""explanation"":""A technology that allows multiple applications to run on a single host operating system, improving resource utilization and deployment efficiency.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files, rather than manual processes.""},{""term"":""Single Sign-On (SSO)"",""explanation"":""A system that enables users to access multiple applications or services with a single set of login credentials, improving user experience and security.""},{""term"":""ETL (Extract, Transform, Load)"",""explanation"":""A process of extracting data from various sources, transforming it into a standardized format, and loading it into a target system for analysis or reporting.""},{""term"":""CI/CD (Continuous Integration/Continuous Deployment)"",""explanation"":""A set of practices that automate the build, test, and deployment of software applications, ensuring faster time-to-market and improved quality.""}],""skill_priorities"":{""must_have"":[""Docker"",""Kubernetes"",""React or Vue.js or Next.js or Angular.js"",""Terraform"",""Python or Java or Scala"",""AWS"",""OAuth"",""OpenID Connect (OIDC)"",""SAML"",""API development"",""DevOps principles"",""CI/CD pipelines""],""nice_to_have"":[""Airflow"",""Flask"",""Apache Spark"",""Glue"",""Hadoop"",""Hive"",""Redshift"",""Tableau"",""AWS Quick Sight""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you handle containerization in a microservices architecture?"",""example_answer"":""I use Docker to create containers for each microservice, and then orchestrate them using Kubernetes to ensure efficient resource utilization and scalability.""},{""question"":""Can you explain the benefits of using Infrastructure as Code (IaC) in a cloud-based environment?"",""example_answer"":""IaC allows us to manage infrastructure resources through code, which improves version control, reduces errors, and enables faster deployment and scaling.""},{""question"":""How do you implement Single Sign-On (SSO) using OAuth and OpenID Connect (OIDC) protocols?"",""example_answer"":""I use OAuth to authenticate users and obtain an access token, which is then used to authenticate with the OpenID Connect (OIDC) provider, enabling SSO across multiple applications.""}],""red_flags"":[""Lack of experience with cloud platforms, particularly AWS"",""Inability to write clean, efficient, and well-documented code"",""Limited understanding of DevOps principles and CI/CD pipelines""],""confidence_score"":95.0}"
Cloud Services Engineer,"Description

About Us

At Versa Networks, we're revolutionizing the way businesses connect, secure, and optimize their networks. Our mission is to secure anywhere, anytime access to anything. As a leader in Secure SD-WAN, SSE (Secure Service Edge), SASE (Secure Access Service Edge) and Next-generation Managed Services, we are empowering organizations across the globe to transform their IT infrastructure for the modern cloud era. Our innovative products enable enterprises to deliver a seamless, scalable, and secure digital experience, no matter where their users, devices, or applications are located. Founded by industry veterans and backed by premier venture capital firms, Versa is a market leader driving innovation and growth as it positions itself for a future IPO.

We believe in fostering a culture of innovation, collaboration, and customer success. Our team is comprised of passionate, forward-thinking professionals dedicated to driving the future of networking technology. We encourage creativity, offer opportunities for growth, and provide a dynamic environment where our people can thrive and make an impact.

At Versa Networks, we don’t just build products – we build relationships, elevate businesses, and shape the digital future. Join us and be part of a fast-paced, cutting-edge company that's making a real difference in how the world connects and communicates.

Job Summary

We are looking for Cloud Services Engineer to join our Cloud Services Team. Your main responsibility will be to build cloud-scale micro-services for various projects in cloud security.

Responsibilities

Discover, Catalog and Annotate Cloud Applications
Perform In-depth Research and Analysis of Cloud Applications and Document them
Research APIs, Protocol, Headers and Data of Cloud Applications
Design, integrate security of Cloud Applications in on-premises and cloud environments
Write effective, maintainable, and well-tested code

Qualifications

BS or MS degree in Computer Science, Electrical Engineering or related field
5-10 years of related development experience
Strong cloud application programming skills
Experience working with security frameworks and cloud security paradigms
Containerization and Orchestration: Hands-on experience with Kubernetes or Docker, allowing you to manage containerized applications effectively.
Experience working with Ubuntu OS.
Expertise in platforms like AWS, Azure, or Google Cloud is added advantage
Utilize automation tools such as Ansible, Terraform, Helm and CloudFormation to streamline cloud environment provisioning.
Experience design, analysis, implementation, and maintenance of Rest APIs
Good oral and written communication
Additional Skills
Thorough understanding of web-scale/planet-scale applications
Thorough understanding of virtualization technologies and multiple cloud environments
Understanding of database technologies with hands on experience in any databases like redis, mongoDB
Experience with programming languages like Python, GoLang
Location: Canada

Applicants must be authorized to work in the Canada

The pay range for this position at commencement of employment in California, Washington, or New York City is expected in the range of $100,000 CAD to $125,000 CAD. A candidate’s specific pay within this range will depend on a variety of factors, including job-related skills, training, location, experience, relevant education, certifications, and other business and organizational needs.

Why Versa?

Benefits

At Versa Networks, we believe in taking care of our people – both professionally and personally. We offer a comprehensive benefits package designed to support the well-being, growth, and work-life balance of our employees. When you join our team, you can expect:

Competitive Salary & Incentives: We offer a competitive compensation package with and pre-IPO equity to reward your hard work and dedication.
Health & Wellness: Comprehensive medical, dental, and vision insurance plans to ensure you and your family stay healthy and covered.
Paid Time Off (PTO): Enjoy a generous PTO policy that includes vacation days, sick leave, and paid holidays to recharge and take care of personal matters.
Flexible Work Environment: We understand the importance of work-life balance. Enjoy the flexibility of remote work, and hybrid option to create the work schedule that works best for you.
Professional Development: We believe in continuous learning. Access to training, certifications, and educational resources to help you grow in your career and stay ahead of industry trends.
Employee Recognition: We celebrate achievements both big and small, with regular recognition programs and awards that highlight your contributions to our collective success.
Collaborative Culture: Be part of a dynamic, inclusive, and supportive team where innovation and collaboration are at the heart of everything we do.
Parental Leave: Generous parental leave policies to support you during life's important moments.

At Versa Networks, our benefits are designed to help you thrive both inside and outside the office. Join us and experience a rewarding, fulfilling career in a supportive environment that values your health, happiness, and success.

Versa Networks is an Equal Opportunity Employer. We are committed to providing equal employment opportunities to all employees and applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other protected characteristic. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.","{""role_summary"":""Design, integrate, and maintain cloud-scale micro-services for various projects in cloud security as a Cloud Services Engineer."",""key_terms"":[{""term"":""Cloud security paradigms"",""explanation"":""Approaches and principles for securing cloud-based applications and data.""},{""term"":""Containerization"",""explanation"":""A method of deploying applications in containers, such as Docker, to improve portability and efficiency.""},{""term"":""Orchestration"",""explanation"":""The process of automating and managing the deployment of containerized applications, often using tools like Kubernetes.""},{""term"":""Web-scale/planet-scale applications"",""explanation"":""Large-scale applications designed to handle high traffic and large user bases, often using distributed architectures.""},{""term"":""Virtualization technologies"",""explanation"":""Software that creates a virtual version of a physical environment, such as servers or storage, to improve efficiency and flexibility.""}],""skill_priorities"":{""must_have"":[""Cloud application programming skills"",""Experience with security frameworks and cloud security paradigms"",""Containerization and orchestration experience with Kubernetes or Docker"",""Experience with Ubuntu OS"",""Experience with automation tools like Ansible, Terraform, Helm, and CloudFormation""],""nice_to_have"":[""Expertise in platforms like AWS, Azure, or Google Cloud"",""Experience with programming languages like Python, GoLang"",""Understanding of database technologies with hands-on experience in any databases like Redis, MongoDB""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement security for a cloud-based application?"",""example_answer"":""I would start by identifying the application's security requirements and then implement a layered security approach using a combination of security frameworks and cloud security paradigms. I would also ensure that the application is properly configured and monitored to detect and respond to potential security threats.""},{""question"":""How do you manage and orchestrate containerized applications?"",""example_answer"":""I use tools like Kubernetes to automate the deployment and scaling of containerized applications. I also ensure that the containers are properly configured and monitored to ensure high availability and performance.""}],""red_flags"":[""Lack of experience with cloud security paradigms"",""Inability to design and implement secure cloud-based applications"",""Limited understanding of containerization and orchestration""],""confidence_score"":90.0}"
"Cloud Engineer, Deloitte Global Technology","Job Type: PermanentWork Model: RemoteReference code: 127916Primary Location: Toronto, ONAll Available Locations: Toronto, ON; Calgary, AB; Vancouver, BC

Our Purpose

At Deloitte, our Purpose is to make an impact that matters. We exist to inspire and help our people, organizations, communities, and countries to thrive by building a better future. Our work underpins a prosperous society where people can find meaning and opportunity. It builds consumer and business confidence, empowers organizations to find imaginative ways of deploying capital, enables fair, trusted, and functioning social and economic institutions, and allows our friends, families, and communities to enjoy the quality of life that comes with a sustainable future. And as the largest 100% Canadian-owned and operated professional services firm in our country, we are proud to work alongside our clients to make a positive impact for all Canadians.

By living our Purpose, we will make an impact that matters.

Have many careers in one Firm.
Enjoy flexible, proactive, and practical benefits that foster a culture of well-being and connectedness.
Learn from deep subject matter experts through mentoring and on the job coaching


What will your typical day look like?

In this role, you will:

Design and prototype Application Programming Interface (API) specifications to support provisioning of cloud infrastructure and services, automate controls and compliance, and support a more consistent, predictable, and secure delivery of cloud platform services.
Contribute to engineering and architectural strategic direction and thought leadership for cloud platform solutions.
Partner with business-led development teams to understand application lifecycle challenges and design cloud platform solutions to automate and streamline their processes.
Participate in planning and workshops with the cloud platform development team to meet cloud software development expectations and milestones.
Have a deep understanding of IaaS and PaaS services offered on the various cloud platforms and understand how to use them together to build complex solutions.
Cultivate and participate in the DevOps culture and practices by deeply understanding the tools, processes, and mindset.
Ensure cloud platform development teams are using the full set of DevOps tools by continuously reviewing and leading the establishment of the right tooling and processes that will result in a stable, consistent and fully automated build/release pipeline.
Be a trusted automation and tooling advisor for DevOps initiatives by providing objective, practical and relevant ideas, insights and advice.
Partner with business, development, and operations teams to design and prototype practical automation solutions and custom modules.
Troubleshoot automation issues and find practical solutions that move projects forward in a timely manner.
Plan, organize, and control multiple responsibilities to achieve project objectives; technically guide projects through to completion.
Ensure deliverables are completed within target timeframes and are consistently of high-quality.

About The Team

Deloitte Technology works at the forefront of technology development and processes to support and protect Deloitte around the world. In this truly global environment, we operate not in ""what is"" but rather ""what can be"" to help Deloitte deliver and connect with its clients, its communities, and one another in ways not previously conceived.

Enough about us, let’s talk about you

You bring the following:

A bachelor’s degree in computer science, Business Information Systems or similar
Public Cloud certifications (Azure, AWS, GCP)
SAFe, Agile, or Scrum certifications
Advanced proficiency with cloud solution architecture (Azure, AWS, or Google Cloud);
Agile development methodology and practices (Scaled Agile Framework or SAFe preferred); planning tools (e.g. Azure DevOps, Jira);
Advanced proficiency with using continuous integration tools (e.g. Azure DevOps, Jenkins) and p roficiency with code management tools (e.g. GitHub, BitBucket);
Intermediate proficiency with backend API design and development (e.g. OpenAPI Spec, Swagger, C# .NET, Python); configuration management tools (Puppet, Chef, Ansible);
Advanced proficiency in scripting (PowerShell, Perl, Bash);
Intermediate proficiency in enterprise application, server, software and networking architecture and troubleshooting; Windows Server administration; Linux/Unix administration; proficiency with database operations and queries (e.g. MS SQL Server, T-SQL, Mysql, MongoDB);
Familiarity with cloud security/compliance standards (ISO 27001, CIS, NIST); datacenter infrastructure (DNS, LDAP, email relays, etc.); virtualization (Hyper-V, VMWare, Openstack);
Knowledge of best practices for IT operations in an always-on, always-available service model;
Exceptional communication skills and the ability to communicate appropriately with corporate executives and technical teams; influencing and reasoning skills; good at conflict resolution and consensus building.

Total Rewards

The salary range for this position is $85,000 - $156,000, and individuals may be eligible to participate in our bonus program. Deloitte is fair and competitive when it comes to the salaries of our people. We regularly benchmark across a variety of positions, industries, sectors, targets, and levels. Our approach is grounded on recognizing people's unique strengths and contributions and rewarding the value that they deliver.

Our Total Rewards Package extends well beyond traditional compensation and benefit programs and is designed to recognize employee contributions, encourage personal wellness, and support firm growth. Along with a competitive base salary and variable pay opportunities, we offer a wide array of initiatives that differentiate us as a people-first organization. Some representative examples include: $4,000 per year for mental health support benefits, a $1,300 flexible benefit spending account, 38+ days off (including 10 firm-wide closures known as ""Deloitte Days""), flexible work arrangements and a hybrid work structure.

Our promise to our people: Deloitte is where potential comes to life.

Be yourself, and more.

We are a group of talented people who want to learn, gain experience, and develop skills. Wherever you are in your career, we want you to advance.

You Shape How We Make Impact.

Diverse perspectives and life experiences make us better. Whoever you are and wherever you’re from, we want you to feel like you belong here. We provide flexible working options to support you and how you can contribute.

Be the leader you want to be

Some guide teams, some change culture, some build essential expertise. We offer opportunities and experiences that support your continuing growth as a leader.

Have as many careers as you want.

We are uniquely able to offer you new challenges and roles – and prepare you for them. We bring together people with unique experiences and talents, and we are the place to develop a lasting network of friends, peers, and mentors.

The next step is yours

At Deloitte, we are all about doing business inclusively – that starts with having diverse colleagues of all abilities. Deloitte encourages applications from all qualified candidates who represent the full diversity of communities across Canada. This includes, but is not limited to, people with disabilities, candidates from Indigenous communities, and candidates from the Black community in support of living our values, creating a culture of Diversity Equity and Inclusion and our commitment to our AccessAbility Action Plan , Reconciliation Action Plan and the BlackNorth Initiative .

We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation for the recruitment process (including alternate formats of materials, accessible meeting rooms or other accommodations) or indigenouscareers@deloitte.ca for any questions relating to careers for Indigenous peoples at Deloitte (First Nations, Inuit, Métis).

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.

Deloitte Canada has 20 offices with representation across most of the country. We acknowledge that Deloitte offices stand on traditional, treaty, and unceded territories in what is now known as Canada. We recognize that Indigenous Peoples have been the caretakers of this land since time immemorial, nurturing its resources and preserving its natural beauty. We acknowledge this land is still home to many First Nations, Inuit, and Métis Peoples, who continue to maintain their deep connection to the land and its sacred teachings. We humbly acknowledge that we are all Treaty people, and we commit to fostering a relationship of respect, collaboration, and stewardship with Indigenous communities in our shared goal of reconciliation and environmental sustainability.","{""role_summary"":""Design and prototype cloud infrastructure and services, automate controls and compliance, and support a more consistent, predictable, and secure delivery of cloud platform services."",""key_terms"":[{""term"":""API"",""explanation"":""Application Programming Interface, a set of defined rules that enable different applications to communicate with each other.""},{""term"":""IaaS"",""explanation"":""Infrastructure as a Service, a cloud computing model that provides virtualized computing resources over the internet.""},{""term"":""PaaS"",""explanation"":""Platform as a Service, a cloud computing model that provides a complete development and deployment environment for applications.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""SAFe"",""explanation"":""Scaled Agile Framework, a methodology that helps large teams and organizations implement agile practices.""}],""skill_priorities"":{""must_have"":[""Public Cloud certifications (Azure, AWS, GCP)"",""Advanced proficiency with cloud solution architecture"",""Agile development methodology and practices"",""Advanced proficiency with continuous integration tools"",""Intermediate proficiency with backend API design and development""],""nice_to_have"":[""SAFe, Agile, or Scrum certifications"",""Familiarity with cloud security/compliance standards"",""Knowledge of best practices for IT operations in an always-on, always-available service model""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the differences between IaaS and PaaS cloud computing models?"",""example_answer"":""IaaS provides virtualized computing resources, while PaaS provides a complete development and deployment environment for applications. IaaS gives more control over the infrastructure, whereas PaaS provides more abstraction and ease of use.""},{""question"":""How do you ensure consistency and automation in cloud platform development?"",""example_answer"":""I use continuous integration tools like Azure DevOps and Jenkins to automate the build and release pipeline. I also ensure that the development team follows DevOps practices and uses the right tooling and processes to achieve consistency.""}],""red_flags"":[""Lack of experience with public cloud certifications"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Cloud Architect,"Cloud Architect – Hybrid (Vancouver, BC, Canada)
Contract: 1 year (high likelihood of extension or conversion)
Pay Rate: Up to $110/hr

My client is a global leader in the gaming industry, known for creating some of the most iconic and immersive entertainment experiences in the world. With a portfolio that includes blockbuster franchises enjoyed by millions, they are at the forefront of innovation in cloud infrastructure, multiplayer gaming, and large-scale content delivery. Their technology powers seamless, high-performance gaming experiences, pushing the limits of what’s possible in interactive entertainment.

They are looking for a Cloud Architect to design and optimize scalable cloud infrastructure, supporting cutting-edge game development and live services. This role requires expertise in DevOps, cloud platforms (AWS, Azure, GCP), and infrastructure automation, ensuring the company's systems remain highly available, secure, and efficient.
Responsibilities:

Design and implement scalable cloud infrastructure for large-scale gaming applications.
Develop Infrastructure as Code (IaC) solutions using Terraform, Python, and Go.
Manage containerized workloads with Kubernetes and Docker, optimizing for high availability and performance.
Implement and manage CI/CD pipelines with ArgoCD.
Monitor system performance and security using Grafana and other observability tools.
Collaborate with game developers, DevOps teams, and security engineers to optimize cloud environments.

Requirements:
5+ years of experience as a Cloud Architect or DevOps Engineer,
Expertise in AWS, Azure, or GCP, with hands-on experience in multi-cloud environments.
Strong knowledge of Kubernetes, Docker, and container orchestration.
Proficiency in Infrastructure as Code (Terraform) and scripting languages (Python, Go).
Experience with ArgoCD, Grafana, and cloud security best practices.
Strong problem-solving skills and the ability to work in a fast-paced, collaborative environment.

As a Cloud Architect, you will:
Work with a team of top-tier engineers at a company that sets the gold standard for gaming technology.
Build and scale cloud infrastructure that supports millions of players worldwide.
Be part of a culture that values innovation, creativity, and technical excellence.

If you’re a passionate Cloud Architect and want to work at the intersection of gaming and large-scale infrastructure, this is the opportunity for you!

We make an active choice to be inclusive towards everyone every day. Let us know if you have any accessibility requirements or would like to apply for this role another way by emailing: george.ethell@signify-tech.com

(Skillset: Cloud Architect, DevOps, AWS, Azure, GCP, Kubernetes, IaC, Terraform, Python, Go, ArgoCD, Grafana, Cloud Security, Security, Finance, FinOps, CI/CD, Docker, Cloud)","{""role_summary"":""Design and optimize scalable cloud infrastructure to support cutting-edge game development and live services, ensuring high availability, security, and efficiency."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice that manages and provisions infrastructure resources through code and configuration files, rather than through graphical user interfaces.""},{""term"":""Container orchestration"",""explanation"":""The automated management of containerized applications, including deployment, scaling, and networking.""},{""term"":""CI/CD pipelines"",""explanation"":""Automated workflows that integrate code changes from development to production, ensuring continuous integration and delivery.""}],""skill_priorities"":{""must_have"":[""Cloud Architect or DevOps Engineer experience"",""Expertise in AWS, Azure, or GCP"",""Kubernetes and Docker experience"",""Terraform and scripting languages (Python, Go) proficiency"",""ArgoCD, Grafana, and cloud security best practices experience""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing scalable cloud infrastructure for large-scale gaming applications?"",""example_answer"":""I would consider factors such as high availability, security, and performance, and design a multi-cloud strategy using AWS, Azure, or GCP. I would also implement Infrastructure as Code (IaC) solutions using Terraform and scripting languages like Python and Go.""},{""question"":""Can you explain your experience with container orchestration using Kubernetes and Docker?"",""example_answer"":""I have hands-on experience with Kubernetes and Docker, and have successfully implemented containerized workloads in a cloud environment. I understand the importance of optimizing for high availability and performance.""}],""red_flags"":[""Lack of experience with multi-cloud environments"",""Inability to work in a fast-paced, collaborative environment""],""confidence_score"":95.0}"
Cloud Data Engineer,"DataOps/Cloud Data Engineer - Azure
Duration: 12+ Months contract
Hybrid
Toronto,ON

Experience:

Cloud DataOPS
· Expert experience with Microsoft Azure technologies, including Azure pipeline, DACPAC, storage account, disk, file share, Azure key vault, Azure portal, virtual machine, Azure DevOps, Data Lake, Data Lakehouse, Azure monitoring tools.
· Experience with Cloud data platforms, data management and data exchange tools and technologies.
· Experience with Data pipeline and workflow development, orchestration, deployment, and automation.
· Experience in DataOPS principle, best practice, and implementation and Agile project development and deployment.
· Experience in Continuous Integration/Continuous Development/Deployment (CI/CD) and Data provisioning Automation.
· Experience with digital product, data analysis, data exchange, data provisioning, and data security.
· Experience with structured, semi-structured, unstructured data collection, ingestion, provisioning and exchange technological development.
· Experience with DataOPS performance monitoring and tuning.

Database Management
· Expert data/database administration experience, e.g., Microsoft Azure SQL database and Synapse database, Oracle, IMS, DB2, etc.
· Extensive experience with SQL Server Stored Procedure, Oracle PL/SQL, PL/1 development and performance tuning.
Data Replication Pipelines
· Experience with Azure SQL, Oracle, IMS/DB2 data replication.","{""role_summary"":""Design, develop, and maintain cloud-based data pipelines and workflows on Microsoft Azure, ensuring efficient data management, exchange, and security."",""key_terms"":[{""term"":""Cloud DataOPS"",""explanation"":""A set of practices that combines data engineering and DevOps to manage data pipelines and workflows in cloud environments.""},{""term"":""Azure pipeline"",""explanation"":""A cloud-based service for automating and managing the build, test, and deployment of software applications.""},{""term"":""DACPAC"",""explanation"":""A file format used to package and deploy SQL Server databases to Microsoft Azure.""},{""term"":""Data Lake"",""explanation"":""A centralized repository that stores raw, unprocessed data in its native format, allowing for flexible data analysis and processing.""},{""term"":""Data Lakehouse"",""explanation"":""A data management architecture that combines the benefits of data warehouses and data lakes, providing a unified platform for data storage and analysis.""},{""term"":""Azure DevOps"",""explanation"":""A set of cloud-based services for collaborative software development, delivery, and deployment.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a software development practice that automates the build, test, and deployment of code changes.""},{""term"":""DataOPS principle"",""explanation"":""A set of best practices for managing data pipelines and workflows, focusing on automation, monitoring, and collaboration.""}],""skill_priorities"":{""must_have"":[""Microsoft Azure technologies"",""Cloud DataOPS"",""Data pipeline development"",""Data management and exchange tools"",""DataOPS principle and best practices"",""Agile project development and deployment"",""CI/CD"",""Data provisioning automation"",""Database administration (Azure SQL, Oracle, IMS, DB2)""],""nice_to_have"":[""Oracle PL/SQL development"",""IMS/DB2 data replication""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach data pipeline development and orchestration in a cloud-based environment?"",""example_answer"":""I use Azure pipeline and DataOPS principles to design and develop data pipelines, ensuring automation, monitoring, and collaboration. I also leverage Azure DevOps for continuous integration and deployment.""},{""question"":""Can you explain the concept of a Data Lakehouse and its benefits?"",""example_answer"":""A Data Lakehouse is a unified platform that combines the benefits of data warehouses and data lakes, providing a centralized repository for raw and processed data. It enables flexible data analysis, processing, and reporting, while ensuring data quality and security.""}],""red_flags"":[""Lack of experience with Microsoft Azure technologies"",""Inadequate understanding of Cloud DataOPS principles and best practices"",""Insufficient experience with data pipeline development and orchestration""],""confidence_score"":90.0}"
Cloud Engineer IV,"OnX is a leading technology solution provider that serves businesses, healthcare organizations, and government agencies across Canada. OnX combines deep technical expertise with a full suite of flexible technology solutions—including Generative AI, Application Modernization, Managed Hybrid Cloud, Cybersecurity, Unified Communications, and Infrastructure solutions. From developing and deploying modern applications and the secure, scalable platforms on which they run, to managing, monitoring, and optimizing their operations, OnX delivers comprehensive technology solutions for its clients’ transformative business initiatives. For more information, please visit www.onx.com.

Overview

In today's rapidly evolving environment, organizations need to make data-driven decisions that deliver enterprise value. Our OnX Cloud and Artificial Intelligence practitioners design, develop, and implement large-scale data ecosystems, leveraging cloud-based platforms to integrate structured and unstructured data. We utilize automation, cognitive, and science-based techniques to manage data, predict scenarios, and prescribe actions. By continuously optimizing our cloud infrastructure and providing As-a-Service offerings, we ensure ongoing insights and improvements to enhance operational efficiency. We assist clients in transforming their businesses by developing organizational intelligence programs and strategies, enabling them to stay ahead in their markets.

Our Team Works With Clients To

Implement large-scale data ecosystems, including data management, governance, and the integration of structured and unstructured data to generate insights using cloud-based platforms.
Use automation, cognitive, and science-based techniques to manage data, predict scenarios, and prescribe actions.
Enhance operational efficiency by maintaining data ecosystems, sourcing analytics expertise, and providing As-a-Service offerings for continuous insights and improvements.

Responsibilities

As a Cloud Engineer, you will:

Design, develop, and implement large-scale data ecosystems: Collaborate with cross-functional teams to ensure seamless integration and deployment of data ecosystems in a DevOps environment, utilizing CI/CD, Docker, and Kubernetes.
Automate infrastructure provisioning and management using Infrastructure as Code (IaC) practices: Employ automation, cognitive, and science-based techniques to manage data, predict scenarios, and prescribe actions.
Support the technical implementation of cloud solutions: Troubleshoot and resolve technical issues to maintain operational efficiency. Provide technical guidance and support during the implementation and maintenance phases.
Optimize cloud infrastructure: Stay updated with the latest cloud technologies and best practices to ensure the infrastructure remains cutting-edge and provide solutions to complex data-related challenges. Maintain data ecosystems, source analytics expertise, and provide As-a-Service offerings for continuous insights and improvements.

Requirements

Required:

5-8 Years of Industry Experience
Hands-on experience with CI/CD pipelines, Docker, and Kubernetes.
Proven experience in cloud engineering or a similar role.
Strong understanding of cloud platforms (e.g., AWS, Azure, GCP).
Proficiency in Infrastructure as Code (IaC) tools, especially Terraform.
Solid understanding of networking, security, and DevOps practices.
Excellent problem-solving skills and the ability to troubleshoot complex technical issues.
2+ years of experience in Java, .NET or Python
Effective communication skills, written and oral

Nice To Have

Experience in Git, Redhat OpenShift, VMWare, Databricks, Snowflake, Python, OpenSearch, ElasticSearch, Oracle or MS SQL DBs
Familiarity with other IaC tools such as CloudFormation or Ansible.
Experience with monitoring and logging tools (e.g., Prometheus, Grafana, ELK stack).
AWS, Microsoft Azure or Google Cloud certifications

Education

Four years of College resulting in a Bachelor's Degree or equivalent Bachelor's in Business, Computer Science, Engineering, or related field

Due to U.S. Government requirements applicable to foreign-owned telecommunications providers, non-US citizens may be required to submit to an extensive government agency background check which will necessitate disclosure of sensitive Personally Identifiable Information.

The Pay Range For This Role Is

120,000 - 160,000 CAD per year(Remote - Toronto, CA)","{""role_summary"":""Design, develop, and implement large-scale data ecosystems as a Cloud Engineer, utilizing cloud-based platforms to integrate structured and unstructured data, and ensuring ongoing insights and improvements to enhance operational efficiency."",""key_terms"":[{""term"":""Generative AI"",""explanation"":""A type of artificial intelligence that generates new, original content, such as images, videos, or text.""},{""term"":""Application Modernization"",""explanation"":""The process of updating or re-architecting legacy applications to modern standards, often using cloud-native technologies.""},{""term"":""Managed Hybrid Cloud"",""explanation"":""A cloud computing model that combines on-premises infrastructure with public cloud services, managed by a third-party provider.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files, rather than manual processes.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a software development practice that automates testing, building, and deployment of code changes.""},{""term"":""Docker"",""explanation"":""A containerization platform that allows developers to package, ship, and run applications in containers.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system that automates deployment, scaling, and management of containerized applications.""}],""skill_priorities"":{""must_have"":[""Hands-on experience with CI/CD pipelines, Docker, and Kubernetes"",""Proven experience in cloud engineering or a similar role"",""Strong understanding of cloud platforms (e.g., AWS, Azure, GCP)"",""Proficiency in Infrastructure as Code (IaC) tools, especially Terraform"",""Solid understanding of networking, security, and DevOps practices"",""Excellent problem-solving skills and the ability to troubleshoot complex technical issues"",""2+ years of experience in Java, .NET or Python"",""Effective communication skills, written and oral""],""nice_to_have"":[""Experience in Git, Redhat OpenShift, VMWare, Databricks, Snowflake, Python, OpenSearch, ElasticSearch, Oracle or MS SQL DBs"",""Familiarity with other IaC tools such as CloudFormation or Ansible"",""Experience with monitoring and logging tools (e.g., Prometheus, Grafana, ELK stack)"",""AWS, Microsoft Azure or Google Cloud certifications""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a large-scale data ecosystem using cloud-based platforms?"",""example_answer"":""I would start by assessing the client's data requirements and identifying the most suitable cloud platform for their needs. Then, I would design a data ecosystem that integrates structured and unstructured data, utilizing automation, cognitive, and science-based techniques to manage data, predict scenarios, and prescribe actions. Finally, I would implement the solution using Infrastructure as Code (IaC) practices and ensure seamless integration with the client's existing infrastructure.""},{""question"":""How do you stay updated with the latest cloud technologies and best practices?"",""example_answer"":""I regularly follow industry blogs and news, attend webinars and conferences, and participate in online forums to stay current with the latest cloud technologies and best practices. I also engage with my peers and colleagues to share knowledge and experiences.""}],""red_flags"":[""Lack of hands-on experience with CI/CD pipelines, Docker, and Kubernetes"",""Insufficient understanding of cloud platforms and Infrastructure as Code (IaC) practices"",""Poor problem-solving skills and inability to troubleshoot complex technical issues""],""confidence_score"":90.0}"
"Software Engineer, New Grad","The simple task of buying software, services, or tools at work has become hopelessly complicated at even the most innovative companies in the world. Today, enterprises spend $120T+ per year globally (>30 times larger than annual consumer e-commerce spend) and rely on vendors more than ever before to run their businesses.

Our cofounders started Zip in 2020 to address this seemingly intractable problem with a purpose-built procurement platform that provides a simple, consumer-grade user experience. Within the last 4 years, Zip has created a new category and developed the leading solution in this $50B+ TAM space. Today, the world’s leading companies like OpenAI, Snowflake, Anthropic, Coinbase, and Prudential rely on Zip to manage billions of dollars in spend.

We have a world-class team coming from category-defining companies like Airbnb, Meta, Stripe, Salesforce, Apple, and Google. With a $2.2 billion valuation and $370 million in funding from Y Combinator, Tiger Global, BOND, DST Global, and CRV, we’re focused on developing cutting-edge technology, expanding into new global markets, and—above all–driving incredible value for our customers. Join us!

Your Role

As a Software Engineer you will be responsible for building Zip’s core products and architecture. You will ship features that will be immediately used by our customers, and will work with a tight-knit team that values open communication and cross-functional collaboration. We move quickly to solve a wide range of complex technical and product challenges. While we are an experienced team that can provide constant guidance and mentorship, we value engineers who can scope and solve difficult technical challenges.

You Will

Design and build highly reliable and resilient products and features
Work closely with cross functional product and customer-facing teams to understand requirements and ship thoughtful solutions
Write high-quality, extensible, and maintainable code
Design and build scalable frontend applications and components
Design and build APIs to drive existing and new features for a web-based application


Qualifications

Pursuing a BS or MS in Computer Science or related technical field involving coding (e.g. physics or math), with a graduation date between December 2024 - June 2025
Experience with web applications and API development. At Zip, our stack includes Python, Javascript/TypeScript, React, and GraphQL
Ability and interest to quickly learn new frameworks, architecture patterns, and programming languages as needed
Fantastic written and verbal communication skills
Prior internships in high-growth startup environment


Perks & Benefits

At Zip, we’re committed to providing our employees with everything they need to do their best work.

📈 Start-up equity
🦷 Health, vision & dental coverage
🚠 Team building events & happy hours
🌴 Flexible PTO
💻 Apple equipment plus home office budget


We're looking to hire Zippers and that means hiring people who take ownership, communicate openly, have an underdog mindset, and are excited to increase the pace of innovation for every business in the world. We encourage all candidates to apply even if your experience doesn't exactly match up to our job description. We are committed to building a diverse and inclusive workspace where everyone (regardless of age, religion, ethnicity, gender, sexual orientation, and more) feels like they belong. We look forward to hearing from you!","{""role_summary"":""As a Software Engineer at Zip, you will build core products and architecture, shipping features used by customers and collaborating with cross-functional teams to solve complex technical and product challenges."",""key_terms"":[{""term"":""GraphQL"",""explanation"":""A query language for APIs that allows for flexible and efficient data retrieval.""},{""term"":""TypeScript"",""explanation"":""A statically typed, superset of JavaScript that helps catch errors early and improve code maintainability.""},{""term"":""React"",""explanation"":""A popular JavaScript library for building user interfaces and managing state changes in web applications.""}],""skill_priorities"":{""must_have"":[""Experience with web applications and API development"",""Python"",""JavaScript/TypeScript"",""React"",""GraphQL""],""nice_to_have"":[""Prior internships in high-growth startup environment""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach designing a scalable frontend application for a web-based platform?"",""example_answer"":""I would consider using a modular architecture, separating concerns into smaller components, and leveraging caching mechanisms to improve performance. I'd also ensure the application is responsive and accessible across various devices and browsers.""},{""question"":""Can you explain how you would optimize the performance of a GraphQL API?"",""example_answer"":""I would focus on optimizing query complexity, using caching mechanisms like Redis, and implementing pagination to reduce the amount of data transferred. I'd also consider using GraphQL subscriptions for real-time updates and leveraging Apollo Client for efficient data fetching.""}],""red_flags"":[""Lack of experience with web applications and API development"",""Inability to learn new frameworks, architecture patterns, and programming languages quickly""],""confidence_score"":90.0}"
Azure Cloud Engineer,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.

The opportunity

We are seeking an Azure Cloud Engineer to join EY Canada. In this role, you will be required to offer expert advice, planning, and practical assistance to EY's clients who want to move their IT infrastructure to a cloud-based system. This individual will be part of a diverse team of innovative and talented professionals, committed to providing top-tier consulting services to our clients.

Your Key Responsibilities:

Work with a variety of Canadian clients across different industries to understand their specific cloud computing needs and objectives.
Design and implement tailored cloud infrastructure, applications, and platform solutions, considering Canadian data privacy laws and regulations.
Create and execute effective data migration and cloud implementation strategies, specific to each client.
Monitor, maintain, and troubleshoot cloud-based systems, ensuring optimal performance and reliability.
Develop comprehensive backup and recovery strategies that comply with Canadian business continuity standards.
Communicate complex cloud concepts, ensuring that relevant stakeholders understand the risks and benefits.
Follow EY methodologies and use EY tools to deliver seamless and compelling cloud solutions.
Stay current with trends and developments in cloud computing, with a particular focus on their relevance to the Canadian market.
Ensure EY's quality and professional standards are maintained.
Collaborate with other EY teams to create integrated solutions.
Train and support clients during the cloud transition process, maintaining good client relationships.

To qualify for this role you must have:

Bachelor’s degree in computer science, IT, Systems Engineering, or a related field. Higher degree or equivalent experience is preferred.
3-5 years of experience as a Cloud Engineer or in a similar role, with prior consulting experience.
Proven expertise in Azure Cloud – experience with AWS, GCP an asset.
Experience in Design and Implementation:
Designing and deploying scalable, highly available, and fault-tolerant systems on cloud platforms (e.g., AWS, Azure, Google Cloud Platform).
Implementing and managing cloud infrastructure and services, including compute, storage, networking, and databases.
Migrating existing on-premises applications and services to the cloud.
Experience in Maintenance and Optimization:
Monitoring cloud environments to ensure optimal performance and cost-efficiency.
Performing regular maintenance tasks, updates, and upgrades.
Troubleshooting and resolving technical issues related to cloud resources.
Experience in Security and Compliance:
Ensuring cloud environments comply with relevant security standards and regulations.
Implementing and managing security measures such as firewalls, identity and access management (IAM), and encryption.
Conducting security audits and risk assessments.
Experience in Automation and Orchestration:
Automating repetitive tasks using scripting languages (e.g., Python, Bash) and infrastructure as code (IaC) tools (e.g., Terraform, CloudFormation).
Implementing orchestration solutions to manage complex workflows and dependencies across multiple cloud services.
Experience in Collaboration and Support:
Collaborating with development teams to support DevOps practices and continuous integration/continuous deployment (CI/CD) pipelines.
Providing technical support and guidance to other teams and stakeholders.
Documenting cloud architectures and procedures.
Strong understanding of cloud-based technologies, covering data storage, networking, and cybersecurity.
Superior written and verbal communication skills in English, French language skills is a plus.
Familiarity with Canadian data protection laws and business practices.
Professional cloud certifications like AWS Solutions Architect, Google Professional Cloud Architect, or Microsoft Certified: Azure Solutions Architect Expert is a plus.
Ability to manage multiple client engagements simultaneously.
Willingness to travel, as needed, to meet client needs and project commitments.
Exhibits EY’s values – integrity, respect, and teaming, energy, enthusiasm, and the courage to lead.

What We Offer

We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. In addition, our Total Rewards package allows you decide which benefits are right for you and which ones help you create a solid foundation for your future. Our Total Rewards package includes a comprehensive medical, prescription drug and dental coverage, a defined contribution pension plan, a great vacation policy plus firm paid days that allow you to enjoy longer long weekends throughout the year, statutory holidays and paid personal days (based on province of residence), and a range of exciting programs and benefits designed to support your physical, financial and social well-being. Plus, we offer:

Support and coaching from some of the most engaging colleagues in the industry
Learning opportunities to develop new skills and progress your career
The freedom and flexibility to handle your role in a way that’s right for you

The salary range for this job in British Columbia is $72,000 to $132,000. Individual salaries within this range are determined through a wide variety of factors including but not limited to education, experience, knowledge, skills and work location city.

Diversity and Inclusion at EY

Diversity and inclusiveness are at the heart of who we are and how we work. We’re committed to fostering an environment where differences are valued, policies and practices are equitable, and our people feel a sense of belonging. We embrace diversity and are committed to combating systemic racism, advancing gender equity and women in leadership, advocating for the 2SLGBTQIA+ community, promoting our neuroinclusion and accessibility initiatives, and are dedicated to amplifying the voices of Indigenous peoples (First Nations, Inuit, and Métis) nationally as we strive towards reconciliation. Our diverse experiences, abilities, backgrounds, and perspectives make our people unique and help guide us. Because when people feel free to be their authentic selves at work, they bring their best and are empowered to build a better working world.

EY | Building a better working world

EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.

Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.

Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.","{""role_summary"":""An Azure Cloud Engineer responsible for providing expert advice, planning, and practical assistance to clients moving their IT infrastructure to a cloud-based system, ensuring optimal performance, reliability, and compliance with Canadian data privacy laws and regulations."",""key_terms"":[{""term"":""Azure Cloud"",""explanation"":""A cloud computing platform and set of services offered by Microsoft, used for building, deploying, and managing applications and services through Microsoft-managed data centers across the globe.""},{""term"":""Cloud Infrastructure"",""explanation"":""The combination of hardware, software, and network resources required to support the computing requirements of a cloud-based system, including servers, storage, networking, and databases.""},{""term"":""Data Migration"",""explanation"":""The process of transferring data from one system or storage location to another, often involving the transfer of data from on-premises infrastructure to a cloud-based system.""},{""term"":""Cloud Security"",""explanation"":""The practices, technologies, and controls designed to protect cloud-based systems, data, and applications from unauthorized access, use, disclosure, disruption, modification, or destruction.""}],""skill_priorities"":{""must_have"":[""Azure Cloud experience"",""Cloud infrastructure design and implementation"",""Data migration and cloud implementation strategies"",""Cloud security and compliance"",""Strong written and verbal communication skills in English""],""nice_to_have"":[""Experience with AWS or GCP"",""Professional cloud certifications (e.g., AWS Solutions Architect, Google Professional Cloud Architect, or Microsoft Certified: Azure Solutions Architect Expert)"",""French language skills"",""Familiarity with Canadian data protection laws and business practices""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the key considerations for designing a scalable and fault-tolerant cloud infrastructure?"",""example_answer"":""When designing a scalable and fault-tolerant cloud infrastructure, it's essential to consider factors such as load balancing, auto-scaling, and redundancy to ensure high availability and minimize downtime. Additionally, implementing monitoring and logging tools can help identify and troubleshoot issues quickly.""},{""question"":""How would you approach migrating an on-premises application to a cloud-based system?"",""example_answer"":""I would start by assessing the application's current architecture and identifying potential bottlenecks. Then, I would develop a migration strategy that considers factors such as data transfer, security, and performance. Finally, I would execute the migration plan, ensuring minimal disruption to the business and providing training and support to stakeholders.""}],""red_flags"":[""Lack of experience with Azure Cloud or cloud infrastructure design and implementation"",""Inability to communicate complex cloud concepts effectively"",""Insufficient knowledge of cloud security and compliance regulations""],""confidence_score"":90.0}"
Sr. GCP Cloud Engineer,"Rackspace Technology is a leading provider of expertise and managed services across all the major public and private cloud technologies. We’ve evolved Fanatical Support to encompass the entire customer journey — providing Fanatical Experience™ from first consultation to daily operations. Our passionate experts combine the power of proactive, always-on service and expertise with best-in-class tools and automation to deliver technology when and how our customers need it.

As part of our commitment to our customers, we are dedicated to helping enable creative, automation-based solutions for all sizes of businesses and require an experienced Cloud Engineer to join our team.

The ideal candidate will have several years’ experience with Google Cloud design and implementation. You will be working in a dynamic environment and encouraged to come up with innovative solutions to technical problems, analyze and prioritize problems, putting users at the heart of every decision.

You will ideally have proven experience in multiple GCP deployments. Your engagements will see you working directly with customers and prospects. You will have confidence in knowing your skills (and limitations), you are calm and collected under pressure and always available to mentor the less experienced. Your colleagues see you as a good team player who is keen to share knowledge as well as to listen and learn from others.

Work Location: Remote (Ontario, Alberta, and British Columbia)

Key Responsibilities

Own and complete key tasks and deliverables, and collaborate with others to define and implement optimal, complete solutions based on stake holder’s needs.
Deliver solutions that solve for new levels of complexity, scale, and performance, and in turn, enable breakthrough innovations. Create and apply frameworks, methods, best practices, and artifacts that deliver prescriptive guidance to customers, and publish and present the min large forums and across various media platforms.
Technical depth and hands-on implementation experience of various practices and tools in the DevOps toolchain.
Comfortable rolling up their sleeves to design and code modules for infrastructure, application, and processes.
Design, Build and maintain cloud-based application that uses Google Kubernetes Engine


Qualifications

Security in GCP
Networking in GCP
GKE and overall compute in GCP, including GCE
GCP Storage - Spanner, Cloud SQL, MemoryStore, GCS, etc
Automation and operations in GCP
GCP Observability, GKE Observability and GCP Logs/Metrics/Traces
Datadog, New Relic and Synthetic Testing.
Bachelor’s degree, or equivalent experience, in Computer Science, Engineering. or a related field.
4+years of experience as a technical specialist.
3+years of hands-on experience of programming in languages with the following Python, Java, and GO.
Subject Matter Expert level practical Linux administration skills in a Cloud or Virtualized environment.
Expert level familiarity with automating cloud native technologies, deploying applications, and provisioning infrastructure using bash, python, or GO
Expert Knowledge of the primary Google services (compute engine, load balancing, Cloud Storage)
Experience with automating cloud native technologies, deploying applications, and provisioning infrastructure.
Expert level knowledge and Hands-on experience with Infrastructure as Code utilizing Terraform.
Experience developing cloud native CI/CD workflows and tools, such as Jenkins, Bamboo, TeamCity, Cloud Build (Google) and/or GitLab.
Hands-on experience with microservices and distributed application architecture utilizing containers, Kubernetes, and/or serverless technology.
Experience with seamless/automated build scripts used for release management across all environments.
Experience with the full software development lifecycle and delivery using Agile practices
In depth understanding of IP networking, VPN's, DNS, load balancing and firewalls.
Willingness to travel to customer locations as needed.
Experience with multi-cloud architecture and deployment


Discover your inner Racker: Racker Life

""Remote postings are limited to candidates residing within the country specified in the posting location""

About Rackspace Technology

We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.

More on Rackspace Technology

Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.","{""role_summary"":""Design and implement cloud-based solutions using Google Cloud Platform, working directly with customers and prospects to deliver innovative solutions and provide technical expertise."",""key_terms"":[{""term"":""Google Cloud Platform (GCP)"",""explanation"":""A suite of cloud computing services offered by Google, including computing, storage, networking, and more.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files, rather than manual processes.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a set of practices that automate testing, building, and deployment of software applications.""}],""skill_priorities"":{""must_have"":[""Google Cloud Platform (GCP) design and implementation"",""DevOps toolchain experience"",""Programming skills in Python, Java, or GO"",""Linux administration skills in a Cloud or Virtualized environment"",""Experience with Infrastructure as Code (IaC) using Terraform"",""Knowledge of Google Cloud services (compute engine, load balancing, Cloud Storage)""],""nice_to_have"":[""Experience with multi-cloud architecture and deployment"",""Knowledge of Datadog, New Relic, and Synthetic Testing"",""Experience with microservices and distributed application architecture"",""Experience with seamless/automated build scripts for release management""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a scalable cloud-based application using Google Kubernetes Engine?"",""example_answer"":""I would start by assessing the application requirements and identifying the necessary components. Then, I would design a scalable architecture using Kubernetes, considering factors such as load balancing, autoscaling, and resource utilization. Finally, I would implement the design using GKE, ensuring proper configuration, monitoring, and logging.""},{""question"":""How do you approach automating cloud native technologies, deploying applications, and provisioning infrastructure?"",""example_answer"":""I use a combination of tools such as Terraform, Ansible, and bash scripts to automate cloud native technologies. I also leverage cloud provider APIs and SDKs to provision infrastructure and deploy applications. Additionally, I ensure proper testing, validation, and monitoring of automated processes.""}],""red_flags"":[""Lack of hands-on experience with Google Cloud Platform (GCP)"",""Inability to design and implement scalable cloud-based applications"",""Limited experience with DevOps toolchain and automation""],""confidence_score"":90.0}"
Ingénieur DevOps / DevOps Engineer,"Ingénieur DEVOPS (English follow) 
 Vous recherchez un environnement de travail stimulant au sein d'une équipe jeune et dynamique ? 
 Nous sommes à l'avant-garde de la fourniture de solutions logicielles dans un environnement collaboratif en constante évolution. Notre mission est d'autonomiser les entreprises avec une technologie évolutive, sécurisée et innovante. Nous recherchons un ingénieur DevOps Azure compétent avec une expertise approfondie de Kubernetes, Docker et des services partagés pour rejoindre notre équipe en pleine croissance. 
 Si vous êtes passionné par la conteneurisation, l'automatisation et la livraison transparente de logiciels dans des environnements dynamiques basés sur le cloud, nous voulons vous entendre ! 
 Aperçu du rôle 
En tant qu'ingénieur DevOps Azure, vous jouerez un rôle essentiel dans la conception, la mise en œuvre et la maintenance de nos processus DevOps et de notre infrastructure sur Azure. Vous travaillerez avec Kubernetes et Docker pour concevoir, mettre en œuvre et optimiser les charges de travail conteneurisées dans nos environnements Azure .NET. Vous favoriserez également l'adoption de services partagés pour rationaliser le développement et l'efficacité opérationnelle. Vous travaillerez en étroite collaboration avec des équipes interfonctionnelles, notamment les développeurs, l'assurance qualité et les opérations, afin de garantir des pipelines CI/CD transparents, une infrastructure robuste et des performances système optimales. 
 Principales responsabilités 
Expertise en matière de conteneurisation : Construire et gérer des applications .NET conteneurisées à l'aide de Docker et orchestrer des déploiements avec Kubernetes dans Azure (AKS). 
Pipelines CI/CD : Développer et maintenir des pipelines CI/CD dans Azure DevOps pour permettre l'intégration et la livraison continues. 
Architecture de services partagés : Concevoir et mettre en œuvre des plateformes de services partagés (i.e., journalisation, surveillance, identité) pour normaliser et optimiser les flux de travail de développement et d'exploitation. 
Infrastructure as Code (IaC) : Automatiser le provisionnement et la gestion de l'infrastructure à l'aide de Terraform. 
Architecture en nuage : Concevoir, déployer et maintenir des environnements Azure évolutifs et sécurisés pour prendre en charge des applications conteneurisées et basées sur des microservices. 
Surveillance et dépannage : Maintenir et améliorer les solutions de surveillance comme Datadog et Azure Monitor pour assurer la santé et la performance du système. 
Automatisation : Rationalisez et automatisez les tâches opérationnelles, en réduisant les interventions manuelles. 
Sécurité et conformité : Intégrez les meilleures pratiques de sécurité dans les processus DevOps, en garantissant la conformité avec les normes du secteur. 
Documentation : Créer une documentation complète pour les pratiques de conteneurisation, les services partagés et les flux de travail opérationnels. 
 Compétences et qualifications 
5+ ans d'expérience en tant qu'ingénieur DevOps, avec un accent sur les environnements Azure. 
Forte expertise dans Kubernetes (AKS de préférence) et Docker pour la gestion des applications .NET conteneurisées. 
Expérience avérée dans la conception et la mise en œuvre de plateformes de services partagés. 
Maîtrise de la configuration et de la gestion du pipeline CI/CD à l'aide d'Azure DevOps. 
Expérience pratique de l'infrastructure en tant que code (i.e.,Terraform). 
Maîtrise des langages de script comme PowerShell, Python ou Bash. 
Solide compréhension des principes de mise en réseau, de sécurité et d'évolutivité du cloud. 
Expérience avec des outils de surveillance comme Datadog et Azure Monitor. 
 Atouts 
Certifications Azure (i.e., AZ-400, AZ-104 ou AZ-305). 
Expérience des services administrés et Service Mesh.  
Connaissance des méthodologies Agile et des outils tels que Jira ou Azure Boards et Confluence. 

Parlons maintenant des avantages!
Télétravail
Un régime de rémunération attrayant
Un environnement Agile qui est génial, expérimenté et amusant
Programmes de formation et de remboursement des frais de scolarité
Régime complet de soins de santé et d'avantages sociaux, avec un compte de mieux-être.
RRSP/DPSP
Un équilibre travail-vie personnelle apprécié
Des collègues et des dirigeants formidables
Des événements employés tout au long de l'année pour célébrer nos victoires et apprendre à se connaître

  --------------------------------------------------------- 
 DEVOPS Engineer 
 Looking for a stimulating work environment in a young and dynamic team? 
 We are at the forefront of delivering software solutions in a fast-paced, collaborative environment. Our mission is to empower businesses with scalable, secure, and innovative technology. We are seeking a skilled Azure DevOps Engineer with deep expertise in Kubernetes, Docker, and shared services to join our growing team. 
 If you’re passionate about containerization, automation, and enabling seamless software delivery in dynamic, cloud-based environments, we want to hear from you! 
 Role Overview 
As an Azure DevOps Engineer, you will play a critical role in designing, implementing, and maintaining our DevOps processes and infrastructure on Azure. Working with Kubernetes and Docker to design, implement, and optimize containerized .NET workloads across our Azure environments. You will also drive the adoption of shared services to streamline development and operational efficiency. You'll work closely with cross-functional teams, including developers, QA, and operations, to ensure seamless CI/CD pipelines, robust infrastructure, and optimal system performance. 
 Main responsibilities 
Containerization Expertise: Build and manage containerized .NET applications using Docker and orchestrate deployments with Kubernetes in Azure (AKS). 
CI/CD Pipelines: Develop and maintain CI/CD pipelines in Azure DevOps to enable continuous integration and delivery. 
Shared Services Architecture: Design and implement shared services platforms (e.g., logging, monitoring, identity) to standardize and optimize development and operations workflows. 
Infrastructure as Code (IaC): Automate infrastructure provisioning and management using Terraform. 
Cloud Architecture: Design, deploy, and maintain scalable and secure Azure environments to support containerized and microservices-based applications. 
Monitoring & Troubleshooting: Maintain and improve monitoring solutions like Datadog and Azure Monitor to ensure system health and performance. 
Automation: Streamline and automate operational tasks, reducing manual intervention. 
Security & Compliance: Integrate security best practices into DevOps processes, ensuring compliance with industry standards. 
Documentation: Create comprehensive documentation for containerization practices, shared services, and operational workflows. 
 Skills and Qualifications 
5+ years of experience as a DevOps Engineer, with a focus on Azure environments. 
Strong expertise in Kubernetes (AKS preferred) and Docker for containerized .NET application management. 
Proven experience designing and implementing shared services platforms. 
Proficient in CI/CD pipeline setup and management using Azure DevOps. 
Hands-on experience with Infrastructure as Code (e.g., Terraform). 
Proficiency in scripting languages like PowerShell, Python, or Bash. 
Strong understanding of cloud networking, security, and scalability principles. 
Experience with monitoring tools like Datadog or Azure Monitor. 
 Preferred
Azure certifications (e.g., AZ-400, AZ-104, or AZ-305). 
Experience with administered services and Service Mesh.  
Knowledge of Agile methodologies and tools like Jira or Azure Boards and confluence. 

Now let's talk Perks!
Remote work (from Canada)
Attractive compensation package
An Agile environment that is great, experienced and fun
Training and tuition reimbursement programs
Full health and benefit plan, with Wellness account of 500$
RRSP/DPSP
Valued work-life balance
Great coworkers and leaders
Employee gatherings throughout the year to celebrate our victories and to get to know one another.","{""role_summary"":""Design, implement, and maintain DevOps processes and infrastructure on Azure, focusing on containerization, automation, and seamless software delivery in dynamic, cloud-based environments."",""key_terms"":[{""term"":""Containerization"",""explanation"":""The process of packaging an application and its dependencies into a container that can be run consistently across different environments.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""Docker"",""explanation"":""A containerization platform that allows developers to package, ship, and run applications in containers.""},{""term"":""Azure DevOps"",""explanation"":""A suite of services that provides an end-to-end DevOps solution for planning, developing, delivering, and operating software.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files, rather than through graphical user interfaces.""}],""skill_priorities"":{""must_have"":[""Azure DevOps"",""Kubernetes"",""Docker"",""Containerization"",""CI/CD Pipelines"",""Infrastructure as Code (IaC)""],""nice_to_have"":[""Azure Certifications (AZ-400, AZ-104, or AZ-305)"",""Experience with administered services and Service Mesh"",""Knowledge of Agile methodologies and tools like Jira or Azure Boards and Confluence""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach containerization of .NET applications using Docker and Kubernetes in Azure?"",""example_answer"":""I would use Docker to package the .NET application and its dependencies into a container, and then use Kubernetes to orchestrate the deployment and scaling of the containerized application in Azure.""},{""question"":""Can you explain how you would design and implement a CI/CD pipeline in Azure DevOps?"",""example_answer"":""I would use Azure DevOps to create a pipeline that automates the build, test, and deployment of the application, leveraging tools like Docker and Kubernetes for containerization and orchestration.""}],""red_flags"":[""Lack of experience with Azure DevOps and Kubernetes"",""Inability to explain containerization concepts and Docker usage"",""No experience with Infrastructure as Code (IaC) using Terraform""],""confidence_score"":90.0}"
DevOps Engineer II (Canada Remote),"Requisition #: 16346

Our Mission: Powering Innovation That Drives Human Advancement

When visionary companies need to know how their world-changing ideas will perform, they close the gap between design and reality with Ansys simulation. For more than 50 years, Ansys software has enabled innovators across industries to push boundaries by using the predictive power of simulation. From sustainable transportation to advanced semiconductors, from satellite systems to life-saving medical devices, the next great leaps in human advancement will be powered by Ansys.

Innovate With Ansys, Power Your Career.

Summary

This DevOps Engineer II is responsible for supporting the overall productivity of smaller development teams and enhancing the security posture of their products. In this role, the candidate will work hands-on with developers and testers to provide build and deployment services for the Ansys products and investigate methods to improve product security and stability.

Responsibilities

Manage build, testing, and distribution systems
Explore methods and technologies to improve product security
Mitigate third-party security vulnerabilities
Enhance and refactor application code
Liaison with corporate build, testing and dev services teams
Automate deployment of the system for testing and production use
Perform performance testing and optimization of the deployment
Actively participate in project planning, design brainstorm sessions and team meetings

Minimum Qualifications

BS in Engineering, Computer Science or related field with 2 years’ experience or Master's Degree
Experience with system administration, IT, or software development
Familiarity with VDIs and Windows Server (2016/2019/2022) and bat or PowerShell scripting.
Familiarity with Windows Virtualization (Hyper-V, VM or Azure Virtual Machines).
Hands-on experience in creation and deployment of containers
Hands-on experience with Static Application Security Testing (SAST) tools such as Coverity and SonarQube
Hands-on experience with Software Composition Analysis (SCA) tools such as FlexNet Code Insight
High proficiency in Java, C#, C++ and object-oriented programming principles and Python
Highly motivated with a willingness to learn new technologies and make architectural decisions
Strong team player who thrives in an open and collaborative environment and is committed to meeting team goals

Preferred Qualifications

Experience setting up and managing builds and deployment pipelines using Azure DevOps, TeamCity, GitHub or any CI/CD environment.
Familiarity with Docker for Linux-based virtualization.
Configuration management tools such as Ansible, Puppet
Hands-on experience with artifact repositories and package manager such as JFrog artifactory repository, Conan
Cloud APIs such as AWS or Azure
Experience in Rocky, Red Hat, or CentOS environments.
Knowledge of Bash scripting and package management tools (apt, yum, dnf).

At Ansys, we know that changing the world takes vision, skill, and each other. We fuel new ideas, build relationships, and help each other realize our greatest potential. We are ONE Ansys. We operate on three key components: our commitments to stakeholders, our values that guide how we work together, and our actions to deliver results. As ONE Ansys, we are powering innovation that drives human advancement

Our Commitments

Amaze with innovative products and solutions
Make our customers incredibly successful
Act with integrity
Ensure employees thrive and shareholders prosper

Our Values

Adaptability: Be open, welcome what’s next
Courage: Be courageous, move forward passionately
Generosity: Be generous, share, listen, serve
Authenticity: Be you, make us stronger

Our Actions

We commit to audacious goals
We work seamlessly as a team
We demonstrate mastery
We deliver outstanding results

VALUES IN ACTION

Ansys is committed to powering the people who power human advancement. We believe in creating and nurturing a workplace that supports and welcomes people of all backgrounds; encouraging them to bring their talents and experience to a workplace where they are valued and can thrive.

Our culture is grounded in our four core values of adaptability, courage, generosity, and authenticity. Through our behaviors and actions, these values foster higher team performance and greater innovation for our customers.

We’re proud to offer programs, available to all employees, to further impact innovation and business outcomes, such as employee networks and learning communities that inform solutions for our globally minded customer base.

Welcome What’s Next In Your Career At Ansys

At Ansys, you will find yourself among the sharpest minds and most visionary leaders across the globe. Collectively, we strive to change the world with innovative technology and transformational solutions. With a prestigious reputation in working with well-known, world-class companies, standards at Ansys are high — met by those willing to rise to the occasion and meet those challenges head on. Our team is passionate about pushing the limits of world-class simulation technology, empowering our customers to turn their design concepts into successful, innovative products faster and at a lower cost. Ready to feel inspired? Check out some of our recent customer stories, here and here .

At Ansys, it’s about the learning, the discovery, and the collaboration. It’s about the “what’s next” as much as the “mission accomplished.” And it’s about the melding of disciplined intellect with strategic direction and results that have, can, and do impact real people in real ways. All this is forged within a working environment built on respect, autonomy, and ethics.

CREATING A PLACE WE’RE PROUD TO BE

Ansys is an S&P 500 company and a member of the NASDAQ-100. We are proud to have been recognized for the following more recent awards, although our list goes on: Newsweek’s Most Loved Workplace globally and in the U.S., Gold Stevie Award Winner, America’s Most Responsible Companies, Fast Company World Changing Ideas, Great Place to Work Certified (China, Greece, France, India, Japan, Korea, Spain, Sweden, Taiwan, and U.K.).

For more information, please visit us at www.ansys.com

Ansys is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other protected characteristics.

Ansys does not accept unsolicited referrals for vacancies, and any unsolicited referral will become the property of Ansys. Upon hire, no fee will be owed to the agency, person, or entity.","{""role_summary"":""Support the productivity of smaller development teams and enhance the security posture of their products as a DevOps Engineer II."",""key_terms"":[{""term"":""VDIs"",""explanation"":""Virtual Desktop Infrastructure, a technology used to provide virtual desktops to users.""},{""term"":""Windows Virtualization"",""explanation"":""A technology that allows multiple virtual machines to run on a single physical machine.""},{""term"":""Static Application Security Testing (SAST) tools"",""explanation"":""Tools used to identify security vulnerabilities in application code.""},{""term"":""Software Composition Analysis (SCA) tools"",""explanation"":""Tools used to identify and manage open-source and third-party components in application code.""},{""term"":""CI/CD environment"",""explanation"":""Continuous Integration and Continuous Deployment environment, used to automate the build, test, and deployment of software.""},{""term"":""Ansible"",""explanation"":""A configuration management tool used to automate the deployment and management of infrastructure and applications.""}],""skill_priorities"":{""must_have"":[""System administration"",""IT or software development experience"",""Familiarity with VDIs and Windows Server"",""Familiarity with Windows Virtualization"",""Hands-on experience with container creation and deployment"",""Hands-on experience with SAST tools"",""Hands-on experience with SCA tools"",""High proficiency in Java, C#, C++, and Python""],""nice_to_have"":[""Experience with Azure DevOps, TeamCity, GitHub, or CI/CD environment"",""Familiarity with Docker for Linux-based virtualization"",""Experience with configuration management tools such as Ansible, Puppet"",""Hands-on experience with artifact repositories and package managers"",""Cloud APIs such as AWS or Azure"",""Experience in Rocky, Red Hat, or CentOS environments"",""Knowledge of Bash scripting and package management tools""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach improving the security posture of a product?"",""example_answer"":""I would start by conducting a thorough security assessment to identify vulnerabilities, then implement measures such as static application security testing and software composition analysis to mitigate risks.""},{""question"":""Can you explain the benefits of using containerization in a DevOps environment?"",""example_answer"":""Containerization allows for greater flexibility and efficiency in deploying applications, as well as improved security and isolation between applications.""}],""red_flags"":[""Lack of experience with Windows Virtualization"",""Inability to work collaboratively in an open and dynamic environment""],""confidence_score"":90.0}"
Java Cloud Engineer (AWS or GCP),"Iris's client, one of the world's largest financial institutions is looking to hire a Java Cloud Engineer – (AWS or GCP) for a long term contract opportunity.

Our client is one of the world's largest financial institutions, serving individual consumers, small and middle market businesses and large corporations with a full range of banking, investing, asset management and other financial and risk-management products and services. It is a leading provider of global corporate and investment banking services.



Position: Cloud Engineer – (AWS or GCP)
Location: Mississauga, ON
Duration: Long Term Open Ended Contract



Must have:

Strong programming skills with hands-on experience designing and implementing high volume, high availability applications with a very high degree of automation. Technical proficiency in the required programming languages, frameworks and technologies, including Java, SpringBoot, MongoDB, JSON and XML data notations.
In-depth knowledge of AWS services such as ECS, EC2, DocumentDB, Lambda, and S3, and their integration into complex cloud architectures.
Excellent interpersonal and communication skills.



About Iris Software Inc.

With 4,000+ associates and offices in India, U.S.A. and Canada, Iris Software delivers technology services and solutions that help clients complete fast, far-reaching digital transformations and achieve their business goals. A strategic partner to Fortune 500 and other top companies in financial services and many other industries, Iris provides a value-driven approach - a unique blend of highly-skilled specialists, software engineering expertise, cutting-edge technology, and flexible engagement models. High customer satisfaction has translated into long-standing relationships and preferred-partner status with many of our clients, who rely on our 30+ years of technical and domain expertise to future-proof their enterprises. Associates of Iris work on mission-critical applications supported by a workplace culture that has won numerous awards in the last few years, including Certified Great Place to Work in India; Top 25 GPW in IT & IT-BPM; Ambition Box Best Place to Work, #3 in IT/ITES; and Top Workplace NJ-USA.","{""role_summary"":""Design and implement high-volume, high-availability cloud applications with a high degree of automation, utilizing Java and cloud services such as AWS or GCP."",""key_terms"":[{""term"":""ECS"",""explanation"":""Elastic Container Service, a container orchestration service in AWS that allows running and managing Docker containers at scale.""},{""term"":""EC2"",""explanation"":""Elastic Compute Cloud, a virtual server service in AWS that provides resizable compute capacity.""},{""term"":""DocumentDB"",""explanation"":""A document-oriented database service in AWS that allows storing, managing, and querying JSON-like data.""},{""term"":""Lambda"",""explanation"":""A serverless compute service in AWS that runs code in response to events, without provisioning or managing servers.""},{""term"":""S3"",""explanation"":""Simple Storage Service, an object storage service in AWS that allows storing and retrieving large amounts of data.""},{""term"":""SpringBoot"",""explanation"":""A Java-based framework for building web applications and microservices, known for its simplicity and ease of use.""},{""term"":""MongoDB"",""explanation"":""A NoSQL document-oriented database that allows storing and managing large amounts of semi-structured data.""},{""term"":""JSON"",""explanation"":""JavaScript Object Notation, a lightweight data interchange format used for exchanging data between web servers and web applications.""},{""term"":""XML"",""explanation"":""Extensible Markup Language, a markup language used for storing and transporting data between systems.""}],""skill_priorities"":{""must_have"":[""Java"",""AWS or GCP"",""SpringBoot"",""MongoDB"",""JSON"",""XML""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a highly available cloud application using Java and AWS services?"",""example_answer"":""I would use a microservices architecture with load balancing, auto-scaling, and containerization using ECS and EC2. I would also implement a database solution using DocumentDB and S3 for storing and retrieving data.""},{""question"":""Can you explain the benefits of using SpringBoot for building cloud-native applications?"",""example_answer"":""SpringBoot provides a simple and efficient way to build cloud-native applications with minimal configuration and setup. It also provides built-in support for cloud services such as AWS and GCP, making it easier to deploy and manage applications in the cloud.""}],""red_flags"":[""Avoid candidates without hands-on experience with AWS or GCP services."",""Be cautious of candidates with limited experience in designing and implementing high-volume, high-availability applications.""],""confidence_score"":90.0}"
Cloud Security Engineer,"Ingénieur – Défense numérique (« SRE – Security »)

Élevez les affaires chez SIA Innovations

Alors que les organisations dépendent de plus en plus des données et de l'automatisation, la confiance zéro et la gestion des menaces continuent de gagner en importance de manière exponentielle. Nous voulons être à l'avant-garde, en guidant nos clients vers des opérations informatiques sûres et résilientes avec une sécurité sans friction.

Chez SIA Innovations, nous sommes des innovateurs qui s'engagent à aider nos clients dans leur virage numérique en tirant parti des technologies IA et cloud hybride d'IBM et Palo Alto Networks. Nous créons de la valeur en aidant nos clients à augmenter la productivité, à améliorer l'agilité et la résilience, et à soutenir les opérations durables.

Votre rôle et responsabilités

En tant qu'Ingénieur – Défense numérique, vous jouerez un rôle central pour guider nos clients et sécuriser leurs parcours de confiance zéro (« zero trust »). Vous montrerez l'exemple en dirigeant notre studio de Sécurité et notre équipe de spécialistes sur des projets clients et de la R&D interne. Vous faites la promotion de notre leadership en matière de solutions de confiance numérique et gestion des menaces qui font de SIA le partenaire de choix de nos clients en matière de cybersécurité.

Le candidat idéal pour ce poste excelle dans des environnements dynamiques et rapides et fait preuve d'une forte combinaison de compétences techniques, de connaissances des affaires, de créativité et de capacités de leadership. Vous êtes capable de relever des défis complexes, de concevoir des solutions innovantes et de guider les projets et les équipes vers les résultats commerciaux souhaités.

L'Ingénieur – Défense numérique est axé sur le client et sur les résultats, et ses responsabilités incluront :

Prendre en charge des projets d'architecture, de développement et de déploiement de solutions innovantes qui tirent parti des plateformes et technologies de sécurité de Palo Alto Networks et d'IBM.
Veiller à ce que les solutions soient alignées sur les exigences ; influencer et obtenir l'adhésion des principales parties prenantes ; gérer les attentes et garantir la satisfaction du client.
Diriger le studio « Sécurité » – prendre en charge les projets, encadrer l'équipe, animer les réunions agiles (« scrums » et « sprints »), faire des présentations mensuelles, aider les RH en menant des évaluations de performance pour les employés du studio et en participant à des activités de recrutement.
Diriger les activités et projets de recherche et développement expérimental pour accroître nos connaissances et compétences, développer et améliorer nos méthodologies, et élaborer des offres de solutions et services SIA.
Fournir un support prévente à l'équipe marketing et ventes de SIA (saisir les besoins des clients, répondre aux appels d'offres, développer des propositions et des plans de projet, créer et animer des présentations techniques, des démos, des ateliers et des PoT / PoC).
Participer activement aux médias sociaux et à d'autres occasions de réseautage pour promouvoir votre marque et notre entreprise (y compris des messages et des articles sur les pages vitrines).

Expertise technique et professionnelle requise

Les candidats idéals possèdent le profil suivant :

Compréhension approfondie des technologies de sécurité de Palo Alto Networks (Cortex XSIAM) et d'IBM (QRadar SIEM/SOAR/EDR/XDR, Guardium, Verify).
Compréhension des réseaux de données et du DevSecOps.
Familiarité avec les technologies et déploiements cloud, en particulier Kubernetes et Red Hat OpenShift.
Solides capacités de leadership, de communications, d'empathie et un esprit de croissance.
Maîtrise de l'anglais et du français.
Curiosité (explorateur), créativité et compétences organisationnelles.
À l'aise avec les ventes complexes et des cycles de vente longs.

Autres détails

Emploi permanent à temps plein en présentiel (bureau au centre-ville de Montréal).
Doit être résident de la région de Montréal et avoir l'autorisation de travailler au Canada.
Doit être disponible pour des déplacements occasionnels au Canada, aux États-Unis et aux Caraïbes – pour des projets client, des conférences et de la formation.

Cloud Security Engineer

Elevate business at SIA Innovations

As organizations rely more and more on data and automation, zero-trust and threat management continue to grow exponentially in importance. We want to be at the forefront, guiding our customers towards secure and resilient IT operations with frictionless security.

At SIA Innovations, we are innovators committed to helping our customers transform digitally by leveraging AI and hybrid cloud technologies from IBM and Palo Alto Networks. We create value by helping our customers increase productivity, improve agility & resiliency, and support sustainable operations.

Your role and responsibilities

As an Engineer – Digital Defense, you will play a central role in guiding our customers and securing their zero trust journeys. You will lead by example by directing our Security studio and it's team of specialists on customer and internal R&D projects. You will promote our leadership in digital trust and threat management solutions that make SIA the cybersecurity partner of choice for our customers.

The ideal candidate for this position excels in fast-paced, dynamic environments and demonstrates a strong combination of technical skills, business knowledge, creativity and leadership abilities. You are able to tackle complex challenges, design innovative solutions and guide projects and teams towards the desired business outcomes.

The Engineer - Digital Defense is customer-focused and results-driven, with responsibilities that include:

Taking ownership of projects to architect, develop and deploy innovative solutions that leverage Palo Alto Networks and IBM security platforms and technologies.
Ensure solutions are aligned with requirements; influence and gain buy-in from key stakeholders; manage expectations and ensure customer satisfaction.
Lead the Security studio - take charge of projects, coach the team, lead agile meetings (""scrums"" and ""sprints""), make monthly presentations, assist HR by conducting performance reviews for studio employees and participating in recruitment activities.
Lead research and experimental development activities and projects to increase our knowledge and skills, develop and improve our methodologies, and develop SIA solution and service offerings.
Provide pre-sales support to SIA's marketing and sales team (understand customer needs, respond to RFPs, develop proposals & project plans, create & facilitate technical presentations, demos, workshops, and PoT / PoCs).
Actively participate in social media and other networking opportunities to promote your brand and our company (including posts and articles on showcase pages).

Technical and professional expertise required

Ideal candidates have the following profile:

In-depth understanding of security technologies from Palo Alto Networks (Cortex XSIAM) and IBM (QRadar SIEM/SOAR/EDR/XDR, Guardium, Verify).
Understanding of data networks and DevSecOps.
Familiarity with cloud technologies and deployments, particularly Kubernetes and Red Hat OpenShift.
Strong leadership and communication skills, empathy, and a growth mindset.
Curiosity (explorer), creativity and organizational skills.
Fluency in English and French.
Comfortable with complex sales and long sales cycles.

Other details

Permanent, full-time, face-to-face position (office located in downtown Montreal).
Must be a resident of the Montreal area and have authorization to work in Canada.
Must be available for occasional travel in Canada, the U.S. and the Caribbean - for customer projects, conferences and training.

Apply today!

Join the SIA Innovations team, where your knowledge, experience and winning attitude will help you contribute to SIA's success and growth. We value diversity and employees with a growth mindset (explorers who are adaptable, teachable and coachable), personal & professional agility, and values that align with SIA's purpose, mission and culture.

SIA's CX North Star is to guide and support our customers on their journey to becoming virtual enterprises. Our mission is to make intelligent digital solutions affordable for our customers through the currency of our skills. In embracing transparency, adaptability, and a growth mindset, we open the doors to continuous improvement, innovation and unlimited potential for us and society's future. If you're passionate about growth through innovation, trend spotting and real-time tracking for agile execution, SIA Innovations is your ideal next step.

Ready to contribute to SIA's growth and success? Apply now and help us shape a successful digital future for our customers.","{""role_summary"":""Lead the development and deployment of innovative security solutions, guiding customers towards secure and resilient IT operations with frictionless security, and promoting SIA's leadership in digital trust and threat management solutions."",""key_terms"":[{""term"":""Zero Trust"",""explanation"":""A security concept that assumes no user or device, whether inside or outside an organization's network, is trusted by default.""},{""term"":""DevSecOps"",""explanation"":""A set of practices that combines software development (DevOps) and security to ensure the secure development, deployment, and operation of software systems.""},{""term"":""Cortex XSIAM"",""explanation"":""A security information and event management (SIEM) system from Palo Alto Networks that provides real-time threat detection and incident response.""},{""term"":""QRadar SIEM/SOAR/EDR/XDR"",""explanation"":""A suite of security products from IBM that provide threat detection, incident response, and security orchestration capabilities.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating the deployment, scaling, and management of containerized applications.""},{""term"":""Red Hat OpenShift"",""explanation"":""A container application platform that provides a hybrid cloud environment for deploying and managing containerized applications.""}],""skill_priorities"":{""must_have"":[""In-depth understanding of security technologies from Palo Alto Networks and IBM"",""Understanding of data networks and DevSecOps"",""Familiarity with cloud technologies and deployments, particularly Kubernetes and Red Hat OpenShift"",""Strong leadership and communication skills, empathy, and a growth mindset""],""nice_to_have"":[""Curiosity (explorer), creativity and organizational skills"",""Fluency in English and French"",""Comfortable with complex sales and long sales cycles""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a zero-trust architecture for a cloud-based application?"",""example_answer"":""I would start by identifying the application's sensitive data and assets, then implement multi-factor authentication, network segmentation, and encryption to restrict access to those assets. I would also use tools like Cortex XSIAM and QRadar to monitor and respond to threats in real-time.""},{""question"":""Can you explain the concept of DevSecOps and how it differs from traditional security practices?"",""example_answer"":""DevSecOps is a set of practices that integrates security into every stage of the software development lifecycle, from design to deployment. This approach differs from traditional security practices, which often focus on security as an afterthought or a separate phase. By integrating security into DevOps, we can identify and address security vulnerabilities earlier, reducing the risk of security breaches.""}],""red_flags"":[""Lack of experience with cloud security technologies and deployments"",""Inability to communicate technical concepts to non-technical stakeholders"",""Unwillingness to adapt to changing security requirements and threats""],""confidence_score"":90.0}"
Platform Engineer,"At Nirmata, our mission is to accelerate adoption of cloud native technologies for enterprises. We believe that software can radically transform the world and are building a solution to help enterprises deliver and operate mission critical software at scale. Nirmata is an enterprise-grade multi-cloud Kubernetes platform.

As a Platform Engineer at Nirmata, you will play a key role in operation and lifecycle management of Nirmata’s cloud-native environment delivering SaaS services to customers. You will be implementing necessary tools and processes to deliver a highly available, secure, performant and compliant global SaaS service. You will be collaborating with development, operations and customer success teams to deliver the right solution for Nirmata customers. Your areas of responsibility will span cloud infrastructure builds, CI/CD pipeline, security, performance and availability, monitoring and site reliability engineering.

Responsibilities

Responsible for production and development environment performance and availability.
Manage lifecycle of production and development cloud infrastructure, pipelines, security, monitoring and site reliability.
Troubleshoot and resolve technical issues in production systems.
Provide design and operational solutions for
Manage production and development escalations and work with engineering teams to resolve critical issues.
Create and update technical documentation of different solutions and processes being implemented in the production and dev environment.
Build tools and automation for smooth deployment of applications in production and development environments.
Be a point of escalation to resolve production and development environment issues.
Assist with scoping efforts for deployments and new integrations.
Maintain current technical knowledge of relevant technologies, including Nirmata, Kubernetes, virtualization, networking, monitoring, converged infrastructure, and storage networks.
Responsible for security and compliance of the production and development environments.

Requirements

Bachelor of Arts/Science or equivalent degree in computer science or related field
4+ years of professional experience
Experience with multi-account AWS infrastructure management
Strong Linux OS administration and management skills
Proficiency in shell scripting or Python
Experience with containers, Docker, and Kubernetes
Strong communication and collaboration skills
Ability to diagnose complex technical problems and provide solutions
Broad knowledge in other technical areas to manage complex integration efforts.

Skills

Kubernetes, docker, containers.
AWS cloud - EKS, IAM, networking, storage,
Has experience in DevOps methodologies, tools, and automation.
Linux OS administration and management skills.
Automation skills with shell scripting or python.
Experience with technologies like containers, Docker, and Kubernetes.
Strong problem-solving and analytical skills to troubleshoot complex technical issues.
Familiarity with compliance and security management in cloud environments.

About Nirmata

Nirmata empowers organizations to innovate rapidly without compromising security or compliance. With Gartner forecasting that 99% of cloud security failures will result from misconfigurations by 2027, Nirmata's policy-as-code platform offers a proactive solution. Nirmata's highly customizable policies seamlessly integrate with your cloud-native environments, ensuring robust governance and security at scale. Trusted by top financial institutions and global enterprises—and with over 3.2 billion downloads of Kyverno, Nirmata's open source policy engine —Kyverno simplifies compliance, mitigates risk, and accelerates the enterprise journey to secure innovation.

Nirmata’s success is built on the diverse contributions of its employees. We're committed to an inclusive workplace where everyone's perspective is valued, and we do not discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, marital, veteran, or disability status. All application information will be kept confidential in accordance with EEO guidelines.

Nirmata uses E-Verify for US-based roles, confirming work authorization after a job offer is accepted and the I-9 is completed. If E-Verify can't confirm authorization, we'll provide instructions on contacting DHS or SSA before any action is taken. See the Notice of Right to Work for details.

By submitting your application, you acknowledge that Nirmata will process your personal data in accordance with our Privacy Policy.","{""role_summary"":""As a Platform Engineer at Nirmata, you will be responsible for the operation and lifecycle management of Nirmata's cloud-native environment, delivering SaaS services to customers, and collaborating with development, operations, and customer success teams."",""key_terms"":[{""term"":""Cloud-native environment"",""explanation"":""A software system designed to take advantage of cloud computing principles, such as scalability and on-demand resources.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating the deployment, scaling, and management of containerized applications.""},{""term"":""CI/CD pipeline"",""explanation"":""A set of practices and tools that automate the build, test, and deployment of software applications, ensuring continuous integration and delivery.""},{""term"":""Site reliability engineering"",""explanation"":""A set of practices that apply software engineering principles to IT operations, focusing on the reliability, scalability, and performance of systems.""}],""skill_priorities"":{""must_have"":[""Kubernetes"",""AWS cloud (EKS, IAM, networking, storage)"",""Linux OS administration and management skills"",""Proficiency in shell scripting or Python"",""Experience with containers, Docker""],""nice_to_have"":[""DevOps methodologies, tools, and automation"",""Automation skills with shell scripting or python"",""Familiarity with compliance and security management in cloud environments""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you troubleshoot a performance issue in a Kubernetes cluster?"",""example_answer"":""I would start by checking the cluster's resource utilization, then investigate the application logs, and finally, use tools like kubectl to debug the issue.""},{""question"":""Can you explain how you would implement a CI/CD pipeline for a cloud-native application?"",""example_answer"":""I would use tools like Jenkins or GitLab CI/CD to automate the build, test, and deployment process, ensuring continuous integration and delivery.""}],""red_flags"":[""Lack of experience with Kubernetes or cloud-native environments"",""Inability to troubleshoot complex technical issues"",""Limited knowledge of security and compliance in cloud environments""],""confidence_score"":90.0}"
AWS Data Engineer,"AWS cloud Infra Engineer

Skillset Required:- Python, Ansible and CI/CD pipeline

Data warehousing technologies

Data Lake

Red Shift","{""role_summary"":""Design, implement, and maintain scalable and secure cloud infrastructure on AWS, ensuring efficient data warehousing and analytics capabilities."",""key_terms"":[{""term"":""Ansible"",""explanation"":""An automation tool for configuring and managing infrastructure and applications.""},{""term"":""CI/CD pipeline"",""explanation"":""A set of practices and tools for continuous integration and continuous delivery of software applications.""},{""term"":""Data warehousing"",""explanation"":""A system for storing and managing large amounts of data to support business intelligence and analytics.""},{""term"":""Data Lake"",""explanation"":""A centralized repository for storing raw, unprocessed data in its native format.""},{""term"":""Red Shift"",""explanation"":""A data warehousing and analytics service on AWS for analyzing data across data warehouses, data lakes, and databases.""}],""skill_priorities"":{""must_have"":[""Python"",""Ansible"",""CI/CD pipeline""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you automate infrastructure deployment and management using Ansible?"",""example_answer"":""I use Ansible playbooks to define infrastructure configurations and automate deployment, ensuring consistency and reducing errors.""},{""question"":""Can you explain the benefits of using a CI/CD pipeline in a cloud infrastructure?"",""example_answer"":""A CI/CD pipeline enables automated testing, deployment, and rollback of infrastructure changes, reducing errors and increasing efficiency.""}],""red_flags"":[""Lack of experience with AWS cloud infrastructure"",""Inability to automate infrastructure deployment using Ansible""],""confidence_score"":80.0}"
Cyber Security Analyst (Recent Graduates),"Take a central role

The Bank of Canada has a vision to be a leading central bank—dynamic, engaged and trusted—committed to a better Canada. No other employer in the country offers you the unique opportunity to work at the very center of Canada’s economy, in an organization with significant impact on the economic and financial well-being of all Canadians. You will be challenged, energized and motivated to excel in our environment.

Building on the principles that have always guided us – excellence, integrity and respect – we strive to be forward-looking and innovative, to welcome people with diverse perspectives and talents, and to earn trust by living up to our commitments and by clearly explaining the intent of our policies and actions.

With our defined-benefit pension plan, benefits, and high flexibility for work life balance - find out more about why we are annually ranked as one of Canada's top employers: Working Here - Bank of Canada

Find out more about the next steps in our Recruitment process .

To be considered

All interested candidates are encouraged to apply. For this position we are also open to recent graduates of a bachelor’s degree or college diploma in computer science, engineering, cyber security, or a relevant field. The completion date for your relevant diploma or degree would ideally be between January 2021 to May 2024.



What You Will Do

Our Identity & Access Management team is responsible to strengthen the identity and access management controls to secure internal and external access to the Bank’s digital resources. This includes adopting a zero trust architecture in our technical integration and secure development activities and advancing the IAM use cases to reduce the attack surface.

The focus of this role is to support fulfilment of the Identity and Access Management (IAM) services, monitor and enforce IT Security Standards across the Bank and provide advisory and assistance for the users. Further, this group is focused on introducing automation to further enhance its ability to respond to cyber events and incidents and improve operational efficiency.

You will also have an opportunity to contribute to the development, implementation, deployment and support activities of Identity and Access Management (IAM) capabilities to manage identities and control access for users of Bank systems.



Your Knowledge And Skills

Ability to systematically analyze information, define problems and draw logical conclusions.
Basic experience in developing, testing and maintaining automation scripts.
Basic understanding of TCP/IP fundamentals, security event analysis & correlation.
Basic skills in gathering and documenting business and functional requirements toward the implementation of infrastructure security access controls & technologies and configuration and optimization of security tools
Strong communication, interpersonal and organizational.
Ability to work effectively, independently or as part of a team.
Self-starter and innovative problem solver who enjoys working in a dynamic work environment.
Excellent report writing skills.
Data analysis or data analytics experience to assess and present complex technical data



What You Will Learn And Gain In Experience

A combination of knowledge in OS platforms, applications, databases, cloud, web services, IT Network Infrastructures.
Ability to discuss status with technical experts and perform security testing and validation on various platforms.
Obtain experience in developing, testing and maintaining automation scripts.
Get better understanding of TCP/IP fundamentals, security event analysis & correlation.
Obtain experience in gathering and documenting business and functional requirements toward the implementation of infrastructure security access controls & technologies and configuration and optimization of security tools.
Gain additional understanding in Cyber Security and Identity and Access Management industry and trends.



Nice to have

Basic knowledge of the Cyber Security, Identity and Access Management industry and trends.
Basic understanding of directories services i.e. AD, LDAP
Participation in ethical hacking competitions, capture-the-flag events, bug bounty programs or other activities related to cyber security assessment and controls.
Understanding of information security concepts (e.g., vulnerability, threat, asset, safeguard, risk, Common Vulnerability Scoring System, disaster recovery, etc.) or cyber risk frameworks.
A combination of knowledge in OS platforms, applications, databases, cloud, web services, IT Network Infrastructures.



Application process

All applicants must submit a completed online application that includes the following documentation to support their candidacy:

a resume
cover letter (including information such as reasons for pursuing a specific field of study, research and career)
official or unofficial transcripts of your academic record. (Relevant courses you have attended must be clearly identified by their course titles)

What You Need To Know

Language requirement: English or French essential
Priority will be given to Canadian citizens and permanent residents
Security level required: Be eligible to obtain Secret
There will be no relocation assistance provided
Please save a copy of the job poster. Once the closing date has passed, it will no longer be available.

Remote work / Hybrid Work Model

The Bank offers work arrangements that provide employees with flexibility, enable high-performing teams, and support an excellent workplace culture. Most employees can telework from home for a substantial part of each month as part of the Bank`s hybrid work model, and they are expected on site at the Bank location a minimum of eight days per month to help build connections between colleagues. You must live in Canada, and within reasonable commuting distance of

the office. For this position, should you not live within reasonable commuting distance of the office, you will be able to work 100% remote (within Canada) for the duration of this term.

We wish to thank all applicants for their interest and effort in applying for this position. Only candidates selected for interviews will be contacted.

What You Can Expect From Us

This is a great opportunity to join a leading organization and be part of a high-performing team. We offer a competitive compensation and benefits package designed to meet your needs at every stage of your life and career. For more information on key benefits please visit A great deal to consider .

Salaries are based on qualifications and experience and typically range from $69,298 to $81,527 (job grade 14)
The Bank offers an incentive for successfully meeting expectations at 3 to 5% of your base salary. The Bank offers performance pay for those who exceed expectations (7% of your base salary). Exceptional performers who far exceed expectations may be eligible for higher performance pay.
Flexible and comprehensive benefits so you can choose the level of health and dental coverage that meets your needs
Extra vacation days (up to five each year) that you can purchase to add to your vacation entitlement
Option to join the indexed, defined-benefit pension plan after 24 consecutive months of service

We wish to thank all applicants for their interest and effort in applying for this position. Only candidates selected for interviews will be contacted.","{""role_summary"":""Support the Identity and Access Management team in strengthening identity and access management controls, monitoring and enforcing IT security standards, and providing advisory services to users."",""key_terms"":[{""term"":""Zero Trust Architecture"",""explanation"":""A security approach that assumes no user or device, whether inside or outside an organization's network, is trusted by default.""},{""term"":""TCP/IP Fundamentals"",""explanation"":""The basic principles and protocols that govern the internet and enable communication between devices.""},{""term"":""Security Event Analysis & Correlation"",""explanation"":""The process of identifying, categorizing, and linking security-related events to detect and respond to potential threats.""},{""term"":""Cyber Security and Identity and Access Management"",""explanation"":""The practices, technologies, and processes designed to protect digital identities, data, and systems from unauthorized access, use, disclosure, disruption, modification, or destruction.""}],""skill_priorities"":{""must_have"":[""Ability to systematically analyze information"",""Basic experience in developing, testing and maintaining automation scripts"",""Basic understanding of TCP/IP fundamentals, security event analysis & correlation"",""Strong communication, interpersonal and organizational skills""],""nice_to_have"":[""Basic knowledge of the Cyber Security, Identity and Access Management industry and trends"",""Basic understanding of directories services i.e. AD, LDAP"",""Participation in ethical hacking competitions, capture-the-flag events, bug bounty programs or other activities related to cyber security assessment and controls"",""Understanding of information security concepts""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of zero trust architecture and how it applies to identity and access management?"",""example_answer"":""Zero trust architecture is a security approach that assumes no user or device, whether inside or outside an organization's network, is trusted by default. In the context of identity and access management, it means implementing strict access controls, authentication, and authorization mechanisms to ensure that only authorized users have access to sensitive resources and data.""},{""question"":""How would you analyze and respond to a security event, such as a potential cyber attack?"",""example_answer"":""I would follow a structured approach to analyze the event, including identifying the source and scope of the attack, assessing the potential impact, and containing the incident. I would then develop a plan to eradicate the threat, recover from the incident, and implement measures to prevent similar events in the future.""}],""red_flags"":[""Lack of experience in developing, testing, and maintaining automation scripts"",""Insufficient understanding of TCP/IP fundamentals and security event analysis & correlation"",""Inability to work effectively in a team environment""],""confidence_score"":85.0}"
Security Analyst,"As one of Canada's largest and fastest growing cryptocurrency trading platforms, NDAX has set the bar high for the country's fintech industry and is constantly leading the way in terms of security and innovation. We're on a mission to empower more Canadians to unlock the full potential of digital finance. To address the various needs in the Canadian cryptocurrency space, NDAX has assembled a multidisciplinary team with diverse backgrounds, including finance, technology, engineering, compliance, marketing, and more.

We're proud to have been recognized as one of Canada's Best Workplaces by Great Place to Work®.

NDAX is currently looking to hire a Security Analyst to join our team, safeguarding systems and data against threats. Ideal candidates understand security principles, tech-savvy, and proactive in risk mitigation.

Position Type: Full Time - Permanent

Key Responsibilities:

Monitor security alerts and incidents, analyze data, and respond promptly to potential security threats
Conduct regular vulnerability assessments and penetration testing to identify and remediate security weaknesses
Develop and implement incident response plans, and lead efforts to investigate and resolve security incidents
Contribute to the development, implementation, and enforcement of security policies, standards, and procedures
Educate and train employees on security best practices to enhance the overall security posture of the organization
Evaluate and recommend security technologies and solutions to enhance the organization's security infrastructure
Conduct risk assessments to identify and prioritize security risks, and work with stakeholders to implement risk mitigation strategies
Ensure compliance with relevant security standards, regulations, and industry best practices
Maintain accurate and up-to-date documentation related to security policies, procedures, and incident response activities
Promote a culture of security awareness and compliance throughout the organization through training and communication initiatives
Collaborate with cross-functional teams to integrate security best practices into the development and maintenance of systems and applications


Requirements

Bachelor's degree in Computer Science, Information Security, or a related field. Relevant certifications (e.g., CISSP, CISM, CompTIA Security+) are a plus
Experience with certificate automation platform
Proven experience in information security, with a focus on security analysis, incident response, and vulnerability management
Strong understanding of network security, encryption, firewalls, intrusion detection/prevention systems, and other security technologies
Excellent analytical and problem-solving skills, with the ability to analyze security events and identify potential risks
Strong communication skills, both written and verbal, with the ability to convey complex security concepts to technical and non-technical stakeholders
Ability to work collaboratively in a team environment and contribute to the success of the overall security program
Demonstrated commitment to staying current with evolving security threats, technologies, and best practices


Benefits

Extended Healthcare Plan (Medical, Disability, Dental & Vision)
Paid Time Off
Training & Development Opportunities
Bonus - Awards - Gifts
Stock Option Plan
Free snacks and drinks at the office","{""role_summary"":""The Security Analyst is responsible for safeguarding systems and data against threats, identifying and remediating security weaknesses, and promoting a culture of security awareness and compliance throughout the organization."",""key_terms"":[{""term"":""Vulnerability assessments"",""explanation"":""Identifying and evaluating weaknesses in systems or applications that could be exploited by attackers.""},{""term"":""Penetration testing"",""explanation"":""Simulating a cyber attack on a computer system, network, or web application to test its defenses.""},{""term"":""Incident response plans"",""explanation"":""Procedures to follow in the event of a security incident, such as a data breach or ransomware attack.""},{""term"":""CISSP"",""explanation"":""Certified Information Systems Security Professional, a certification for information security professionals.""},{""term"":""Certificate automation platform"",""explanation"":""A system that automates the management of digital certificates, used for secure communication and authentication.""}],""skill_priorities"":{""must_have"":[""Experience in information security"",""Strong understanding of network security"",""Analytical and problem-solving skills"",""Strong communication skills""],""nice_to_have"":[""Relevant certifications (e.g., CISSP, CISM, CompTIA Security+)"",""Experience with certificate automation platform""]},""proposed_screening_questions_with_answers"":[{""question"":""What steps would you take to respond to a security incident, and how would you prioritize your actions?"",""example_answer"":""I would first contain the incident to prevent further damage, then conduct a thorough analysis to identify the root cause. Next, I would develop a plan to remediate the issue and implement it, while also communicating with stakeholders and ensuring compliance with relevant regulations.""},{""question"":""How do you stay current with evolving security threats and best practices?"",""example_answer"":""I regularly follow industry blogs and news sources, participate in online forums and discussion groups, and attend conferences and training sessions to stay up-to-date on the latest security trends and technologies.""}],""red_flags"":[""Lack of experience in information security"",""Inability to communicate complex security concepts to non-technical stakeholders""],""confidence_score"":95.0}"
IT Security Engineer,"We are looking for IT Security Engineer

Responsibilities

Implementation, management, and monitoring of IT security measures and protections within the organization
Analysis and evaluation of potential threats, designing and implementing security solutions
Monitoring IT infrastructure to identify security vulnerabilities and taking appropriate corrective actions
Responding to security incidents and providing technical support in IT security
Collaborating with IT teams and other departments to implement and maintain security policies, standards, and procedures
Managing security tools, creating IT security reports, and conducting audits
Adjusting security strategies to changing industry requirements and regulations

Requirements

Minimum 3 years of experience in IT Security or a related field
Knowledge of IT security tools and technologies
Ability to identify and analyze potential threats, and develop appropriate security solutions
Knowledge of risk management principles and procedures for responding to security incidents
Ability to work in a team and good interpersonal communication skills
IT security certifications such as CISSP, CISM, CEH, are an additional advantage

We Offer

B2B contract type
Full-time employment
Remote and flexible working hours","{""role_summary"":""An IT Security Engineer is responsible for implementing, managing, and monitoring IT security measures, analyzing potential threats, and responding to security incidents to ensure the organization's IT infrastructure is secure."",""key_terms"":[{""term"":""CISSP"",""explanation"":""Certified Information Systems Security Professional, a certification for IT security professionals demonstrating expertise in security and risk management.""},{""term"":""CISM"",""explanation"":""Certified Information Security Manager, a certification for IT security professionals demonstrating expertise in information security management.""},{""term"":""CEH"",""explanation"":""Certified Ethical Hacker, a certification for IT security professionals demonstrating expertise in ethical hacking and penetration testing.""}],""skill_priorities"":{""must_have"":[""Knowledge of IT security tools and technologies"",""Ability to identify and analyze potential threats"",""Knowledge of risk management principles and procedures for responding to security incidents""],""nice_to_have"":[""IT security certifications such as CISSP, CISM, CEH""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a situation where you identified a potential security threat and implemented a solution?"",""example_answer"":""In my previous role, I identified a vulnerability in our network infrastructure and implemented a patch to prevent a potential breach. I worked with the IT team to develop a plan to roll out the patch across the organization, ensuring minimal disruption to business operations.""},{""question"":""How do you stay up-to-date with changing industry requirements and regulations in IT security?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read relevant publications to stay current with the latest developments in IT security. I also collaborate with colleagues and peers to share knowledge and best practices.""}],""red_flags"":[""Lack of experience in IT security or a related field"",""Inability to identify and analyze potential threats""],""confidence_score"":90.0}"
Cybersecurity Analyst,"Your role as Cybersecurity Analyst

Reporting to CISO, you will contribute to securing Dialogue systems against cyber threats, ensuring the integrity, confidentiality and availability of data through detailed analysis, incident response, policy and protocols development and implementation.

What You’ll Be Doing

Monitor, review, and analyze the security of systems and processes, including network logs and security data. Perform security incident response activities and develop relevant indicators (KRIs/KPIs) based on complex analysis.
Assist in threat response exercises and business continuity plan testing. Support daily cybersecurity operations such as incident response, patch management, vulnerability management, and access management.
Develop, administer, and implement cybersecurity policies, protocols, plans, and guidelines. This includes creation and maintenance of security plans and protocols to prevent and mitigate potential incidents.
Conduct information systems security controls and risk assessments to identify vulnerabilities. Assist in the creation and maintenance of the security risk register, audit requests, and vendor assessments.
Review and maintain information security policies and training materials, respond to security questionnaires, and collaborate in change management communications and processes. Consult with IT and Engineering directors to develop the objectives of the cybersecurity program and facilitate compliance training.

We'd Love To Hear From You If You Have

5+ years of experience in cybersecurity operations with increasing responsibilities.
Demonstrated expertise or experience with Incident Response, Vulnerability Management, Network Security, Identify and Access Management, Cloud-based technology (Okta, Auth0, AWS, DataGuard, GCP, Google Workspace), Zero Trust Network Access, scripting knowledge is a plus.
Knowledge of frameworks and industry standards: NIST CSF, OWASP, MITRE ATT&CK, SSDLC.
Information security certifications (CRISC, CISA, CISM, CGEIT, CISSP, CCSP) are considered an asset.

Please note that as we serve customers across Canada, bilingualism is essential for this position. You may be required to communicate in French and English.

At Dialogue, your well-being is our priority

Taking care of others also means taking care of our team. We’ve got you covered!

A fully funded benefits plan, including a wellness reimbursement program
Unlimited access to a variety of Dialogue's programs for you and your immediate family
4 weeks of vacation, 9 wellness days and 1 paid volunteer day
A hybrid work approach that involves 3 days per week in our beautiful Montreal or Toronto offices
Access to a custom learning program, including an allocated budget for continuous external training
Short and long-term incentive plans, including restricted stock units (RSUs)
An optional parental benefits program
Qualifying permanent and part-time employees are eligible for a Group Retirement Savings Program (GRSP) with a matching employer contribution from their first day at Dialogue, in accordance with policy terms

About Dialogue

Dialogue is the #1 virtual care provider in Canada. By developing our Integrated Health Platform🅫, we provide exceptional online health and wellness programs (primary care, mental health, iCBT, EAP, and wellness) to organizations that want to improve the wellness of their employees and families.

When It Comes To Our Work, We Set The Bar High. Together, We’re Transforming Health And Helping Millions Improve Their Well-being. We’re Firm Believers That Great People Don’t Settle On

Impact

Community

Growth

Excellence

Feel like you can make a difference? Good news, we saved you a seat!

Come as you are. As a proud equal opportunity employer, Dialogue is dedicated to creating a diverse and inclusive workplace for everyone. Qualified applicants will be considered regardless of citizenship, ethnicity, race, colour, religion, gender, gender identity or expression, sexual orientation, disability, age, or veteran status. Applicants who require specialized accommodation are encouraged to contact accessibility@dialogue.co.","{""role_summary"":""Contribute to securing systems against cyber threats, ensuring data integrity, confidentiality, and availability through analysis, incident response, and policy development."",""key_terms"":[{""term"":""Incident Response"",""explanation"":""Responding to and managing cybersecurity incidents to minimize damage.""},{""term"":""Vulnerability Management"",""explanation"":""Identifying and mitigating vulnerabilities in systems and applications to prevent exploitation.""},{""term"":""Network Security"",""explanation"":""Protecting computer networks from unauthorized access, use, disclosure, disruption, modification, or destruction.""},{""term"":""Identify and Access Management"",""explanation"":""Managing digital identities and access to resources to ensure secure authentication and authorization.""},{""term"":""Cloud-based technology"",""explanation"":""Using cloud computing services and platforms, such as Okta, Auth0, AWS, DataGuard, GCP, and Google Workspace, to store and process data.""},{""term"":""Zero Trust Network Access"",""explanation"":""A security approach that assumes no user or device, whether inside or outside an organization's network, is trusted.""},{""term"":""NIST CSF"",""explanation"":""The National Institute of Standards and Technology Cybersecurity Framework, a set of guidelines for managing and reducing cybersecurity risk.""},{""term"":""OWASP"",""explanation"":""The Open Web Application Security Project, a non-profit organization that provides resources for web application security.""},{""term"":""MITRE ATT&CK"",""explanation"":""A knowledge base of cyber adversary tactics and techniques, used to better understand and defend against attacks.""},{""term"":""SSDLC"",""explanation"":""The Secure Software Development Life Cycle, a process for integrating security into software development.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in cybersecurity operations"",""Demonstrated expertise or experience with Incident Response, Vulnerability Management, Network Security, Identify and Access Management"",""Knowledge of frameworks and industry standards: NIST CSF, OWASP, MITRE ATT&CK, SSDLC"",""Bilingualism (French and English)""],""nice_to_have"":[""Scripting knowledge"",""Information security certifications (CRISC, CISA, CISM, CGEIT, CISSP, CCSP)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with incident response and how you would handle a security breach?"",""example_answer"":""I have experience with incident response and have developed relevant indicators (KRIs/KPIs) based on complex analysis. In the event of a security breach, I would follow our established incident response plan, which includes containment, eradication, recovery, and post-incident activities.""},{""question"":""How do you stay current with emerging threats and vulnerabilities in cloud-based technologies?"",""example_answer"":""I regularly review industry reports and publications, such as OWASP and MITRE ATT&CK, to stay informed about emerging threats and vulnerabilities. I also participate in training and certification programs to maintain my knowledge and skills.""}],""red_flags"":[""Lack of experience with cloud-based technologies"",""No knowledge of industry standards and frameworks (NIST CSF, OWASP, MITRE ATT&CK, SSDLC)""],""confidence_score"":90.0}"
Cyber Security Specialist,"As one of Canada's largest and fastest growing cryptocurrency trading platforms, NDAX has set the bar high for the country's fintech industry and is constantly leading the way in terms of security and innovation. We're on a mission to empower more Canadians to unlock the full potential of digital finance. To address the various needs in the Canadian cryptocurrency space, NDAX has assembled a multidisciplinary team with diverse backgrounds, including finance, technology, engineering, compliance, marketing, and more.

We're proud to have been recognized as one of Canada's Best Workplaces by Great Place to Work®.

If you are an experienced Cyber Security Specialist, NDAX has the right opportunity for you!

Key Responsibilities

Safeguards information system assets by identifying and solving potential and actual security problems
Protects system by defining access privileges, control structures, and resources
Recognizes problems by identifying abnormalities; reporting violations
Implements security improvements by assessing current situation; evaluating trends; anticipating requirements
Determines security violations and inefficiencies by conducting periodic audits
Upgrades system by implementing and maintaining security controls
Keeps users informed by preparing performance reports; communicating system status
Maintains quality service by following organization standards
Maintains technical knowledge by attending educational workshops; reviewing publications
Contributes to team effort by accomplishing related results as needed


Cyber Security Qualifications / Skills

System administration
Network security
Problem solving
Information security policies
On-call network troubleshooting
Firewall administration
Network protocols
Routers, hubs, and switches
Informing others
Process improvement


Requirements

Bachelor's degree in Computer Science, Information Systems, or equivalent education or work experience
4+ years of prior relevant experience
Advanced certifications such as SANS GIAC/GCIA/GCIH, CISSP or CASP and/or SIEM-specific training and certification
Hold DoD-8570 IAT Level 2 baseline certification (Security+ CE or equivalent) at start date
Advanced understanding of TCP/IP, common networking ports and protocols, traffic flow, system administration, OSI model, defense-in-depth and common security elements
Hands-on experience analyzing high volumes of logs, network data (e.g. Netflow, FPC), and other attack artifacts in support of incident investigations
Experience with vulnerability scanning solutions
Familiarity with the DOD Information Assurance Vulnerability Management program
Proficiency with any of the following: Anti-Virus, HIPS, ID/PS, Full Packet Capture, Host-Based Forensics, Network Forensics, and RSA Security
In-depth knowledge of architecture, engineering, and operations of at least one enterprise SIEM platform (e.g. Nitro/McAfee Enterprise Security Manager, ArcSight, QRadar, LogLogic, Splunk)
Experience developing and deploying signatures (e.g. YARA, Snort, Suricata, HIPS)
Understanding of mobile technology and OS (i.e. Android, iOS, Windows), VMware technology, and Unix and basic Unix commands


Benefits

Extended Healthcare Plan (Medical, Disability, Dental & Vision)
Life Insurance
Paid Time Off
Training & Development Opportunities
Bonus - Awards - Gifts
Work From Home - Flexible hour
Free access to gym (For Calgary based employees only)
Free snacks and drinks at the office","{""role_summary"":""A Cyber Security Specialist responsible for safeguarding information system assets, identifying and solving security problems, and implementing security improvements to protect the organization's systems and data."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a system that monitors and analyzes security-related data from various sources to provide real-time insights and alerts.""},{""term"":""DOD-8570 IAT Level 2"",""explanation"":""A US Department of Defense certification requirement for Information Assurance (IA) personnel, ensuring they have the necessary skills and knowledge to perform IA functions.""},{""term"":""TCP/IP"",""explanation"":""Transmission Control Protocol/Internet Protocol, a set of communication protocols used to interconnect devices on the internet.""},{""term"":""OSI model"",""explanation"":""Open Systems Interconnection model, a conceptual framework used to understand how data is transmitted over a network.""},{""term"":""Defense-in-depth"",""explanation"":""A security strategy that involves multiple layers of defense to protect against various types of attacks and vulnerabilities.""}],""skill_priorities"":{""must_have"":[""System administration"",""Network security"",""Problem solving"",""Information security policies"",""TCP/IP"",""Network protocols"",""Routers, hubs, and switches"",""SIEM-specific training and certification""],""nice_to_have"":[""Anti-Virus"",""HIPS"",""ID/PS"",""Full Packet Capture"",""Host-Based Forensics"",""Network Forensics"",""RSA Security"",""YARA"",""Snort"",""Suricata"",""Mobile technology and OS"",""VMware technology"",""Unix and basic Unix commands""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the OSI model and how it relates to network security?"",""example_answer"":""The OSI model is a 7-layered framework that helps understand how data is transmitted over a network. In terms of network security, it's essential to understand how data flows through each layer to identify potential vulnerabilities and implement effective security controls.""},{""question"":""How would you approach incident response and analysis in a SIEM environment?"",""example_answer"":""I would start by analyzing logs and network data to identify the source and scope of the incident. Then, I would use my knowledge of SIEM platforms to develop and deploy signatures to detect similar threats in the future. Finally, I would document the incident and implement process improvements to prevent similar incidents from occurring.""}],""red_flags"":[""Lack of hands-on experience with SIEM platforms"",""Inability to analyze high volumes of logs and network data"",""Limited understanding of TCP/IP and common networking protocols""],""confidence_score"":90.0}"
Cyber Security Analyst I (3am-11amPST),"COMPANY OVERVIEW:

With over two decades of successfully operating, managing, and securing private, public, and hybrid cloud environments, Ntirety has led enterprises across industries through the volatile early days of data hosting into the world of 24x7 managed security with our premier Compliant Security solutions. Through cost effective and scalable solutions tailored to business-specific needs, Ntirety eliminates gaps in both security posture and compliance documentation by delivering solutions that cover the entire application, the entire compliance and security process, the entire time.

When it comes to a cybersecurity crisis, the question is not if, but when it will happen - that's why Ntirety's mission to provide proactive compliant security is crucial in today's business landscape. No matter what role or department you work in, being a part of Ntirety means supporting all of our different teams to help keep our clients protected and updated on the latest in cybersecurity.

Join the team at the forefront of this mission-critical industry. For more information about Ntirety, please visit www.ntirety.com.

POSITION PURPOSE:

Cyber security analysts are responsible for managing, monitoring, troubleshooting and protecting both the security of our internal environment and that of our customers. They will perform any steps necessary to that end. They will design, implement, monitor, and evaluate the security systems that protect an organization's computer systems and data. As a Cyber Security Analyst, you will monitor the computer networks under management for security issues, install security software, and document any security issues you identify. This role also acts as the first point of contact for customer related security incidents and questions.

In order to be eligible for the Employee Bonus Plan, all employees are required to be performing their job duties satisfactorily during the applicable bonus period. This includes consistent responsiveness during any assigned On Call periods. Employees should also review the Employee Bonus Plan eligibility requirements to determine if they are eligible. If you have any questions on your eligibility for the Employee Bonus Plan please contact Human Resources.

ESSENTIAL JOB DUTIES AND RESPONSIBILITIES:

Monitor computer networks for security issues and respond accordingly, including:
Creating/Managing firewall rules
Managing anti-virus endpoint tools
Performing event correlation analysis on potential threats identified through our SIEM
Configuring/Managing log management
Configuring/Managing file integrity monitoring
Performing vulnerability scans and remediation of identified risks
The methodology & analysis of identifying compromised servers
Performing rule tuning in our SIEM for improved detection capabilities
Interact with customers by phone, chat, or trouble ticket on any customer facing security issues
Investigate, document and assess security breaches and other cyber security incidents
Install security measures and operate software to protect systems and information infrastructure, including firewalls and data encryption programs
Prepare security reports for customer business insights reviews to support our guidance level agreements initiatives
Identify and fix detected vulnerabilities to maintain a high-security standard
Work with other technology teams and customers to perform tests and uncover network or other vulnerabilities
May be relied upon as a technical point of contact during Escalated Events relating to security
Review, investigate and respond to any external ""abuse"" complaints coming from our IP space
Develop best practices for IT security
Research security enhancements and make recommendations to management
Handle escalated internal or customer security issues from support or other operations team
Takes part in any security-oriented projects or critical initiatives
Stay up to date on information technology & security news, trends and standards
Deliver an exceptional customer experience every day
Other duties as identified or assigned


DESIRED ROLE OUTCOMES:

Keep us and our customers free from security incidents but respond capably when one occurs
Contribute to continually improving our detection of security threats
Provide valuable insights and visibility around security incidents to our customers
Have a staff of customer focused, energetic and security savvy team members


Requirements

DESIRED MINIMUM QUALIFICATIONS:

Must have technical troubleshooting and problem-solving skills
Understanding of network management principles
Experience in systems administration of Windows and Linux based operating systems
Working knowledge of Palo Alto firewalls, Juniper networking equipment, LogRhythym SIEM solution or similar technologies
Understanding of firewalls, proxies, SIEM, antivirus, penetration testing, vulnerability scans and IDS/IPS concepts
Ability to identify and mitigate network vulnerabilities and explain how to avoid them
Understanding of patch management with the ability to deploy patches in a timely manner while understanding business impact
Ability to learn and communicate technical information to non-technical people
Must have excellent written & oral communication skills, and strong interpersonal skills
Must emulate the Ntirety Values in all that they do
Bachelor's degree in computer science or related field or equivalent experience


PREFERRED SKILLS:

Additional certifications in security related disciplines (eg: Security+, CEH, CISSP, etc.)


Benefits

Ntirety is an Equal Employment Opportunity / Affirmative Action Employer (EEO/AA).

Ntirety offers a competitive salary and benefits including Paid Time Off, FREE Medical to Employees, Dental, retirement plan with 401(k) match, and much more. If you are interested in joining a profitable, growing, and dynamic company, we want to hear from you! Ntirety is an Equal Opportunity Employer and does not discriminate on the basis of race, color, religion, sex, age, national origin, disability, veteran status, sexual orientation, or any other classification protected by Federal, State or local law.

Ntirety thanks all candidates for their interest; however, only shortlisted candidates will be contacted.","{""role_summary"":""Manage and monitor internal and customer environments to prevent and respond to security incidents, ensuring the security and compliance of computer systems and data."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a system that monitors and analyzes security-related data from various sources.""},{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection System/Intrusion Prevention System, a system that detects and prevents unauthorized access to a computer system or network.""},{""term"":""Palo Alto firewalls"",""explanation"":""A type of network security system that monitors and controls incoming and outgoing network traffic based on predetermined security rules.""},{""term"":""LogRhythym SIEM solution"",""explanation"":""A specific Security Information and Event Management system used to monitor and analyze security-related data from various sources.""}],""skill_priorities"":{""must_have"":[""Technical troubleshooting and problem-solving skills"",""Understanding of network management principles"",""Experience in systems administration of Windows and Linux based operating systems"",""Understanding of firewalls, proxies, SIEM, antivirus, penetration testing, vulnerability scans and IDS/IPS concepts""],""nice_to_have"":[""Additional certifications in security related disciplines (eg: Security+, CEH, CISSP, etc.)""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you respond to a security incident in a customer's environment?"",""example_answer"":""I would first contain the incident, then conduct a thorough investigation to identify the root cause, and finally implement measures to prevent similar incidents in the future.""},{""question"":""Can you explain the concept of patch management and its importance in security?"",""example_answer"":""Patch management is the process of identifying, acquiring, installing, and verifying patches for products and systems. It's crucial in security as it helps to fix vulnerabilities and prevent exploitation by attackers.""}],""red_flags"":[""Lack of experience in systems administration of Windows and Linux based operating systems"",""Inability to communicate technical information to non-technical people""],""confidence_score"":90.0}"
Application Security Analyst-Canada,"Role: Application Security Analyst

Location: Regina, SK-Day one onsite

Duration: 6+ Months

Job Description

The duties of the resource will include, but are not necessarily limited to
Utilizing both automated and manual techniques to test security within applications.
Performance of application vulnerability assessments and penetration testing.
Responsible for web application and mobile application security testing.
Responsible for security testing of web services and APIs.
Performance of code reviews on code developed by AMS team, when required.
Performance of false positive/negative analysis and providing recommendations to developers.
Responsible for protecting all web applications using WAF.","{""role_summary"":""An Application Security Analyst is responsible for identifying and addressing security vulnerabilities in applications, web services, and APIs using various testing techniques, code reviews, and security tools."",""key_terms"":[{""term"":""Penetration testing"",""explanation"":""Simulating a cyber attack on an application to test its defenses and identify vulnerabilities.""},{""term"":""WAF"",""explanation"":""Web Application Firewall, a security system that protects web applications from attacks.""},{""term"":""False positive/negative analysis"",""explanation"":""Evaluating the accuracy of security test results to minimize incorrect warnings or missed threats.""}],""skill_priorities"":{""must_have"":[""Application security testing"",""Vulnerability assessment"",""Penetration testing"",""Code review""],""nice_to_have"":[""Web application firewall (WAF) experience"",""Mobile application security testing""]},""proposed_screening_questions_with_answers"":[{""question"":""What is the difference between a vulnerability scan and a penetration test?"",""example_answer"":""A vulnerability scan is an automated process that identifies potential security weaknesses, whereas a penetration test is a simulated attack on an application to test its defenses and identify exploitable vulnerabilities.""},{""question"":""How do you prioritize and address false positive security test results?"",""example_answer"":""I review the test results, verify the findings, and provide recommendations to developers to address the identified vulnerabilities, ensuring accurate and efficient security testing.""}],""red_flags"":[""Lack of experience with application security testing tools and techniques"",""Inability to explain the difference between a vulnerability scan and a penetration test""],""confidence_score"":85.0}"
Info Security Analyst x6,"Are you a Info Security Analyst looking for a new opportunity?

Are you looking for a new contract opportunity?

We are pleased to offer you a new contract opportunity for you to consider: Info Security Analyst

Start: ASAP
Estimated length: 6 months
Location: Toronto
Hybrid role- onsite twice a week

Advantages

You will have an opportunity to work with a leading employer in the local market.
Potential for contract extension and conversion.

Responsibilities

Develop and implement comprehensive risk management strategies and policies to mitigate identified risks, including but not limited to, cyber threats, data breaches, IT outages, and technology compliance issues.
Collaborate with IT, business units, and cybersecurity teams to enhance the banks cyber and technology risk posture through proactive risk identification, assessment, and response planning.
Oversee and guide the risk assessment process for new and existing technologies, digital initiatives, and third-party service providers, ensuring comprehensive risk evaluation and mitigation planning.
Provide expert advice and guidance to senior management on technology and cyber risk trends, potential impacts on the bank, and recommended risk mitigation strategies.
Facilitate and promote a culture of risk awareness and cybersecurity resilience across the organization, including the development and delivery of risk management training programs.
Monitor and analyze developments in technology and cybersecurity threats, including regulatory changes, to continuously refine and update risk management strategies.
Prepare and present detailed risk reports and dashboards to senior management and relevant committees, highlighting the banks risk posture, emerging risks, and effectiveness of risk mitigation efforts.

Qualifications

Compliance testing experience
Fraud/AML/KYC/Insider Risk experience
Financial institution background
Cyber Risk Assessment experience
BISO – Business Information Security Officer

NICE TO HAVE

Company’s Bank experience

Summary

Do you have this experience? If you answer YES, then please apply IMMEDIATELY to so we can then discuss your experience and interest in this opportunity!

Randstad Technologies Group

Canada's largest provider of IT Staffing Solutions, offering hundreds of permanent and contract opportunities across all roles, levels and platforms. Our Web-based tools help you see and apply for jobs matched automatically to your skills and preferences. When you're ready to interview we meet with you in person to help you build the technology career path you've always wanted. Visit www.randstad.ca to get started!

Randstad Canada is committed to fostering a workforce reflective of all peoples of Canada. As a result, we are committed to developing and implementing strategies to increase the equity, diversity and inclusion within the workplace by examining our internal policies, practices, and systems throughout the entire lifecycle of our workforce, including its recruitment, retention and advancement for all employees. In addition to our deep commitment to respecting human rights, we are dedicated to positive actions to affect change to ensure everyone has full participation in the workforce free from any barriers, systemic or otherwise, especially equity-seeking groups who are usually underrepresented in Canada's workforce, including those who identify as women or non-binary/gender non-conforming; Indigenous or Aboriginal Peoples; persons with disabilities (visible or invisible) and; members of visible minorities, racialized groups and the LGBTQ2+ community.

Randstad Canada is committed to creating and maintaining an inclusive and accessible workplace for all its candidates and employees by supporting their accessibility and accommodation needs throughout the employment lifecycle. We ask that all job applications please identify any accommodation requirements by sending an email to accessibility@randstad.ca to ensure their ability to fully participate in the interview process.","{""role_summary"":""An Info Security Analyst responsible for developing and implementing risk management strategies, collaborating with teams to enhance cyber and technology risk posture, and providing expert advice on risk trends and mitigation strategies."",""key_terms"":[{""term"":""Cyber threats"",""explanation"":""Potential digital attacks or breaches on the bank's systems or data.""},{""term"":""Risk assessment"",""explanation"":""Evaluating and identifying potential risks or threats to the bank's technology and cybersecurity.""},{""term"":""BISO"",""explanation"":""Business Information Security Officer, a role responsible for overseeing and implementing information security within an organization.""},{""term"":""AML/KYC/Insider Risk"",""explanation"":""Anti-Money Laundering, Know Your Customer, and Insider Risk, referring to regulations and practices to prevent financial crimes and ensure customer due diligence.""}],""skill_priorities"":{""must_have"":[""Compliance testing experience"",""Fraud/AML/KYC/Insider Risk experience"",""Financial institution background"",""Cyber Risk Assessment experience"",""BISO – Business Information Security Officer""],""nice_to_have"":[""Company’s Bank experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with risk assessment and mitigation strategies in a financial institution?"",""example_answer"":""In my previous role, I developed and implemented a comprehensive risk management strategy that reduced cyber threats by 30%. I worked closely with the IT team to identify potential risks and developed mitigation plans to ensure compliance with regulatory requirements.""},{""question"":""How do you stay current with emerging trends and threats in cybersecurity?"",""example_answer"":""I regularly attend industry conferences and webinars, and participate in online forums to stay informed about the latest developments in cybersecurity. I also conduct regular risk assessments to identify potential threats and develop strategies to mitigate them.""}],""red_flags"":[""Lack of experience in compliance testing and fraud/AML/KYC/Insider Risk"",""No experience working in a financial institution""],""confidence_score"":90.0}"
Information Security Analyst,"JOB PURPOSE

Reporting to the Information Security Officer, the Information Security Analyst will possess a strong background in managing infrastructure, coupled with significant experience and expertise in cybersecurity. This role will involve analyzing threats, implementing security controls, responding to incidents, and supporting cybersecurity initiatives and projects.

PRIMARY RESPONSIBILITIES
Oversee and create all Information Security-related tasks within CanDeal environments and new projects.
Conduct in-depth security assessments of infrastructure components to identify vulnerabilities, assess risks, and recommend mitigation strategies.
Monitor security alerts and events, investigate incidents, and lead incident response efforts to contain and remediate security breaches.
Provide level 3 support to the Security Operations teams, particularly in conducting investigations derived from threat intelligence.
Develop and implement security policies, standards, and procedures to ensure compliance with regulatory requirements and industry best practices.
Manage and maintain security technologies and tools, including firewalls, intrusion detection/prevention systems (IDS/IPS), antivirus, and endpoint security solutions.
Proficiency in conducting penetration tests, including planning, executing, and analyzing results to identify vulnerabilities and enhance security measures.
Collaborate with cross-functional teams to integrate security requirements into the design and deployment of IT systems and applications.
Provide guidance and support to IT teams on security-related matters, including security awareness training and adherence to security policies.
Stay abreast of the latest cybersecurity threats, trends, and technologies through continuous learning and participation in industry events and training programs.
Assist in the development and implementation of cybersecurity initiatives and projects to enhance the organization's security posture.
Read, analyze, and design process and procedure, also, be able to identify enhancements opportunities, prepare supporting data and present to management for approval.
Conducting audit meetings, summarizing the discussions, defining action items, and follow up until completion.
Participate in on-call rotation to provide after-hours support for security incidents and emergencies.

QUALIFICATIONS

Education & Experience
Bachelor’s degree in computer science, technology or related field is required.
AWS Certified Security and/or AWS Solutions Architect Certification is required.
Certification(s) in cybersecurity (e.g. CISSP, CCSP, CySA+, GSEC, OSCP, Azure Security Engineer) preferred.
Minimum of four (4) years of experience in IT security-related projects, including working with security controls and processes, with a preference for experience in the financial services industry.

Knowledge, Skills & Abilities
Demonstrated proficiency in technology troubleshooting and exceptional analytical abilities, capable of thinking creatively to resolve issues.
Experience with security technologies and tools, such as firewalls, IDS/IPS, antivirus, and endpoint security solutions.
Strong technical knowledge of networking, operating systems, and cloud environments.
Robust experience in cloud security to enhance organization's resilience in an increasingly cloud-centric environment.
Familiarity with security frameworks and standards, including NIST Cybersecurity Framework and ISO 27001/27002.
Excellent verbal and written communication skills, with the ability to effectively clarify complex technical issues and concepts in a business-friendly manner to various audiences.
Strong organizational skills, with the abilities to manage multiple deliverables in a demanding, time-sensitive environment, adapt to frequently changing priorities by prioritizing tasks and escalate / communicate issues or seek assistance to overcome obstacles.
Ability to work effectively within a team, as well as independently.

Key Qualities for Success
Have a deep interest in computing and cybersecurity.
Self-motivated and driven.
Highly attentive to detail and committed to quality.
Enthusiastic, service oriented.

DECISION MAKING
Recommends IT security tools to the ISO based on current industry knowledge and best practice and provides input to IT Security policies.
Collaborate with teams to align security measures with organizational goals and continuously improve security posture through proactive initiatives.","{""role_summary"":""The Information Security Analyst is responsible for managing infrastructure, analyzing threats, implementing security controls, responding to incidents, and supporting cybersecurity initiatives and projects."",""key_terms"":[{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection/Prevention Systems, used to identify and prevent potential security threats.""},{""term"":""Endpoint security solutions"",""explanation"":""Software or systems that protect endpoint devices, such as laptops or smartphones, from cyber threats.""},{""term"":""NIST Cybersecurity Framework"",""explanation"":""A set of guidelines and best practices for managing and reducing cybersecurity risk.""},{""term"":""ISO 27001/27002"",""explanation"":""International standards for information security management systems, providing guidelines for implementing and maintaining information security controls.""},{""term"":""Penetration testing"",""explanation"":""Simulated cyber attacks against a computer system, network, or web application to assess its security vulnerabilities.""}],""skill_priorities"":{""must_have"":[""AWS Certified Security and/or AWS Solutions Architect Certification"",""Experience with security technologies and tools"",""Strong technical knowledge of networking, operating systems, and cloud environments""],""nice_to_have"":[""Certification(s) in cybersecurity (e.g. CISSP, CCSP, CySA+, GSEC, OSCP, Azure Security Engineer)"",""Experience in the financial services industry""]},""proposed_screening_questions_with_answers"":[{""question"":""What steps would you take to respond to a security incident, and how would you contain and remediate the breach?"",""example_answer"":""I would immediately notify the security team and begin incident response efforts, including isolating affected systems, conducting a thorough investigation, and implementing remediation measures to prevent future occurrences.""},{""question"":""How do you stay current with the latest cybersecurity threats, trends, and technologies?"",""example_answer"":""I participate in industry events, training programs, and online forums to stay informed about emerging threats and best practices in cybersecurity.""}],""red_flags"":[""Lack of experience with cloud security"",""Inability to communicate complex technical issues to non-technical stakeholders""],""confidence_score"":90.0}"
Cyber Security Engineer,"Company Description

Momentum Financial Services is a leading provider of financial services in North America. For 40 years, we've been committed to providing financial solutions that meet the evolving needs of consumers and business owners. Through our retail network of over 400 locations, known as Moneymart, Insta Cheques and the Cheque Cashing store, we provide access to cash and related products to help our customers achieve their goals.

Our highly skilled workforce puts customers first in everything we do. We serve 2 million people annually with diverse and innovative financial products such as loans, cheque cashing, money transfer and prepaid cards. Through this ever-evolving suite of services, we empower customers to manage their finances and improve their lives. Wherever customers are on their financial journey, Momentum Financial Services Group provides solutions.

#Corporate

Job Description

Candidates must reside in the GTA area to be considered for this role as they will be required to be in office 3 days a week at the Toronto Corporate Office.

General Function

We are seeking a highly skilled and experienced Cyber Security Engineer to join our dynamic team. The successful candidate will play a crucial role in ensuring the integrity, confidentiality, and availability of our systems and data. As a Cyber Security Engineer, you will be responsible for designing, implementing, and maintaining security measures to protect our organization against cyber threats and vulnerabilities.

Responsibilities

Develop and implement robust security solutions to safeguard our systems, networks, and applications.
Conduct regular security assessments, and vulnerability scans to identify and mitigate potential risks.
Monitor security logs and alerts to detect and respond to security incidents in a timely manner.
Collaborate with cross-functional teams to integrate security best practices into the development and deployment of new technologies and initiatives.
Stay abreast of emerging cyber threats, security technologies, and industry best practices to continuously enhance our security posture.
Provide technical guidance and support to internal stakeholders on security-related matters.
Participate in incident response activities and assist in post-incident analysis and remediation efforts.
Ensure compliance with relevant regulatory requirements and industry standards related to information security.

Qualifications

Bachelor's degree in Computer Science, Information Security, or a related field. Advanced degree or relevant certifications (e.g., CISSP, CISM, CEH) preferred.
Proven experience in cyber security engineering/Architecture roles, preferably within the financial industry.
Strong understanding of security principles, protocols, and technologies, including but not limited to firewalls, intrusion detection/prevention systems, encryption, application security, and endpoint security.
Hands-on experience with security tools and technologies such as SIEM, IDS/IPS, DLP, and vulnerability management platforms.
Proficiency in scripting and programming languages (e.g., Python, PowerShell) for automation and tool development.
Excellent analytical and problem-solving skills with a keen attention to detail.
Effective communication and interpersonal skills with the ability to collaborate effectively across teams and communicate complex technical concepts to non-technical stakeholders.
Ability to work independently and prioritize tasks in a fast-paced environment.

Additional Information

All your information will be kept confidential according to EEO guidelines.

Notice to Ontario Applicants – Momentum Financial Services Group is committed to accommodating applicants with disabilities up to the point of undue hardship during the recruitment, assessment, and selection process. If you are selected for an interview, please notify Momentum Financial Services Group if you require accommodation in respect of the materials or procedures used at any time during this process. If you require accommodation, we will work with you to determine how to meet your needs.

Note to Internal Applicants: All internal applicants are required to notify current manager regarding interest in applying for this role.","{""role_summary"":""A Cyber Security Engineer responsible for designing, implementing, and maintaining security measures to protect the organization's systems, networks, and applications from cyber threats and vulnerabilities."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a system that monitors and analyzes security-related data from various sources to provide real-time insights and alerts.""},{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection System/Intrusion Prevention System, a security system that monitors network traffic for signs of unauthorized access or malicious activity.""},{""term"":""DLP"",""explanation"":""Data Loss Prevention, a system that monitors and controls data usage to prevent unauthorized access, use, or transmission of sensitive data.""},{""term"":""CISSP"",""explanation"":""Certified Information Systems Security Professional, a certification for information security professionals that demonstrates expertise in designing, implementing, and managing a secure IT environment.""},{""term"":""CISM"",""explanation"":""Certified Information Security Manager, a certification for information security professionals that demonstrates expertise in developing and implementing an information security program.""},{""term"":""CEH"",""explanation"":""Certified Ethical Hacker, a certification for security professionals that demonstrates expertise in identifying vulnerabilities and weaknesses in computer systems.""}],""skill_priorities"":{""must_have"":[""Proven experience in cyber security engineering/architecture roles"",""Strong understanding of security principles, protocols, and technologies"",""Hands-on experience with security tools and technologies"",""Proficiency in scripting and programming languages"",""Excellent analytical and problem-solving skills""],""nice_to_have"":[""Advanced degree or relevant certifications (e.g., CISSP, CISM, CEH)"",""Experience in the financial industry""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with security information and event management (SIEM) systems, and how have you used them to detect and respond to security incidents?"",""example_answer"":""I have worked with SIEM systems to monitor and analyze security-related data from various sources. In my previous role, I used SIEM to detect and respond to a security incident involving unauthorized access to sensitive data. I was able to identify the source of the incident and implement measures to prevent similar incidents in the future.""},{""question"":""How do you stay current with emerging cyber threats and security technologies, and how do you incorporate this knowledge into your work as a Cyber Security Engineer?"",""example_answer"":""I regularly follow industry blogs and news sources to stay current with emerging cyber threats and security technologies. I also participate in online forums and attend conferences to stay up-to-date with the latest developments. In my previous role, I used this knowledge to implement a new security measure that protected our organization from a recently discovered vulnerability.""}],""red_flags"":[""Lack of experience with security tools and technologies"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
"Security Analyst, Threat Detection and Response","About Four Seasons

Four Seasons is powered by our people. We are a collective of individuals who crave to become better, to push ourselves to new heights and to treat each other as we wish to be treated in return. Our team members around the world create amazing experiences for our guests, residents, and partners through a commitment to luxury with genuine heart. We know that the best way to enable our people to deliver these exceptional guest experiences is through a world-class employee experience and company culture.

At Four Seasons, we believe in recognizing a familiar face, welcoming a new one and treating everyone we meet the way we would want to be treated ourselves. Whether you work with us, stay with us, live with us or discover with us, we believe our purpose is to create impressions that will stay with you for a lifetime. It comes from our belief that life is richer when we truly connect to the people and the world around us.

About the location:

Four Seasons Hotels and Resorts is a global, luxury hotel management company. We manage over 120 hotels and resorts and 50 private residences in 47 countries around the world and growing. Central to Four Seasons employee experience and social impact programming is the company’s commitment to supporting cancer research, and the advancement of diversity, inclusion, equality and belonging at Four Seasons corporate offices and properties worldwide. At Four Seasons, we are powered by people and our culture enables everything we do.

Four Seasons has an exciting opportunity in our Information Systems Technology department for a Threat Detection and Response Security Analyst. Working with the Security Operations team, the Threat Detection and Response Security Analyst will detect, analyze, and respond to internal and external cyber threat events that would have an impact on the business functions of Four Seasons Hotels and Resorts.

This role is based in Four Seasons Hotels and Resorts, Toronto Corporate Office, reporting to the Director, Global IT Security. This role involves interactions with primarily internal stakeholders at various levels.

What You’ll Be Doing

Security Technology Implementation:

Develops requirements for detection models and enhancements to existing systems
Works cross-functionally with Security Engineering team to design and implement advanced detection and response systems that can detect and respond to sophisticated cyber threats.
Builds solutions for analyzing security events data at scale and protecting Four Seasons networks, systems, and data from threats
Writes unit test cases, review, and optimize threat detections, and implement pipelines to automate detection validation
Implements integrations or efficiencies for security solutions

Security Threat Detection

Performs proactive threat hunting to identify potential security threats
Provides actionable insights to help identify, prevent, detect, and respond to anomalous or potentially malicious user and entity activity
Investigates threat campaigns to identify elements used (IPs, Domains, etc.)
Identifies internal and external threats that could result in unauthorized disclosure, misuse, alteration, or destruction of customer’s information assets

Security Threats Analysis

Analyses security events and qualifying these events according to the different kinds of threat: spam, scam, phishing, spear phishing, malware, ransomware, and others.
Analyses internal and external threats and provide security summaries of findings.

Security Threat Response

Blocks elements used in threat campaigns
Thinks creatively and holistically about reducing risk in a complex environment
Creates and update our detection rules on various platforms to block advanced threats predictively

Information Security Reporting

Writes documentation and reporting on ongoing threats and techniques used
Communicates results clearly and focus on impact

Incident Response

Streamlines incident response capabilities, ensuring the tooling and processes are clear
Assists in conducting investigations of security breaches and non-adherence to IT security policies and procedures, including those of a sensitive and confidential nature
Reports findings and recommendations to Manager.

Security Operations

Participates in resolving technical issues with the team
Documents solutions and processes appropriately and knowledge transfer to the team
Assists the team with investigating security alerts from security platforms

Vulnerability Management

Conducts Network and System Vulnerability assessments and documentation of corrective/remediation actions
Drives the end-to-end vulnerability lifecycle from discovery to closure
Ensures timely follow up with patch management and vulnerability remediation with impacted stakeholders

Who You Are

Has a passion for Information Security and Privacy disciplines
Highly critical and analytical disposition
High attention to detail and strong listening skills
Ability to work independently with minimal supervision
Natural curiosity and an ability to undertake creative exploration
Self-motivated, with critical attention to deadlines and reporting
The ability to manage tasks simultaneously and meet deadlines within a high energy, fast paced and evolving environment
The ability to grasp and communicate technical issues to a variety of audiences
Be curious, propose initiatives, autonomous, resourceful, and rigorous

What You Bring

Minimum 3 years of relevant experience in an IT Security role
Proven experience performing analysis of threat events (e.g., first, or third-party applications, system / data access, event logs), network security, digital forensics, and incident response investigations.
Experience with tactical threat intelligence and/or hunting for sophisticated threat actors in an enterprise environment
Strong experience with cloud operations – security focused (AWS, Azure)
Experience with IT/Network operations including server and network/firewall configuration
Very strong working knowledge of security tools such as firewalls, IDS/IPS, A/V, EDR, anti-spam, content management, server, and network device hardening, etc.
Expert knowledge of Python or similar programming languages
Knowledge writing / working with APIs and associated technologies
Preferred experience with above systems in a hotel/hospitality environment
Bachelor’s degree or equivalent business qualifications
Information Security certification required (CISSP, GIAC, GSEC, GMON, or similar)
In-depth knowledge of threat landscape and MITRE ATT&CK
Proven experience performing analysis of security threats to determine scope and propose best response
Very strong working knowledge of security tools such as firewalls, IDS/IPS, A/V, EDR, anti-spam, content management, server, and network device hardening, etc.
Competence in using an internal and external ticketing system for ITIL-based incident, problem and change management
Previous experience in troubleshooting day-to-day operational processes such as report generation, data verification, data correlation, etc.
Proficiency in running, adjudicating and remediating results from vulnerability scans
Strong understanding of PCI DSS
Strong experience with cloud operations – security focused (AWS, Azure)
Experience in WAF technologies
Strong understanding of computer networking
Experience with IT/Network operations including server and network/firewall configurations
Scripting knowledge (VBS/JS, PowerShell, Bash, Python)
Experience and/or knowledge of security and privacy-enhancing technologies such as identity management, application security, and network security technologies
Working knowledge of OWASP Top 10 and application security fundamentals
Understanding and experience with enterprise SIEM technologies
Industry certifications (ISC2: CISSP, CCSP, ISACA: CISM, SANS: GSEC, GCIA, GMON) are strong assets
Deep understanding of cyber threats and attack methods to help design and implement advanced detection and response systems.
Experience with Intrusion Detection and Prevention Systems (IDPS), Web Proxy, Antivirus, Security Information and Event Management (SIEMs), and/or Endpoint Detection agents

All internal applications must be submitted and approved in Workday by June 21, 2024.

This role will be a Hybrid working model, which will require 3 days per week in the Four Seasons Corporate Office located at 1165 Leslie Street, Toronto, Ontario

Four Seasons is committed to providing employment accommodation in accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act. If contacted for an employment opportunity, please advise Human Resources if you require accommodation.","{""role_summary"":""The Threat Detection and Response Security Analyst will detect, analyze, and respond to internal and external cyber threat events that could impact Four Seasons Hotels and Resorts' business functions."",""key_terms"":[{""term"":""Threat Detection"",""explanation"":""Identifying potential security threats to prevent unauthorized access or malicious activity.""},{""term"":""Security Operations"",""explanation"":""The process of monitoring, detecting, and responding to security threats to protect an organization's assets.""},{""term"":""MITRE ATT&CK"",""explanation"":""A globally recognized knowledge base of adversary tactics and techniques used to identify and mitigate cyber threats.""},{""term"":""SIEM"",""explanation"":""Security Information and Event Management systems that collect, monitor, and analyze security-related data from various sources.""},{""term"":""Vulnerability Management"",""explanation"":""The process of identifying, classifying, and remediating vulnerabilities in systems and applications to prevent exploitation.""}],""skill_priorities"":{""must_have"":[""Minimum 3 years of relevant experience in an IT Security role"",""Proven experience performing analysis of threat events"",""Strong experience with cloud operations – security focused (AWS, Azure)"",""Expert knowledge of Python or similar programming languages"",""Information Security certification required (CISSP, GIAC, GSEC, GMON, or similar)""],""nice_to_have"":[""Preferred experience with above systems in a hotel/hospitality environment"",""Experience with WAF technologies"",""Scripting knowledge (VBS/JS, PowerShell, Bash, Python)"",""Industry certifications (ISC2: CISSP, CCSP, ISACA: CISM, SANS: GSEC, GCIA, GMON)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the difference between threat detection and threat response?"",""example_answer"":""Threat detection involves identifying potential security threats, while threat response involves taking action to prevent or mitigate the impact of a detected threat.""},{""question"":""How would you approach threat hunting in a cloud-based environment?"",""example_answer"":""I would use a combination of cloud-native security tools and threat intelligence feeds to identify potential threats, and then use automation and orchestration to respond to detected threats.""}],""red_flags"":[""Lack of experience with cloud security operations"",""Inability to communicate technical issues to non-technical stakeholders"",""Limited knowledge of threat intelligence and threat hunting""],""confidence_score"":90.0}"
Security Operations Analyst (Contract),"KUBRA is looking for a Security Operations Analyst to join our Information Security team!

As a Security Operations Analyst your job will be to enhance and validate the compliance, integrity, and security of KUBRA's systems and services.

This is an 18-month contract opportunity with a hybrid work model based out of our office Mississauga, ON.

What You Get To Do Every Day

Maintain the security infrastructure (Firewalls, IDS/IPS, AV, SIEM, FIM, servers etc)
Monitor systems, software and skills to stay ahead of emerging threats:
Participate in security investigations and Assist during Incident Response and Recovery activities.
Maintain and enforce KUBRA’s IT management control framework that defines the institution’s overall approach to IT risk and control
Participate in on-call rotation to respond, investigate and resolve Security Incidents
Track and action alerts to ensure proper response is taken by coordinating the work efforts of internal teams and actions required of external service providers.
Apply understanding of environment and operational issues to work with external or internal parties for implementation or optimization of specific SIEM use cases to help improve detection and response.
Maintain the vulnerability security digest and provide updates to relevant parties
Monitor threat feeds and provide regular threat intelligence updates.
Conduct access control reviews on a case-by-case basis to systems and work with internal and external resources to update user control lists and provide reports.
Assist in remediation tasks related to audits/penetration tests.
Evaluate and provide guidance to exemption requests as per corporate policy and tandards, to advise of risk involved.

What kind of person should you be?

Ability to detail and effectively discriminate relevant logs / security events
Ability to handle multiple tasks and projects concurrently
Excellent written and verbal communication skills
Ability to plan and manage complex security projects, and meet the deadlines
Excellent organization, time management and problem-solving skills
Ability to handle pressure under minimum or no direct supervision

What skills do you need?

Degree or equivalent Experience in Computer Information Systems Incident Handler certification i.e., E|CIH, GCIH, IHRP, CSIH, CIHE is required
Other relevant certifications that are considered an asset including MCSE, CCNA, CCNP, GCIH, GCIA, GCFE, GREM, GCFA, GSEC etc.
1-2 years experience in a Security Operations role
1-2 years of experience in Incident Management and related processes
Prior experience with Cloud based services (AWS/Azure) is considered a strong asset
Prior experience architecting information security solutions considered a strong asset
Knowledge of PCI DSS requirements is preferred

What can you expect from us?

Award-winning culture that fosters growth, diversity and inclusion for all
Free unlimited access to our refreshment stations (fully stocked with tea, coffee and other beverages)

While we value the skills and experiences listed in our job requirements, we also recognize that talent comes in many forms, and welcome applications from candidates who meet most but not all specified requirements. If you possess a strong desire to learn and grow in a dynamic work environment, apply now!

KUBRA is a fast-growing company that delivers customer communications solutions to some of the largest utility, insurance, and government entities across North America. KUBRA offers billing and payments, mapping, mobile apps, proactive communications, and artificial intelligence solutions for customers. With more than 1.5 billion customer interactions annually, KUBRA services reach over 40% of households in the U.S. and Canada. KUBRA is an operating subsidiary of Hearst.

Our office is small enough to allow creative individuals to flourish, yet large enough to provide long-term stability. We place a tremendous amount of responsibility on our team members to be productive, focused and self-motivated. We offer a casual work environment, competitive compensation and a stellar benefits program.","{""role_summary"":""The Security Operations Analyst is responsible for enhancing and validating the compliance, integrity, and security of KUBRA's systems and services."",""key_terms"":[{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection System/Intrusion Prevention System, used to detect and prevent unauthorized access to computer systems.""},{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a system that monitors and analyzes security-related data from various sources.""},{""term"":""FIM"",""explanation"":""File Integrity Monitoring, a system that monitors and detects changes to files and folders.""},{""term"":""PCI DSS"",""explanation"":""Payment Card Industry Data Security Standard, a set of security standards designed to ensure that companies that handle credit card information maintain a secure environment.""}],""skill_priorities"":{""must_have"":[""Degree or equivalent"",""Experience in Computer Information Systems"",""Incident Handler certification (e.g., E|CIH, GCIH, IHRP, CSIH, CIHE)""],""nice_to_have"":[""MCSE, CCNA, CCNP, GCIH, GCIA, GCFE, GREM, GCFA, GSEC certifications"",""Prior experience with Cloud based services (AWS/Azure)"",""Prior experience architecting information security solutions"",""Knowledge of PCI DSS requirements""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you handle a security incident response and recovery activity?"",""example_answer"":""I would follow the incident response plan, contain the incident, eradicate the root cause, recover from the incident, and conduct a post-incident activity to identify areas for improvement.""},{""question"":""Can you explain how you would maintain and enforce KUBRA's IT management control framework?"",""example_answer"":""I would review and update the framework regularly, ensure that all controls are implemented and operating effectively, and provide training to employees on the framework and its requirements.""}],""red_flags"":[""Lack of experience in a Security Operations role"",""No prior experience with Cloud based services (AWS/Azure)""],""confidence_score"":90.0}"
Security Assessment -Cyber Risk /AML,"orking with one of the top financial clients this role calls for a Security Assessment -Cyber Risk /AML who will be responsible for leading the identification and assessment of technology and cybersecurity risks across the bank's digital assets, IT infrastructure, and operations, ensuring alignment with the bank’s risk appetite and regulatory requirements. The successful candidate will facilitate and promote a culture of risk awareness and cybersecurity resilience across the organization, including the development and delivery of risk management training programs.
Responsibilities:
Develop and implement comprehensive risk management strategies and policies to mitigate identified risks, including but not limited to, cyber threats, data breaches, IT outages, and technology compliance issues.
Collaborate with IT, business units, and cybersecurity teams to enhance the bank's cyber and technology risk posture through proactive risk identification, assessment, and response planning.
Oversee and guide the risk assessment process for new and existing technologies, digital initiatives, and third-party service providers, ensuring comprehensive risk evaluation and mitigation planning.
Provide expert advice and guidance to senior management on technology and cyber risk trends, potential impacts on the bank, and recommended risk mitigation strategies.
Monitor and analyze developments in technology and cybersecurity threats, including regulatory changes, to continuously refine and update risk management strategies.
Prepare and present detailed risk reports and dashboards to senior management and relevant committees, highlighting the bank's risk posture, emerging risks, and effectiveness of risk mitigation efforts.

Desired Skill Set:
2 years of experience as a BISO – Business Information Security Officer
2 years of proven expertise in Audit or AML/Compliance testing experience
2 years of experience in Cyber Risk Assessment
Financial institution background
2 years of Fraud/AML/KYC/Insider Risk experience

Nice To Have:
Previous financial institution experience

BeachHead is an equal opportunity agency and employer. We advocate for you and welcome anyone regardless of race, color, religion, national origin, sex, physical or mental disability, or age.","{""role_summary"":""Lead the identification and assessment of technology and cybersecurity risks across a bank's digital assets, IT infrastructure, and operations, ensuring alignment with the bank's risk appetite and regulatory requirements."",""key_terms"":[{""term"":""Cyber Risk"",""explanation"":""The risk of financial loss, disruption, or damage to the reputation of an organization due to a failure of its information technology systems.""},{""term"":""AML"",""explanation"":""Anti-Money Laundering, a set of procedures and regulations designed to prevent criminals from disguising illegally obtained funds as legitimate income.""},{""term"":""BISO"",""explanation"":""Business Information Security Officer, a senior-level executive responsible for overseeing and implementing an organization's information security strategy.""},{""term"":""KYC"",""explanation"":""Know Your Customer, a process of verifying the identity of customers and assessing their risk profile to prevent fraud and other financial crimes.""},{""term"":""Insider Risk"",""explanation"":""The risk of financial loss, disruption, or damage to the reputation of an organization due to the actions of an employee or other insider with access to sensitive information.""}],""skill_priorities"":{""must_have"":[""Cyber Risk Assessment"",""Audit or AML/Compliance testing experience"",""Fraud/AML/KYC/Insider Risk experience"",""Financial institution background""],""nice_to_have"":[""Previous financial institution experience""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with Cyber Risk Assessment, and how do you stay current with emerging threats?"",""example_answer"":""I have 2 years of experience in Cyber Risk Assessment, and I regularly review industry reports and attend conferences to stay informed about the latest threats and mitigation strategies.""},{""question"":""Can you describe your approach to developing and implementing comprehensive risk management strategies and policies?"",""example_answer"":""I would work closely with stakeholders to identify risks, develop mitigation plans, and implement policies that align with the organization's risk appetite and regulatory requirements.""}],""red_flags"":[""Lack of experience in Cyber Risk Assessment"",""Inability to communicate complex technical risks to non-technical stakeholders""],""confidence_score"":90.0}"
Information Security Engineer,"Explore the opportunity to join us as an Information Security Engineer in Canada. Details are provided below. This is a full-time position with remote work options, but candidates must reside in Canada.

Job Type: Full Time (100% Remote)

Responsibilities

Monitor, evaluate, and maintain systems and procedures to safeguard infrastructure, databases, and Web-based security.
Identify, integrate, monitor, and improve infosec controls by understanding business processes. Assist in defining security requirements and reviewing systems to determine if they have been designed to comply with established security standards. Help in developing new standards as necessary.
Conduct vulnerability assessments and monitor systems for potential security concerns. Design and configure infrastructure systems to help mitigate findings and improve security posture.
Assist with security architecture reviews and conduct threat modeling exercises as new products and features are rolled out
Research security trends, new methods, and techniques used in unauthorized data access to preemptively eliminate the possibility of system breaches.
Respond to alerts from information security tools and triage and analyze potential security issues
Troubleshoot security system and related issues.
Collaborate and maintain relationships with various engineering teams across the organization to communicate and remediate security issues on time
Educate engineering teams on security best practices and promote security by design
Ensure compliance with regulations and privacy laws.

Skills Required

Minimum 5 years of experience working in security or related industry
Proficient in one or more programming languages such as React, Python, Ruby, etc.
Minimum 2 years of experience in secure coding/development
Effective communication skills and experience collaborating with engineering teams
Have a deep understanding of common application security vulnerabilities
Demonstrated expertise in the Infrastructure security domain
Understanding of Infrastructure security in the context of SDLC and CI-CD
Experience working in all parts of the Infrastructure lifecycle
Effective in communicating security vulnerabilities to key stakeholders
Cloud Security Certifications like AWS Certified Security Specialty is preferred.

Apply!

Techedin is a global IT Services company complementing the efforts of technology-driven enterprises in developing cutting-edge solutions for humans. We offer services in enterprise app development, content management solutions (CMS), customer relationship management (CRM), cloud engineering, custom software development, and data engineering. Our services include IT Consulting, project management, Software Quality Assurance, and data and analytics services. We develop and maintain various software applications and all other computer-related ancillary services. We have excellent professionals working round the clock to build the best technology teams and products for our customers.","{""role_summary"":""An Information Security Engineer is responsible for maintaining and improving the security of infrastructure, databases, and web-based systems, ensuring compliance with regulations and privacy laws, and collaborating with engineering teams to promote security best practices."",""key_terms"":[{""term"":""Infosec"",""explanation"":""Short for Information Security, it refers to the practice of protecting electronic information from unauthorized access, use, disclosure, disruption, modification, or destruction.""},{""term"":""SDLC"",""explanation"":""Software Development Life Cycle, it's a process used to design, develop, and test software. In the context of infrastructure security, it involves integrating security practices throughout the development process.""},{""term"":""CI-CD"",""explanation"":""Continuous Integration and Continuous Deployment, it's a practice that involves automating the build, test, and deployment of software to ensure faster and more reliable releases.""},{""term"":""Cloud Security Certification"",""explanation"":""A certification that demonstrates expertise in securing cloud-based systems and infrastructure, such as AWS Certified Security Specialty.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in security or related industry"",""Proficient in one or more programming languages"",""2+ years of experience in secure coding/development"",""Effective communication skills"",""Deep understanding of common application security vulnerabilities"",""Demonstrated expertise in Infrastructure security domain""],""nice_to_have"":[""Cloud Security Certification like AWS Certified Security Specialty""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of integrating security practices throughout the SDLC?"",""example_answer"":""Integrating security practices throughout the SDLC ensures that security is considered at every stage of development, reducing the risk of vulnerabilities and ensuring compliance with regulations.""},{""question"":""How would you approach identifying and mitigating potential security concerns in a cloud-based infrastructure?"",""example_answer"":""I would conduct vulnerability assessments, monitor systems for potential security concerns, and design and configure infrastructure systems to mitigate findings and improve security posture.""}],""red_flags"":[""Lack of experience in secure coding/development"",""Inability to communicate security vulnerabilities to key stakeholders""],""confidence_score"":90.0}"
XDR - Cyber Security,"Hi,

Hope you are doing Great!!!

This side Priya Rajput from Zortech Solutions trying to reach you for an exciting job opening, kindly have a look to job description and revert me with your positive feedback. My mail ID is priya@zortechsolutions.ca or call me on +1 (437) 370-7612.

Role: XDR - Cyber Security

Location: Toronto, ON-Onsite

Duration: Fulltime Permanent

Required Skills And Responsibilities

The job description for a Palo Alto XDR (Extended Detection and Response) role typically includes the following responsibilities:
Deploying and managing Palo Alto XDR solutions: The XDR specialist is responsible for the installation, configuration, and maintenance of Palo Alto's XDR platform. This involves working with various teams to ensure proper setup and integration with existing security infrastructure.
Monitoring and analyzing security events: The XDR specialist will monitor the XDR platform for security events, including threats, vulnerabilities, and anomalous activities. They will analyze the data and alerts generated by the system to identify potential security incidents.
Incident response and investigation: In case of a security incident, the XDR specialist will be responsible for quickly and effectively responding to the incident. This involves taking appropriate actions to mitigate the impact, identifying the root cause, and conducting a thorough investigation to prevent similar incidents in the future.
Threat hunting and intelligence: The XDR specialist should actively engage in threat hunting activities, proactively looking for signs of malicious activity or potential vulnerabilities within the network. They should stay up-to-date with the latest Security Threats and intelligence to enhance the organization's defense against evolving threats.
Collaboration and communication: The XDR specialist will work closely with other teams, such as Network Security, system administrators, and the Security Operations Center (SOC), to ensure smooth integration and effective incident response. They should also effectively communicate any detected threats or incidents to appropriate stakeholders.
Documentation and reporting: The XDR specialist will maintain accurate and up-to-date documentation of configurations, incidents, investigations, and any other relevant information. They should also prepare and present regular reports on security events, incidents, and overall system performance to management.
Continuous improvement: The XDR specialist should actively seek opportunities to enhance the effectiveness and efficiency of the XDR platform and related security processes. This includes evaluating new features and updates, implementing best practices, and providing feedback to the vendor for product improvement..

Required Skills Set: -

Required Skills

Years of Experience

When Last Used This Skill In Your Career Project Year And Month

Rating (E1 as Lowest to E5 as Highest)

Overall Experience

Cyber Security

XDR (Extended Detection and Response)

Security Threats

Network Security

Security Operations Center (SOC)

Documentation and Reporting

Continuous Improvement



Thanks & Regards

Priya Rajput | Account Manager

Email- priya@zortechsolutions.ca

2600 Skymark Ave, Building 7 Suite 104, Mississauga Ontario, L4W 5B2 Canada.

The information contained in this electronic message and any attachments to this message are intended for the exclusive use of the addressee(s) and may contain proprietary, confidential or privileged information. If you are not the intended recipient, you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately and destroy all copies of this message and any attachments. The views expressed in this E-mail message (including the enclosure/(s) or attachment/(s) if any) are those of the individual sender, except where the sender expressly, and with authority, states them to be the views of ZorTech Solutions Inc. Before opening any e-mail and attachments please check them for viruses. ZorTech Solutions Inc does not accept any liability for virus infected mails.","{""role_summary"":""The XDR Cyber Security role is responsible for deploying, managing, and monitoring Palo Alto XDR solutions, responding to security incidents, and collaborating with other teams to ensure effective incident response and security infrastructure integration."",""key_terms"":[{""term"":""XDR"",""explanation"":""Extended Detection and Response, a cybersecurity solution that provides real-time threat detection and response capabilities.""},{""term"":""Palo Alto XDR"",""explanation"":""A specific XDR platform provided by Palo Alto, a cybersecurity company, that offers advanced threat detection and response features.""},{""term"":""Security Operations Center (SOC)"",""explanation"":""A team responsible for monitoring and responding to security incidents, often working closely with XDR specialists to ensure effective incident response.""},{""term"":""Threat Hunting"",""explanation"":""Proactively searching for signs of malicious activity or potential vulnerabilities within a network to enhance an organization's defense against evolving threats.""}],""skill_priorities"":{""must_have"":[""Cyber Security"",""XDR (Extended Detection and Response)"",""Security Threats"",""Network Security"",""Security Operations Center (SOC)""],""nice_to_have"":[""Documentation and Reporting"",""Continuous Improvement""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with Palo Alto XDR solutions and how you've used them to respond to security incidents?"",""example_answer"":""In my previous role, I successfully deployed and managed Palo Alto XDR solutions, which enabled us to detect and respond to security threats in real-time. I worked closely with our SOC team to ensure effective incident response and collaborated with network security teams to integrate the XDR platform with our existing security infrastructure.""},{""question"":""How do you stay up-to-date with the latest security threats and intelligence, and how do you apply that knowledge to enhance an organization's defense?"",""example_answer"":""I regularly follow industry reports and threat intelligence feeds to stay informed about emerging threats. I also participate in threat hunting activities to proactively identify potential vulnerabilities and work with our SOC team to develop strategies to mitigate those threats.""}],""red_flags"":[""Lack of experience with Palo Alto XDR solutions"",""Inability to effectively communicate security incidents to stakeholders""],""confidence_score"":90.0}"
Cyber Security Project Coordinator,"Collaborate with both internal and external partners and stakeholders to decompose high-level information into detailed business requirements
Facilitate work sessions, focus groups, and coordinate/conduct application demonstrations as required
Contribute to the quality of design and implementation by identifying risks and issues and effectively managing and communicating them to all stakeholders
Support the development of a prioritized product backlog, including the development of user stories, acceptance criteria and scenarios from which the development team to start building applications
Represent the voice of the customer throughout the software development lifecycle
Engage in day-to-day activities with the solution teams as required. This includes, but is not limited to: attending daily scrum meetings, leading refinement sessions, engaging with the development team, and providing direction/focus
Make recommendations that go beyond the initial requests
Provide input to the test plans, sign off on test cases, and participate in end-to-end (E2E) and User Acceptance Testing (UAT)
Write and edit user procedural documentation such as user guides and manuals
Provide support for customer issues and follow up on a timely basis to ensure the problem has been resolved
Concisely document all problems and their resolution in the ticketing system


Requirements

10 years previous experience in the telecommunication industry and Government of Canada contracts

Experience in business analysis - collecting, documenting and articulating requirements
Excellent communications skills, both written and verbal, with the ability to effectively communicate and present to various audiences
Highly organized, detail-oriented and the ability to manage multiple projects simultaneously with aggressive timelines
Action oriented and demonstrated ability to deliver results
Ability to work with change/ambiguity, in a competitive environment where priorities change frequently
Proven problem-solving ability with complex, technical and abstract concepts
Tenacity and creative approach to achieving goals
A team player with the confidence to challenge and escalate when necessary


Benefits

Work hours are Monday - Friday, normal 37.5 hours weeks working onsite up to 5 days a week
Location: Onsite in Toronto
Type of job: Temporary Contractor
Hourly contract rate: TBD depending on experience
Date candidate required: Immediate
Length of Contract: 12 months with the possibility of extension","{""role_summary"":""Collaborate with stakeholders to gather business requirements, facilitate work sessions, and contribute to the quality of design and implementation. Support the development of a product backlog, represent the customer's voice, and engage with solution teams to deliver results."",""key_terms"":[{""term"":""Product backlog"",""explanation"":""A prioritized list of features or user stories to be developed in a software project.""},{""term"":""User stories"",""explanation"":""A brief description of a software feature from the user's perspective, used to guide development.""},{""term"":""Acceptance criteria"",""explanation"":""Conditions that must be met for a software feature to be considered complete and satisfactory.""},{""term"":""Scrum meetings"",""explanation"":""Daily meetings in Agile development where team members share progress, plans, and obstacles.""},{""term"":""Refinement sessions"",""explanation"":""Meetings where the development team and stakeholders discuss and clarify software requirements.""},{""term"":""E2E and UAT"",""explanation"":""End-to-end and User Acceptance Testing, ensuring software meets requirements and user expectations.""}],""skill_priorities"":{""must_have"":[""Business analysis"",""Communication skills"",""Organizational skills"",""Problem-solving ability""],""nice_to_have"":[""Experience in telecommunication industry and Government of Canada contracts""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to gather and document complex business requirements from stakeholders?"",""example_answer"":""In my previous role, I worked with cross-functional teams to gather requirements for a new software feature. I facilitated workshops, conducted interviews, and created detailed documentation to ensure all stakeholders were aligned. The outcome was a successful implementation that met the business needs.""},{""question"":""How do you handle conflicting priorities and tight deadlines in a fast-paced environment?"",""example_answer"":""I prioritize tasks based on business needs, communicate proactively with stakeholders, and focus on delivering high-quality results. In my previous experience, I managed multiple projects simultaneously and consistently met deadlines while maintaining quality.""}],""red_flags"":[""Lack of experience in business analysis and stakeholder communication"",""Inability to work in a fast-paced environment with changing priorities""],""confidence_score"":90.0}"
Threat Analyst 3,"About Us
Sophos is a worldwide leader and innovator of advanced cybersecurity solutions, including Managed Detection and Response (MDR) and incident response services and a broad portfolio of endpoint, network, email, and cloud security technologies that help organizations defeat cyberattacks. As one of the largest pure-play cybersecurity providers, Sophos defends more than 500,000 organizations and more than 100 million users globally from active adversaries, ransomware, phishing, malware, and more. Sophos’ services and products connect through its cloud-based Sophos Central management console and are powered by Sophos X-Ops, the company’s cross-domain threat intelligence unit. Sophos X-Ops intelligence optimizes the entire Sophos Adaptive Cybersecurity Ecosystem, which includes a centralized data lake that leverages a rich set of open APIs available to customers, partners, developers, and other cybersecurity and information technology vendors. Sophos provides cybersecurity-as-a-service to organizations needing fully managed, turnkey security solutions. Customers can also manage their cybersecurity directly with Sophos’ security operations platform or use a hybrid approach by supplementing their in-house teams with Sophos’ services, including threat hunting and remediation. Sophos sells through reseller partners and managed service providers (MSPs) worldwide. Sophos is headquartered in Oxford, U.K. More information is available at www.sophos.com. 

Role Summary
As a Threat Analyst on our Managed Threat Response (MTR) team, you will provide best-in-class monitoring, detection, and response services to proactively defend customer environments before attacks prevail. You will work alongside and contribute to a team of cyber threat hunters, incident response analysts, engineers, and ethical hackers by using enterprise, log analysis and endpoint collection systems to facilitate investigations, identification, and neutralization of cyber threats. 
Shift- 8 AM - 5 PM EST

What You Will Do
Investigate and analyze logs and security-related events via Sophos tooling
Identify and respond to cyber threats occurring within customer environments
Communicate and document findings to various customer audiences including technical and executive teams
Follow up with customers through to issue resolution and drive continuous improvement by providing detailed recommendations to minimize risk in customer environments 
Acknowledge and satisfy inbound customer requests and interact with customers through various mediums
Collaborate and assist with core security and threat response teams
Actively research emerging Indicators of Compromise/Attack, exploits and vulnerabilities with the intent of operationalizing findings to better protect our customers

What You Will Bring
Willingness to work outside of standard business hours, including weekends and holidays – our MTR service is 24x7x365
Excellent troubleshooting and analytical skills, with proven ability to think outside the box
Customer service-oriented with strong written and verbal communication skills
Must thrive within a team environment as well as on an individual basis
Passion for all things related to information technology and cybersecurity
Natural curiosity and ability to learn new skills quickly
Innovative mindset and driven to contribute to a team providing a best-in-class cybersecurity service
Minimum 4+ years of experience working in a SOC environment or computer security team in an IT environment
Experience with threat hunting
Experience with endpoint and network security monitoring 
Experience administering and supporting Windows OS (both workstations and server) and one of the following: Apple or Linux-based operating systems (e.g. XP, Windows 7, 2003, 2008, OS X)
Knowledge of common adversary tactics and techniques, e.g., obfuscation, persistence, defense evasion, etc
Knowledge of Mitre ATT&CK framework
Knowledge of incident response procedures
Basic understanding of network traffic analysis including TCP/IP, routing, switching, protocols, etc
Basic understanding of Windows event log analysis
A plus if you have:
Experience with SQL query construction 
Experience with OSQuery 
Experience with enterprise information security data management - SIEM experience 
Programming and scripting skills - proficient knowledge of Powershell 


In the United States, the base salary for this role ranges from $83,000 to $138,000. In Canada, the base salary for this role ranges from $74,000 to $123,000. In addition to base salary, we offer additional compensation including bonus eligibility and a comprehensive benefits package.  A candidate’s specific pay within this range will depend on a variety of factors, including job-related skills, training, location, experience, relevant education, certifications, and other business and organizational needs. 
#B2

Ready to Join Us?
At Sophos, we believe in the power of diverse perspectives to fuel innovation. Research shows that candidates sometimes hesitate to apply if they don't check every box in a job description. We challenge that notion. Your unique experiences and skills might be exactly what we need to enhance our team. Don't let a checklist hold you back – we encourage you to apply.
What's Great About Sophos?
·   Sophos operates a remote-first working model, making remote work the primary option for most employees. However, some roles may necessitate a hybrid approach. Please refer to the location details in our job postings for further information.
·   Our people – we innovate and create, all of which are accompanied by a great sense of fun and team spirit
·   Employee-led diversity and inclusion networks that build community and provide education and advocacy
·   Annual charity and fundraising initiatives and volunteer days for employees to support local communities
·   Global employee sustainability initiatives to reduce our environmental footprint
·   Global fitness and trivia competitions to keep our bodies and minds sharp
·   Global wellbeing days for employees to relax and recharge 
·   Monthly wellbeing webinars and training to support employee health and wellbeing
Our Commitment To You
We’re proud of the diverse and inclusive environment we have at Sophos, and we’re committed to ensuring equality of opportunity.   We believe that diversity, combined with excellence, builds a better Sophos, so we encourage applicants who can contribute to the diversity of our team.  All applicants will be treated in a fair and equal manner and in accordance with the law regardless of gender, sex, gender reassignment, marital status, race, religion or belief, color, age, military veteran status, disability, pregnancy, maternity or sexual orientation.  We want to give you every opportunity to show us your best self, so if there are any adjustments we could make to the recruitment and selection process to support you, please let us know. 
Data Protection
If you choose to explore an opportunity, and subsequently share your CV or other personal details with Sophos, these details will be held by Sophos for 12 months in accordance with our Privacy Policy and used by our recruitment team to contact you regarding this or other relevant opportunities at Sophos.  If you would like Sophos to delete or update your details at any time, please follow the steps set out in the Privacy Policy describing your individual rights.  If you have any questions about Sophos’ data protection practices, please contact dataprotection@sophos.com.","{""role_summary"":""Provide best-in-class monitoring, detection, and response services to proactively defend customer environments from cyber threats."",""key_terms"":[{""term"":""Managed Threat Response (MTR)"",""explanation"":""A service that provides proactive defense against cyber threats to customer environments.""},{""term"":""Threat Hunting"",""explanation"":""The process of proactively searching for and identifying potential cyber threats.""},{""term"":""Indicators of Compromise/Attack"",""explanation"":""Signs that a system or network has been compromised or attacked by a cyber threat.""},{""term"":""Mitre ATT&CK framework"",""explanation"":""A knowledge base of adversary tactics and techniques used to identify and mitigate cyber threats.""},{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a system that monitors and analyzes security-related data.""}],""skill_priorities"":{""must_have"":[""Experience working in a SOC environment or computer security team"",""Experience with threat hunting"",""Experience with endpoint and network security monitoring"",""Knowledge of common adversary tactics and techniques"",""Knowledge of Mitre ATT&CK framework"",""Basic understanding of network traffic analysis"",""Basic understanding of Windows event log analysis""],""nice_to_have"":[""Experience with SQL query construction"",""Experience with OSQuery"",""Experience with enterprise information security data management - SIEM experience"",""Programming and scripting skills - proficient knowledge of Powershell""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with threat hunting and how you've used it to identify potential cyber threats?"",""example_answer"":""In my previous role, I used threat hunting to identify a potential phishing attack on our network. I analyzed network traffic and system logs to identify the source of the attack and worked with our incident response team to contain and mitigate the threat.""},{""question"":""How do you stay current with emerging cyber threats and tactics?"",""example_answer"":""I regularly review industry reports and threat intelligence feeds to stay informed about emerging threats. I also participate in online forums and discussion groups to stay connected with other cybersecurity professionals and learn from their experiences.""}],""red_flags"":[""Lack of experience working in a SOC environment or computer security team"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
SOC Analyst (Onsite - Night Shift),"Position: SOC Analyst
Location: Downtown Toronto
Job Type: Permanent Full Time

Our client is an MSSP security organization, and they are looking for a SOC Analyst who will join their Security Operations Center (SOC) team to help monitor and respond to security incidents. The Analyst will work closely with a team of experienced cybersecurity professionals to detect, analyze, and mitigate potential threats.

This role needs someone to work from office and night shifts.

If you have prior experience in similar area, then please reach out on Shubham.sharma@qauntum-qtr.com.

Responsibilities:
Monitor and analyze alerts from security tools, networks, and systems to identify and validate security incidents.
Perform initial assessment and triage on the security alerts and escalate as needed.
Participate in incident response efforts, collaborating with other teams as required.
Document incident details and actions taken in the incident management system.
Maintain knowledge of the latest cybersecurity threats and trends.
Participate in continuous learning and professional development opportunities.
Support the development and refinement of SOC processes and procedures.

Qualifications:
Bachelor’s degree in computer science, Information Technology, Cybersecurity, or a related field.
1-2 years of experience in a SOC or similar cybersecurity role preferred.
Familiarity with various security technologies (SIEM, EDR, NDR, etc.) and security concepts, ideally knows Sumologic
Basic understanding of network protocols, system vulnerabilities, and malware.
Strong analytical and problem-solving skills.","{""role_summary"":""Monitor and respond to security incidents as part of a Security Operations Center team, working closely with experienced cybersecurity professionals to detect, analyze, and mitigate potential threats."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a type of security technology used to monitor and analyze security-related data from various sources.""},{""term"":""EDR"",""explanation"":""Endpoint Detection and Response, a type of security technology used to monitor and respond to endpoint security threats.""},{""term"":""NDR"",""explanation"":""Network Detection and Response, a type of security technology used to monitor and respond to network security threats.""},{""term"":""Sumologic"",""explanation"":""A specific SIEM solution used for log analysis and incident response.""}],""skill_priorities"":{""must_have"":[""Analytical and problem-solving skills"",""Familiarity with security technologies (SIEM, EDR, NDR, etc.)"",""Basic understanding of network protocols, system vulnerabilities, and malware""],""nice_to_have"":[""1-2 years of experience in a SOC or similar cybersecurity role"",""Knowledge of Sumologic""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for analyzing and triaging security alerts?"",""example_answer"":""I would first review the alert details, then use my knowledge of security technologies and concepts to assess the severity and potential impact. If necessary, I would escalate the alert to the incident response team and collaborate with them to resolve the issue.""},{""question"":""How do you stay current with the latest cybersecurity threats and trends?"",""example_answer"":""I regularly review industry reports and blogs, participate in online forums and discussions, and engage in continuous learning and professional development opportunities to stay up-to-date on the latest threats and trends.""}],""red_flags"":[""Lack of experience working with security technologies (SIEM, EDR, NDR, etc.)"",""Inability to work night shifts""],""confidence_score"":90.0}"
IT Security Analyst,"A career that gives you purpose. A company that stands up for you. A team where you can be yourself. Sound too good to be true? This is life at Houle. We believe in empowering communities through local projects that positively impact people's lives. We're a passionate group of people who love collaborating on innovative and challenging projects.

About This Role

We are recruiting for an IT Security Analyst to join our Corporate IT team based in Burnaby. Here's how your role will strengthen our team.

This position will collaborate with the IT department to develop and implement security policies and procedures, investigate security incidents, and ensure smooth operations of all IT systems from a security perspective across Houle office locations and job sites.

Your Responsibilities

Identify and address vulnerabilities in network, applications, infrastructure, and source code vulnerabilities leveraging appropriate security tools
Coordinate the resolution of risks from penetration testing and vulnerability scanning activities
Support implementation, maintenance, and improvement of security tools such as SIEM, EDR/XDR, security Firewalls, Spam and Web filtering, Access control, Mobile security etc.
Conduct risk assessments, threat modelling, privacy assessments and information security reviews on projects and all existing technology and systems
Assist in regularly assessing the strength of the organization's IT security governance and current processes, procedures, and technical security controls best practices, and propose, and implement initiatives to remediate control gaps to reduce enterprise risk

Your Experience And Skills

Bachelor's degree in computer science, or equivalent training or education
Minimum 4 years related IT experience in an Enterprise IT environment, with recent relevant experience
Currently hold or working towards relevant Professional IT Security Certifications (CISSP, etc.)
Excellent written and verbal communication skills
Strong aptitude to take on new challenges and learn innovative technologies
Collaborative personality and work well with customers and internal team members

About Houle

As BC's leading electrical contractor and systems integrator, we believe in delivering safe, reliable power for the future. From hospitals and universities, to airports, shipping terminals and shopping centres, our electrical and technology professionals proudly provide innovative solutions that create value for our customers every day.

Since 1944, we've been dedicated to our craft, committed to quality workmanship, and building teams that thrive. Driven by purpose and connected through collaboration, our focus on people guides our success in delivering some of the most exciting infrastructure projects in the province.

As a certified Great Place to Work and Best Managed company, we have been recognized for our efforts in creating a safe and inclusive work environment.

Why join our team?

We emphasize having a work-life balance - We offer flexible work schedules and a competitive vacation policy.
Continuous development is a top priority - Whether you're looking for a corporate career or a career in the field, you are supported with access to tools and training for development and growth.
Our employee benefits prioritize your financial, physical, and mental well-being - From RRSP matching to health and wellness reimbursements and additional Houle days off, we've got you covered.
We have many exciting project opportunities - With many projects on the go around BC, we're certain you will find countless ways to bring communities to life.
We have fun! Connection is key at Houle, from industry events to themed office gatherings, we never miss an opportunity to celebrate. Join us for our summer bbqs, potlucks, charity fundraisers, community volunteering, and many more fun events!
A safe space for everyone - We celebrate diversity and are proud to be an equal-opportunity employer. We're committed to diversity and inclusion and strive to foster, cultivate and preserve a culture of belonging for all employees.

Salary range: $68,000-$90,000 per year plus a competitive total compensation package. Actual salary will be commensurate with experience, skills and overall match to the position offered. Let's chat throughout the hiring process and determine the best fit.

Sound like a match? We'd love to connect.

Please visit https://www.houle.ca/current-career-opportunities/ and click on the listing for IT Security Analyst. The opportunity will remain open until it has been filled.

Connect with us on LinkedIn, Instagram, Facebook, and Twitter!","{""role_summary"":""Collaborate with the IT department to develop and implement security policies and procedures, investigate security incidents, and ensure smooth operations of all IT systems from a security perspective."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a system that monitors and analyzes security-related data from various sources.""},{""term"":""EDR/XDR"",""explanation"":""Endpoint Detection and Response/Extended Detection and Response, a solution that monitors endpoints and detects threats in real-time.""},{""term"":""CISSP"",""explanation"":""Certified Information Systems Security Professional, a certification that validates expertise in information security.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in computer science or equivalent"",""Minimum 4 years related IT experience in an Enterprise IT environment"",""Excellent written and verbal communication skills"",""Strong aptitude to take on new challenges and learn innovative technologies""],""nice_to_have"":[""Relevant Professional IT Security Certifications (CISSP, etc.)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of threat modeling in IT security and provide an example of how you've applied it in a previous role?"",""example_answer"":""Threat modeling is essential in identifying potential security risks and vulnerabilities. In my previous role, I conducted a threat modeling exercise to identify potential attack vectors on our organization's cloud infrastructure. I worked with the development team to implement additional security controls, reducing the risk of a successful attack.""},{""question"":""How do you stay current with emerging IT security threats and trends?"",""example_answer"":""I regularly follow industry blogs and news outlets, participate in online forums and discussion groups, and attend webinars and conferences to stay informed about the latest security threats and trends.""}],""red_flags"":[""Lack of experience with security tools such as SIEM, EDR/XDR, and security Firewalls"",""Inability to communicate technical security information to non-technical stakeholders""],""confidence_score"":85.0}"
Security Analyst (Co-op),"We’re looking for entry-level security specialists to grow our team. If you are a student and looking to work a co-op term as an Information Security Analyst or Specialist and look forward to working in challenging and changing environments, we have an excellent opportunity for you.

As part of the Control Gap team, you’ll work with high-profile clients in various industries and collaborate with a team of highly-skilled security consultants on challenging projects, large and small. We analyse, assess and design effective security controls to help clients achieve Payment Card Industry (PCI) compliance, privacy compliance, and to improve enterprise-wide security.

As an entry-level subject matter expert, you’ll work within our team to input and help advise clients on data security to help prevent potential security breaches before they occur. We provide services onsite at our client sites and also remotely.

We value strong knowledge of information security controls and principles, privacy frameworks, the Payment Card Industry Data Security Standard (PCI DSS). You also must have exceptional written and verbal skills. As a co-op student, no real world work experience as an information security analyst or specialist is required.

After your co-op work term, you can earn an option to join our team fulltime. As a fulltime employee, our intent is to have you learn and grow with us while, if you desire, working towards being a well rounded security consultant and to obtain the elite Payment Card Industry Qualified Security Assessor (PCI QSA) certification, and other valuable industry security and audit related certifications.

Our people are our most valuable assets and we believe in fostering career development and growth opportunities for every individual on our team. We also offer a competitive benefits package and an excellent work environment that encourages team work. 

Responsibilities:

Assisting with conducting various information security, compliance assessments, analyses, and providing advice and consultation (e.g. Report on Compliance, Risk Assessments, Gap Analysis, and more)
Assisting with creating professional reports for our clients that detail your assessment findings, and your advice
Assisting with consulting with clients to help them understand our findings and their remediation options
Assisting with providing advisory and input on security architecture with regards to PCI, Privacy, and Cyber Security
Assisting our sales team with pre-sales activities, proposal creation, needs analysis, and solution design
Attending industry events and webinars
Working with multiple clients on a number of projects
Writing summaries and executive briefs

Education and Work Experience:

You must be working on a degree in Information Security, or in a related field
Minimum 0 years of experience in an Information Technology field
Minimum 0 years of experience working in Information Security domains
Minimum 0 years of experience measuring security controls, IT auditing, business processes, providing advice, and/or related security consulting experience

Industry Certifications:

Any industry certification in Information Security or Audit is an asset

Technical Skills:

Familiarity with as much of the following, or the eagerness to learn and to be proficient in these areas
Familiarity with Information Technology systems
Familiarity with various information security concepts, including; network and wireless security, application security, industry best practices, systems hardening, data encryption, data privacy, incident response, business continuity, physical security, risk assessments, vulnerability scanning, penetration testing, file integrity monitoring, log monitoring, and documented security governance controls (i.e. policies, processes, standards, procedures).
Familiarity with a variety of security products and technologies
Familiarity with industry best practices and standards such as CIS and NIST, including security hardening techniques
Understanding of Unix, Linux, Windows and database server configurations
Understanding of networking systems configurations, including firewalls
Understanding of application architecture, software development lifecycle processes, including secure coding techniques
Understanding of server virtualization technologies, including AIX, ZOS, and SAN storage systems

Soft Skills:

Exceptional customer service, communication and interpersonal skills
Strong written and verbal communication skills.
Strong organizational skills
Strong time management skills
Honesty and integrity
Dedication to providing solutions to meet or exceed client's needs and expectations
Ability to handle challenges and project work loads

Benefits:

Start as a co-op student, and earn an option for fulltime employment
Hourly compensation as a co-op student
Company team building events throughout each year","{""role_summary"":""Assist in conducting information security assessments, analyses, and providing advice to clients as an entry-level security specialist in a co-op program."",""key_terms"":[{""term"":""PCI DSS"",""explanation"":""Payment Card Industry Data Security Standard, a set of security standards for organizations that handle credit card information.""},{""term"":""PCI QSA"",""explanation"":""Payment Card Industry Qualified Security Assessor, a certification for security professionals who assess and validate PCI DSS compliance.""},{""term"":""CIS"",""explanation"":""Center for Internet Security, a non-profit organization that provides cybersecurity best practices and standards.""},{""term"":""NIST"",""explanation"":""National Institute of Standards and Technology, a US government agency that provides cybersecurity guidelines and standards.""}],""skill_priorities"":{""must_have"":[""Information security controls and principles"",""Privacy frameworks"",""PCI DSS"",""Exceptional written and verbal skills""],""nice_to_have"":[""Industry certification in Information Security or Audit"",""Familiarity with security products and technologies"",""Understanding of Unix, Linux, Windows, and database server configurations"",""Understanding of networking systems configurations""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your understanding of PCI DSS, and how would you ensure compliance in a client's organization?"",""example_answer"":""PCI DSS is a set of security standards for organizations that handle credit card information. To ensure compliance, I would conduct a thorough risk assessment, identify vulnerabilities, and implement security controls such as encryption, firewalls, and access controls.""},{""question"":""How would you approach a security breach incident response?"",""example_answer"":""I would follow a structured incident response plan, containing the breach, assessing the damage, notifying stakeholders, and implementing remediation measures to prevent future breaches.""}],""red_flags"":[""Lack of understanding of information security concepts"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Cybersecurity Specialist,"TrustFlight is at the forefront of digitizing the aviation industry with the creation of intelligent workflow applications that automate operating and maintenance processes, enabling our customers to focus on the data and insights that matter. TrustFlight has bases in both England (London & Leamington Spa) and Canada (Vancouver). Our business is rapidly expanding, and we’re proud to share that we’re entirely self-funded and consistently profitable.

Not only are we disrupting the sector, we are creating a great place to work that gives our people the freedom to create, innovate and influence how we do this. We continue to build an amazing group of people who are all here to make our products, services and culture the most envied in the industry!

We are in search of a proficient Cybersecurity Specialist to join our Operations team, focusing on the most critical element for both our company and our clients: security. This vital role involves conducting thorough security assessments, developing and implementing robust security policies, and ensuring compliance with industry standards and best practices. As a key member of our team, you will delve into every aspect of our security operations, providing comprehensive protection across various layers — from network and cloud infrastructure to application layer and customer-facing interfaces. This position offers an exceptional opportunity to be at the forefront of cybersecurity in the aviation industry, where you will play a pivotal role in safeguarding our operations and maintaining our pioneering status.

In this role, you will be energized and guided by our experienced Operations team, fostering a dynamic environment for continuous learning and improvement. Your contributions will be instrumental in elevating our cybersecurity capabilities to their fullest potential, thereby enhancing the efficiency and safety of the aviation industry. At TrustFlight, we deeply value teamwork and are committed to the personal and professional growth of each team member. We are looking for professionals who are confident in their ability to acquire new skills and grow their expertise through dedicated mentorship and a supportive work culture.

Responsibilities

Conduct security assessments, risk analysis, and vulnerability testing of various operating environments.
Develop and review policies and standards with stakeholders.
Ensure compliance with cybersecurity policies and industry standards.
Assist in upholding and managing security certifications such as ISO27001, SOC2, and others.
Provide training and guidance on security protocols and best practices.
Research and evaluate new and emerging security technologies and integrations.
Influence Operational decisions by contributing insightful security perspectives that consider both technical and strategic aspects.
Collaborate with IT and cross-functional teams to ensure security best practices are integrated into all aspects of technology.
Manage and respond to cybersecurity incidents.


You ideally need the following to qualify:

Bachelor’s degree in Computer Science, Information Technology, Cybersecurity, or a related field.
Experience with implementing and managing security systems and tools.
Knowledge and experience of IT Controls, IT Security, NIST CSF-RMF, ISO 27001/2, and COBIT.
Professional certifications such as CRISC, CISSP, CISM, CISA, CompTIA Security+, GSEC or equivalent are highly desirable.
Experience working with SaaS, PaaS, and IaaS providers, providing guidance on secure system and service configuration.
Familiarity with scripting languages (e.g., Python, PowerShell) for automation of security tasks.
Proficiency in written and verbal communication skills.
Demonstrated eagerness and capability to quickly learn and master missing hands-on skills as needed.


The following will be considered as a significant plus and would enhance your candidacy:

Hands-on infrastructure experience with Google Cloud and Microsoft Azure platform security.
Knowledge of network security protocols, firewall administration, intrusion detection systems, SIEMs, ACLs, security groups, endpoint protection, and secure coding practices.
Experience in enforcing IT access control policies using MDM/MAM.
Knowledge of GRC tools.


Job location

This role will be based out of our office in Vancouver. With our hybrid working policy, we encourage a harmonious balance between working from home and collaborating in the office, typically three days per week. This empowers an agile and flexible environment that supports your needs. However, it’s important to note that for you to fully harness the benefits of collaborating closely with our exceptional team across multiple timezones, this role demands a heightened level of flexibility.

Benefits

We offer a generous holiday allowance that increases the longer you are here. We are keen for birthdays to be celebrated and so we offer an additional day off to everyone.
It is important to us that we all work in an environment that is supportive of health and wellbeing; healthcare cover for all our people covers your health, dental and ophthalmic requirements to support you physically and mentally.
Our generous company contribution to your pension is greater than the local requirements and over time you can plan effectively for your future with our matching contribution scheme.
We place huge importance on the contribution and experience you bring to the team, the salary will be based on the value you will bring to the role with a range spanning from 75-115K CAD.


How To Apply

Tell us about you in a cover letter, outlining what you will bring to the role and how you can contribute to creating best in class tools and services throughout the aviation industry. Please also include your resume.

TrustFlight is an equal opportunity employer. We work together to create the most talented team that celebrates inclusivity, diversity and equality in a serious way. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. All candidates will receive consideration for this role without regard for gender, gender identity, race, national origin, colour, religion, disability or age. Our inclusive culture empowers all of us to inspire, enlighten and thrive.","{""role_summary"":""A Cybersecurity Specialist is needed to join the Operations team at TrustFlight, focusing on security assessments, policy development, and compliance with industry standards to safeguard operations and maintain pioneering status in the aviation industry."",""key_terms"":[{""term"":""ISO27001"",""explanation"":""An international standard for information security management systems, ensuring the confidentiality, integrity, and availability of information.""},{""term"":""SOC2"",""explanation"":""A set of compliance standards for service organizations, ensuring the security, availability, processing integrity, confidentiality, and privacy of customer data.""},{""term"":""NIST CSF-RMF"",""explanation"":""A framework for managing and reducing cybersecurity risk, providing guidelines for identifying, protecting, detecting, responding, and recovering from cyber threats.""},{""term"":""COBIT"",""explanation"":""A framework for IT governance and management, providing guidelines for managing and controlling IT processes and ensuring alignment with business objectives.""},{""term"":""CRISC"",""explanation"":""A professional certification for risk and information systems control, demonstrating expertise in identifying, assessing, and mitigating risk.""},{""term"":""CISSP"",""explanation"":""A professional certification for information systems security professionals, demonstrating expertise in designing, implementing, and managing secure IT systems.""},{""term"":""CISM"",""explanation"":""A professional certification for information security managers, demonstrating expertise in designing, implementing, and managing information security programs.""},{""term"":""CISA"",""explanation"":""A professional certification for information systems auditors, demonstrating expertise in auditing, controlling, and securing IT systems.""},{""term"":""CompTIA Security+"",""explanation"":""A professional certification for IT security professionals, demonstrating expertise in network security, vulnerabilities, and risk management.""},{""term"":""GSEC"",""explanation"":""A professional certification for security professionals, demonstrating expertise in security principles, network security, and risk management.""},{""term"":""SaaS"",""explanation"":""Software as a Service, a cloud-based software delivery model where applications are hosted and managed by a third-party provider.""},{""term"":""PaaS"",""explanation"":""Platform as a Service, a cloud-based platform for developing, running, and managing applications, providing a complete development and deployment environment.""},{""term"":""IaaS"",""explanation"":""Infrastructure as a Service, a cloud-based infrastructure for computing resources, providing virtualized computing resources over the internet.""},{""term"":""MDM/MAM"",""explanation"":""Mobile Device Management and Mobile Application Management, solutions for managing and securing mobile devices and applications in an enterprise environment.""},{""term"":""GRC"",""explanation"":""Governance, Risk, and Compliance, a set of practices and tools for managing and mitigating risk, ensuring compliance with regulations, and maintaining governance.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in Computer Science, Information Technology, Cybersecurity, or a related field"",""Experience with implementing and managing security systems and tools"",""Knowledge and experience of IT Controls, IT Security, NIST CSF-RMF, ISO 27001/2, and COBIT"",""Professional certifications such as CRISC, CISSP, CISM, CISA, CompTIA Security+, GSEC or equivalent"",""Experience working with SaaS, PaaS, and IaaS providers"",""Familiarity with scripting languages (e.g., Python, PowerShell) for automation of security tasks"",""Proficiency in written and verbal communication skills""],""nice_to_have"":[""Hands-on infrastructure experience with Google Cloud and Microsoft Azure platform security"",""Knowledge of network security protocols, firewall administration, intrusion detection systems, SIEMs, ACLs, security groups, endpoint protection, and secure coding practices"",""Experience in enforcing IT access control policies using MDM/MAM"",""Knowledge of GRC tools""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with conducting security assessments and risk analysis, and how do you stay current with emerging threats and vulnerabilities?"",""example_answer"":""I have conducted security assessments and risk analysis for various operating environments, including cloud-based and on-premise systems. I stay current with emerging threats and vulnerabilities by attending industry conferences, participating in online forums, and reading relevant publications.""},{""question"":""How do you ensure compliance with industry standards and best practices in cybersecurity, and what certifications do you hold?"",""example_answer"":""I ensure compliance with industry standards and best practices by staying up-to-date with the latest regulations and guidelines, such as ISO 27001 and NIST CSF-RMF. I hold certifications in CISSP and CISM, demonstrating my expertise in information systems security and management.""}],""red_flags"":[""Lack of experience with cloud-based security systems and tools"",""Inability to communicate technical information to non-technical stakeholders"",""Limited knowledge of industry standards and best practices in cybersecurity""],""confidence_score"":90.0}"
Staff Security Analyst,"Hi there! Thanks for stopping by 👋

Are you actively looking for a new opportunity? Or just checking the market? Well… you might just be in the right place to join our team.

The Staff Analyst, Security is a critical member of Lightspeed’s Security Operations Team. They actively monitor, analyze, and respond to security incidents, conduct in-depth analysis of security events, aid in the development and maintenance of standard operating procedures for incident detection and response, and collaborate with cross-functional teams to resolve incidents, while proactively identifying and mitigating emerging threats.

What you'll be responsible for

Monitor and triage security alerts from various sources, including SIEM, IDS/IPS, firewalls, and endpoint protection systems.
Conduct in-depth analysis of security events to identify potential threats and vulnerabilities.
Develop and implement best practices for detection engineering.
Aid in the development and maintenance of standard operating procedures for incident detection and response.
Collaborate with cross-functional teams to resolve security incidents promptly.
Proactively identify and mitigate emerging threats.
Oversee the transition from SIEM to SOAR (Security Orchestration, Automation, and Response).
Maintain and update security tools and technologies.
Provide timely reports on security activities.
Communicate effectively with both technical and non-technical stakeholders
Partner / mentor fellow security team members.
Advocate for security best practices and proactive threat mitigation throughout the organization.
Participate in incident response planning and lead remediation efforts in case of security breaches.


What you’ll be bringing to the team

Significant experience with incident response procedures, including containment, eradication, and recovery.
Significant experience using SIEM tools for log analysis and threat detection.
Significant experience with additional security tools, such as EDR, CSPM, and DLP.
Significant experience in detection engineering.
Crowd strike experience a plus, and extensive knowledge of security controls, access controls, network security, vulnerability management.
Experience transitioning from SIEM to SOAR.
Experience working with large-scale cloud environments (AWS, GCP, etc).
Thorough understanding of threat intelligence sources and how to apply them in security operations.
Demonstrated ability to lead cross-functional initiatives.
Relevant certifications, such as CompTIA Security+ or CISSP, are a plus


What's in it for you?

Join a fast-paced, high-growth company.
Surround yourself with strong talent and enjoy continuous professional growth.
Develop in a modern and proven technology stack.
Great benefits and perks, including equity and flexible/hybrid remote work options, in a diverse and inclusive environment.
Development of very high traffic products, used at the global scale.
Opportunities to learn and expand your skill set
Become a valued part of the diverse and inclusive Lightspeed family.


… and enjoy a range of benefits that’ll keep you happy, healthy and (not) hungry:

Lightspeed equity scheme (we are all owners)
Flexible paid time off policy
Health Insurance
Health and wellness benefit of $500 per year
Paid leave and assistance for new parents
Mental health online platform and counseling & coaching services
Volunteer day


To all recruitment agencies: Lightspeed does not accept unsolicited agency resumes. If we have not directly engaged your company in writing to supply candidates for a specific vacancy, Lightspeed will not be responsible for any fees related to unsolicited resumes.

Lightspeed is a proud equal opportunity employer and we are committed to creating an inclusive and barrier-free workplace. Lightspeed welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.

Where to from here?

Obviously, this has to be mutually beneficial: we want you to step into a role you love, and we want to offer you a place you’re proud to come to every day. For a glimpse into our world check out our career page here.

Lightspeed is building communities through commerce, and we need people from all backgrounds and lived experiences to do that. We were founded in 2005, in Montreal’s gay village and our original members were all part of the LGBTQ+ community. The ethos of our business has been about inclusion from the very beginning, and we strive to provide a workplace where everyone belongs.

Who We Are

Powering the businesses that are the backbone of the global economy, Lightspeed's one-stop commerce platform helps merchants innovate to simplify, scale, and provide exceptional customer experiences. Our cloud commerce solution transforms and unifies online and physical operations, multichannel sales, expansion to new locations, global payments, financial solutions, and connection to supplier networks.

Founded in Montréal, Canada in 2005, Lightspeed is dual-listed on the New York Stock Exchange (NYSE: LSPD) and Toronto Stock Exchange (TSX: LSPD). With teams across North America, Europe, and Asia Pacific, the company serves retail, hospitality, and golf businesses in over 100 countries.

Lightspeed handles your information in accordance with our Applicant Privacy Statement.","{""role_summary"":""The Staff Analyst, Security is responsible for monitoring and analyzing security incidents, developing and maintaining standard operating procedures, and collaborating with cross-functional teams to resolve incidents and identify emerging threats."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a system that monitors and analyzes security-related data from various sources.""},{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection System/Intrusion Prevention System, a system that detects and prevents unauthorized access to a network.""},{""term"":""SOAR"",""explanation"":""Security Orchestration, Automation, and Response, a system that automates and streamlines security incident response.""},{""term"":""EDR"",""explanation"":""Endpoint Detection and Response, a system that monitors and responds to endpoint security threats.""},{""term"":""CSPM"",""explanation"":""Cloud Security Posture Management, a system that monitors and manages cloud security configurations.""},{""term"":""DLP"",""explanation"":""Data Loss Prevention, a system that monitors and prevents unauthorized data exfiltration.""}],""skill_priorities"":{""must_have"":[""incident response procedures"",""SIEM tools"",""security tools (EDR, CSPM, DLP)"",""detection engineering"",""cloud security (AWS, GCP)""],""nice_to_have"":[""Crowd Strike experience"",""CompTIA Security+ or CISSP certification""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with incident response procedures, including containment, eradication, and recovery?"",""example_answer"":""In my previous role, I developed and implemented incident response procedures that reduced mean time to detect (MTTD) by 30% and mean time to respond (MTTR) by 25%.""},{""question"":""How do you stay current with emerging threats and vulnerabilities in the security landscape?"",""example_answer"":""I regularly review threat intelligence reports from reputable sources and participate in industry forums to stay informed about emerging threats and vulnerabilities.""}],""red_flags"":[""Lack of experience with SIEM tools"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Cyber Security Analyst,"Pen Tester & Application Security
Experienced in Security Testing, Threat Modelling and Security Risk Assessment.
Experienced in Web application and Mobile application penetration testing.
Coding skills to test/simulate infiltration.
Excellent knowledge of computer security and systems.
Understanding of how vulnerabilities and security breaches can disrupt business.
Good in troubleshooting and problem-solving skills.
Application security tools for the whole development life cycle
Creating threat models
Rating discovered risks.
Gap analysis on security tools
Mitigating web application vulnerabilities
Creating a DevSecOps pipeline
Application security as a service model
Creating a software security ecosystem that benefits development.
Setting up Security program for contin","{""role_summary"":""Conduct security testing, threat modeling, and risk assessments to identify vulnerabilities and mitigate security breaches in web and mobile applications, ensuring business continuity."",""key_terms"":[{""term"":""Threat Modelling"",""explanation"":""A process to identify, evaluate, and prioritize potential security threats to an application or system.""},{""term"":""DevSecOps"",""explanation"":""A practice that integrates security into the development and operations lifecycle to ensure secure software development.""},{""term"":""Gap analysis"",""explanation"":""A method to identify and address security vulnerabilities in an application or system by comparing current security controls with desired security controls.""}],""skill_priorities"":{""must_have"":[""Security testing"",""Threat modeling"",""Web application penetration testing"",""Mobile application penetration testing"",""Coding skills""],""nice_to_have"":[""DevSecOps"",""Application security as a service model""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach threat modeling for a web application?"",""example_answer"":""I would identify the application's assets, identify potential threats, and prioritize them based on likelihood and impact. Then, I would develop a mitigation plan to address the identified threats.""},{""question"":""Can you explain how you would rate discovered risks in a security risk assessment?"",""example_answer"":""I would use a risk rating framework such as CVSS to evaluate the severity of the discovered risks, considering factors such as likelihood, impact, and exploitability.""}],""red_flags"":[""Lack of experience in web application penetration testing"",""Inability to explain threat modeling concepts""],""confidence_score"":90.0}"
Security Analyst II,"Cyderes (Cyber Defense and Response) is a pure-play, full life-cycle cybersecurity services provider with award-winning managed security services, identity and access management, and professional services designed to manage the cybersecurity risks of enterprise clients. We specialize in multi-technology, complex environments with the in speed and agility needed to tackle the most advanced cyber threats. We leverage our global scale and decades of experience to accelerate our clients’ cyber outcomes through a full lifecycle of cybersecurity services. We are a global company with operating centers in the United States, Canada, the United Kingdom, and India.

About The Role
The Managed Services Security Analyst II is responsible for security solutions for clients. The Security Analyst II will demonstrate the capacity to consistently meet and exceed client expectations representing and reinforcing the Cyderes brand through positive interaction with other teams within the company. Perform deep

dive investigations into security threats, understand and implement MITRE mapping to identify customers current security posture.

Responsibilities

Perform triage and advanced analysis tasks across endpoint, server, and network infrastructure
Perform Threat Hunting on customer networks to detect, isolate threats and provide recommendations
Provide proactive security investigation and searches on client environment to detect malicious activities
Coordinate Incident investigations and deep dive analysis on detected threats
Understand and identify indicators of attack and compromise in alerts, by hunting through data, and from review of investigation notes
Have full understanding of the MITRE ATT&CK framework. Mapping clients use cases to tactics and techniques
Update documentation and runbooks to ensure repeatable analysis
Actively participate in an after-hours on-call rotation as Incident Controller
Scope customer security incidents




Requirements

3 or more years of progressing/in-depth IT security experience
System Administration experience (Windows, Unix/Linux, Mac)
Advanced understanding of networking concepts and ability to analyze network artifacts
Demonstrate experience in using Endpoint Detection and Response software (Sentinel1, Crowdstrike, Defender ETC.)
Advanced knowledge of at least one leading SIEM platform (Sentinel, Splunk, Elastic, IBM Qradar, Chronicle etc.)
Possess at least one industry certification Sec+, CEH, SANS Certification (e.g. GCIH, GCIA, GSEC, GMON), OSCP etc. or working towards a related certification
Basic scripting or development experience in one of the following languages: Python, JavaScript, PowerShell, bash, etc




Cyderes is an Equal Opportunity Employer (EOE). Qualified applicants are considered for employment without regard to race, religion, color, sex, age, disability, sexual orientation, genetic information, national origin, or veteran status.

Note: This job posting is intended for direct applicants only. We request that outside recruiters do not contact us regarding this position.","{""role_summary"":""The Managed Services Security Analyst II is responsible for providing security solutions to clients, performing deep dive investigations into security threats, and implementing MITRE mapping to identify clients' current security posture."",""key_terms"":[{""term"":""MITRE ATT&CK framework"",""explanation"":""A globally recognized framework for identifying and mitigating cyber threats, used to map clients' use cases to tactics and techniques.""},{""term"":""Endpoint Detection and Response software"",""explanation"":""Tools used to detect and respond to endpoint security threats, such as Sentinel1, Crowdstrike, and Defender.""},{""term"":""SIEM platform"",""explanation"":""Security Information and Event Management platforms, such as Sentinel, Splunk, Elastic, and IBM Qradar, used for monitoring and analyzing security-related data.""}],""skill_priorities"":{""must_have"":[""3+ years of IT security experience"",""System Administration experience"",""Advanced understanding of networking concepts"",""Experience with Endpoint Detection and Response software"",""Advanced knowledge of at least one leading SIEM platform"",""Industry certification (e.g. Sec+, CEH, SANS Certification)""],""nice_to_have"":[""Basic scripting or development experience in Python, JavaScript, PowerShell, or bash""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would perform a deep dive investigation into a security threat?"",""example_answer"":""I would start by analyzing network artifacts and logs to identify the source of the threat. Then, I would use my knowledge of the MITRE ATT&CK framework to map the threat to tactics and techniques, and finally, I would provide recommendations for mitigation and remediation.""},{""question"":""How do you stay current with the latest cyber threats and security technologies?"",""example_answer"":""I regularly review industry reports and blogs, participate in online forums and discussions, and attend training and certification programs to stay up-to-date with the latest threats and technologies.""}],""red_flags"":[""Lack of experience with Endpoint Detection and Response software"",""Limited knowledge of SIEM platforms"",""No industry certification""],""confidence_score"":90.0}"
Information Security Analyst #12655,"INFORMATION SECURITY ANALYST #12655
FULL-TIME
MARKHAM, ON
UP TO $115K

Are you interested in innovation in the automotive industry?
Are you an expert in information security and risk management?
Are you skilled in recommending and executing security solutions?

The Company
Our client is an enduring global presence in the automotive industry and a financial services division committed to top-quality service. They are looking for a skilled professional in information security with a solution-oriented mindset and collaborative work ethic to join their team to set and maintain the highest standards in their business operations. If you are an expert in this space with a love for automotives, this is your chance to join an incredible team and support exciting projects!

Company Perks and Rewards
Competitive compensation
Access to health benefits from day one
Pension plan with matched contribution
Employee discount on vehicles
Learning and development opportunities
Tuition and fitness reimbursement
Fantastic company culture
Hybrid work model
And more!

The Job!
Key responsibilities include:
Maintain and monitor security access to portals and shared drives.
Conduct regular reviews and risk assessments of information systems and infrastructure.
Develop and implement risk treatment and mitigation, with recommendations for improvement.
Analyze architecture and determine requirements to enhance security measures.
Align solutions with Information Security policies and standards.
identify security threats and advise Management with appropriate urgency.
Provide guidance on reducing risk to various teams and service partners.
Support and coordinate business continuity and disaster recovery activities.
Develop and conduct training on information security and business continuity.
Assist with annual policy and procedure reviews and improvements.
Participate in IT projects.’
Other tasks as required.

What you bring to the job
You are committed to accuracy and efficiency. You value collaborative work as well as independence. You are passionate about your work and performing at your best. You also have:
Post-secondary education in Computer Science, Engineering, or a similar program.
At least 5 years of experience in information security (on-prem and cloud).
Experience in a similar role with the financial services industry.
A range of diverse technical and security experience, including risk assessment and phishing simulations.
Experience with vendor assessment processes and vendor management.
Ability to identify and mitigate risks for processes, operations, programs, and projects.
Experience with Business Continuity Plans and Disaster Recovery.
Knowledge and experience with managing security technologies.
Knowledge of software and infrastructure development, as well as network protocols, topologies, segmentation, etc.
Thorough understanding of operating systems, databases, applications, mobile security, etc.
Familiarity with various network security technology, processes, and solutions.
Related certification or licensing would be an asset (e.g. CISSP, CCSP, ISSAP, CCSK)


Qualified job seekers are asked to apply with attention to Antoinette King. Reference # 12655

I really look forward to hearing from you, but please understand that I will only be contacting those that are applicable for the role!
Options Consulting Solutions is an equal opportunity employer and welcomes applications from all individuals. Applicants selected for an in-person interview will be asked whether specific accommodations are needed to support a personal disability.
You can also find more jobs that may be suited to you on the Options Consulting Solutions Indeed and LinkedIn pages. Follow us on Instagram and Facebook for job searching tips and other updates.","{""role_summary"":""The Information Security Analyst is responsible for maintaining and monitoring security access, conducting risk assessments, and developing and implementing risk treatment and mitigation strategies to ensure the highest standards in business operations."",""key_terms"":[{""term"":""Risk Assessment"",""explanation"":""Evaluating potential security threats and vulnerabilities to identify areas for improvement.""},{""term"":""Risk Treatment and Mitigation"",""explanation"":""Developing and implementing strategies to reduce or eliminate identified security risks.""},{""term"":""Information Security Policies and Standards"",""explanation"":""Guidelines and regulations governing information security practices within an organization.""},{""term"":""Business Continuity and Disaster Recovery"",""explanation"":""Plans and procedures to ensure continued business operations in the event of disruptions or disasters.""},{""term"":""Phishing Simulations"",""explanation"":""Testing an organization's susceptibility to phishing attacks to identify areas for improvement.""},{""term"":""Vendor Assessment Processes"",""explanation"":""Evaluating the security and risk management practices of third-party vendors.""}],""skill_priorities"":{""must_have"":[""At least 5 years of experience in information security (on-prem and cloud)"",""Experience in a similar role with the financial services industry"",""Knowledge of software and infrastructure development, as well as network protocols, topologies, segmentation, etc."",""Thorough understanding of operating systems, databases, applications, mobile security, etc.""],""nice_to_have"":[""Related certification or licensing (e.g. CISSP, CCSP, ISSAP, CCSK)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with risk assessment and mitigation strategies in a cloud-based environment?"",""example_answer"":""In my previous role, I conducted regular risk assessments of our cloud-based infrastructure and developed mitigation strategies to reduce the risk of data breaches. I worked closely with our development team to implement security patches and ensure compliance with industry standards.""},{""question"":""How do you stay current with emerging security threats and trends in the financial services industry?"",""example_answer"":""I regularly attend industry conferences and webinars, and participate in online forums and discussion groups to stay informed about the latest security threats and trends. I also conduct regular security audits and risk assessments to identify areas for improvement.""}],""red_flags"":[""Lack of experience in the financial services industry"",""Limited knowledge of cloud-based security solutions"",""No experience with business continuity and disaster recovery planning""],""confidence_score"":90.0}"
OneTrust Application Security Analyst,"The team of resources will provide thought leadership for the Data Privacy Enablement Project along with design and technical expertise for the OneTrust implementation. They will be responsible for leading their work streams by developing roadmaps, conducting execution planning, composing user stories, and collaborating with interfacing teams. Team members must be full-stack privacy analysts who are able to provide hands-on-keyboard OneTrust configuration and troubleshooting along with in-depth data privacy compliance knowledge and expertise. Must be OneTrust certified and know how to fully develop , configure and troubleshoot within the OneTrust applications.

Develop technical architectures, frameworks and strategies, either for an organization or for a major application area, to meet the business and application requirements.
Analyze and evaluate alternative technology solutions to meet business problems. Ensure the integration of all aspects of technology solutions.
Evaluate hardware and software relative to their ability to support specified requirements and by determining potential and actual bottlenecks, improve system performance through recommended hardware changes.
Review computer software systems and data requirements as well as communication and response needs and determine operating systems and languages needed to support them.
Monitor industry trends to ensure that solutions fit with best practice directions for technology.
Provide information, direction and support for emerging technologies.
Review application and program design or technical infrastructure design to ensure adherence to standards and to recommend performance improvements


Requirements

Certifications required:
Security Analyst: OneTrust Certified in PIA & DPIA Automation
Security Analyst: OneTrust Certified in PIA & Privacy Rights Automation
Experience required:
Security Analyst: 3+ years of systems integrations experience, 2+ years of OneTrust: experience
Security Analyst: 2+ years of systems integrations experience, 1+ years of OneTrust experience

Benefits

Type of job: Temporary Contractor - 1 year
Date candidate required: Immediate
Location: Toronto
Work hours are Monday - Friday, normal 37.5 hour week","{""role_summary"":""Lead the Data Privacy Enablement Project, providing technical expertise for OneTrust implementation, and ensuring data privacy compliance. Develop technical architectures, analyze alternative technology solutions, and evaluate hardware and software to meet business requirements."",""key_terms"":[{""term"":""OneTrust"",""explanation"":""A software platform for data privacy management and compliance.""},{""term"":""PIA"",""explanation"":""Privacy Impact Assessment, a process to identify and mitigate privacy risks.""},{""term"":""DPIA"",""explanation"":""Data Protection Impact Assessment, a process to identify and mitigate data protection risks.""}],""skill_priorities"":{""must_have"":[""OneTrust certification"",""OneTrust configuration and troubleshooting"",""Data privacy compliance knowledge"",""Systems integration experience""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach a OneTrust implementation for a large-scale data privacy project?"",""example_answer"":""I would start by conducting a thorough analysis of the organization's data privacy requirements, then develop a roadmap for the implementation, and finally configure and troubleshoot the OneTrust application to ensure compliance.""},{""question"":""How do you stay up-to-date with emerging technologies in data privacy and compliance?"",""example_answer"":""I regularly review industry trends, attend webinars, and participate in online forums to stay current with best practices and new technologies in data privacy and compliance.""}],""red_flags"":[""Lack of OneTrust certification or experience"",""Insufficient data privacy compliance knowledge""],""confidence_score"":90.0}"
"Cybersecurity Specialist - Milwaukee, WI - USA","Hello,

I Hope you are doing great.

This is Bhanu from Intellectt INC; we’ve got an important role Cybersecurity Specialist( Medical device ) - Milwaukee, WI with one of our prestigious clients. Interested candidates can please send your updated resume at bhanu@intellectt.com

We're happy to sponsor TN VISA who are qualified and ready to relocate immediately. (Passport Mandatory)

Role: Cybersecurity Specialist( Medical device )

Location: Milwaukee, WI

Essential Job Functions

Develop deep understanding of Medtech security processes and procedures to serve as a subject matter expert on cybersecurity activities
Partner with engineering teams to drive successful adherence to Medtech product security programs during product development, testing, and release phases.
Work with external partners as well as collaborate with internal cross functional teams to own and drive cybersecurity project deliverables.
Collaborate with product development teams to identify potential cybersecurity risks during the pre-market phase.
Deliver documentation for pre-market development activities including security plans, architecture and data flow diagrams, threat models, requirements, SBOM, and risk documentation.
Monitor and drive post-market vulnerability management activities, with adherence to strict timelines.
Recommend and execute security measures to mitigate identified risks and improve product security.
Guide teams to make decisions that balance business needs with security objectives.
Think across organizational boundaries and empathize with customers, both internal and external.
Perform other related duties and responsibilities, as assigned

Knowledge And Experience

Bachelor's degree in Computer Science, Cybersecurity, or a related field (or equivalent practical experience). 6+ yrs of experience.
In-depth knowledge of pre-market product security and familiarity with industry best practices.
Experience with security risk management techniques and tactics.
Experience in assessing pre-market cybersecurity risks, vulnerability testing, and implementing security measures.
Strong understanding of secure software development lifecycles (SDLC) and related processes.
Working knowledge of regulatory standards and compliance frameworks (e.g., NIST Cybersecurity Framework, ISO27001, SOC2, HIPAA, GDPR).
Experience working in a regulated environment, FDA-regulated preferred.
Demonstrated organizational skills, attention to detail, the ability to handle multiple assignments simultaneously in a timely manner and be able to meet assigned deadlines.
Committed to working with a sense of urgency and embracing new challenges.
Strong communication and interpersonal skills.

Qualification

BS degree in Computer Science; MS in Cybersecurity preferred



Poldas Ajay Bhanu | Sr Recruiter

Intellectt INC

732 784 4384

732 412 6999- Ext: 159

Bhanu@intellectt.com intellectt.com/

517 Route 1 South, Suite 1115 Iselin, NJ 08830.

WhatsApp: https://chatwith.io/s/bhanu","{""role_summary"":""The Cybersecurity Specialist will serve as a subject matter expert on cybersecurity activities, partnering with engineering teams to drive successful adherence to Medtech product security programs and identifying potential cybersecurity risks during the pre-market phase."",""key_terms"":[{""term"":""Medtech security processes"",""explanation"":""Security processes and procedures specific to medical technology devices.""},{""term"":""Pre-market phase"",""explanation"":""The stage of product development before a product is released to the market.""},{""term"":""SBOM"",""explanation"":""Software Bill of Materials, a list of components used in a software application.""},{""term"":""NIST Cybersecurity Framework"",""explanation"":""A set of guidelines for managing and reducing cybersecurity risk.""},{""term"":""ISO27001"",""explanation"":""An international standard for information security management systems.""},{""term"":""SOC2"",""explanation"":""A set of compliance standards for service organizations.""},{""term"":""HIPAA"",""explanation"":""Health Insurance Portability and Accountability Act, a US law for protecting sensitive patient data.""},{""term"":""GDPR"",""explanation"":""General Data Protection Regulation, a European Union law for protecting personal data.""}],""skill_priorities"":{""must_have"":[""6+ years of experience in cybersecurity"",""In-depth knowledge of pre-market product security"",""Experience with security risk management techniques and tactics"",""Strong understanding of secure software development lifecycles (SDLC) and related processes"",""Working knowledge of regulatory standards and compliance frameworks""],""nice_to_have"":[""MS in Cybersecurity"",""Experience working in a regulated environment, FDA-regulated preferred""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of secure software development lifecycles (SDLC) in medical device development?"",""example_answer"":""Secure SDLC is crucial in medical device development as it ensures that security is integrated into every stage of the development process, reducing the risk of vulnerabilities and protecting patient data.""},{""question"":""How do you stay up-to-date with the latest regulatory standards and compliance frameworks in the medical device industry?"",""example_answer"":""I regularly review industry publications and attend conferences to stay current with the latest developments in regulatory standards and compliance frameworks, such as NIST Cybersecurity Framework and HIPAA.""}],""red_flags"":[""Lack of experience in medical device security"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Security Analyst - HYBRID,"Are you passionate about cybersecurity and ready to make an impact in a dynamic environment? Our Calgary client is expanding their Cybersecurity Office (CSO) Governance, Risk and Compliance (GRC) team and we're looking for a motivated Cybersecurity Compliance Specialist to join their team. In this role, you'll play a crucial part in ensuring compliance with company policies and standards, conducting assessments, and reporting on cybersecurity across our corporate and ICS environments. If you're ready to grow your expertise and contribute to safeguarding our client's operations, apply now and be part of a mission to secure the future of energy.

Advantages

Contribute to cybersecurity governance across corporate and ICS environments, ensuring critical infrastructure protection.
Opportunity to expand knowledge and skills in cybersecurity compliance, automation, and risk management.
Work with PowerBI and ServiceNow to develop innovative dashboards and automate security controls.
Engage with a supportive team of cybersecurity professionals and collaborate closely with IT and business stakeholders.
Influence cybersecurity strategy by identifying and mitigating emerging security risks through comprehensive assessments and compliance attestations.

Responsibilities

Perform assessments and report on cybersecurity compliance across TC Energy
Conduct internal Cybersecurity audits
Participate in Cybersecurity Compliance attestations
Drive automation of security controls with a focus on continuous monitoring
Develop scripts to automate manual tasks and processes within the Cybersecurity Office
Develop PowerBI and ServiceNow dashboards leveraging available data sources
Develop ServiceNow GRC Compliance features, such as integration with Governance and Risk areas and management of Non-Conformances
Review Vulnerability Management Metrics and streamline processes to improve efficiency
Collaborate with system administrators, developers, and IT teams to coordinate the remediation of identified vulnerabilities
Conduct research to maintain and expand knowledge on the latest cybersecurity controls and standards, as well as the threat and vulnerability landscape
Collaborate with CSO GRC Manager, Cybersecurity Office team members, IS teams, business units and other stakeholders on areas related to cybersecurity governance,

Qualifications

5+ years in cybersecurity compliance, risk management, or related fields.
Proficiency in interpreting and implementing cybersecurity policies and standards.
Proven ability to conduct cybersecurity audits and assessments across complex environments.
Experience in automating security controls and processes, with scripting skills in languages such as Python or PowerShell.
Strong understanding of cybersecurity technologies, including vulnerability management, and experience with tools like ServiceNow and PowerBI.

Summary

If you're ready to leverage your expertise in a role that offers both challenges and rewards, we invite you to apply now via this job ad or reach out to your Randstad Digital representative immediately!

P.S. Don’t forget that when you update your profile on Randstad.ca it helps us find you faster when we do have roles that match your skills! So even if this role isn’t for you please update your profile so we can find you!

We look forward to supporting you in your job search!

Good luck!

Randstad Canada is committed to fostering a workforce reflective of all peoples of Canada. As a result, we are committed to developing and implementing strategies to increase the equity, diversity and inclusion within the workplace by examining our internal policies, practices, and systems throughout the entire lifecycle of our workforce, including its recruitment, retention and advancement for all employees. In addition to our deep commitment to respecting human rights, we are dedicated to positive actions to affect change to ensure everyone has full participation in the workforce free from any barriers, systemic or otherwise, especially equity-seeking groups who are usually underrepresented in Canada's workforce, including those who identify as women or non-binary/gender non-conforming; Indigenous or Aboriginal Peoples; persons with disabilities (visible or invisible) and; members of visible minorities, racialized groups and the LGBTQ2+ community.

Randstad Canada is committed to creating and maintaining an inclusive and accessible workplace for all its candidates and employees by supporting their accessibility and accommodation needs throughout the employment lifecycle. We ask that all job applications please identify any accommodation requirements by sending an email to accessibility@randstad.ca to ensure their ability to fully participate in the interview process.","{""role_summary"":""A Cybersecurity Compliance Specialist ensures company policies and standards are met, conducts assessments, and reports on cybersecurity across corporate and ICS environments."",""key_terms"":[{""term"":""GRC"",""explanation"":""Governance, Risk, and Compliance, referring to the management of cybersecurity risks and compliance with company policies and standards.""},{""term"":""ICS"",""explanation"":""Industrial Control Systems, referring to the computerized systems used to monitor and control industrial processes.""},{""term"":""PowerBI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""ServiceNow"",""explanation"":""A cloud-based IT service management platform that provides a range of IT services, including incident management, problem management, and change management.""}],""skill_priorities"":{""must_have"":[""5+ years in cybersecurity compliance, risk management, or related fields"",""Proficiency in interpreting and implementing cybersecurity policies and standards"",""Experience in automating security controls and processes"",""Scripting skills in languages such as Python or PowerShell""],""nice_to_have"":[""Experience with tools like ServiceNow and PowerBI""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of continuous monitoring in cybersecurity compliance?"",""example_answer"":""Continuous monitoring is essential in cybersecurity compliance as it enables real-time identification and mitigation of security risks, ensuring the organization remains compliant with policies and standards.""},{""question"":""How would you approach automating security controls and processes?"",""example_answer"":""I would identify manual tasks and processes that can be automated, develop scripts using languages like Python or PowerShell, and integrate them with existing systems to improve efficiency and reduce risk.""}],""red_flags"":[""Lack of experience in cybersecurity compliance and risk management"",""Inability to interpret and implement cybersecurity policies and standards""],""confidence_score"":90.0}"
Security Incident Analyst 2,"About Behavox

Behavox is shaping the future for how businesses harness their most important raw material - data. Our mission is bold: Organize enterprise data into actionable information that protects and promotes the business growth of multinational companies around the world.

From managing enterprise risk and compliance to maximizing revenue and value, our data operating platform presents a widespread opportunity to build multilingual, AI/ML-based solutions that activate data for every function within a global enterprise.

Our approach is unique, and it’s validated by our customers who tell us to keep forging ahead because no one else is aggregating, analyzing, and acting on data to uncover opportunities or solve problems quite the way we are.

We are looking for fearless innovators who have an insatiable appetite for building what no one has built before.

About The Role

As part of the Behavox Cyber Security team the Security Incident Response Analyst will monitor, detect, analyze, and mitigate cyber security incidents. The role requires a highly talented individual who is willing to demonstrate strong problem-solving skills, has experience in various investigation toolsets and best practices, is able to think critically, and can allow for flexible scheduling. This role will act as an appointed leader of the Incident Response Team (IRT) for the duration of the incident being responded to.

This is a great opportunity for the right talented individual to:

Improve and optimization of SIEM security events working on a team dedicated to extraordinary Cyber Security standards.
Use modern IR approaches and frameworks (e.g. MITRE ATT&CK and Threat Intelligence).
Learn and manage our EDR (Endpoint Detection and Response) platform.

What You'll Bring

A deep and genuine interest in Behavox as demonstrated by a connection to its mission, marketplace and/or technologies.
2+ years of working experience in cyber security incident response, managing threat intelligence strategy, monitoring of cloud infrastructure and web application security.
Experience working with Endpoint Detection and Response (EDR) tools, Intrusion Detection Systems, Firewalls, Vulnerability Assessment tools.
Experience working with Security Information and Event Management (SEIM) solutions with Security-related designations e.g. GCIH/CCFP preferred.
Background in hands-on computer and networking experience to include an understanding of TCP/IP, routing, and major Internet protocols.

What You'll Do

Respond to security incidents using SIEM systems and/or IDS monitoring to contain, eradicate and report on them.
Design and/or improve on Incident Response capabilities that positively impact risk assessmnet and planning.
Implement Incident Response capabilities utilizing EDR or other relevant technologies that deliver efficiencies in incident handling.
Document Incident Response processes through the development of Playbooks and/or Runbooks to provide continuous improvement.
Write Incident Reports that incorporate recommendations and directives to create iterative feedback loops.

What We Offer

A truly global mission with a passionate highly talented community in locations all over the World.
The ability to have significant impact and potential for learning as our aspirations require bold innovation.
A highly competitive cash compensation package with performance bonuses baked into salary payments .
A flexible work schedule that allows for Remote or Hybrid work as appropriate to the role and location.
A very generous time-off policy (30 days annually), with public holidays for your geography in addition.

About Our Process

We take Talent very seriously and we are building a community of extraordinary individuals working together in very high performing teams. We also know that the best Talent always has options so we believe that the process has to be a two way assessment - the company AND the candidate assessing the business needs alignment, the career next step alignment, and the cultural alignment.

During the process we will begin by exploring the core factors regarding salary and location along with core experience and skills and values alignment. We will then deep dive explore the critical technical competencies we have identified for the role, and then we will deep dive in behavioral competencies.

The most aligned candidate will then be asked to do a practical work task simulation activity so we can make sure that you will enjoy the kind of work the role requires, and this task will typically be presented and discussed with a group of colleagues and managers. Finally we will ask you to meet with a number of our senior leaders to make sure that you are making the most informed call possible.","{""role_summary"":""The Security Incident Response Analyst will monitor, detect, analyze, and mitigate cyber security incidents, acting as a leader of the Incident Response Team to improve and optimize SIEM security events and incident response capabilities."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a system that monitors and analyzes security-related data from various sources.""},{""term"":""EDR"",""explanation"":""Endpoint Detection and Response, a platform that monitors endpoint devices to detect and respond to security threats.""},{""term"":""MITRE ATT&CK"",""explanation"":""A framework for understanding and mitigating cyber attacks, providing a structured approach to incident response.""},{""term"":""Threat Intelligence"",""explanation"":""The process of gathering, analyzing, and sharing information about potential cyber threats to improve incident response and prevention.""}],""skill_priorities"":{""must_have"":[""2+ years of experience in cyber security incident response"",""Experience working with EDR tools, Intrusion Detection Systems, Firewalls, and Vulnerability Assessment tools"",""Background in hands-on computer and networking experience""],""nice_to_have"":[""Security-related designations (e.g. GCIH/CCFP)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a recent incident response scenario you handled, and how you contained and eradicated the threat?"",""example_answer"":""In my previous role, I responded to a phishing attack that compromised several employee accounts. I used our SIEM system to identify the source of the attack and worked with the IT team to isolate the affected systems. I then implemented a containment strategy to prevent further damage and eradicated the threat by updating our firewall rules and conducting a thorough system scan.""},{""question"":""How do you stay current with emerging cyber threats and update your incident response strategies accordingly?"",""example_answer"":""I regularly follow industry blogs and threat intelligence feeds to stay informed about emerging threats. I also participate in online forums and attend webinars to stay up-to-date on the latest incident response strategies and best practices.""}],""red_flags"":[""Lack of experience with EDR tools and SIEM systems"",""Inability to think critically and adapt to new incident response scenarios""],""confidence_score"":90.0}"
Vulnerability Assessment Analyst,"LastPass, the #1 password leader, provides password and identity management solutions that are convenient, easy to manage, and effortless to use, helping more than 32 million users and 100,000 businesses organize and protect their online lives. As a pioneer in cloud security technology, LastPass provides award-winning password and identity management solutions that are convenient, effortless, and easy to manage. LastPass values users’ privacy and security, so your sensitive information is always hidden – even from us.

We welcome new ideas, support your growth, and recognize your value, if this aligns with what you are looking for in your next career move, Join Us

LastPass is looking for a Vulnerability Assessment Analyst:

As a Trust & Security team member, you will collaborate with security professionals and engineering teams to identify, verify, prioritize, and address vulnerabilities. This joint effort is aimed at enhancing overall security and minimizing potential threats. Additionally, you will contribute to developing a strong vulnerability management program, ensuring the organization's security and compliance standards are upheld.

If you are passionate about complex problem solving and motivated by scale, then this is the role for you!

Who will you work with?

You will be part of our Security Posture and Attack Surface Engineering & Research (SPASER) team. You'll collaborate with Trust & Security teams to enhance our vulnerability management program. You'll focus on daily vulnerability assessments and support critical security functions like threat intelligence and incident response. Working closely with engineering teams, you'll improve our security posture by treating vulnerabilities and suggesting enhancements.

What are some of the exciting challenges you will be working on?

Regularly assessing the organization's information systems, networks, and applications, using both automated scans and manual methods, across on-premise and cloud-based environments.
Analyzing vulnerability scan results to pinpoint risks, threats, and potential vulnerabilities.
Delivering clear, concise reports to key stakeholders, including IT, Platform, and Software Engineering teams.
Collaborating with the vulnerability treatment team to prioritize and address vulnerabilities based on risk level and potential impact.
Working closely with incident response and threat intelligence teams to identify and mitigate security risks.
Offering strategies to mitigate and remediate identified vulnerabilities.
Validating vulnerability assessment findings, including false positives and false negatives.
Staying updated on emerging threats and technologies to evolve testing methodologies.
Supporting improvements to vulnerability management tools for effective detection and fewer false positives.
Monitoring and tracking vulnerability status and trends.
Establishing metrics to evaluate vulnerability management effectiveness and find areas for enhancement.
Building strong partnerships across security and non-security teams to support vulnerability management processes.

What does it take to work at LastPass?

Previous experience in cybersecurity roles.
Passion for cybersecurity, particularly in vulnerability management, and a knack for spotting vulnerabilities.
Hands-on experience with vulnerability management tools, methods, and strategies.
Familiarity with cloud environments, including cloud-specific security measures and best practices.
Strong analytical skills and critical thinking ability, always striving for process improvement.
Self-motivated and able to work independently, but also effective in teamwork.
Excellent written and verbal communication in English, enabling effective collaboration.
Positive, can-do attitude and willingness to contribute hands-on to the team.

Why LastPass?

Market-leading password manager
High-growth, collaborative environment with inclusive teams
Remote first culture
Competitive compensation
Flexible Paid time off policies including but not limited to: Monthly self-care days (12 extra paid days off annually), volunteering days
Generous Parental leave
Comprehensive health coverage, dependents included
Home office setup support
LastPass families free account up to 5 members
Continuous learning and development opportunities

Unlock your potential with us - your skills, experience, and unique perspective matter more than just checking the boxes. Apply today, and let's build the future together!

We’re building an inclusive community that reflects the people of all races, genders, sexual orientations, national origins, backgrounds, and perspectives who share our world.

For all US based jobs please review our Applicant Privacy Notice

For all EU based jobs please review our Candidate Privacy Notice

Please review our CCPA Notice","{""role_summary"":""Collaborate with security professionals and engineering teams to identify, verify, prioritize, and address vulnerabilities, enhancing overall security and minimizing potential threats."",""key_terms"":[{""term"":""Vulnerability Management"",""explanation"":""The process of identifying, classifying, prioritizing, and remediating vulnerabilities in an organization's systems, networks, and applications.""},{""term"":""Cloud Security"",""explanation"":""The practice of protecting cloud-based systems, data, and applications from cyber threats and unauthorized access.""},{""term"":""Threat Intelligence"",""explanation"":""The process of gathering, analyzing, and disseminating information about potential cyber threats to help organizations prepare and respond to attacks.""},{""term"":""Incident Response"",""explanation"":""The process of responding to and managing cybersecurity incidents, such as data breaches or ransomware attacks, to minimize damage and restore normal operations.""}],""skill_priorities"":{""must_have"":[""Previous experience in cybersecurity roles"",""Hands-on experience with vulnerability management tools, methods, and strategies"",""Familiarity with cloud environments, including cloud-specific security measures and best practices"",""Strong analytical skills and critical thinking ability""],""nice_to_have"":[""Passion for cybersecurity, particularly in vulnerability management"",""Self-motivated and able to work independently"",""Excellent written and verbal communication in English""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with vulnerability management tools and strategies?"",""example_answer"":""I've worked with Nessus and OpenVAS for vulnerability scanning, and I'm familiar with the CVSS scoring system. I've also developed custom scripts to automate vulnerability scanning and reporting.""},{""question"":""How do you stay updated on emerging threats and technologies in cybersecurity?"",""example_answer"":""I regularly follow industry blogs and news outlets, such as Cybersecurity News and Dark Reading. I also participate in online forums and attend webinars to stay current on the latest trends and best practices.""}],""red_flags"":[""Lack of experience with cloud-based security measures"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Senior Security Analyst,"Come Build a Better Financial Future for all Canadians

At Neo, we're building a more rewarding financial experience for all Canadians.

Life at a rapidly expanding tech startup is demanding, exhilarating, and not for everyone.

From world-class creative minds to brilliant engineers, it's high-performing people that make Neo a workplace with passion and purpose.

Since being founded in 2019, Neo has built incredible traction and is one of the fastest growing fintechs in Canada.

LinkedIn's Top Startup in Canada for 2022 and 2023
Top-ranked mobile apps and credit cards
Canada's top-rated credit card
Team of 700+ people
1M+ customers in 3 years
11K+ retail partners


High Performance at Neo

We recruit, hire, and build our company culture around these attributes:

Teamwork: We trust, respect, encourage, and show up for each other — through good times and hard. We're on this mission not just for ourselves, but also for the people we work with — and ultimately, for our customers.

Ownership: We all have a stake in Neo's success — so we go out of our way to do what needs to get done. We hold ourselves accountable to deliver on our commitments — to our customers, to our partners, and to our team. When we fall short, we find a way to do better in the future.

Professional Integrity: We're asking millions of Canadians to trust us with their hard-earned money — so we hold ourselves (and each other) to the highest standards of integrity.

The Role

We are seeking a skilled and experienced Senior Security Analyst to join our IT Security team. The Senior Security Analyst will be responsible for implementing security measures to safeguard our organization's IT systems and data, monitoring, analyzing, and responding to security incidents, and assessing threats.

What You'll Be Doing

Implementation and maintenance of security controls, policies, and procedures to protect against cyber threats
Architect cloud-first security systems (e.g. Netskope, Zscaler, Crowdstrike, Cloud-native DLP, AWS security, etc)
Monitor security alerts and logs from various systems, applications, and network devices to detect and investigate potential security incidents
Conduct security event analysis and triage security alerts to identify and prioritize potential threats or vulnerabilities
Perform security assessments, risk analysis, and vulnerability scans to identify weaknesses in systems and recommend remediation measures
Collaborate with cross-functional teams to integrate security into IT infrastructure, applications, and services
Provide guidance and expertise on security best practices and recommend security enhancements
Document security incidents, investigations, and actions taken for future reference and improvement
Stay updated on emerging security threats, vulnerabilities, and industry best practices


Who We're Looking For

Bachelor's degree in Computer Science, Information Security, or related field (or equivalent work experience)
5+ years experience as a Security Analyst or in a similar role focusing on standards and compliance
Proven experience in IT security, incident response, or a related field
Familiarity with security tools and technologies such as SIEM, IDS/IPS, antivirus, and endpoint protection
Knowledge of security frameworks and best practices (e.g., NIST, CIS, SOC2, PCI, etc)
Strong analytical and problem-solving skills
Excellent communication and teamwork abilities


Working at Neo

Joining Neo means betting on yourself and discovering your full potential. As individuals and as a team, we continually challenge ourselves and each other to do our best work. We're making change happen at a rapid pace — providing endless opportunities to sharpen your skills, expand your knowledge, and find new solutions to complex problems. That means rapid career progression and constant learning opportunities.

The people who thrive at Neo are resourceful, relentless, and want to win. We hold ourselves to high standards, because we're on a mission that matters — to transform financial services for the better. If that's what you're looking for, read on.

We trust, respect, and show up for each other. That means truthful conversations, frequent feedback, and working with people who push you to be your best. We're evolving quickly as an organization, we work together in person, and the pace of progress isn't for everyone. That's why we're looking for change-makers who love a challenge — who would rather blaze a trail through uncertainty than travel a well-paved road.

Our team members earn meaningful equity in the company through stock options — so Neo's growth benefits everyone who helps make it happen. That also means taking on more responsibility than you may have had at your last job. We don't get hung up on job titles or hierarchy — we're focused on doing what it takes to accomplish our mission.

Check out these videos from our employees to learn more about Working at Neo.

Apply with Us

We believe in equal opportunity, and are committed to creating an inclusive climate where everyone can thrive. Customers trust us with their finances, so successful candidates for this position will be required to undergo a security screening, including a criminal records check and a credit check.","{""role_summary"":""A Senior Security Analyst responsible for implementing security measures, monitoring and responding to security incidents, and assessing threats to safeguard the organization's IT systems and data."",""key_terms"":[{""term"":""Cloud-first security systems"",""explanation"":""Security systems that prioritize cloud-based infrastructure and applications, such as Netskope, Zscaler, and Crowdstrike.""},{""term"":""SIEM"",""explanation"":""Security Information and Event Management system, used to monitor and analyze security-related data from various sources.""},{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection System/Intrusion Prevention System, used to detect and prevent potential security threats.""},{""term"":""NIST"",""explanation"":""National Institute of Standards and Technology, a framework for security best practices and standards.""},{""term"":""SOC2"",""explanation"":""Service Organization Control 2, a compliance standard for service organizations, focusing on security, availability, and confidentiality.""}],""skill_priorities"":{""must_have"":[""5+ years of experience as a Security Analyst or in a similar role"",""Proven experience in IT security, incident response, or a related field"",""Familiarity with security tools and technologies"",""Knowledge of security frameworks and best practices""],""nice_to_have"":[""Bachelor's degree in Computer Science, Information Security, or related field""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of implementing security controls and policies in a cloud-first environment?"",""example_answer"":""In a cloud-first environment, implementing security controls and policies is crucial to protect against cyber threats. This includes configuring security systems, such as Netskope and Zscaler, to monitor and respond to security incidents. It's essential to have a robust security framework in place to ensure the confidentiality, integrity, and availability of data.""},{""question"":""How would you approach conducting a security assessment and risk analysis for a new application?"",""example_answer"":""I would start by identifying the application's assets and data flows, then assess the potential threats and vulnerabilities. Next, I would evaluate the existing security controls and identify gaps. Finally, I would recommend remediation measures and prioritize them based on risk severity and business impact.""}],""red_flags"":[""Lack of experience in IT security, incident response, or a related field"",""Inability to communicate technical security concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Cybersecurity expert,"ALTER SOLUTIONS is a consulting and technology expertise company founded in 2006. Our mission is to support our clients with their technical and organizational cybersecurity challenges. Our services are structured around the following areas of expertise:
Security Management
Architecture and Integration
Audit and Penetration Testing
Cyber Defense
We are an international group established in over ten countries, with a team of 750 employees.
Our success is driven by the development and fulfillment of each team member, and we place great importance on providing the best possible working conditions:
Remote work available for a majority of our projects
A Flex Office work environment available to everyone at all times to promote communication and collaboration
Expert communities to share and disseminate skills within the group
Close project management and HR support
Annual training and certification opportunities
Recognition of our consultants' expertise development
Strong openness to short-term or long-term international mobility

Job Description

We are looking for a cybersecurity expert for one of our client, a french multinational.
The group is established in 38 countries and operates 90 industrial sites.
The security of information systems has become a top priority for our client in recent years, especially to adapt to new challenges around cloud and cybersecurity. To continue its security plan, our client is seeking a Cybersecurity Expert. Reporting to the Group Information Systems Security Manager, the position has an international context. You will work as the technical Security reference for the entire Group.
Key Responsibilities:
Leverage your advanced technical expertise to contribute to the selection and implementation of appropriate security solutions.
Participate in the development and updating of security policies and ensure their dissemination and explanation to entities (international context).
Provide technical support on cybersecurity tools provided to all Group Information Security Managers.
Participate in technical analysis and lead the resolution of security incidents in connection with impacted entities and external stakeholders (CSIRT, ANSSI, etc.).
Optimize and automate security controls.
Conduct technical monitoring related to market security solutions and current affairs.
Implement and animate the cybersecurity community, bringing together cybersecurity experts from the client’s global locations.
Identify, communicate, and present risks, and provide associated solutions to the cybersecurity community.
Lead and provide technical support during vulnerability and intrusion audits on services used by the Group or specific entities. Ensure the dissemination of results and the definition and follow-up of remediation actions.
Document existing initiatives and best practices.
Participate in the development of regular user and IT security awareness campaigns.
Investigate resources exposed on the Internet without following validation processes.
Optional: Knowledge of security issues in industrial environments. Ability to assist requesting entities in implementing security policies in industrial environments (existing installations or projects).
Technical environment:
Windows 10/2016 ou +
Azure/Office 365
Varonis
Qualys
SentinelOne
ElasticSearch/QRadar

Qualifications

A technical background with at least 5 years of experience in cybersecurity.
Rigorous and autonomous.
Desired skills :
Expertise in choosing and implementing security solutions.
Experience in developing and updating security policies and ensuring their dissemination.
Ability to provide technical support on cybersecurity tools.
Proficiency in technical analysis and incident resolution.
Skill in optimizing and automating security controls.
Knowledge of market security solutions and current affairs.
Ability to build and lead a cybersecurity community.
Proficiency in identifying, communicating, and presenting risks.
Experience in leading vulnerability and intrusion audits.
Capability to document initiatives and best practices.
Experience in developing user and IT security awareness campaigns.
Ability to investigate internet-exposed resources.
Optional Skills:
Knowledge of security in industrial environments.
Ability to assist in implementing security policies in industrial environments.","{""role_summary"":""A Cybersecurity Expert responsible for providing technical security expertise to a French multinational company, ensuring the implementation and maintenance of robust security solutions, and leading the cybersecurity community across global locations."",""key_terms"":[{""term"":""CSIRT"",""explanation"":""Computer Security Incident Response Team, a team responsible for responding to and managing cybersecurity incidents.""},{""term"":""ANSSI"",""explanation"":""Agence Nationale de la Sécurité des Systèmes d'Information, the French national agency responsible for cybersecurity and information system security.""},{""term"":""Varonis"",""explanation"":""A cybersecurity company providing data security and analytics solutions.""},{""term"":""SentinelOne"",""explanation"":""A cybersecurity company providing endpoint security and threat detection solutions.""},{""term"":""ElasticSearch/QRadar"",""explanation"":""ElasticSearch is a search and analytics engine, and QRadar is a security information and event management (SIEM) system, used for monitoring and analyzing security-related data.""}],""skill_priorities"":{""must_have"":[""Technical background with at least 5 years of experience in cybersecurity"",""Expertise in choosing and implementing security solutions"",""Experience in developing and updating security policies"",""Ability to provide technical support on cybersecurity tools"",""Proficiency in technical analysis and incident resolution"",""Skill in optimizing and automating security controls"",""Knowledge of market security solutions and current affairs"",""Ability to build and lead a cybersecurity community"",""Proficiency in identifying, communicating, and presenting risks"",""Experience in leading vulnerability and intrusion audits"",""Capability to document initiatives and best practices"",""Experience in developing user and IT security awareness campaigns""],""nice_to_have"":[""Knowledge of security issues in industrial environments"",""Ability to assist requesting entities in implementing security policies in industrial environments""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with implementing and maintaining security solutions in a multinational organization?"",""example_answer"":""In my previous role, I was responsible for implementing a security information and event management (SIEM) system across multiple locations. I worked closely with the IT team to ensure seamless integration and provided training to end-users on the system's functionality.""},{""question"":""How do you stay current with market security solutions and current affairs?"",""example_answer"":""I regularly attend industry conferences and webinars, participate in online forums and discussion groups, and follow reputable sources on social media to stay informed about the latest security trends and threats.""}],""red_flags"":[""Lack of experience in leading a cybersecurity community"",""Inability to communicate technical risks to non-technical stakeholders"",""Limited knowledge of industrial security environments""],""confidence_score"":85.0}"
Cyber Security Admin,"Description

Role: Cybersecurity

Location: Montreal, QC

Bilingual: French and English

Duration; 12 Months (Contract)

Hybrid Role

We want a French-speaking candidate

You are recognized for your ability to integrate and evolve systems, you are excited about the idea of working on Cybersecurity solutions? Relevant to IT Cybersecurity delivery for the business line responsible for cybersecurity, it is at the heart of our reflections on ways of doing things and creating value for the business lines and the Bank. You will have the opportunity to represent the Bank's values and use your power to act to participate in the creation of innovative solutions by responding to real business problems, putting the use of IT resources into perspective form the bank. Your knowledge of the technologies and platforms supporting identity and access management functions will allow you to develop them.

We will count on you to implement actions to achieve our vision. To support our development, we are currently looking for a person who will be able to act as an integrator for GIA services in the Entra ID (Azure AD) environment.

Responsibilities:

Act as an expert with internal customers by supporting them in their consumption of GIA services and identity directories: Entra ID (Azure AD), LDAP, Active Directory
Ensure compliance with existing processes by completing all analyzes leading to the effective integration of the Bank's applications into GIA solutions;
Contribute to the development of tools facilitating the collection of information or the optimization of existing processes;
Participate in the company's documentation effort (training support, Wiki) and produce the reports/procedures necessary for the quality of deliverables for our clients;


Actor in sharing knowledge and transferring knowledge to other advisors; Skills sought:

Have good communication and collaboration skills;
Be naturally “customer” oriented;
Be able to adapt quickly and evolve in your working methods;
Know how to manage unforeseen events that may arise throughout projects;
Be aware of identity management and Cybersecurity challenges;


Know how to anticipate issues in order to avoid them to facilitate the team's work; Technically and conceptually master the following aspects:

Master Entra ID (Azure AD), Active Directory Services, Enterprise Apps, Certificates,
Knowledge of SAML, OIDC, LDAP, Graph API protocols;
Familiar with SSO application integrations with Entra ID (Azure AD);
AWS knowledge is a plus;
Advanced knowledge of complex and extensive business networks in a multi-cloud and hybrid context;


Good understanding of networks and firewalls;



Hold a college diploma with a specialization in computer science or a certificate of relevant studies;



Have a minimum of 6 years of experience in a similar position;



Holding relevant Microsoft Azure or AWS certifications is a plus

:","{""role_summary"":""This Cybersecurity role involves integrating and evolving systems, supporting internal customers, and ensuring compliance with existing processes to achieve the Bank's vision."",""key_terms"":[{""term"":""GIA services"",""explanation"":""GIA services refer to the Bank's cybersecurity solutions, specifically identity and access management functions.""},{""term"":""Entra ID (Azure AD)"",""explanation"":""Entra ID is a cloud-based identity and access management solution, also known as Azure Active Directory (Azure AD).""},{""term"":""LDAP"",""explanation"":""LDAP (Lightweight Directory Access Protocol) is a protocol used for directory services and identity management.""},{""term"":""SAML"",""explanation"":""SAML (Security Assertion Markup Language) is a protocol used for exchanging authentication and authorization data between systems.""},{""term"":""OIDC"",""explanation"":""OIDC (OpenID Connect) is an authentication protocol used for verifying identities and obtaining basic profile information.""},{""term"":""Graph API"",""explanation"":""Graph API is a RESTful API used for accessing and manipulating data in Microsoft Azure Active Directory.""},{""term"":""SSO"",""explanation"":""SSO (Single Sign-On) is a feature that allows users to access multiple applications with a single set of login credentials.""}],""skill_priorities"":{""must_have"":[""Entra ID (Azure AD)"",""Active Directory Services"",""Enterprise Apps"",""Certificates"",""SAML"",""OIDC"",""LDAP"",""Graph API"",""Networks and firewalls"",""College diploma in computer science or relevant studies"",""Minimum 6 years of experience in a similar position""],""nice_to_have"":[""AWS knowledge"",""Microsoft Azure or AWS certifications""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would integrate a new application into Entra ID (Azure AD)?"",""example_answer"":""I would start by assessing the application's requirements and configuring the necessary settings in Entra ID. Then, I would test the integration to ensure seamless authentication and authorization.""},{""question"":""How do you stay up-to-date with the latest developments in identity management and Cybersecurity?"",""example_answer"":""I regularly follow industry blogs and attend webinars to stay informed about the latest trends and best practices in identity management and Cybersecurity.""}],""red_flags"":[""Lack of experience with Entra ID (Azure AD) or similar identity management solutions"",""Inability to adapt quickly to changing project requirements""],""confidence_score"":90.0}"
Security Architect,"designing, implementing, optimizing, and supporting IT infrastructure across on-premises and Azure Cloud environments, encompassing virtualization and cybersecurity
Proficient in configuring and migrating from legacy third-party Mobile Device Management (MDM) solutions to Microsoft Intune
Deep understanding of design and configuration for MDM, for a replacement for Blackberry UEM
Expertise in security policies tailored to support the M365 security posture, responsible for defining and configuring security policies such as Conditional Access policies and DLP policies
Key responsibility includes support configuring and refining existing security policies and MDM policies to facilitate migrations to M365


Requirements

Outstanding knowledge of change management principles and performance evaluation processes
Exceptional technical knowledge
Effective written and oral communication skills
7+ years of relevant work experience


Benefits

Type of job: Temporary Contractor - 1 year
Date candidate required: Immediate
Location: Toronto
Work hours are Monday - Friday, normal 37.5 hour week","{""role_summary"":""Design, implement, optimize, and support IT infrastructure across on-premises and Azure Cloud environments, focusing on virtualization, cybersecurity, and mobile device management."",""key_terms"":[{""term"":""Azure Cloud"",""explanation"":""A cloud computing platform and set of services offered by Microsoft.""},{""term"":""Virtualization"",""explanation"":""A technology that allows multiple virtual machines to run on a single physical machine.""},{""term"":""Microsoft Intune"",""explanation"":""A cloud-based endpoint management solution that helps manage and secure devices.""},{""term"":""Mobile Device Management (MDM)"",""explanation"":""A set of policies, procedures, and technologies used to manage and secure mobile devices.""},{""term"":""Conditional Access policies"",""explanation"":""Policies that define the circumstances under which a user can access a resource.""},{""term"":""DLP policies"",""explanation"":""Data Loss Prevention policies that help detect and prevent unauthorized data exfiltration.""}],""skill_priorities"":{""must_have"":[""Azure Cloud"",""Microsoft Intune"",""Mobile Device Management (MDM)"",""Virtualization"",""Cybersecurity"",""Change management principles"",""Performance evaluation processes""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach migrating from a legacy MDM solution to Microsoft Intune?"",""example_answer"":""I would first assess the current MDM infrastructure, identify the devices and applications that need to be migrated, and then develop a phased migration plan to minimize disruption. I would also ensure that the new Intune environment is properly configured and secured.""},{""question"":""Can you explain how you would design and implement Conditional Access policies to support an organization's security posture?"",""example_answer"":""I would start by assessing the organization's security requirements and identifying the resources that need to be protected. Then, I would design and implement Conditional Access policies that take into account factors such as user location, device type, and authentication level.""}],""red_flags"":[""Lack of experience with Microsoft Intune or Azure Cloud"",""Inability to explain change management principles or performance evaluation processes""],""confidence_score"":90.0}"
Cybersecurity Lead,"About Us

Pathway Communications is a leading Canadian Managed IT and Cybersecurity Services Provider with a rich history of success since 1995. Our team of over 150 technical staff, which works out of four offices, delivers cutting-edge IT management and cybersecurity services to businesses across Canada and the USA. Our services include IT infrastructure and application management, 24/7 cybersecurity and SOC, data centre services, private and public cloud solutions, secure connectivity, telephony and expert consulting. Our commitment to excellence is reinforced by the critical certifications we have. These include, amongst others, SOC, ISO 27000, PCI DSS and Uptime Institute Tier III Certifications for our data centre.

The position

We are seeking an experienced Cybersecurity Lead/Manager to lead cybersecurity service delivery and ensure that our clients receive the highest standards of safety and protection. This pivotal role includes management of our 24/7 Security Operations Centre (SOC), strategic customer liaison and engagement, sales engineering, contributions to pricing and new service development.

Key responsibilities

Leadership of the SOC: Direct and manage the 24/7 SOC and its team of skilled technical staff. Oversee security operations including continuous security monitoring, incident response and remediation and the use of threat intelligence to ensure timely detection and mitigation of cyber threats, risks and vulnerabilities
Security architecture: Oversee the design and implementation of secure client IT architecture and systems. Develop, implement, and refine proactive security tactics and methods to counter emerging threats
Risk management: Develop and maintain a comprehensive cyber risk management framework that aligns with industry standards (e.g., NIST, ISO 27001) and incorporates the unique requirements of clients. Continuously identify, assess, and mitigate client cyber risk exposure; implement and maintain robust risk management practices
Customer engagement: Serve as the primary cybersecurity contact with clients. Provide expert advice and support to clients on cybersecurity matters and ensure a high level of customer satisfaction with company cybersecurity solutions. Build and maintain strong client relationships.
Technical sales engineering support. Collaborate with the sales team to provide cybersecurity expertise during the sales process. Assist in developing proposals, pricing strategies, and client presentations. Play a pivotal role in the technical evaluation and design stage of the sales process, acting as a consultant to both clients and the sales team
Cybersecurity strategy: Contribute to strategic planning and development of the company’s cybersecurity services. Stay abreast of the regulatory environment and emerging cybersecurity trends, threats and technologies to ensure that our services remain at the forefront of the industry
Compliance and governance: Ensure compliance with relevant cyber security regulations and standards (e.g., GDPR, PIPEDA, MFIPPA, PCI-DSS). Conduct regular vulnerability assessments, penetration tests, and compliance audits for clients. Develop and enforce policies and procedures related to information security and privacy
Vendor management: Manage relationships with cybersecurity vendors and service providers. Ensure the quality and effectiveness of vendor products and services
Continuous improvement: Promote a culture of innovation; identify and implement state-of-the-art security tools and techniques which will adapt to changes in the cyber threat landscape and technological advancements; provide continuous staff training and skill improvement

Required Qualifications And Skills.

Experience: 12 to 15 years in Information Technology management out of which 7 years should consist of hands-on experience in cybersecurity, in a leadership role, preferably managing a SOC
Education: Bachelor's degree in Computer Science, Information Technology, Cybersecurity, or related field. Master’s degree preferred
Certifications: CISSP, CISM, CEH, or equivalent; relevant vendor certifications
Technical expertise: Strong knowledge of operating systems, networks, virtualised server environments and storage. Proficiency in the hands-on use of cybersecurity tools and technologies, including but not limited to SIEMs, SOARs, firewalls, IDS &IPS, EDR, cloud and mobile security, vulnerability and penetration testing, zero trust systems, threat intelligence platforms and desktop exercises. Experience with forensics tools desirable
Communication skills: Interpersonal, communication and presentation skills to effectively engage and build trust with clients and team members
Employee management: Leadership, management and mentorship of technical staff

Join us

At Pathway Communications, you’ll have the opportunity to work and expand your career and skills as part of the leadership team in a dynamic, innovative environment where your contributions are valued. If you’re passionate about cybersecurity and looking for a challenging, yet rewarding role we’d love to hear from you.

Others

Candidates must be willing to undergo a technical exam.
All applications must be submitted through this job posting. For any concerns or queries, kindly email recruitment@pathcom.com

Disclaimer: Please note that this document is intended to provide an overview of job accountabilities and does not necessarily list all tasks related to the job. Pathway Group of Companies is an equal opportunity employer and is committed to providing equal treatment with respect to employment without discrimination because of race, ancestry, place of origin, citizenship, creed, sex, sexual orientation, age, marital status, family status, disability, color, or ethnic origin as required by the Ontario Human Rights Code.

Powered by JazzHR

tX3a5RvYWn","{""role_summary"":""Lead cybersecurity service delivery, manage the 24/7 Security Operations Centre (SOC), and ensure clients receive the highest standards of safety and protection."",""key_terms"":[{""term"":""SOC"",""explanation"":""Security Operations Centre, a team that monitors and responds to cybersecurity threats.""},{""term"":""NIST"",""explanation"":""National Institute of Standards and Technology, a framework for managing cybersecurity risks.""},{""term"":""ISO 27001"",""explanation"":""International Organization for Standardization's standard for information security management.""},{""term"":""PCI DSS"",""explanation"":""Payment Card Industry Data Security Standard, a set of security standards for organizations that handle credit card information.""},{""term"":""SIEMs"",""explanation"":""Security Information and Event Management systems, software that monitors and analyzes security-related data.""},{""term"":""SOARs"",""explanation"":""Security Orchestration, Automation, and Response systems, software that automates and streamlines security incident response.""},{""term"":""EDR"",""explanation"":""Endpoint Detection and Response, a solution that monitors endpoint devices for signs of malicious activity.""},{""term"":""Zero trust systems"",""explanation"":""A security approach that assumes no user or device is trusted by default, and verifies the identity and permissions of all users and devices.""}],""skill_priorities"":{""must_have"":[""12-15 years of IT management experience"",""7 years of hands-on experience in cybersecurity"",""Leadership experience in managing a SOC"",""CISSP, CISM, CEH, or equivalent certifications"",""Strong knowledge of operating systems, networks, virtualized server environments, and storage"",""Proficiency in cybersecurity tools and technologies""],""nice_to_have"":[""Master's degree in Computer Science, Information Technology, Cybersecurity, or related field"",""Experience with forensics tools""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with managing a Security Operations Centre (SOC), and how have you ensured timely detection and mitigation of cyber threats?"",""example_answer"":""I have managed a SOC for 5 years, and I ensure timely detection and mitigation of cyber threats by implementing a robust incident response plan, conducting regular vulnerability assessments, and staying up-to-date with emerging threats and technologies.""},{""question"":""How do you stay current with emerging cybersecurity trends, threats, and technologies?"",""example_answer"":""I regularly attend industry conferences, participate in online forums and discussions, and read relevant publications to stay current with emerging cybersecurity trends, threats, and technologies.""}],""red_flags"":[""Lack of experience in managing a SOC"",""Insufficient knowledge of cybersecurity tools and technologies"",""No relevant certifications""],""confidence_score"":90.0}"
Senior IT Security Analyst,"Company Description

At Sleep Country Canada/Dormez-vous? (SCC/DV), we are inspired every day through our purpose to transform lives by awakening Canadians to the power of sleep and our vision to champion sleep as the key to healthier and happier lives, helping everyone achieve better tomorrows through better tonight’s.

Guided by our values – We CARE About People; We WIN Together; We DREAM Big and We DELIVER with Excellence – we are building on our 30-year foundation of taking care of each other and our customers’ sleep needs, with passion and commitment to be the best that we can be. We invest in our sleep ecosystem, innovative products, world-class customer experience, our communities and diverse best-in-class team to be Canada’s leading sleep partner.

Job Description

The Senior IT Security Analyst ensures that all in-scope day to day, and project activities are properly defined; effectively managed; deliver the expected results; and meet SCC standards and policies, and that documentation, deployment, and testing is performed according to professional industry standards.

Reporting to the Manager, Information Security, responsibilities include but are not limited to;

Conduct studies that evaluate, recommend, and implement security solutions to enhance core security capabilities in the areas of security infrastructure, access management, identity management, networking, databases, servers.
Perform the deployment, integration, and initial configuration of all new security solutions and enhancements to existing security solutions in accordance with standards and best practices.
Research and provide gap analysis of the current processes leading to the completion of documenting current processes and identifying opportunities for process improvements.
Evaluate internal and external environment for threats, changes, related to Information Security and perform the role as Information Security subject matter expert to ensure these are properly addressed and controlled.
Work with cross-functional teams to develop and implement incident response plans, including documenting procedures and conducting training exercises.
Manage and maintain security technologies such as firewalls, intrusion detection and prevention systems, and security information and event management (SIEM) tools.
Assess information risk and facilitate remediation of identified vulnerabilities for IT security across the enterprise;
Resolve security incidents in a timely and effective manner, ensuring minimal impact to the organization and learning from incidents to prevent future occurrences.
Lead and participate in the design and execution of vulnerability assessments, penetration tests and security audits.
Ongoing management of the organization’s security awareness program; ensure that organizational processes adhere to regulatory compliance requirements.
Conduct research on emerging security threats and trends, and develop strategies to mitigate risks
Provide reporting and data-driven insights on the organization’s security posture, including vulnerabilities, incidents, and remediation efforts to senior management.

Qualifications

8+ years of work experience in IT Security or equivalent combination of transferrable experience and education through university or college degree in an IT related field.
Proven leadership abilities including effective knowledge sharing, conflict resolution, facilitation of open discussions, fairness and displaying appropriate levels of assertiveness.
Proven ability to work under stress in emergencies with flexibility to handle multiple high-pressure situations simultaneously.
Thorough knowledge of Information security principles and framework (ISO 27001, NIST, ZTNA, etc..).
Thorough knowledge and experience on securing on-perm infrastructure, Google Cloud and Azure.
Thorough knowledge and experience on Microsoft security tools and processes.
Thorough knowledge on firewalls (Palo Alto), DNS, Cloudflare, Switches, Citrix, etc.
Ability to secure online and on-premise infrastructures, filter out suspicious activity, and find and mitigate security risks before any breaches can occur.
Hands-on experience in security incident investigation and resolution.
Cyber and Technical Threat Analyses
Ability to communicate highly complex technical information clearly and articulately for all levels and audiences.
Ability to manage tasks independently and take ownership of responsibilities
Strong customer focus with ability to manage customer expectations and experience and build long-term relationships.
Strong team-oriented interpersonal skills with the ability to interface with a broad range of people and roles including vendors and IT-business personnel.
Ability to adapt to a rapidly changing environment
High critical thinking skills to evaluate alternatives and present solutions that are consistent with business objectives and strategy.
Thorough knowledge of patching and deployment technologies for windows platforms
Strong technical knowledge of current systems, software, protocols and standards. Including TCP/IP and network administration/protocols
Experience developing, documenting and maintaining procedures.
Ability to learn from mistakes and apply constructive feedback to improve performance.
Any one or more security certifications (CISSP, CISA, CEH, GIAC, SANS).

Additional Information

Why members of our Corporate team love working at Sleep Country Canada/Dormez-vous?:

This is not a job but a CAREER with opportunities for growth and advancement
Diverse and inclusive work environment
We will invest in you and provide extensive training, mentoring and continuous development
Access to training and development platforms
Full medical, dental benefits and a Deferred Profit Sharing Program
Annual Wellness Credit of up to $250.00 for any products/services that improve your health and well-being, i.e., health assessments, nutrition counselling, hiking shoes, a yoga outfit or fitness equipment!
Associate Discount Program where you will be able to enjoy some of the world’s best sleep products
Maternity/Parental leave top up benefits
Tuition Reimbursement Program that covers professional AND personal development
Long service awards, celebrations and other social events
Associate Referral Program
Paid day off to volunteer at your local charity of choice
Recognized as one of Canada’s Most Admired Corporate Cultures in 2023 by Waterstone Human Capital

Commitment to Equity, Diversity, Inclusion & Belonging (EDI&B)

At SCC/DV, we are committed to building a company culture of inclusion and diversity where differences are embraced and valued, this allows us to better understand and meet the needs of our customers and the communities we serve. We want to ensure every job applicant is treated fairly and with respect regarding race, national or ethnic origin, religion, age, gender, sexual orientation, or disability.

About Sleep Country Canada/Dormez-vous?

Sleep Country is Canada’s leading specialty sleep retailer with a purpose to transform lives by awakening Canadians to the power of sleep. Sleep Country Canada operates under the retailer banners; Sleep Country, Dormez-vous, the rest, Endy, Hush, Silk & Snow and most recently acquired, Casper Canada. The Company has omnichannel and ecommerce operations including over 300 corporate-owned stores and 18 distribution centers warehouses across Canada. Recognized as one of Canada’s Most Admired Corporate Cultures in 2023 by Waterstone Human Capital, Sleep Country is committed to building a company culture of inclusion and diversity where differences are embraced and valued. The Company actively invests in its sleep ecosystem, innovative products, world-class customer experience, communities and its people. For more information about Sleep Country, please visit www.sleepcountry.ca.","{""role_summary"":""The Senior IT Security Analyst is responsible for ensuring the security and integrity of the organization's IT systems and infrastructure, by evaluating, recommending, and implementing security solutions, managing security technologies, and providing expertise on information security."",""key_terms"":[{""term"":""ISO 27001"",""explanation"":""An international standard for information security management systems that provides guidelines for implementing and maintaining a secure information security management system.""},{""term"":""NIST"",""explanation"":""The National Institute of Standards and Technology, a non-regulatory agency of the United States Department of Commerce that provides guidelines and standards for information security.""},{""term"":""ZTNA"",""explanation"":""Zero Trust Network Architecture, a security approach that assumes no user or device, whether inside or outside an organization's network, is trusted, and verifies the identity and permissions of all users and devices before granting access to resources.""},{""term"":""Palo Alto"",""explanation"":""A type of firewall that provides network security and threat prevention capabilities.""},{""term"":""DNS"",""explanation"":""Domain Name System, a system that translates human-readable domain names into IP addresses that computers can understand.""},{""term"":""Cloudflare"",""explanation"":""A content delivery network and security company that provides services to protect and accelerate websites and applications.""},{""term"":""CISSP"",""explanation"":""Certified Information Systems Security Professional, a certification for information security professionals that demonstrates expertise in designing, implementing, and managing a secure information security program.""}],""skill_priorities"":{""must_have"":[""8+ years of work experience in IT Security or equivalent combination of transferrable experience and education"",""Proven leadership abilities"",""Thorough knowledge of Information security principles and framework"",""Thorough knowledge and experience on securing on-perm infrastructure, Google Cloud and Azure"",""Thorough knowledge and experience on Microsoft security tools and processes"",""Ability to secure online and on-premise infrastructures, filter out suspicious activity, and find and mitigate security risks""],""nice_to_have"":[""Security certifications (CISSP, CISA, CEH, GIAC, SANS)"",""Experience developing, documenting and maintaining procedures"",""Knowledge of patching and deployment technologies for windows platforms"",""Strong technical knowledge of current systems, software, protocols and standards""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with implementing security solutions in a cloud-based environment?"",""example_answer"":""I have implemented security solutions in both Google Cloud and Azure environments, and have experience with securing on-premise infrastructure. I have also worked with Microsoft security tools and processes to ensure the security of our systems.""},{""question"":""How do you stay current with emerging security threats and trends?"",""example_answer"":""I regularly research and read industry publications to stay current with emerging security threats and trends. I also participate in online forums and attend conferences to stay up-to-date with the latest developments in the field.""}],""red_flags"":[""Lack of experience with cloud-based security solutions"",""Inability to communicate complex technical information clearly and articulately""],""confidence_score"":90.0}"
Infotek Consulting Services Inc.,"Infotek Consulting is searching for a seasoned Information Security Analyst to work on a hybrid contract assignment based in Toronto.

Project: Mitigate the next generation of cross-pillar security challenges and financial crimes through the establishment of a Fusion capability. Fusion takes a collaborative, integrated, cross-pillar approach to prevent, detect, investigate, and respond to threats and risks. B

How you’ll succeed
• Consulting - Review and interpret requirements documentation, architecture diagrams and solution designs to help determine the feasibility of a project and its security risk. Assess business needs against potential risks and provide your recommendations to enhance our information security landscape.
• Delivery and Execution - You will help us execute detailed threat risk and information security assessments, deviations, coordination of penetration testing and reporting. Help us complete requests from external partners (corporate and institutional clients) and recommend new controls to reduce risks.
• Communication - Build and present documentation to executive management aimed at communicating potential risks and providing recommendations. Provide feedback to and participate in the design and implementation of security assessment processes across the organization. Research, design, and implement security monitoring practices and operationalize these processes across the group.

Must Haves:
1. Information security analyst – 10+ years
2. Experience in Risk advisory – 5+ years
3. Experience with Archer – 2 years
4. Relationship management experience
5. Cloud Azure experience – 2 years

Nice to have:
1. Experience with financial crime
2. banking/financial industry experience","{""role_summary"":""An Information Security Analyst will work on a hybrid contract assignment to mitigate security challenges and financial crimes by establishing a Fusion capability, which involves reviewing requirements, assessing risks, and providing recommendations to enhance information security."",""key_terms"":[{""term"":""Fusion capability"",""explanation"":""A collaborative, integrated approach to prevent, detect, investigate, and respond to threats and risks.""},{""term"":""Archer"",""explanation"":""A software platform used for risk management and compliance.""},{""term"":""Cloud Azure"",""explanation"":""A cloud computing platform and set of services offered by Microsoft.""}],""skill_priorities"":{""must_have"":[""Information security analysis"",""Risk advisory experience"",""Archer experience"",""Relationship management experience"",""Cloud Azure experience""],""nice_to_have"":[""Financial crime experience"",""Banking/financial industry experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to assess the feasibility of a project and its security risk?"",""example_answer"":""In my previous role, I reviewed requirements documentation and architecture diagrams to identify potential security risks and provided recommendations to enhance our information security landscape.""},{""question"":""How do you stay current with emerging threats and risks in the financial industry?"",""example_answer"":""I regularly research and participate in industry forums to stay informed about emerging threats and risks, and I use this knowledge to inform my recommendations for enhancing information security.""}],""red_flags"":[""Lack of experience with Archer or Cloud Azure"",""Inability to communicate technical information to executive management""],""confidence_score"":90.0}"
"Cybersecurity Analyst, Application Solutions","Company Description

American Iron & Metal (AIM) is a family-owned company and recognized global leader in the metal recycling industry with more than 125 sites and 4000 employees worldwide. We have continued to prosper for the last eight decades thanks to the dedication of our employees and the ongoing trust and support of our customers.

Become part of team AIM, a growing team with an entrepreneurial spirit who has over the years evolved into a successful and multifaceted company with business divisions that include metal recycling, decommissioning and demolition, auto-parts sales and recycling, manufacturing of solder assemblies, construction waste recycling, and production of customized industrial and mining products.

We take pride in doing good things for the environment to help create a greener, more sustainable future for all.

It’s simple; we do it right. We AIM for excellence.

What we offer!

Competitive salary + other perks
Group insurance & RRSP program
Company-wide events throughout the year (BBQ, Holiday party etc.)
Free gym on site
Two cafeterias on site (subsidized meal program available)
Dynamic & rewarding work environment- work on high-impact, meaningful projects while also having fun!

Job Description

We are looking for an innovative and skilled Cybersecurity Analyst to join our security team. The successful candidate will be responsible for managing application vulnerabilities and supporting the software development lifecycle (SDLC) to integrate security practices by design and actively participate in SecOps activities. This person will play a crucial role in protecting the business from threats to our applications.

Cybersecurity Solution Design and Implementation: Develop and deploy strategies and tools to secure the company's IT assets.
Application vulnerability analysis and management: Identify, analyze and manage vulnerabilities in the company's software applications using specialized tools (SonarQube, Invicti, Qualys, etc.), perform regular scans and take corrective actions by collaborating with the development teams to support the resolution.
SDLC Support: Collaborate closely with development teams to integrate security measures (DevSecOps) from the earliest phases of software development (Security by design), ensuring that security is a priority at every stage of the cycle.
Application Security Policy Definition: Establish and maintain security procedures for application development, including codification of secure coding best practices.
Participate in SecOps activities: Improve security posture through continuous monitoring, incident management, and rapid response.
Technology Watch: Stay informed of the latest trends and technologies in cybersecurity to anticipate and defend against new threats.
Reporting and documentation: Write detailed reports on application vulnerabilities, security audits, and corrective actions taken.
Training and mentoring: Provide training and guidance to developers on application security best practices and the importance of security in the development lifecycle.
Cross-departmental collaboration: Work closely with the entire IT team and partners, specifically the development team, to integrate security practices into all aspects of application development.

Qualifications

Degree in computer science, information security, or related field.
Minimum 5 years of experience in a similar position
Mastery of application vulnerability management tools, Cloud development and in-depth understanding of software development processes including the DevSecOps approach.
Technical knowledge: Azure, AzureDevOps, AzurePipeline, Apps Security (dotnet prefered), OWASP, Qualys, SonarQube, SAST, and DAST tool.
Certifications like CISSP, CEH, or CompTIA Security+ are preferred, with a particular focus on those focused on application security, such as GWAPT or CSSLP.
Ability to analyze complex data and make recommendations based on analytics.
Excellent communication skills and ability to collaborate effectively with development and security teams.

Additional Information

American Iron & Metal and its subsidiaries is an equal opportunity employer. All qualified applicants are given consideration regardless of race, religion, colour, gender, sex, age, sexual orientation, gender identity, national origin, marital status, citizenship status, disability, veteran status, or any other protected class as provided in applicable employment laws.

Although we’d love to be able to speak with everyone that applies, due to the volume of applicants we receive and time constraints, only those selected to move forward will be contacted.","{""role_summary"":""The Cybersecurity Analyst is responsible for managing application vulnerabilities, supporting the software development lifecycle, and integrating security practices to protect the business from threats."",""key_terms"":[{""term"":""DevSecOps"",""explanation"":""A practice that integrates security measures into every stage of the software development lifecycle.""},{""term"":""SDLC"",""explanation"":""Software Development Life Cycle, the process of designing, developing, testing, and delivering software.""},{""term"":""SecOps"",""explanation"":""Security Operations, a set of practices that integrate security into IT operations.""},{""term"":""SonarQube"",""explanation"":""A tool used for application vulnerability analysis and management.""},{""term"":""Qualys"",""explanation"":""A tool used for application vulnerability analysis and management.""},{""term"":""AzureDevOps"",""explanation"":""A set of services for collaborative software development, delivery, and collaboration.""},{""term"":""OWASP"",""explanation"":""Open Web Application Security Project, a non-profit organization that provides resources for web application security.""},{""term"":""SAST"",""explanation"":""Static Application Security Testing, a type of security testing that analyzes code for vulnerabilities.""},{""term"":""DAST"",""explanation"":""Dynamic Application Security Testing, a type of security testing that analyzes running applications for vulnerabilities.""}],""skill_priorities"":{""must_have"":[""Application vulnerability management"",""Cloud development"",""DevSecOps"",""Azure"",""AzureDevOps"",""AzurePipeline"",""Apps Security"",""OWASP"",""Qualys"",""SonarQube"",""SAST"",""DAST""],""nice_to_have"":[""CISSP"",""CEH"",""CompTIA Security+"",""GWAPT"",""CSSLP""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you stay informed of the latest trends and technologies in cybersecurity?"",""example_answer"":""I regularly follow industry blogs and attend webinars to stay up-to-date on the latest cybersecurity trends and technologies.""},{""question"":""Can you explain the importance of integrating security practices into the software development lifecycle?"",""example_answer"":""Integrating security practices into the SDLC ensures that security is a priority at every stage of development, reducing the risk of vulnerabilities and improving overall application security.""}],""red_flags"":[""Lack of experience with application vulnerability management tools"",""Inability to analyze complex data and make recommendations based on analytics""],""confidence_score"":90.0}"
"Security Analyst, Governance, Risk & Compliance (GRC)","We’re looking for a Security Analyst- GRC to be part of our Security department at Jobber.

This role is ideal for intermediate level candidates in the security, governance, risk and compliance space. This opportunity fits those earlier in their security career or those looking to pivot into cybersecurity who bring transferrable SaaS skillsets including strong collaboration and communication skills. Our Security Analyst, GRC, focuses on the governance side of security and is not a technical security operations position requiring specific technical certifications or experience. Our ideal candidate is strong with data and possesses analytical skills.

Jobber exists to help people in small businesses be successful. We work with small home service businesses, like your local plumbers, painters, and landscapers, to transform the way service is delivered through technology. With Jobber they can quote, schedule, invoice, and collect payments from their customers, while providing an easy and professional customer experience. Running a small business today isn’t like it used to be—the way we consume and deliver service is changing rapidly, technology is evolving, and customers expect more. That’s why we put the power and flexibility in their hands to run their businesses how, where, and when they want!

Our culture of transparency, inclusivity, collaboration, and innovation has been recognized by Great Place to Work, Canada’s Most Admired Corporate Cultures, and more. Jobber has also been named on the Globe and Mail’s Canada’s Top Growing Companies list, and Deloitte Canada’s Technology Fast 50™, Enterprise Fast 15, and Technology Fast 500™ lists. With an Executive team that has over thirty years of industry experience of leading the way, we’ve come a long way from our first customer in 2011—but we’ve just scratched the surface of what we want to accomplish for our customers.

The team:

Jobber has a Security team led by our Sr. Director, Security. We have a split focus between governance and operations. All team members are specialized generalists (a primary focus but do a bit of everything). As our team develops and grows you will be collaborating with each member while we work towards making Jobber as secure as possible. We’ll also drive toward team member specialization as we ramp up on capacity and tooling.

The role:

We are seeking a motivated and detail-oriented individual to join our team as a Security Analyst - GRC. Your primary focus will be on governance and awareness, ensuring that our information systems and processes adhere to industry regulations and Jobber best practices. In this role, you will report directly to the Sr.Director, Security and assist in maintaining and enhancing the security posture of our organization. This is an excellent opportunity to gain hands-on experience in the field of information security while working closely with the Jobber Security team.

You'll support a wide range of security initiatives and in the future will have opportunity to specialize as you grow your career.

The Security Analyst - GRC will:

Aid in the maintenance and application of information security policies, standards, and procedures.
Participate in regular audits and assessments to ensure compliance with regulatory requirements, industry standards, and internal policies.
Collaborate with cross-functional teams to identify vulnerabilities and assess the effectiveness of existing controls.
Contribute to the development and maintenance of security documentation, including risk assessments, control frameworks, and incident response plans.
Work with leaders throughout the organization to assess and document risks and treatment plans.
Stay up-to-date with the latest security trends, vulnerabilities, and compliance requirements, and propose recommendations for improvement.
Distribute risk and governance information through reports and presentations
Assist in supplier risk assessments and ensure their compliance with Jobber’s security requirements.

To be successful, you should have:

Excellent analytical and problem-solving skills, with a keen eye for detail.
Ability to work independently as well as collaboratively in a team environment.
Strong verbal and written communication skills, with the ability to effectively communicate technical concepts to non-technical stakeholders.
High level of integrity and confidentiality when handling sensitive information.
A passion for learning and a drive to stay updated with emerging technologies and security trends.

Nice to have:

Audit, risk management experience
Cloud technology specifically AWS
Startup mindset

All interviews are currently being conducted virtually—via phone or video.

What you can expect from Jobber:

Having been named as a Top 10 Great Place to Work in Canada, we walk the talk. Here are just some of the great things you can expect from us:

A total compensation package that includes an extended health benefits package with fully paid premiums for both body and mind, RRSP matching, and stock options.
A dedicated Coaching and Development function, including Development Coaches, to help build the career you want and hit the goals you set, while ensuring you’re reaching your fullest potential.
Support for all your breaks: from vacation to rest and recharge, your birthday off to celebrate, health days to support your physical and mental health, and parental leave top-ups to support your growing family.
A unique opportunity to build, grow, and leave your impact on a $400-billion industry that has no dominant player...yet.
To work with a group of people who are humble, supportive, and give a sh*t about our customers.

We believe that diverse teams perform better and that fostering an inclusive work environment is a key part of growing a successful team. We welcome people of diverse backgrounds, experiences, and perspectives. We are an equal opportunity employer, and we are committed to working with applicants requesting accommodation at any stage of the hiring process.

A bit more about us:

Job by job, we’re transforming the way service is delivered. Your lawn care provider, home cleaning service, plumber or painter could use Jobber to better connect with their customers, save time in the office, invoice faster, and get paid! We’re bringing tens of thousands of people together with technology to deliver billions of dollars a year in services to happy customers. Jobber exists to help make these small businesses successful, and when they’re successful we all win!","{""role_summary"":""The Security Analyst - GRC is responsible for ensuring Jobber's information systems and processes adhere to industry regulations and best practices, focusing on governance and awareness."",""key_terms"":[{""term"":""GRC"",""explanation"":""Governance, Risk, and Compliance, referring to the management of an organization's overall governance, risk, and compliance activities.""},{""term"":""SaaS"",""explanation"":""Software as a Service, a software delivery model where applications are hosted and managed by a third-party provider.""},{""term"":""AWS"",""explanation"":""Amazon Web Services, a cloud computing platform providing a range of services including computing power, storage, and databases.""}],""skill_priorities"":{""must_have"":[""Analytical and problem-solving skills"",""Strong verbal and written communication skills"",""Ability to work independently and collaboratively"",""High level of integrity and confidentiality""],""nice_to_have"":[""Audit, risk management experience"",""Cloud technology specifically AWS"",""Startup mindset""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with governance, risk, and compliance in a previous role?"",""example_answer"":""In my previous role, I was responsible for maintaining and applying information security policies, standards, and procedures. I worked closely with cross-functional teams to identify vulnerabilities and assess the effectiveness of existing controls.""},{""question"":""How do you stay up-to-date with the latest security trends, vulnerabilities, and compliance requirements?"",""example_answer"":""I regularly read industry publications and attend webinars to stay current on emerging technologies and security trends. I also participate in online forums and discussion groups to stay informed about best practices and new developments.""}],""red_flags"":[""Lack of experience in governance, risk, and compliance"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Senior Security Analyst-Canada,"Role: Senior Security Analyst-Senior resource

Location: Regina, SK-Day one onsite

Duration: 6+ Months

Job Description

Client is looking for a Senior resource onsite Regina with ICS/SCADA Certification / Min. 5 years work experience in cyber security.

1.1 Background

Enterprise Security is responsible for all aspects of security within the organization including cyber, physical and personnel security. We operate with our partners in the SCADA and Automations teams to provide security to the Industrial Control Systems Network along with our partners in Information Systems to secure the corporate IT infrastructure. SaskEnergy Enterprise Security department continues to expand its scope of practice.

1.2 Description Of Requirements

SaskEnergy is seeking two (2) Senior Security Analysts with broad technical and security-based backgrounds to join the Enterprise Security Team.

Typical activities in this role include but not limited to:

Perform security monitoring including alert triaging, investigation, and Incident reporting
Monitor Threat Intelligence feeds and implement security controls to mitigate emerging threats
Perform Vulnerability Assessments and Internal Penetration Testing on enterprise and partner infrastructure and services.
Perform Threat Risk Assessment to identify and document security risks and recommended controls
Work with the security team to perform security solutions evaluation and selection
Participate in the development of detailed technical security standards and configuration baselines to provide to various technical teams across SEI.
Maintains knowledge of applicable privacy and security laws, organizational regulation requirements and global security frameworks to ensure SEI compliance.
Assist with internal and external audit requirements and help to remediate highlighted issues.
Perform root cause analysis of technical security incidents identifying method of attack and required countermeasures.
Perform other related tasks that may be assigned

The Successful Senior Security Analyst Will

Have a minimum of eight (8) years of recent and practical IT experience Information Technology and/or ICS\SCADA.
Must have demonstrated experience in Cybersecurity, with minimum of five (5) years working as part of a cybersecurity team.
Show a broad understanding of security principles, practices, and IT security trends
Must have demonstrated experience with security incident handling and response.
Must have demonstrated hands-on experience with IT security technologies, such as but not limited to:

i. Intrusion Detection System (IDS)/Intrusion Protection System (IPS)

ii. Next-Gen Firewall such as Fortinet or Palo Alto

iii. Next-Gen Secure Web Gateway- ZScaler, Netskope

iv. Cloud Email Gateway

v. Microsoft Azure/Defender technologies

vi. Microsoft Network Policy Server (NPS)

vii. Network Access Control (NAC)

viii. Public Key Infrastructure (PKI)

ix. PowerShell

x. Python

xi. Industrial Control System (ICS) Threat Detection tools

xii. etc.

Must have Security Certification (CISSP, SANS GIAC certification, CISM)
Experience working in ICS/SCADA Security will be an added advantage.
North American work experience.

NOTE: Above should be clearly detailed within submitted Resume.","{""role_summary"":""The Senior Security Analyst is responsible for ensuring the security of industrial control systems and corporate IT infrastructure, performing security monitoring, threat intelligence, vulnerability assessments, and incident response."",""key_terms"":[{""term"":""ICS/SCADA"",""explanation"":""Industrial Control Systems/Supervisory Control and Data Acquisition, referring to systems that control and monitor industrial processes.""},{""term"":""CISSP"",""explanation"":""Certified Information Systems Security Professional, a certification for information security professionals.""},{""term"":""SANS GIAC certification"",""explanation"":""SysAdmin, Audit, Network, Security (SANS) Global Information Assurance Certification, a certification for information security professionals.""},{""term"":""CISM"",""explanation"":""Certified Information Security Manager, a certification for information security managers.""},{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection System/Intrusion Prevention System, systems that detect and prevent unauthorized access to a network.""},{""term"":""Next-Gen Firewall"",""explanation"":""Next-Generation Firewall, a type of firewall that provides advanced security features such as application awareness and intrusion prevention.""},{""term"":""PKI"",""explanation"":""Public Key Infrastructure, a system that enables secure communication over the internet using public-key cryptography.""},{""term"":""NAC"",""explanation"":""Network Access Control, a system that restricts access to a network based on user identity, location, and device security posture.""}],""skill_priorities"":{""must_have"":[""ICS/SCADA certification"",""5+ years of experience in cybersecurity"",""8+ years of experience in IT"",""CISSP, SANS GIAC certification, or CISM"",""Experience with security incident handling and response"",""Hands-on experience with IT security technologies (IDS/IPS, Next-Gen Firewall, etc.)""],""nice_to_have"":[""Experience working in ICS/SCADA Security"",""North American work experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the difference between an IDS and an IPS?"",""example_answer"":""An IDS (Intrusion Detection System) detects and alerts on potential security threats, while an IPS (Intrusion Prevention System) detects and prevents potential security threats in real-time.""},{""question"":""How would you handle a security incident involving an industrial control system?"",""example_answer"":""I would follow our incident response plan, which includes containment, eradication, recovery, and post-incident activities. I would also work closely with the ICS/SCADA team to ensure the incident is fully resolved and to identify opportunities for improvement.""}],""red_flags"":[""Lack of ICS/SCADA certification or experience"",""Limited experience with security incident handling and response"",""No hands-on experience with IT security technologies""],""confidence_score"":90.0}"
Network Security Engineer,"This is a Permanent role with one of our client

Network Security Engineer
Perm role with an End Client
Location: Mississauga, ON - Hybrid- 3 days in office
Hands on network firewall administration on Palo Alto, Fortinet or checkpoint
Must be well versed with next generation firewall
Understands and as implemented network segmentation using firewall policies
Working knowledge of SASE technology such as Netskope or Zscaler
Hands on experience with Web application firewall capabilities such as F5, Barracuda, Cloudflare, Akamai
Worked with Qualys or Tenable or Rapid 7 vulnerability mgmt tools
Worked with Symantec/Mcafee/Cylance/Eset/Sentinel One end point protection
Worked with Splunk, Netskope, S1","{""role_summary"":""This Network Security Engineer role is responsible for hands-on administration of network firewalls, implementing network segmentation, and working with various security technologies to ensure network protection."",""key_terms"":[{""term"":""Next Generation Firewall"",""explanation"":""A type of firewall that provides advanced security features, such as application awareness and intrusion prevention, to protect networks from modern threats.""},{""term"":""SASE"",""explanation"":""Secure Access Service Edge, a cloud-based security framework that provides secure, fast, and reliable access to applications and resources.""},{""term"":""Web Application Firewall"",""explanation"":""A security system that protects web applications from various types of attacks, such as SQL injection and cross-site scripting.""},{""term"":""Vulnerability Management"",""explanation"":""The process of identifying, classifying, and remediating vulnerabilities in systems and applications to prevent exploitation by attackers.""},{""term"":""Endpoint Protection"",""explanation"":""Security solutions that protect endpoint devices, such as laptops and desktops, from various types of threats, including malware and unauthorized access.""}],""skill_priorities"":{""must_have"":[""Palo Alto, Fortinet, or Checkpoint firewall administration"",""Network segmentation using firewall policies"",""SASE technology (Netskope or Zscaler)"",""Web application firewall capabilities (F5, Barracuda, Cloudflare, Akamai)"",""Vulnerability management tools (Qualys, Tenable, Rapid 7)"",""Endpoint protection (Symantec, McAfee, Cylance, Eset, Sentinel One)""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would implement network segmentation using firewall policies?"",""example_answer"":""I would use a combination of VLANs, subnets, and access control lists to segment the network into different zones, and then configure firewall policies to restrict traffic between zones based on business requirements.""},{""question"":""How do you stay up-to-date with the latest threats and vulnerabilities in network security?"",""example_answer"":""I regularly review threat intelligence reports, participate in online security forums, and attend webinars to stay current with the latest threats and vulnerabilities, and adjust my security configurations accordingly.""}],""red_flags"":[""Lack of hands-on experience with Palo Alto, Fortinet, or Checkpoint firewalls"",""Inability to explain the concept of network segmentation using firewall policies""],""confidence_score"":90.0}"
Security Awareness & Engagement Analyst- Operations,"We’re looking for a Security Awareness & Engagement Analyst (early career) to be part of our Security department.

This role is ideal for entry level candidates interested in the security space. This opportunity fits those earlier in their security career, new graduates with internship experience, or those looking to pivot into cybersecurity who bring transferrable SaaS skill sets including strong collaboration and communication skills. Our Security Awareness & Engagement Analyst focuses on the education and engagement side of security and is not a deeply technical position requiring specific certifications or experience. Our ideal candidate is seasoned at cross functional team engagement, by branding the importance of strong security posture within an organization.

Jobber exists to help people in small businesses be successful. We work with small home service businesses, like your local plumbers, painters, and landscapers, to transform the way service is delivered through technology. With Jobber they can quote, schedule, invoice, and collect payments from their customers, while providing an easy and professional customer experience. Running a small business today isn’t like it used to be—the way we consume and deliver service is changing rapidly, technology is evolving, and customers expect more. That’s why we put the power and flexibility in their hands to run their businesses how, where, and when they want!

Our culture of transparency, inclusivity, collaboration, and innovation has been recognized by Great Place to Work, Canada’s Most Admired Corporate Cultures, and more. Jobber has also been named on the Globe and Mail’s Canada’s Top Growing Companies list, and Deloitte Canada’s Technology Fast 50™, Enterprise Fast 15, and Technology Fast 500™ lists. With an Executive team that has over thirty years of industry experience of leading the way, we’ve come a long way from our first customer in 2011—but we’ve just scratched the surface of what we want to accomplish for our customers.

The team:

Jobber has a Security team led by our Sr. Director, Security. We have a split focus between governance and operations. Team members are specialized generalists (we have a primary focus but do a bit of everything). As our team develops and grows you will be collaborating with each member while we work towards making Jobber as secure as possible. We’ll also drive toward team member specialization as we ramp up on capacity and tooling.

The role:

We are seeking a motivated and detail-oriented individual to join our team as a Security Awareness & Engagement Analyst. This is an entry level position and an exciting opportunity to join the Security industry. Your primary focus will be on awareness, training, and internal engagement, ensuring that our awareness program is meeting the best practices set by the industry. In this role, you will report directly to the Sr.Director, Security and assist in maintaining and enhancing the security engagement within Jobber. This is an excellent opportunity to gain hands-on experience in the field of information security while working closely with the Jobber Security team.

You'll support a wide range of security initiatives and in the future will have opportunity to further specialize as you grow your career

The Security Awareness Analyst will:

Lead the development and delivery of security awareness training and educational materials for employees across the organization ranging from general awareness to role-specific security training.
Design and run phishing simulation exercises, analyze results, and provide feedback to leaders across the org.
Maintain day to day operations of the training platforms and evaluate ongoing solution fit - you’ll have an opportunity to shape the future of the program
Engage with employees across the organization to foster a security-first culture through the security help desk, presentations, and regular communications.
Regularly review and update training materials, staying current with the latest security trends and threats, and collecting feedback to enhance effectiveness.
Other duties as assigned

To be successful, you should have:

Strong verbal and written communication skills, with the ability to effectively communicate technical concepts to non-technical stakeholders.
Excellent analytical and problem-solving skills, with a keen eye for detail.
Ability to work independently as well as collaboratively in a team environment.
High level of integrity and confidentiality when handling sensitive information.
A passion for learning and a drive to stay updated with emerging technologies and security trends.

Nice to have:

Security Awareness Platform Experience (KnowB4, Ninjio, InfoSec IQ etc)
Startup mindset
Experience with the creation and rollout of new training materials

All interviews are currently being conducted virtually—via phone or video.

What you can expect from Jobber:

Having been named as a Top 10 Great Place to Work in Canada, we walk the talk. Here are just some of the great things you can expect from us:

A total compensation package that includes an extended health benefits package with fully paid premiums for both body and mind, RRSP matching, and stock options.
A dedicated Coaching and Development function, including Development Coaches, to help build the career you want and hit the goals you set, while ensuring you’re reaching your fullest potential.
Support for all your breaks: from vacation to rest and recharge, your birthday off to celebrate, health days to support your physical and mental health, and parental leave top-ups to support your growing family.
A unique opportunity to build, grow, and leave your impact on a $400-billion industry that has no dominant player...yet.
To work with a group of people who are humble, supportive, and give a sh*t about our customers.

We believe that diverse teams perform better and that fostering an inclusive work environment is a key part of growing a successful team. We welcome people of diverse backgrounds, experiences, and perspectives. We are an equal opportunity employer, and we are committed to working with applicants requesting accommodation at any stage of the hiring process.

A bit more about us:

Job by job, we’re transforming the way service is delivered. Your lawn care provider, home cleaning service, plumber or painter could use Jobber to better connect with their customers, save time in the office, invoice faster, and get paid! We’re bringing tens of thousands of people together with technology to deliver billions of dollars a year in services to happy customers. Jobber exists to help make these small businesses successful, and when they’re successful we all win!","{""role_summary"":""The Security Awareness & Engagement Analyst is responsible for educating and engaging employees on security best practices, developing and delivering security awareness training, and fostering a security-first culture within the organization."",""key_terms"":[{""term"":""Security Awareness"",""explanation"":""Educating employees on security best practices to prevent cyber threats and promote a secure work environment.""},{""term"":""Phishing Simulation"",""explanation"":""A training exercise that mimics a phishing attack to test employees' ability to identify and respond to security threats.""},{""term"":""Security-First Culture"",""explanation"":""An organizational culture that prioritizes security and encourages employees to take an active role in maintaining security best practices.""}],""skill_priorities"":{""must_have"":[""Strong verbal and written communication skills"",""Excellent analytical and problem-solving skills"",""Ability to work independently and collaboratively"",""High level of integrity and confidentiality""],""nice_to_have"":[""Security Awareness Platform Experience"",""Startup mindset"",""Experience with creating and rolling out new training materials""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach developing a security awareness training program for a diverse group of employees?"",""example_answer"":""I would start by identifying the key security risks and threats relevant to our organization, and then develop training materials that are engaging, interactive, and tailored to different learning styles. I would also ensure that the training is regularly updated to reflect emerging security trends and threats.""},{""question"":""Can you walk me through a time when you had to communicate complex technical information to a non-technical audience?"",""example_answer"":""In my previous role, I had to present security metrics to a group of non-technical stakeholders. I used analogies and visual aids to explain the data, and focused on the key takeaways and recommendations rather than the technical details. The stakeholders appreciated the clear and concise communication, and we were able to make informed decisions based on the data.""}],""red_flags"":[""Lack of experience in security awareness and training"",""Inability to communicate technical information to non-technical stakeholders"",""Poor analytical and problem-solving skills""],""confidence_score"":90.0}"
IT Security TRA and C&A Analyst,"ADGA provides strategic vision, world-class technology and service excellence in the areas of defence, security and enterprise computing to clients in the federal government, other levels of government and the private sector. In a world dominated by convergence, ADGA provides the expertise and innovation that organizations need to stay safe, efficient and productive. This is based on an exceptional balance sheet built since 1967, protecting some of Canada's most critical assets. Headquartered in Ottawa, with offices across Canada, ADGA is a privately owned Canadian company employing more than 800 employees, technical consultants and subject matter experts.

Job Description

ADGA requires the services of an Information Technology Security TRA and C&A Analyst to work on the Identity Credential and Access Management (ICAM) team that is developing an identity solution for small departments and agencies (SDA) in the Government of Canada. The team requires an IT Security TRA and C&A Analyst to assist them in preparing for a Security Assessment of the new architecture, which leverages components of the legacy ICAM solution. The objective of the Security Assessment would be for the new service to gain Authority to Operate on an Enterprise basis with an acceptable level of risk. The ICAM team has identified that the system, once in place, will need to satisfy Protected B – Medium Integrity, Medium Availability (PBMM) security requirements.
The IT Security TRA and C&A Analyst’s responsibilities will include, but are not limited to, the following:
Reviewing, analyzing, and/or applying Federal, Provincial or Territorial IT Security policies, System IT Security Certification & Accreditation processes, IT Security products, safeguards and best practices, and the IT Security risk mitigation strategies.
Identifying threats to, and vulnerabilities of operating systems (such as MS, Unix, Linux, and Novell), and wireless architectures.
Identifying personnel, technical, physical, and procedural threats to and vulnerabilities of Federal, Provincial or Territorial IT systems.
Developing reports such as:
Data security analysis,
Concepts of Operation,
Statements of Sensitivity (SoSs),
Threat assessments,
Privacy Impact Assessments (PIAs),
Non-technical Vulnerability Assessments,
Risk assessments,
IT Security threat, vulnerability and/or risk briefings.
Conducting Certification activities such as:
Developing Security Certification Plans, verifying that the security safeguards meet the applicable policies and standards,
Validating the security requirements by mapping the system-specific security policy to the functional security requirements, and mapping the security requirements through the various stages of design documents, verifying that security safeguards have been implemented correctly and that assurance requirements have been met.
Confirming that the system has been properly configured and that the safeguards meet applicable standards, conduct security testing and evaluation (ST&E) to determine if the technical safeguards are functioning correctly,
Assessing the residual risk provided by the risk assessment to determine if it meets an acceptable level of risk.
Conduct Accreditation activities such as a review of the certification results in the design review documentation by the Accreditation Authority to ensure that the system will operate with an acceptable level of risk and that it will comply with the departmental and system security policies and standards and identify the conditions under which a system is to operate (for approval purposes). This may include the following types of approvals:
Developmental approval by both the Operational and the Accreditation Authorities to proceed to the next stage in an IT system's life cycle development if sensitive information is to be handled by the system during development.
Operational written approval for the implemented IT system to operate and process sensitive information if the risk of operating the system is deemed acceptable, and if the system is in compliance with applicable security policies and standards.
Interim approval—a temporary written approval to process sensitive information under a set of extenuating circumstances where the risk is not yet acceptable, but there is an operational necessity for the system under development.
Develop and deliver training material relevant to the resource category.
The proposed resource may not be solely responsible for the completion of these deliverables. The consultant will be expected to work collaboratively with staff to ensure the work is completed in a way that ensures maximum knowledge transfer.

Qualifications

A minimum of a three-year college diploma in computer science or other IT-related field, a university degree at the Bachelor level in Information Technology or other IT-related field; OR a minimum of 5years within the last 15 years of work experience in the IT field.
A minimum of 5 years experience performing tasks like those listed in the Job Description above.
Must currently have or be eligible for a PWGSC Secret (LVL II) security clearance.
A minimum of 5 years of experience, in the last 10 years, with IT security, including experience in security operations, architecture, incident response, and team leadership.
A minimum of 5 years of experience, in the last 10 years identifying and mitigating risks, along with knowledge of legal and regulatory compliance requirements.
A minimum of 5 years of experience, in the last 10 years developing and implementing comprehensive security policies and frameworks that align with business goals.
Certifications such as CISSP, CISM, CRISC, SABSA Chartered Security Architect, CEH, CCSP, and various GIAC credentials.
A minimum of 5 years of experience, in the last 10 years demonstrating leadership and project management skills, with the ability to guide teams and influence organizational security strategy.

Additional Information

Work-Life Balance
We strongly support a healthy and productive work-life balance. This starts with a flexible approach to work, and policies designed to support employees through their day-to-day routines and major life events. For example, we offer a Maternity/Parental Top-Up (up to 52 weeks) and a Reservist Leave Top-Up (up to 180 days).
Belong@ADGA
ADGA continuously strives to integrate advanced Diversity, Equity & Inclusion (DEI) approaches and practices into our work culture. Our employee-based DEI Committee explores activities and invites discussions that foster an environment where all employees feel valued, respected, and heard.
Compensation
Above and beyond our commitment to offer a competitive base salary, ADGA has a company-wide profit-sharing plan for all full-time and part-time employees.
Comprehensive Benefits and Total Rewards
We offer a comprehensive benefit program, providing employees with the choice between base or enhanced plans. Depending on the plan, ADGA pays for Health & Dental, a Health Spending Account, Short-Term Disability, an Employee Assistance Program, and a Telemedicine service. Also offered: discounts on gym memberships, 5,000+ perks through Perkoplis, a Deferred Profit Sharing Plan, and access to a wide range of other employee-centric services and savings programs.","{""role_summary"":""An IT Security TRA and C&A Analyst is required to assist in preparing for a Security Assessment of a new identity solution for small departments and agencies in the Government of Canada, ensuring the system meets Protected B – Medium Integrity, Medium Availability security requirements."",""key_terms"":[{""term"":""ICAM"",""explanation"":""Identity Credential and Access Management, a system for managing identities and access to resources.""},{""term"":""TRA"",""explanation"":""Threat and Risk Assessment, a process to identify and mitigate security risks.""},{""term"":""C&A"",""explanation"":""Certification and Accreditation, a process to ensure a system meets security requirements and is approved for operation.""},{""term"":""PBMM"",""explanation"":""Protected B – Medium Integrity, Medium Availability, a security requirement for systems handling sensitive information.""}],""skill_priorities"":{""must_have"":[""IT Security TRA and C&A experience"",""PWGSC Secret (LVL II) security clearance"",""5+ years of experience in IT security, including security operations, architecture, incident response, and team leadership"",""5+ years of experience in identifying and mitigating risks, along with knowledge of legal and regulatory compliance requirements"",""5+ years of experience in developing and implementing comprehensive security policies and frameworks that align with business goals""],""nice_to_have"":[""Certifications such as CISSP, CISM, CRISC, SABSA Chartered Security Architect, CEH, CCSP, and various GIAC credentials"",""Leadership and project management skills""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with IT Security TRA and C&A, and how have you applied it in previous roles?"",""example_answer"":""I have 5+ years of experience in IT Security TRA and C&A, and have applied it in previous roles by conducting threat and risk assessments, developing security certification plans, and ensuring compliance with security policies and standards.""},{""question"":""How do you stay current with legal and regulatory compliance requirements in IT security?"",""example_answer"":""I regularly review industry publications and attend training sessions to stay current with legal and regulatory compliance requirements in IT security, and have experience implementing comprehensive security policies and frameworks that align with business goals.""}],""red_flags"":[""Lack of experience with IT Security TRA and C&A"",""Inability to obtain PWGSC Secret (LVL II) security clearance"",""Limited experience in identifying and mitigating risks, or developing and implementing comprehensive security policies and frameworks""],""confidence_score"":90.0}"
Senior Risk and Security Analyst,"Title: Business Information Security Officer
Contract: 6 months
Pay: $56/hr
Location: Downtown, Toronto (Hybrid)

SUMMARY OF DAY-TO-DAY RESPONSIBILITIES:
Lead the identification and assessment of technology and cybersecurity risks across the bank's digital assets, IT infrastructure, and operations, ensuring alignment with the bank’s risk appetite and regulatory requirements.
- Develop and implement comprehensive risk management strategies and policies to mitigate identified risks, including but not limited to, cyber threats, data breaches, IT outages, and technology compliance issues.
- Collaborate with IT, business units, and cybersecurity teams to enhance the bank's cyber and technology risk posture through proactive risk identification, assessment, and response planning.
- Oversee and guide the risk assessment process for new and existing technologies, digital initiatives, and third-party service providers, ensuring comprehensive risk evaluation and mitigation planning.
- Provide expert advice and guidance to senior management on technology and cyber risk trends, potential impacts on the bank, and recommended risk mitigation strategies.
- Facilitate and promote a culture of risk awareness and cybersecurity resilience across the organization, including the development and delivery of risk management training programs.
- Monitor and analyze developments in technology and cybersecurity threats, including regulatory changes, to continuously refine and update risk management strategies.
-Prepare and present detailed risk reports and dashboards to senior management and relevant committees, highlighting the bank's risk posture, emerging risks, and effectiveness of risk mitigation efforts.

MUST HAVE:
Compliance testing experience
Fraud/AML/KYC/Insider Risk experience
Financial institution background
Cyber Risk Assessment experience
BISO – Business Information Security Officer


We thank you for your interest in the position, however, only those who are qualified will be contacted
Inclusion and Equal Opportunity Employment
Our client is an equal opportunity employer committed to diversity and inclusion; creating an inclusive environment where all team members and clients feel like they belong. We are pleased to consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, Aboriginal/Native American status or any other legally-protected factors. We seek applicants with a wide range of abilities, and we provide an accessible candidate experience; accommodations during the application process are available upon request.","{""role_summary"":""Lead the identification and assessment of technology and cybersecurity risks across the bank's digital assets, IT infrastructure, and operations, ensuring alignment with the bank's risk appetite and regulatory requirements."",""key_terms"":[{""term"":""Cyber Risk Assessment"",""explanation"":""Evaluating and identifying potential cyber threats to an organization's digital assets and infrastructure.""},{""term"":""Risk Appetite"",""explanation"":""The level of risk an organization is willing to take on in pursuit of its goals and objectives.""},{""term"":""Regulatory Requirements"",""explanation"":""Laws, rules, and guidelines that organizations must comply with to operate legally and ethically.""},{""term"":""BISO"",""explanation"":""Business Information Security Officer, a role responsible for overseeing and implementing information security strategies and policies.""}],""skill_priorities"":{""must_have"":[""Compliance testing experience"",""Fraud/AML/KYC/Insider Risk experience"",""Financial institution background"",""Cyber Risk Assessment experience"",""BISO – Business Information Security Officer""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with compliance testing and how you've applied it in a financial institution setting?"",""example_answer"":""In my previous role, I conducted regular compliance testing to identify vulnerabilities in our systems. I worked closely with the IT team to implement remediation plans, ensuring we were compliant with regulatory requirements.""},{""question"":""How do you stay current with emerging cyber threats and regulatory changes, and how do you incorporate that knowledge into your risk management strategies?"",""example_answer"":""I regularly review industry reports and attend webinars to stay informed about emerging threats and regulatory changes. I then assess our organization's risk posture and update our risk management strategies accordingly.""}],""red_flags"":[""Lack of experience in a financial institution setting"",""Inability to demonstrate knowledge of regulatory requirements""],""confidence_score"":90.0}"
"Legal Assistant, Privacy & Cybersecurity","Dentons is designed to be different. Our firm leads the way in a rapidly changing legal marketplace. We challenge the status quo and deliver consistent results as well as uncompromising quality and value to our clients. Our global presence is renowned as a firm with over 21,000 individuals in more than 200 offices serving clients across 80+ countries.

Dentons Canada is committed to its people and communities. We are consistently recognized as an employer of choice having received numerous awards including being selected as one of Canada’s Top 100 Employers (2024); Canada’s Top Employers for Young People (2024), and Canada’s Best Diversity Employers (2024).

This role is an opportunity for you to join the world’s largest law firm, a firm that offers opportunities to build your career while growing your skills and deepening your expertise.


POSITION SUMMARY

The Legal Assistant will support lawyers and a Senior Manager within the Privacy Group, as well as support and manage the practice of the National Practice Group Lead (NPGL) for Privacy and Cybersecurity. The Legal Assistant must demonstrate strong technical skills and knowledge to accurately and efficiently manage the production demands of the practice and also possess proven abilities to proactively support the management of the practice, including client relationship management. The position will require a polished, confident and reliable assistant who is able to manage multiple priorities. You are highly organized, proactive, and have a client first approach to work. You are professional and possess a high degree of business maturity and are an active partner in developing and managing the practice.

Generally, the hours of work are from 9 am to 5 pm., however, due to the nature of the role some pre-authorized overtime and flexibility in core hours may be required.


RESPONSIBILITIES

Correspondence/Document management:
Accurately prepare and edit correspondence, reports, minutes and presentations and other documents as required
Updating and maintaining client/matter lists and current client contact records electronically to meet Dentons’ requirements
File management, timekeeping and billing:
Entering and maintaining lawyer’s dockets and coordinating with the Accounting Department, when necessary; preparing detailed billings, and assisting in the management of WIP and AR reports
File opening and closing, and general management of files
Preparing and updating cheque requisitions and expense reports
Maintaining and organizing files, both electronic and hard copy as required
Practice management generally:
Provide support for meetings, including driving agendas, transcribing meeting minutes, executing action steps, and coordinating meeting requirements
Assess the urgency and importance of situations and take the appropriate action
Act as a resource to both internal and external contacts
Develop relationships with all internal stakeholders and act as a liaison between lawyer/clients and colleagues to facilitate work and accomplish objectives in a collaborative effort
Dealing with and responding to client inquiries expeditiously and conducting follow up; keeping the lawyers apprised of interactions in their absence
Competently utilize the Firm’s technology and tools
Processing incoming and outgoing mail, including timely filing and management of email, and managing bring forward
NPGL practice management:
Manage the NPGL calendar by scheduling appointments, changing meetings as required, planning and anticipating the NPGLs needs. Maintain a system to track items requiring follow-up and follow-through
Develop a full working knowledge of the firm's structure, the NPGL’s line of business, key personnel and organizational policies and procedures.
Support Group budget management activities i.e. prepare and submit expense reports, prepare spreadsheets
Manage the calendar, calls, mail, e-mails, meetings and domestic and international travel for the NPGL and coordinate events originating from that position
Support the NPGL in holding others accountable to timelines and commitments by ensuring follow up as required
Juggle multiple competing tasks and demands keeping focused on priorities and deadlines and assisting NPGL to do the same
Maintain a list of active files, their current statuses, and plans for their progression or any pending tasks and hold regular stand-up meeting with the NPGL to advance the files
Support the NPGL with delegation of files and development of a plan for distribution of work to team members
General administrative:
Duties such as scheduling appointments and meetings, photocopying materials, booking meeting rooms, making travel arrangements, etc.; working with other related Departments/services internally to provide documents and other materials on time to meet client needs
Ensuring strict adherence to confidentiality; accountability in relation to both internal and external clients to achieve outputs and goals for the Department and the Firm
Other duties as assigned


REQUIREMENTS

Legal Assistant diploma or college certificate in office or business administration or equivalent
Minimum 5 years of experience as a legal assistant or as an assistant supporting leadership with experience ideally acquired in a professional services environment
Ability to produce a high quality and quantity of work, occasionally under tight timelines
Able to meet deadlines, work well under pressure and take initiative using sound judgment
Strong interpersonal and communication skills (both verbal and written)
Proficiency in Microsoft Office applications and technically savvy
Knowledge of accounting / time entry systems (Intapp Time) and document management systems (Elite and iManage)
Excellent organizational and follow up skills; ability to exercise sound judgment in setting priorities
Professional client and telephone manner and a proven track record of working with confidential information
Able to work independently in a fast-paced, team-oriented environment
Must have excellent problem solving skills, and the ability to work with little instruction
Responsive and proactive
Demonstrated commitment to privacy and ethical conduct


We thank all applicants for their interest, however, only those selected for an interview will be contacted.


At Dentons we are committed to offering equitable and competitive pay, we achieve this by aligning internal salary ranges for specific roles to similar positions in the external market. In the normal course, our practice is to hire, transfer and promote employees within the entry part of our range, adjusting as needed based on the prior experience, skills and competencies required for the role along with any market differentials.

Recognizing our exceptional talent means providing a comprehensive total rewards package beyond a competitive salary. We have curated our employee benefits portfolio to offer inclusive and comprehensive wellbeing and developmental programs for our people. With extended benefits and mental health plans, paid time off, savings plans, fitness subsidy, parental leave top up and more, our benefits are flexible, aligned to our core values and supports the various needs of our people. Additionally, our personal and professional development programs include people networks, mentorships, and leadership series programming to help people grow their career.
Note: Availability of the benefits and perks may be subject to your location and employment type and may have certain eligibility requirements. Dentons reserves the right to alter these programs and offerings in whole or in part at any time without advance notice.


Equal Opportunity Statement
At Dentons Canada, inclusion, diversity and equity (ID&E) are not just ancillary values, they are foundational to our business. We believe that ID&E is essential to the shared success of our team and our clients. Our forward-thinking and inclusive culture supports the professional development of all our people, enhances the leading services we offer to our clients, and informs our commitment to make a positive impact in the communities where we live and work. As a testament to our commitment to ID&E, we have been recognized as one of Canada’s Best Diversity Employer’s for 12 consecutive years (2011-2022), as well as one of Canada’s Top Employers for Young People (2022) for the fifth time.
Dentons Canada is an equal opportunity employer and we welcome your application. All employment decisions, including hiring, will be made without regard to age, ancestry, citizenship, colour, creed, disability, ethnic origin, family status, gender assigned at birth, gender identity, marital status, place of origin, race, sexual orientation or any other characteristic protected by applicable human rights legislation.
We are committed to providing you with an inclusive, barrier-free and accessible workplace to support your success. Should you require accommodation during the recruitment process, for example as a result of a disability, please contact us at careers.canada@dentons.com.","{""role_summary"":""Support lawyers and a Senior Manager within the Privacy Group, managing the production demands of the practice, and possessing proven abilities to proactively support the management of the practice, including client relationship management."",""key_terms"":[{""term"":""NPGL"",""explanation"":""National Practice Group Lead for Privacy and Cybersecurity, responsible for managing the practice and leading the team.""},{""term"":""WIP and AR reports"",""explanation"":""Work-in-Progress and Accounts Receivable reports, used to track and manage the financial aspects of the practice.""},{""term"":""Intapp Time"",""explanation"":""A time entry system used to track and manage lawyer's dockets and billing.""},{""term"":""Elite and iManage"",""explanation"":""Document management systems used to manage and organize files, both electronic and hard copy.""}],""skill_priorities"":{""must_have"":[""Legal Assistant diploma or college certificate in office or business administration or equivalent"",""Minimum 5 years of experience as a legal assistant or as an assistant supporting leadership"",""Proficiency in Microsoft Office applications"",""Knowledge of accounting / time entry systems and document management systems""],""nice_to_have"":[""Experience in a professional services environment"",""Technical savviness""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you prioritize and manage multiple tasks and deadlines in a fast-paced environment?"",""example_answer"":""I would use a task management system to organize and prioritize tasks, and communicate regularly with the team and stakeholders to ensure timely completion of tasks.""},{""question"":""How would you maintain confidentiality and handle sensitive information?"",""example_answer"":""I would ensure that all confidential information is stored securely, and only shared with authorized personnel, and I would maintain a high level of discretion when handling sensitive information.""}],""red_flags"":[""Lack of experience in a professional services environment"",""Inability to work independently in a fast-paced environment""],""confidence_score"":90.0}"
Senior Information Security Analyst,"Our client within the Financial Sector is looking for a Senior Information Security Analyst for a long term role. This is a contract to hire position looking for individuals opened to transitioning into a permanent position after the contract period. The ideal candidate will have a strong understand of Network and Security as well as experience in business continuity, assessments and auditing functions. This position is a hybrid on site role in Downtown Toronto, Ontario looking for individuals available ASAP. If you meet the requirements and are interested in this opportunity please apply to the position directly.

Provide consultation and advice to partners on a broad range Technology Controls / Information Security programs / policies / standards and incidents for own specialized area
Conduct project consulting on assessment of risk, definition of required controls, appropriateness of implemented control procedures, vulnerability assessments and any other relevant areas
Lead or contribute to completion of risk and control design assessments for an application portfolio, articulate and document impact of control gaps to the business and the overall Bank, risk mitigation and remediation plans, remediation strategy document as applicable
Contribute to the definition, development, and oversight of a global security management strategy and framework
Ensure technology, processes, and governance are in place to monitor, detect, prevent, and react to both current and emerging technology / security threats against TDBG’s business
Develop on-going Technology Risk reporting, monitoring key trends and defining metrics to regularly measure control effectiveness for own area
Work proactively with technology partners / stakeholders and service/platform owners to ensure all technology security components are integrated into the bank’s overall Enterprise Architecture, and any control gaps are addressed.
Consult on Regulatory compliance requirements, reporting and questions
Provide support and consulting in preparation for Audits and in composing management responses and appropriate remediation activities
Participate in computer security incident responses relevant to business (or enterprise wide) and represent respective function and Enterprise position to the business, and business needs to incident response team
Adhere to internal policies / procedures, technology control standards, and applicable regulatory guidelines
Contribute to the review of internal processes and activities and assist in identifying potential opportunities for improvement
Adhere to and advise on / oversee / monitor / enforce enterprise frameworks and methodologies that relate to technology controls / information security activities
Influence behavior to reduce risk and foster a strong technology risk management culture throughout the enterprise
Remain informed of emerging issues, industry trends and/or relevant changes
Define / develop / implement / manage standards, policies, procedures, and solutions that mitigate risk and maximize security, availability of service, efficiency, and effectiveness
Actively manage relationships with other areas of Technology / businesses / corporate and/or control functions and ensure alignment with enterprise and/or regulatory requirements
Keep abreast of emerging issues, trends, and evolving regulatory requirements and assess potential impacts to the Bank
Assess / identify key issues and escalate to appropriate levels and relevant stakeholders where required
Maintain a culture of risk management and control, supported by effective processes and sound infrastructure an in alignment with risk appetite
Participate in business specific / cross-functional / enterprise initiatives as a subject matter expert helping to identify risk / provide guidance
May develop / provide / contribute to complex reporting, analysis, and assessments at the functional or enterprise level
Requirements:
Advanced knowledge of one or more technology controls / security domains, disciplines, and practices
Sound to advanced knowledge of organization, technology controls / security/ risk issues
May participate on projects of moderate to high complexity
Acts as a key resource and subject matter expert in at least one technology niche/ field and/or line of business
Generally reports to Manager or Senior Manager","{""role_summary"":""The Senior Information Security Analyst will provide consultation and advice on technology controls, information security programs, and risk assessments to ensure the security and integrity of the organization's systems and data."",""key_terms"":[{""term"":""Technology Controls"",""explanation"":""Policies, procedures, and standards to ensure the secure and efficient use of technology within an organization.""},{""term"":""Information Security"",""explanation"":""The practice of protecting sensitive information from unauthorized access, use, disclosure, disruption, modification, or destruction.""},{""term"":""Risk Assessments"",""explanation"":""The process of identifying, evaluating, and prioritizing potential risks to an organization's assets, data, or operations.""},{""term"":""Auditing Functions"",""explanation"":""The process of examining and evaluating an organization's systems, processes, and controls to ensure compliance with regulations and standards.""},{""term"":""Business Continuity"",""explanation"":""The process of ensuring that an organization can continue to operate effectively in the event of a disaster or major disruption.""}],""skill_priorities"":{""must_have"":[""Advanced knowledge of technology controls and security domains"",""Experience in risk assessments and auditing functions"",""Strong understanding of network and security""],""nice_to_have"":[""Knowledge of business continuity planning"",""Experience in project consulting and risk management""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of technology controls in an organization?"",""example_answer"":""Technology controls are essential to ensure the secure and efficient use of technology within an organization. They help to prevent unauthorized access, use, disclosure, disruption, modification, or destruction of sensitive information.""},{""question"":""How would you conduct a risk assessment for a new application portfolio?"",""example_answer"":""I would identify potential risks, evaluate their likelihood and impact, and prioritize them based on their severity. I would then develop and implement controls to mitigate or eliminate the risks, and monitor and review the effectiveness of the controls.""}],""red_flags"":[""Lack of experience in technology controls and security domains"",""Inability to communicate complex technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Cybersecurity Compliance Specialist,"Raise is hiring a Cybersecurity Compliance Specialist for our client, one of North America's leading energy infrastructure companies with operations in natural gas, oil and power industries throughout Canada, the United States, and Mexico. This position is a five (5)-month contract located in Calgary, Alberta. We are actively seeking talented professionals like you to drive these crucial initiatives forward.

Description

Seeking an energetic Cybersecurity Compliance Specialist who is looking to build their knowledge and experience in the areas of cybersecurity. You will be accountable for enabling compliance policies & standards, performing compliance assessments, and preparing compliance reporting.

In collaboration with other security team members, and other IS and business teams, the specialist will support the complete lifecycle of cybersecurity compliance assessments for corporate and ICS environments. Further, the specialist will identify current/emerging security risks based on the output of the assessments.

What You’ll Do

Perform assessments and report on cybersecurity compliance
Conduct internal Cybersecurity audits
Participate in Cybersecurity Compliance attestations
Drive automation of security controls with a focus on continuous monitoring
Develop scripts to automate manual tasks and processes within the Cybersecurity Office
Develop PowerBI and ServiceNow dashboards leveraging available data sources
Develop ServiceNow GRC Compliance features, such as integration with Governance and Risk areas and management of Non-Conformances
Review Vulnerability Management Metrics and streamline processes to improve efficiency
Collaborate with system administrators, developers, and IT teams to coordinate the remediation of identified vulnerabilities
Conduct research to maintain and expand knowledge on the latest cybersecurity controls and standards, as well as the threat and vulnerability landscape
Collaborate with CSO GRC Manager, Cybersecurity Office team members, IS teams, business units and other stakeholders on areas related to cybersecurity governance,

Qualifications

University Degree in Computer Science, Information Systems or relevant discipline
7+ years of experience in a IT/Cybersecurity role preferred
Experience making visual reports in PowerBI and ServiceNow.
Experience developing ServiceNow GRC Compliance features, such as integration with Governance and Risk areas and management of Non-Conformances
Updated on the latest cybersecurity trends and improve current processes.
Detail-oriented, good at solving problems, and able to work well with others.

Raise is an established hiring firm with over 60 years of experience. We strive to build teams that reflect the diversity of the communities we work in and encourage applications from traditionally underrepresented groups. We value diversity and inclusion and encourage all qualified people to apply. Connecting professionals like you with meaningful work at industry-leading companies in your field. And we walk the walk, too: as a Certified B Corporation, we believe in using business as a force for good for people, our communities, and the environment.

We have a dedicated webpage for accommodations where you can learn more about what we offer, and request accommodation: https://raise.jobs/accommodations/.

Raise will never ask you for personal or banking information during the application process. If you are ever unsure about the legitimacy of this or another job posting by Raise (or have any other questions), please contact us at +1 800-567-9675 or hello@raiserecruiting.com

#WES","{""role_summary"":""The Cybersecurity Compliance Specialist is responsible for ensuring compliance with cybersecurity policies and standards, performing assessments, and reporting on compliance. They will work with various teams to identify and mitigate security risks, automate security controls, and develop reports and dashboards."",""key_terms"":[{""term"":""Cybersecurity Compliance"",""explanation"":""Ensuring that an organization's cybersecurity practices meet regulatory and industry standards.""},{""term"":""ICS Environments"",""explanation"":""Industrial Control Systems environments, which are computer-controlled systems used to monitor and control industrial processes.""},{""term"":""PowerBI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""ServiceNow GRC Compliance"",""explanation"":""A governance, risk, and compliance (GRC) module within ServiceNow that helps organizations manage risk and compliance.""}],""skill_priorities"":{""must_have"":[""Experience with cybersecurity compliance assessments"",""Knowledge of cybersecurity controls and standards"",""Experience with PowerBI and ServiceNow"",""Strong problem-solving skills""],""nice_to_have"":[""7+ years of experience in a IT/Cybersecurity role"",""Experience developing ServiceNow GRC Compliance features""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of continuous monitoring in cybersecurity compliance?"",""example_answer"":""Continuous monitoring is essential in cybersecurity compliance as it enables organizations to identify and respond to security risks in real-time, reducing the likelihood of security breaches and ensuring compliance with regulatory requirements.""},{""question"":""How would you approach automating manual tasks and processes within the Cybersecurity Office?"",""example_answer"":""I would identify areas where automation can improve efficiency, develop scripts to automate tasks, and collaborate with team members to ensure seamless integration with existing processes.""}],""red_flags"":[""Lack of experience with cybersecurity compliance assessments"",""Inability to work collaboratively with cross-functional teams""],""confidence_score"":90.0}"
Security Analyst (H/F),"Description De L'entreprise

Advens est un leader français de la Cybersécurité, indépendant et souverain. Nos 400 experts sont présents partout en France, ainsi qu’à Montréal et en Europe.

Notre mission : protéger les organisations publiques et privées, toujours plus dépendantes du numérique et toujours plus exposées à des attaquants de plus en plus professionnels.

Notre mission de protection nous guide et nous anime au quotidien. Mais elle ne nous suffit pas. Si la cybersécurité permet de faire tourner le monde, notre performance doit participer à le changer.

Notre croissance s’accompagne d’un partage de la valeur au service de cette ambition sociétale. Pour la financer, plus de 50% de notre valeur financière sera redistribuée au fonds de dotation Advens for People & Planet, qui accompagne des initiatives à impact, en faveur de l’inclusion sociale, de l’éducation et de l’environnement.

Description Du Poste

Au sein de notre équipe Blue Team, au cœur de notre SOC, participez à l’identification de comportements anormaux ou des vulnérabilités pour protéger les systèmes d’information de nos clients.

Vos missions :

Vous accompagnez un portefeuille de clients dans la protection de leurs systèmes d’informations en identifiant les comportements anormaux.
Vous élaborez et proposez un plan de remédiation adapté au contexte de votre client et de ses risques métier.
Vous faites part à vos clients des éléments détectés.
Vous participez à l’amélioration des techniques et des règles de détection des incidents de sécurité de notre SOC et ainsi participez à l’évolution d’un produit différenciant sur le marché cyber.

Vos projets :

Au-delà des missions, projetez-vous dans des activités qui pourraient être les vôtres si vous nous rejoignez…

Les algorithmes de mySOC détectent des signaux faibles : leur analyse est entre vos mains.
Pour déjouer les attaques les plus sophistiquées, vous interagissez avec les experts N3 de mySOC.
Vous faites part à l’équipe Produit des évolutions à intégrer dans les outils d’analyse et de remontées d’incidents.
L’équipe de sécurité opérationnelle de l’un de vos clients doit analyser un incident de sécurité : vous la guidez et lui partagez tous vos conseils.
Vous préconisez quelles opérations réaliser au RSSI d’un client qui doit réagir à un incident.

Qualifications

Alors, ce job est fait pour vous ?

La tech, c’est votre truc : il faut pouvoir connaître les attaques pour les contrer.
Vous intervenez auprès de nombreux clients en même temps, depuis notre SOC.
Dans les starting-blocks : à l’affût de toute attaque, vous aimez faire preuve de réactivité.
Vous aimez conseiller : vous analysez, puis expliquez vos plans d’action à votre client en l’accompagnant avec attention.
L’innovation vous tient à cœur : ce que vous voyez au quotidien permet d’améliorer les systèmes de défenses, notamment grâce à la définition de règles de détection.
Vous avez envie d’évoluer ! Si vous commencez dans la fonction Build avec la mise en place de SOC chez le client, vous êtes aussi prêt(e) à devenir référent sur des technologies particulières, voire à évoluer vers d’autres métiers.

Informations supplémentaires

Hybride","{""role_summary"":""Identify and protect clients' information systems from abnormal behaviors and vulnerabilities as a Blue Team member in a Security Operations Center (SOC)."",""key_terms"":[{""term"":""Blue Team"",""explanation"":""A team of security professionals who identify and respond to cyber threats within an organization.""},{""term"":""SOC"",""explanation"":""Security Operations Center, a centralized unit that monitors and responds to security incidents.""},{""term"":""mySOC"",""explanation"":""A proprietary Security Operations Center platform developed by Advens.""},{""term"":""N3"",""explanation"":""A level of expertise or a team of experts in a specific field, in this case, cybersecurity.""},{""term"":""RSSI"",""explanation"":""Responsable de la Sécurité des Systèmes d'Information, a French term for the person responsible for the security of information systems.""}],""skill_priorities"":{""must_have"":[""Cybersecurity knowledge"",""Ability to analyze and respond to security incidents"",""Communication skills for client interaction""],""nice_to_have"":[""Experience with SOC operations"",""Knowledge of security information and event management (SIEM) systems"",""Familiarity with threat intelligence and incident response""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you identify and respond to a potential security threat in a client's information system?"",""example_answer"":""I would use my knowledge of cybersecurity and incident response to analyze the threat, then develop a remediation plan and communicate it to the client. I would also ensure that the client's security team is informed and involved in the response process.""},{""question"":""Can you explain how you would improve the detection of security incidents in a SOC?"",""example_answer"":""I would analyze the current detection rules and algorithms, identify areas for improvement, and propose new rules and techniques to enhance incident detection. I would also collaborate with the SOC team to implement and refine these improvements.""}],""red_flags"":[""Lack of experience in cybersecurity or incident response"",""Inability to communicate technical information to non-technical clients""],""confidence_score"":90.0}"
"Security Analyst, Lawful Acces","We are committed to connecting Canadians through unique partnerships, our world-class network and content Canadians love—and our innovative team is growing. We are looking for dedicated team members to join our Corporate team who have a genuine passion for making positive impacts on customers and the communities where we live and work. We have a variety of business units with exciting and meaningful work waiting for you, including Communications, HR, Legal and Corporate Affairs, Supply Chain, Finance, and Real Estate. If you are considering your next step, we have exciting opportunities waiting for you. Come build a rewarding career at Rogers and be a driving force behind our success story!

12 months contract /Lawful Access Analyst

Ability to work various shifts inclucing midnight-8am,4pm-midnight, 8am-4pm)

Imagine working for an exciting entrepreneurial company where employees are committed to meeting big challenges and making a real difference. That’s Rogers. A leading communications and media company where people come to do great work. Right now we are looking for talented individuals to join our winning team where you will have a chance to innovate, grow and to do what really matters.

Responsibilities Include

Respond to Canadian law enforcement agency phone inquiries requesting assistance due to exigent (emergency) circumstances.
Live answer all calls to determine the nature of the law enforcement inquiry and what is required from Rogers to assist law enforcement.
Support 911 Public Safety Answering Points (PSAPs) across Canada by facilitating access to customer information under exigent circumstances.
Respond to all inquiries from law enforcement agencies pursuant to their criminal investigations as per departmental procedures.
Analyze records and prepare reports containing data stored within business systems in response to court orders.
Manage special projects as assigned.

Qualifications

Bilingualism is required French and English
Ability to work various shifts inclucing midnight-8am,4pm-midnight, 8am-4pm)
Must be able to work shifts. (days, evenings, overnights, week-ends, and statutory holidays
Applicants with a background in legal, telecommunications, or law enforcement related programs are encouraged to apply.
Must be able to obtain and maintain a federal government security clearance.
Excellent communications and customer service skills.
Strict attention to detail.
Must have been living in Canada for 10 years
Professionalism and ability to maintain confidentiality of information.
Previous experience in a call centre and / or customer service role is an asset.
Knowledge of Rogers technologies is an asset.
Knowledge of Vision 21, SGI, AS400, MS Word, Excel preferred.
Credit and criminal background checks will be conducted for all final candidates.

Schedule Full time

Shift Night

Length of Contract 12 Months

Work Location 1 Mount Pleasant (083), Toronto, ON

Travel Requirements None

Posting Category/Function Finance & Accounting & Corporate Security

Requisition ID 311232

At Rogers, we believe the key to a strong business, is a diverse workforce where equity and inclusion are core to making everyone feel like they belong. We do this by embracing our diversity, celebrating our different perspectives, and working towards creating environments that empower our people to bring their whole selves to work. Everyone who applies for a job will be considered. We recognize the business value in creating a workplace where each team member has the tools to reach their full potential by removing any barriers for equal participation. We work with our candidates who are experiencing a disability throughout the recruitment process to ensure that they have what they need to be at their best. Please reach out to our recruiters and hiring managers to begin a conversation about how we can ensure that you deliver your best work. You matter to us! For any questions, please visit the Recruitment Process FAQ.

Successful candidates will be required to complete a background check as part of the hiring process.

Posting Notes Corporate","{""role_summary"":""Work as a Lawful Access Analyst at Rogers, responding to law enforcement agency inquiries, supporting 911 Public Safety Answering Points, and analyzing records to prepare reports. Ensure confidentiality and maintain a high level of professionalism."",""key_terms"":[{""term"":""Exigent circumstances"",""explanation"":""Emergency situations that require immediate assistance from Rogers to law enforcement agencies.""},{""term"":""PSAPs"",""explanation"":""Public Safety Answering Points, which are responsible for answering 911 calls across Canada.""},{""term"":""Court orders"",""explanation"":""Legal documents issued by a court that require Rogers to provide specific information or assistance to law enforcement agencies.""},{""term"":""Federal government security clearance"",""explanation"":""A high-level security clearance required for certain roles at Rogers, which involves a thorough background check and screening process.""}],""skill_priorities"":{""must_have"":[""Bilingualism (French and English)"",""Ability to work various shifts"",""Excellent communications and customer service skills"",""Strict attention to detail"",""Must have been living in Canada for 10 years"",""Ability to obtain and maintain a federal government security clearance""],""nice_to_have"":[""Background in legal, telecommunications, or law enforcement related programs"",""Previous experience in a call centre and/or customer service role"",""Knowledge of Rogers technologies"",""Knowledge of Vision 21, SGI, AS400, MS Word, Excel""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a situation where you had to handle a high-pressure emergency situation in a previous role?"",""example_answer"":""In my previous role as a customer service representative, I received a call from a customer who was experiencing a life-threatening emergency. I remained calm and followed our emergency protocols to ensure the customer received the necessary assistance.""},{""question"":""How would you ensure confidentiality when handling sensitive information in this role?"",""example_answer"":""I understand the importance of maintaining confidentiality in this role. I would ensure that I only access information on a need-to-know basis, and I would follow all security protocols to prevent unauthorized access or disclosure of sensitive information.""}],""red_flags"":[""Candidates without experience working in a call centre or customer service environment"",""Lack of attention to detail in previous roles"",""Inability to obtain and maintain a federal government security clearance""],""confidence_score"":90.0}"
Network Security Consultant,"Our employer, a leading Cybersecurity company, is seeking a Network Security Consultant - IT Security and Recovery Specialist (Remote, Canada). As a consultant on the Cyber Incident Remediation and Restoration (CIRRT) team, your primary role is to deliver services to clients in an effective, proficient, and agile manner. The successful candidate will need strong System Administration and Network Architect hands-on skills to recover infrastructure and systems from a serious Cybersecurity incident.
Travelling will be required, about 30-40% of the time.
Weekly working hours: 50-60 hours (Extra time will be paid at time and a half)

The employer is a global market leader in ransomware post-breach remediation and cyber-attack first response. Also, working with prominent global insurance carriers, leading law firms, and Fortune 1000 businesses.

Your day-to-day:
· You will collaborate with other team members and ensure our team’s expertise and attention to quality is second to none.
· You will strive to find innovative ways, processes and tools to deliver on objectives, faster and at a higher quality while focusing on maximizing revenue generator for the company.
· The team you will be a contributing part of will have the primary responsibility for responding to and recovering from security incidents. As a consultant you will have direct hands-on responsibility in leading engagements and acting as role-model to other team members.
· You will possess an in-depth understanding of technical infrastructure and recovery techniques and have strong experience working in the field.
· You will possess a strong ability to communicate to all levels of stakeholders and provide detailed deliverables which will include reporting and recommendations.
· On the technical front, you will possess a strong skill-set in system, application and network technologies both in configuration, installation and optimization.
· You will have a strong hands-on capabilities with various security tool-sets including to assess, hunt and remediate threats.
· Developing strong and rapid working client relationships is a key aspect of the role. Exceptional attention to detail and uncompromising pursuit of quality are the foundation of this role.

The successful candidate will be responsible for the following:
TECHNICAL
· 7+ years of senior technical support, system administration or related customer facing role.
· Perform cybersecurity incident response and restoration engagements including live response, triage, containment and remediation
· System, network, application rebuild and restoration activities
· Active Directory – Knowledge of design and troubleshooting
· VMWare ESX/HyperV – Knowledge of design, use and troubleshooting.
· Knowledgeable in the Windows environment, including Windows Service and Workstation, troubleshooting and diagnosing low-level operating systems and network issues.
· Confident with a wide range of hardware platforms including NAS, SAN, server and networking devices.
· Passion for solving customer issues and advocating for their success, in a fast paced, highly technical environment.
· Ability to learn new technologies quickly.
· Ability to work independently with little direct supervision and as a part of a team.
· Outstanding analytical and organizational abilities.
· Strong networking background including some of the following skills:
*Network routing protocols - OSPF, BGP, EIGRP, RIP along with other network protocols DHCP, DNS, VPN, IPV4 and IPV6
*Network switching – Understand L2 and L3 switch design to include VLANS and port security
*Enterprise wireless solutions – Cisco, Aruba, FortiNet
*Firewalls - Cisco ASA, Cisco FTD, CheckPoint, FortiNet PaloAlto, Cisco Meraki
*Network traffic capture and analysis

LEADERSHIP
· Directly contribute to revenue targets in delivering engagements
· Responsibility over certain tool selection, evaluation, management and evolution
· Collaborate with management and teams to ensure agility and eliminate unnecessary delays
· Support new services and offerings to the marketplace
· Act as a technical leader and mentor to junior consultants

BUSINESS
· Presence at the local office if needed – Primarily a remote role with attendance at client engagement is required as required
· Work Independently, remotely and with minimal supervision while delivering high quality outputs
· Display an aptitude and desire for continuous learning at the leading edge of security
· Remain current on information security, technical infrastructure and recovery techniques, emerging threat trends, and tools including methodologies to combat the same
· A high degree of comfort in customer facing / consulting situations
· Travel as needed to customer locations to perform reactive and proactive engagements including frequent travel with little notice. Ability to travel internationally is required, primarily around North America.
· Adhere to policies, procedures, and security practices in accordance with assigned customer’s established practices and internal policies
· Take meticulous notes and demonstrate strong reporting capabilities with an emphasis on detail
· Lead and support client scoping and kick-off calls if required
· Ability to remain calm, composed and articulate when dealing with tough customer situations.
· Excellent relationship management, customer service and communication skills in variety of forms (written, live chat, conference calls, in-person).

Preferred Skills:
· Proactive
· Risk assessment and troubleshooting skills
· Deliver table-top engagements
· Adequately communicate findings to the clients
· Help maintain strong client relationships
· Stay up to date by taking company-paid and self-training

Strongly Desired:
· Experience supporting hybrid environments
· Experience supporting security applications such as AV, VPN, Firewall, proxy.
· Linux troubleshooting experience a plus
· Experience with troubleshooting Windows and Mac
· MCP or higher
· Unix/Linux - Have experience designing and implementing different flavors, including troubleshooting
· Macintosh – Knowledge of and use of Macintosh/Apple OS X to include troubleshooting

The compensation package is as follows:
· Competitive Base
· 10% Annual Bonus
· 3 weeks of Paid Vacation
· 3 paid wellness days per year
· Monthly cell/internet reimbursement
· Opportunity to earn time in lieu or an extra variable performance bonus (when working after hours/weekends, etc)
· Fast-growing company, amazing team, great culture.","{""role_summary"":""A Network Security Consultant is responsible for delivering services to clients in an effective, proficient, and agile manner, primarily focusing on recovering infrastructure and systems from serious Cybersecurity incidents."",""key_terms"":[{""term"":""Cyber Incident Remediation and Restoration (CIRRT)"",""explanation"":""A team that responds to and recovers from security incidents.""},{""term"":""System Administration"",""explanation"":""The process of managing and maintaining computer systems, including installation, configuration, and troubleshooting.""},{""term"":""Network Architect"",""explanation"":""A professional responsible for designing and building computer networks, including local area networks (LANs), wide area networks (WANs), and the Internet.""},{""term"":""Ransomware post-breach remediation"",""explanation"":""The process of responding to and recovering from ransomware attacks, including restoring systems and data.""}],""skill_priorities"":{""must_have"":[""7+ years of senior technical support, system administration or related customer facing role"",""System Administration and Network Architect hands-on skills"",""Strong experience working in the field"",""Ability to communicate to all levels of stakeholders"",""Strong hands-on capabilities with various security tool-sets"",""Knowledge of Windows environment, including Windows Service and Workstation"",""Knowledge of Active Directory, VMWare ESX/HyperV, and network protocols""],""nice_to_have"":[""Experience supporting hybrid environments"",""Experience supporting security applications such as AV, VPN, Firewall, proxy"",""Linux troubleshooting experience"",""Experience with troubleshooting Windows and Mac"",""MCP or higher"",""Unix/Linux experience"",""Macintosh knowledge and troubleshooting experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with system administration and network architecture in a cybersecurity incident response scenario?"",""example_answer"":""In my previous role, I worked on a team that responded to a ransomware attack on a client's network. I was responsible for rebuilding the network infrastructure and restoring system functionality. I utilized my knowledge of Active Directory and VMWare ESX to troubleshoot and resolve issues.""},{""question"":""How do you stay current with emerging threat trends and new security tools and technologies?"",""example_answer"":""I regularly attend industry conferences and webinars, and I participate in online forums and discussion groups to stay informed about the latest developments in cybersecurity. I also make time for self-study and training to ensure my skills are up-to-date.""}],""red_flags"":[""Lack of hands-on experience with security tool-sets"",""Inability to communicate technical information to non-technical stakeholders"",""Limited experience with network protocols and architectures""],""confidence_score"":90.0}"
Data Analyst,"About KOHO

KOHO’s purpose is to empower Canadians to build a great financial foundation with products that are radically transparent and easy to manage. We first launched in 2017, and we have since built a community of over 1 million users . Leading investors around the globe believe in our vision, and we’ve successfully raised over $320M to make our vision a reality.

Discover our culture here and get the inside scoop from our team here !

About The Role

KOHO is seeking a highly motivated Data Analyst to collaborate with various departments in leveraging data for informed decision-making. If you thrive on automating reports, building pipelines in DBT, crafting dashboards, and extracting actionable insights from financial data, this role is tailored for you. As part of our team, you will immerse yourself in writing SQL queries, collaborating with technical teams and Product Managers building our features, and engaging in consultative sessions with stakeholders across the business.

What You'll Do

Analyze new and existing data sources to develop accurate and insightful reports.
Build data pipelines in DBT to power our reporting
Perform in-depth analysis of product data to drive strategic decision-making.
Prioritize and manage incoming data requests effectively within your workflow.
Collaborate closely with other members of the data team to execute projects and uphold the integrity of our data warehouse as the cornerstone of truth at KOHO.
Be immersed in a tech pod. Participate in the feature development process from requirements to product launches. Collaborate with software engineers to ensure the data collected meets reporting needs

Who You Are

Proven experience in a data analyst role, with a focus on data modelling
Proficiency in SQL for data manipulation, including self-joins, window functions, and parameter usage.
Demonstrated experience with dbt from previous roles.
Quick grasp of business concepts, metrics, and KPIs.
Well-organized with excellent time management skills.
Bonus: Experience working with Product teams

At KOHO, we are dedicated to providing pay transparency to all candidates. Compensation at KOHO is determined through various factors including but not limited to: comparable salary market data within Canada, technical skill assessment, a holistic view of previous work history, and internal pay equity with other KOHO team members.

Target Base Salary Range

$83,000 — $95,000 CAD

What's In It For You?

We Invest Time And Resources Into Making Sure KOHO Is As Good As The People We Hire. Here Are Some Of The Reasons We Attract The Best People

🧘‍♂️ Balance Your Life - Company-wide summer wellness days, winter holiday closure, personal days, a wellness spending account, and maternity & parental leave top-up

💻 Remote First - Work from anywhere in Canada with a budget to set up your home office

🆙 Level Up - Access to an in-house certified performance coach and an annual training budget

🥅 Reach Your Goals - Salary assessments twice per year

🙌 The KOHO Culture - We have won 7 ""Great Place to Work ®"" awards since 2019

🤝 Be an Owner - Every KOHO employee gets a generous amount of equity with a 10 year exercise window

The KOHO culture is one of collaboration, creativity, and diverse perspectives. We are committed to building and fostering an inclusive, accessible environment for everyone. If you have any questions, concerns, or requests regarding accessibility needs, please contact peopleaccessibility@koho.ca and the People and Culture team will be happy to help.","{""role_summary"":""Collaborate with various departments to leverage data for informed decision-making, automating reports, building pipelines, and extracting actionable insights from financial data."",""key_terms"":[{""term"":""DBT"",""explanation"":""A data transformation tool used to build data pipelines and power reporting.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational database management systems.""},{""term"":""Data Modelling"",""explanation"":""The process of creating a conceptual representation of data structures and relationships to support business intelligence and analytics.""}],""skill_priorities"":{""must_have"":[""Proven experience in a data analyst role"",""Proficiency in SQL"",""Demonstrated experience with dbt"",""Quick grasp of business concepts, metrics, and KPIs"",""Well-organized with excellent time management skills""],""nice_to_have"":[""Experience working with Product teams""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a data pipeline in DBT to power reporting?"",""example_answer"":""I would start by identifying the data sources and requirements, then design and implement the pipeline using DBT's transformation capabilities, ensuring data quality and integrity.""},{""question"":""How do you stay organized and manage multiple data requests effectively?"",""example_answer"":""I prioritize tasks based on urgency and impact, break down complex requests into manageable tasks, and maintain open communication with stakeholders to ensure timely delivery.""}],""red_flags"":[""Lack of experience with data modelling and SQL"",""Inability to work collaboratively with technical teams and stakeholders""],""confidence_score"":90.0}"
Business Data Analyst,"Role: Business Data Analyst
Location: Toronto Canada ( 3 days onsite/week)
Duration: Fulltime

JD:
Understanding the process of auto ingestion and its validation
Building a strategic platform on Azure from the legacy systems
Experience in Data mapping and doing it in a more efficient way and if anything has been done wrong in the source system then get it corrected
Analyse the data what is being done today and how it can be further improved for future
Streamline the data so that it can be used simultaneously at multiple places
Make sure data completion and data accuracy checks have been done on datasets bringing out to cloud platforms
Experience in SQL server and PySpark as legacy system has SQL and strategic platform has PySpark
Experience working in confluence
Experience working on Azure Databricks
Tech stacks for legacy and strategic platform are as below:
Skill required.
Storage - SQL
ETL - SSIS, Stored Procedures
Data type – most batch (ASCII and EBCIDIC)

Must Have :
Data centric project (retail banking/fraud/AML) / work packages for Tier 2-4, low to moderate risk and regulatory projects with multiple stakeholders and across multiple LoB
Advanced to expert knowledge of capital markets products, regulatory reporting, business systems analysis, project delivery practices and standards across the project life-cycle
Data profiling of large datasets using tools like Python notebooks, SQL, MS Excel is a major plus.
Gain/acquire sound to advanced understanding of business and user interaction with technology throughout project delivery
Works independently as the senior or lead business analyst and coaches and guides members within area of expertise
Identifies and leads problem resolution for complex issues at all levels
Contributes to the communication and change management activities across multiple stakeholders
Undergraduate degree (technical or finance discipline)
Azure certification is an asset
Basic python knowledge (data analysis/profiling) is an asset.
5-7 years related business analysis experience


Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. For more information, visit www.genpact.com . Follow us on Twitter, Facebook, LinkedIn, and YouTube.



Best Regards
Kavirala Sandeep Kumar
Talent Acquisition
E: Sandeep.Kavirala@genpact.com
Cell : 713-354-9580
www.Genpact.com","{""role_summary"":""The Business Data Analyst will analyze and improve data processes, build a strategic platform on Azure, and ensure data accuracy and completion. The role involves working with various stakeholders to deliver projects and coach team members."",""key_terms"":[{""term"":""Auto ingestion"",""explanation"":""Automated process of collecting and processing data from various sources.""},{""term"":""Data mapping"",""explanation"":""The process of matching data fields from different systems to ensure consistency and accuracy.""},{""term"":""PySpark"",""explanation"":""A Python library for big data processing and analytics.""},{""term"":""Azure Databricks"",""explanation"":""A cloud-based platform for working with big data and analytics.""},{""term"":""Confluence"",""explanation"":""A collaboration tool for teams to share knowledge and work together.""}],""skill_priorities"":{""must_have"":[""Data centric project experience"",""Advanced knowledge of capital markets products"",""Regulatory reporting"",""Business systems analysis"",""Project delivery practices"",""SQL server"",""PySpark"",""Azure Databricks"",""Confluence""],""nice_to_have"":[""Azure certification"",""Basic python knowledge"",""Data profiling using Python notebooks, SQL, MS Excel""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the process of auto ingestion and its validation?"",""example_answer"":""Auto ingestion involves collecting data from various sources and validating it to ensure accuracy and consistency. This process involves data mapping, data profiling, and data quality checks to ensure that the data is reliable and usable.""},{""question"":""How do you streamline data for simultaneous use at multiple places?"",""example_answer"":""I would analyze the data requirements of each stakeholder and identify the common data elements. Then, I would design a data architecture that allows for efficient data sharing and reuse, ensuring data consistency and accuracy.""}],""red_flags"":[""Lack of experience in data centric projects"",""Limited knowledge of capital markets products and regulatory reporting"",""Inability to work independently as a senior or lead business analyst""],""confidence_score"":90.0}"
Data Analyst (Python),"About: Selby Jennings has partnered with a leading Global trading firm to bring on a Data Analyst to support the Event Analysis and Insights team and work on the analysis of post event data, reports and providing insight.

Qualifications:
3+ YOE of relevant professional experience in data analysis
Exceptional attention to detail and data gathering skills
Bachelor’s degree in a related field - Economics, Finance, Information Technology, or Computer Science
Strong knowledge of Python for data manipulation and visualization

Responsibilities:
Analyze non-financial post event data in order to gain insight and discover potential issues.
Create reports and visualizations to help bring forward relevant information to the stake holders.
Collaborate with the development team to improve and create the necessary analysis tools.
Creating issue tickets and following up with the appropriate teams.
Participate in the research effort revolving around the trade strategies.
Develop necessary scripts for data gathering and manipulation.

This is a full-time, Direct hire opportunity-- No C2C!","{""role_summary"":""Support the Event Analysis and Insights team by analyzing post-event data, creating reports, and providing insights to stakeholders."",""key_terms"":[{""term"":""Post-event data"",""explanation"":""Data collected after an event, used to gain insights and identify potential issues.""},{""term"":""Data manipulation"",""explanation"":""The process of transforming and preparing data for analysis, often using programming languages like Python.""},{""term"":""Data visualization"",""explanation"":""The process of creating graphical representations of data to help stakeholders understand and interpret the information.""}],""skill_priorities"":{""must_have"":[""Python"",""Data analysis"",""Data manipulation"",""Data visualization""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to analyze complex data to identify trends or issues?"",""example_answer"":""In my previous role, I analyzed customer purchase data to identify patterns and trends, which helped inform marketing strategies.""},{""question"":""How do you ensure the accuracy and quality of your data analysis?"",""example_answer"":""I use a combination of data validation techniques and quality control checks to ensure the accuracy and quality of my data analysis.""}],""red_flags"":[""Lack of experience with Python or data manipulation and visualization.""],""confidence_score"":90.0}"
BI & Data Analyst,"Why join us?

Are you looking to join an innovative, global real estate company who builds communities and connects people to exceptional places? If so, we would love to tell you our story.

At Oxford, our culture is truly one of a kind. Across business lines and around the world, we embrace the complex and tackle opportunities with speed and agility. We are ambitious and humble, forward looking and service-focused. We get stuff done, and have fun doing it! We take great pride in contributing to the communities where we live. We believe that what is good for the environment is good for business. Together we deliver exceptional experiences to our over 2 million daily customers.

We are looking for a highly motivated BI & Data Analyst to join the Financial Systems Team in Toronto. This role will report to the Senior Manager, Financial Systems and be responsible for acting as a business partner to our finance stakeholders, performing data analysis using a wide variety of applications (including Power BI, Power Platform, UiPath and SQL), and driving automation efforts within the Finance team. To succeed in this role, candidates must be able to drive project completion with strong communication and project management, combined with experience in data analytics, big data mining, and data flow & structure. This role will require effective customer service management, with a proven ability to build relationships between the business groups, financial team and IT department, while being able to multitask in a complex environment.

As a member of this team, you will

Collaborate with management teams to prioritize business, analytics and information needs and understand project requirements
Work with financial and operational data from primary or secondary data sources from different stakeholder teams and business functions
Seek efficiencies in existing processes and execute process improvement initiatives, including exploring and identifying potential new tools and technologies for enhancing reporting automation capabilities
Identify, analyze, interpret, and report on trends or patterns in complex data sets
Exploring large data sets and drawing meaningful conclusions and insights, including identifying critical metrics and KPIs
Filter and “clean” data by reviewing extracts, reports, printouts, and performance indicators to identify, troubleshoot and resolve problems, including data quality, integrity issues and follow data governance policies
Assist with the preparation and development of reporting, presentations and various materials for discussion at the executive level

To succeed in this role, you have

Undergraduate degree in Accounting, Mathematics, Computer Science or a related field.
Have a minimum of 1-2 years of demonstrated experience in a similar role (e.g. Data Analyst or BI Data Analyst).
Team oriented individual with strong communication skills, who is comfortable engaging with different groups within the organization (including non-technical audiences).
Strong project management and organizational skills and ability to work under pressure and manage high priority projects with multiple or competing deadlines.
Willingness to learn new technologies, including RPA, with a strong inclination to improve processes and not settle for ‘status quo’ to generate efficiencies and improve capabilities.
Experience with UiPath Studio, Power Platform, Power BI, SQL, and advanced Excel functionality (including Power Query, VBA) to develop automation solutions. Experience with other BI Tools an asset.
Technical expertise in data mining and analysis, with an understanding of financial reporting concepts.
Demonstrate strong problem-solving skills and innovative approaches for resolution.

Our story

Oxford Properties Group (“Oxford”) is a leading global real estate investor, asset manager and business builder. It builds, buys, and grows defined real estate operating business with world-class management teams. Established in 1960, Oxford and its portfolio companies manage approximately C$87 billion of assets across four continents on behalf of their investment partners. Oxford’s owned portfolio encompasses office, logistics, retail, multifamily residential, life sciences, hotels, alternatives and credit in global gateway cities and high-growth hubs. A thematic investor with a committed source of capital, Oxford invests in properties, portfolios, development sites, debt, securities, and real estate businesses across the risk-reward spectrum. Together with its portfolio companies, Oxford is one of the world’s most active developers with over 80 projects currently underway globally across all major asset classes. Oxford is owned by OMERS, the Canadian defined benefit pension plan for Ontario's municipal employees.

For more information on Oxford, visit www.oxfordproperties.com

OMERS is committed to having a workforce that reflects the communities in which we live and work. We are an equal opportunity employer committed to a barrier-free recruitment and selection process. At OMERS inclusion and diversity means belonging. How we create a sense of belonging is through our employees and our vast network of Employee Resource Groups. Whether you are passionate about gender, pride, or visible minorities, we have groups that are focused on making a difference in all of our lives.","{""role_summary"":""Act as a business partner to finance stakeholders, performing data analysis and driving automation efforts within the Finance team, while providing exceptional customer service and building relationships between business groups, financial teams, and IT departments."",""key_terms"":[{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""UiPath"",""explanation"":""A software company that specializes in robotic process automation (RPA) and artificial intelligence (AI).""},{""term"":""SQL"",""explanation"":""A standard language for managing relational databases, used for storing, manipulating, and retrieving data.""},{""term"":""RPA"",""explanation"":""Robotic Process Automation, a technology that allows organizations to automate repetitive tasks by using software robots.""},{""term"":""Data mining"",""explanation"":""The process of automatically discovering patterns or relationships in large datasets, often using machine learning or statistical techniques.""},{""term"":""Data governance"",""explanation"":""The practices and policies that ensure the quality, security, and integrity of an organization's data assets.""}],""skill_priorities"":{""must_have"":[""Undergraduate degree in Accounting, Mathematics, Computer Science or a related field"",""1-2 years of demonstrated experience in a similar role"",""Strong communication skills"",""Project management and organizational skills"",""Experience with UiPath Studio, Power Platform, Power BI, SQL, and advanced Excel functionality""],""nice_to_have"":[""Experience with other BI Tools"",""Technical expertise in data mining and analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to analyze complex data sets and draw meaningful conclusions?"",""example_answer"":""In my previous role, I was tasked with analyzing customer purchase behavior. I used Power BI to create interactive visualizations and identified a trend that led to a 10% increase in sales. I presented my findings to the executive team, and we implemented changes to our marketing strategy as a result.""},{""question"":""How do you stay organized when working on multiple projects with competing deadlines?"",""example_answer"":""I prioritize tasks using the Eisenhower Matrix and break down large projects into smaller, manageable chunks. I also use project management tools like Asana to track progress and collaborate with team members.""}],""red_flags"":[""Lack of experience with automation tools like UiPath"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Data Analyst specialist,"About TCS
TCS operates on a global scale, with a diverse talent base of more than 600,000 associates representing 153 nationalities across 55 countries. TCS has been recognized as a Global Top Employer by the Top Employers Institute - one of only eight companies worldwide to have achieved this status. Our organizational structure is domain-led and designed to offer businesses a single window into industry-specific solutions. Our agile industry units have embedded capabilities to enable rapid responses that provide a competitive edge to our customers. This, coupled with a unique Global Network Delivery Model™ (GNDM™), is recognized as the current benchmark of excellence in technology deployment. We have made significant investments in digital technology, horizontal, and vertical platforms, allowing us to successfully serve our clients for over 50 years.
Required Skills and Responsibilities:
•Data cleaning and preparation
•Filtering the historical data, handling different values and preparing data set for analysis
•Data exploration - Use statistical tools and techniques to explore and analyze data, identify patterns, relationships and trends.
•Data Visualization -- create visual representation of data using graphs and charts.
•Reporting - prepare reports and presentations to communicate insights and findings.
•Collaboration with business and technology
•Technical skills Microsoft Excel Power BISQL, Python
•Critical thinking, communication, team skills
Tata Consultancy Services Canada Inc. is committed to meeting the accessibility needs of all individuals in accordance with the Accessibility for Ontarians with Disabilities Act (AODA) and the Ontario Human Rights Code (OHRC). Should you require accommodations during the recruitment and selection process, please inform Human Resource
Thank you for your interest in TCS. Candidates that meet the qualification for this position will be contacted within a 2-week period. We invite you to continue to apply for other opportunities that match your profile.","{""role_summary"":""The Data Analyst role is responsible for preparing and analyzing data to identify trends and insights, and communicating findings to stakeholders through reports and visualizations."",""key_terms"":[{""term"":""Data Visualization"",""explanation"":""Creating graphical representations of data to help stakeholders understand complex information.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing data in relational database management systems.""}],""skill_priorities"":{""must_have"":[""Microsoft Excel"",""Power BI"",""SQL"",""Python""],""nice_to_have"":[""Critical thinking"",""Communication"",""Team skills""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you handle missing or inconsistent data during the data preparation process?"",""example_answer"":""I would use data profiling techniques to identify missing or inconsistent data, and then use data imputation methods such as mean or median imputation to fill in the gaps. I would also document the process and communicate the assumptions made to stakeholders.""},{""question"":""Can you explain a time when you had to communicate complex data insights to a non-technical stakeholder?"",""example_answer"":""In my previous role, I had to present data insights to a marketing team. I created interactive dashboards using Power BI and focused on telling a story with the data, using simple language and avoiding technical jargon. The stakeholders were able to understand the insights and make informed decisions.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Senior Data Analyst,"Looking for Experience in B2B Digital Analytics.

Job Responsibilities:
Partner with analytics teams of leading digital businesses, to design & deliver high-impact analytics solutions to a variety of business problems spanning product, marketing and customer insights
Structure and analyze major business and customer questions through a hypothesis-driven approach
Translate business objectives into actionable analysis and own end-to-end analytics, and effectively communicate complex analytics to a broader audience in writing and presentation formats
Create insightful automated dashboards and data visualizations to track key business metrics
Be an effective execution as well as thought partner to clients, being equally comfortable in taking a 30,000-ft view of business problems as well as get involved in the minutiae of data wrangling and analysis

Mandatory Skills and Qualifications:
3-8 years’ experience in core analytics
Strong hands-on SQL, Forecasting, Data Science/Machine Learning
Good amount of B2B Experience
Stakeholder Management Experience
Experience in R/Python, scripting & automation, visualization tools like Tableau a plus.
Strong communication skills, written and verbal; ability to present data and its implications in a clear, concise manner.
Strong research and analytical mindset and extremely detail-oriented
Self-motivated, energetic, ""can-do"" attitude in a fast-paced environment
Ability to manage priorities across multiple stakeholders

At LatentView Analytics, we value a diverse, inclusive workforce and we provide equal employment opportunities for all applicants and employees. All qualified applicants for employment will be considered without regard to an individual’s race, color, sex, gender identity, gender expression, religion, age, national origin or ancestry, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, genetic information, military or veteran status, or any other basis protected by federal, state or local laws.","{""role_summary"":""Partner with analytics teams to design and deliver high-impact analytics solutions to various business problems, translating business objectives into actionable analysis and communicating complex analytics to a broader audience."",""key_terms"":[{""term"":""Hypothesis-driven approach"",""explanation"":""A method of analysis that involves formulating a hypothesis and testing it using data to draw conclusions.""},{""term"":""Data wrangling"",""explanation"":""The process of cleaning, transforming, and preparing data for analysis.""},{""term"":""Data visualization"",""explanation"":""The process of creating graphical representations of data to communicate insights and trends.""},{""term"":""R/Python"",""explanation"":""Programming languages used for data analysis, machine learning, and visualization.""},{""term"":""Tableau"",""explanation"":""A data visualization tool used to create interactive dashboards and reports.""}],""skill_priorities"":{""must_have"":[""SQL"",""Forecasting"",""Data Science/Machine Learning"",""B2B Experience"",""Stakeholder Management Experience"",""Strong communication skills"",""Research and analytical mindset"",""Self-motivated, energetic attitude""],""nice_to_have"":[""R/Python"",""Scripting & automation"",""Visualization tools like Tableau""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for structuring and analyzing complex business problems?"",""example_answer"":""I would start by identifying the key business objectives and then formulate a hypothesis-driven approach to analyze the problem. I would use tools like SQL and data visualization to extract insights and communicate them effectively to stakeholders.""},{""question"":""How do you ensure that your analytics solutions are actionable and impactful for clients?"",""example_answer"":""I would work closely with clients to understand their business objectives and develop solutions that address their specific needs. I would also ensure that my solutions are data-driven, actionable, and effectively communicated to stakeholders.""}],""red_flags"":[""Lack of experience in B2B digital analytics"",""Inability to communicate complex analytics to non-technical stakeholders""],""confidence_score"":90.0}"
"Analyst, Data Analytics","Canadian Pacific (CP) and Kansas City Southern (KCS) are now CPKC. As the only truly North American railway, we are making big moves! Drawing on our strong foundations and heritage, CPKC moves essential goods across our 20,000-mile network to support economic growth throughout Canada, the U.S. and Mexico. Be a part of history as we connect a continent and create exciting career opportunities across our new transnational network. Visit cpkcr.com to learn about the CPKC advantage, our purpose and culture

PURPOSE OF THE POSITION:

The Analyst, Data Analytics (internally called Specialist, Data Analytics) is responsible for delivering Internal Audit’s data analytics roadmap and supporting completion of the annual audit plans. The successful candidate will work closely with the Internal Audit team and stakeholders across the organization to provide analytics insight on multiple audit engagements and build-out our continuous assurance program. This role will report to the Director, IS Internal Audit and does not have any direct reports.

POSITION ACCOUNTABILITIES:

The successful candidate will perform the following activities
Creatively work with multiple tools to manage and analyze large volumes of data from multiple sources
Work with IA leadership to consistently advance our continuous assurance program
Provide analytics support during planning, execution and reporting phases of audit engagements
Take leadership on audit engagements with a significant data component
Support the development and maintenance of IA’s risk monitoring dashboards
Offer coaching to progressively improve data literacy of the broader audit team
Maintain and develop competencies in advanced analytics, process automation and artificial intelligence
Maintain objectivity and independence while fostering positive and professional relationships with Management
Maintain skills and knowledge through education, training, internal and external partners, colleagues and information sources
Promote innovation within Internal Audit and provide leadership on the use of AI, Machine Learning and similar technologies
Develop knowledge of the railroad and industry/CPKC specific processes and technologies.
Support IA software in the “Super User"" capacity

POSITION REQUIREMENTS:

University degree in Business, Data Science, Computer Science or related field
2+ years of data analytics experience. Audit and/or risk management related experience would be considered as a significant additional asset.
Solid understanding of a combination of ETL and data visualization
Established analytical, investigative, problem-solving and root cause identification skills
Excellent verbal and written communication capabilities with technical and non-technical audiences
Must be both team oriented and able to work independently with limited supervision
Desire to drive change and innovation

WHAT CPKC HAS TO OFFER:

Flexible and competitive benefits package
Competitive company pension and/or retirement plans
Employee Share Purchase Plan
Performance Incentive Program
Annual Fitness Subsidy
Part-time Studies Program

ADDITIONAL INFORMATION:

As an employer with North American presence, the possibility does exist that the location of your position may be changed based on organizational requirements. (Canada and US all Non-Union positions only)

Drug Test Elements:

CPKC is committed to the safety and health of its employees and the general public. New hires may be required to undergo a drug screen. We appreciate your cooperation in keeping CPKC safe and drug free.

Background Investigation:

The successful candidate will need to successfully complete the following clearances:

Criminal history check
Reference check
Background checks that may included 7 years of employment history and Social Security number verification

Management Conductor Program:

Becoming a qualified conductor or locomotive engineer is the single best way for a management employee to learn the business at CPKC. You may be required to obtain a certification or to maintain your current certification/qualification as a conductor or locomotive engineer.

For our US applicants, CPKC is an equal opportunity/affirmative action employer, inclusive of protected veterans and individuals with disabilities. For Canadian applicants CPKC is an employment equity employer committed to the principles of employment equity and inclusion. We encourage all qualified candidates to apply including women, Black, Indigenous, People of Colour (BIPOC), members of the LGBTQ+ community, and people with disabilities. Accommodations for the job application process can be provided, as appropriate, upon request. All applicant information will be managed in accordance with the federal Personal Information Protection and Electronic Documents Act (PIPEDA).

Req ID: 103037
Department: Finance & Accounting
Job Type: Full-Time
Position Type: Non-Union
Location: Calgary, Alberta
Country: Canada
% of Travel: None
# of Positions: 1
Job Grade: 4
Job Available to: Internal & External","{""role_summary"":""The Analyst, Data Analytics is responsible for delivering Internal Audit's data analytics roadmap, supporting audit plans, and providing analytics insights across the organization."",""key_terms"":[{""term"":""Data Analytics"",""explanation"":""The process of extracting insights from large datasets to inform business decisions.""},{""term"":""Continuous Assurance"",""explanation"":""An ongoing process of monitoring and evaluating internal controls to ensure their effectiveness.""},{""term"":""ETL (Extract, Transform, Load)"",""explanation"":""A process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system for analysis.""},{""term"":""Artificial Intelligence (AI) and Machine Learning"",""explanation"":""Technologies used to develop predictive models and automate decision-making processes.""}],""skill_priorities"":{""must_have"":[""University degree in Business, Data Science, Computer Science or related field"",""2+ years of data analytics experience"",""Solid understanding of ETL and data visualization"",""Analytical, investigative, problem-solving and root cause identification skills"",""Excellent verbal and written communication capabilities""],""nice_to_have"":[""Audit and/or risk management related experience"",""Desire to drive change and innovation""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a large dataset to identify trends and insights?"",""example_answer"":""I would first extract the data from multiple sources, then transform it into a standardized format using ETL tools. Next, I would apply data visualization techniques to identify trends and patterns, and finally, I would analyze the results to draw meaningful insights.""},{""question"":""How do you stay current with advancements in AI and Machine Learning, and how do you see these technologies being applied in an audit context?"",""example_answer"":""I regularly read industry publications and attend conferences to stay current with AI and ML advancements. In an audit context, I believe these technologies can be used to automate routine tasks, identify anomalies, and provide predictive insights to inform audit decisions.""}],""red_flags"":[""Lack of experience with ETL and data visualization tools"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Data Analyst (SAS),"Data Analyst (SAS)
Location: Toronto, Canada - Hybrid 1x/week
Contract: 1 year Contract (+extension)

One of our Fortune 500 clients in the Banking Industry is looking for a SAS Developer/SQL Analyst to join their team.

Data Analytics & Reporting
Understands and articulates the business case of business questions and the estimated value being delivered. Designs dashboards and analyzes to be performed, and appropriate visualization and analytics tools to use. Identifies trends and patterns to address identified business questions and provide insights through reporting and data visualization techniques. Works with other data and analytics professionals to optimize, refine, automate and scale analysis into repeatable analytics solutions and decision support tools.

Builds various reporting dashboards using the most appropriate data extraction, data cleaning and data visualization techniques.
Provides value through insights, reporting and data visualization techniques. Selects, configures and implements analytics solutions for consistency and repeatability.
Researches and applies continuous improvement in data visualization by identifying trends and patterns to transform raw data into actionable business insights.
Works with different teams, management and stakeholders to enhance the usability and aesthetic appeal of data analytics solutions deployed in the organization.
Translates business needs to technical specifications and evaluates existing data visualization systems in order to improve them.
Develops data visualizations of ""large"" amounts of data that facilitate the intuitive presentation of data to decision makers.
Documents data flow, systems and processes to improve the design, implementation and management of business/group processes.
Develops tools and delivers training programs for use of reporting tools and self-serve analytics by non-analytical end users; may include delivery of training to audiences.
Focus is primarily on business/group within BMO; may have broader, enterprise-wide focus.
Exercises judgment to identify, diagnose, and solve problems within given rules.
Works independently on a range of complex tasks, which may include unique situations.
Broader work or accountabilities may be assigned as needed.

Qualifications:
Key Skills:
SQL Queries to pull and combine data – There will be a test.
SAS Queries to pull and transform data.
SSRS/Visual studio/Power BI experience for report building.
Foundational level of proficiency:
Technical design optimization.
Decision Making.
Systems Thinking.
Data visualization.
Data storytelling.
Data mining.
Illustration.
Creative thinking.
Problem Solving.
Intermediate level of proficiency:
Insights design.
Insights development and reporting.
Verbal & written communication skills.
Collaboration & team skills.
Technical proficiency gained through education and/or business experience.

ABOUT EIGHT ELEVEN:
At Eight Eleven, our business is people. Relationships are at the center of what we do. A successful partnership is only as strong as the relationship built. We’re your trusted partner for IT hiring, recruiting and staffing needs.
For over 16 years, Eight Eleven has established and maintained relationships that are designed to meet your IT staffing needs. Whether it’s contract, contract-to-hire, or permanent placement work, we customize our search based upon your company's unique initiatives, culture and technologies. With our national team of recruiters placed at 21 major hubs around the nation, Eight Eleven finds the people best-suited for your business. When you work with us, we work with you. That’s the Eight Eleven promise.

Eight Eleven Group provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws.","{""role_summary"":""A Data Analyst (SAS) responsible for designing dashboards, analyzing data, and providing insights to address business questions, with a focus on data visualization and reporting."",""key_terms"":[{""term"":""SAS"",""explanation"":""A software suite used for data management, predictive analytics, and business intelligence.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational database management systems.""},{""term"":""SSRS"",""explanation"":""SQL Server Reporting Services, a reporting software used to create and manage reports.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that provides interactive visualizations and business intelligence capabilities.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to communicate information and insights.""},{""term"":""Data Storytelling"",""explanation"":""The process of communicating insights and findings from data analysis using a narrative approach.""}],""skill_priorities"":{""must_have"":[""SQL Queries"",""SAS Queries"",""SSRS/Visual studio/Power BI experience"",""Data visualization"",""Data storytelling""],""nice_to_have"":[""Technical design optimization"",""Decision Making"",""Systems Thinking"",""Data mining"",""Illustration"",""Creative thinking"",""Problem Solving"",""Insights design"",""Insights development and reporting"",""Verbal & written communication skills"",""Collaboration & team skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach designing a dashboard to address a specific business question?"",""example_answer"":""I would start by understanding the business question and identifying the key metrics that need to be tracked. Then, I would select the most appropriate data visualization tools and techniques to effectively communicate the insights. Finally, I would iterate on the design based on feedback from stakeholders to ensure the dashboard meets their needs.""},{""question"":""How do you stay up-to-date with new trends and tools in data visualization?"",""example_answer"":""I regularly follow industry blogs and attend webinars to stay current with the latest developments in data visualization. I also experiment with new tools and techniques to expand my skillset.""}],""red_flags"":[""Lack of experience with SAS or SQL"",""Inability to communicate complex data insights effectively"",""Limited experience with data visualization tools""],""confidence_score"":90.0}"
BI Analyst,"About Fusemachines

Fusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 400 full-time employees). Fusemachines seeks to bring its global expertise in AI to transform companies around the world.

About The Role

As a Business Intelligence Engineer, you will play a pivotal role in leveraging data to drive strategic decisions and enhance operational efficiency. You will be responsible for designing, developing, and maintaining PowerBI dashboards and reports that provide valuable insights to various stakeholders across the organization. Your work will directly contribute to optimizing business processes and improving customer experiences.

This is a remote role on a contract basis.

Qualification & Experience

Bachelor's or master's degree in a quantitative field such as statistics, mathematics, or computer science
At least 4 years of experience in data analytics, with a focus on business intelligence and data visualization

Required Skills/Competencies

Proven experience as a PowerBI Developer or similar role, with a strong portfolio showcasing impactful dashboards and reports
Proficiency in SQL for data extraction, transformation, and manipulation
Solid understanding of data modeling concepts and experience in designing efficient data models
Strong analytical and problem-solving skills, with the ability to translate business requirements into technical solutions
Excellent communication and collaboration skills, with the ability to work effectively in cross-functional teams
Experience with other BI tools (e.g., Tableau) is a plus

Roles and Responsibilities

Collaborate with cross-functional teams to understand business requirements and translate them into actionable insights using SQL and PowerBI
Develop visually appealing and interactive dashboards and reports to effectively communicate key performance indicators (KPIs), trends, and anomalies
Optimize data models and queries to ensure efficient performance and scalability of PowerBI solutions
Implement best practices for data visualization, ensuring clarity, consistency, and usability for end users
Work closely with data engineers to integrate data from various sources and maintain data accuracy and integrity
Provide training and support to end users to maximize adoption and utilization of PowerBI tools
Stay updated on industry trends and advancements in data visualization and analytics technologies, recommending improvements and innovations as appropriate
Collaborate with IT teams to ensure compliance with data security and governance policies

Fusemachines is an Equal Opportunities Employer, committed to diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or any other characteristic protected by applicable federal, state, or local laws.

Powered by JazzHR

2Nx0znfcUN","{""role_summary"":""As a Business Intelligence Engineer, you will design, develop, and maintain PowerBI dashboards and reports to drive strategic decisions and enhance operational efficiency."",""key_terms"":[{""term"":""PowerBI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""Data Modeling"",""explanation"":""The process of creating a conceptual representation of data structures to organize and standardize data for efficient storage and retrieval.""},{""term"":""SQL"",""explanation"":""A standard programming language used for managing and manipulating data in relational database management systems.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to communicate information and insights more effectively.""}],""skill_priorities"":{""must_have"":[""PowerBI development"",""SQL proficiency"",""Data modeling"",""Analytical and problem-solving skills"",""Communication and collaboration skills""],""nice_to_have"":[""Experience with other BI tools (e.g., Tableau)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize a PowerBI dashboard for better performance and scalability?"",""example_answer"":""I would analyze the data model and queries to identify bottlenecks, then apply best practices for data visualization and optimization techniques to improve the dashboard's performance and scalability.""},{""question"":""How do you ensure data accuracy and integrity in your PowerBI solutions?"",""example_answer"":""I work closely with data engineers to integrate data from various sources, and implement data validation and quality control checks to ensure data accuracy and integrity.""}],""red_flags"":[""Lack of experience with PowerBI development"",""Inability to communicate technical solutions to non-technical stakeholders""],""confidence_score"":90.0}"
Marketing Data Analyst,"Must-haves
- Experience building reports from data in Adobe Analytics technologies
- Knowledge of Adobe back-end segments to identify data discrepancies and flag any issues (ie. Duplicate data)
- Strong Experience with Python
- Hands-on experience writing complex SQL queries and a strong understanding of data quality and complexity – Most important
- Hands-on experience using visualization tools such as Tableau, PowerBI, or Looker to develop reports for various business stakeholders
- Experience using analytics tools to transform data-driven results into actional insights through storytelling

Plusses
- Hands-on experience using BigQuery
- Experience working within eCommerce and knowledge of pre and post-sale data structures
- Previous exposure to a loyalty program
- Ability to make recommendations and next steps based on the data

Day-to-Day
Insight Global is looking for a Marketing Analyst to join the team with one of our largest retail clients in the Greater Toronto Area on a 12-month contract. The selected candidate will be responsible for the following:

- Maintain the accuracy of weekly automated dashboards for the Digital Marketing team. Ensure any supporting documents such as marketing spend tracker and marketing KPI plans are updated and accurate for dashboard automation. Execute and coordinate new automation requests or changes with the automation team.
- Using analytic tools, transform data-driven results into actionable insights through storytelling. Consolidate data into easy-to-understand reports for presentation.
- Highlight and explain discrepancies in data and correct as required.
- Monthly report of data validation/governance
- Support with data pulls related to weekly performance dashboards, campaign performance, voucher activities, or test-and-learn initiatives.
- Ability to complete work functions using Adobe Analytics, Google Analytics, Big Query, SQL, MS Excel, and PowerPoint.","{""role_summary"":""The Marketing Analyst is responsible for maintaining accurate weekly dashboards, transforming data into actionable insights, and identifying discrepancies in data. The role requires strong technical skills in analytics tools and programming languages."",""key_terms"":[{""term"":""Adobe Analytics"",""explanation"":""A tool used to analyze and report on website and mobile app data.""},{""term"":""Back-end segments"",""explanation"":""A feature in Adobe Analytics that allows for the creation of custom data segments.""},{""term"":""BigQuery"",""explanation"":""A cloud-based data warehousing and analytics platform.""},{""term"":""Data governance"",""explanation"":""The process of ensuring the accuracy, quality, and security of an organization's data.""},{""term"":""Tableau/PowerBI/Looker"",""explanation"":""Data visualization tools used to create interactive dashboards and reports.""}],""skill_priorities"":{""must_have"":[""Adobe Analytics"",""Python"",""SQL"",""Data visualization tools (Tableau, PowerBI, Looker)""],""nice_to_have"":[""BigQuery"",""eCommerce experience"",""Loyalty program experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data quality and accuracy in your reports?"",""example_answer"":""I use a combination of data validation rules and data profiling techniques to identify and correct errors. I also perform regular data audits to ensure data consistency and accuracy.""},{""question"":""Can you explain how you would transform complex data into actionable insights for stakeholders?"",""example_answer"":""I would use data visualization tools to create interactive dashboards that tell a story with the data. I would also provide clear and concise recommendations based on the insights derived from the data.""}],""red_flags"":[""Lack of experience with Adobe Analytics"",""Inability to write complex SQL queries""],""confidence_score"":90.0}"
Data Analyst II,"We are looking for a Data Analyst II / Data Engineer in Canada. The position's description is given below. The role provides 100% remote flexibility on a full-time (permanent)/T4 hourly basis; however, candidates must be located in Canada.

Must have skills: Python, SQL, Looker

Minimum Qualifications

Bachelor’s degree or higher in a quantitative field
At least 3 years of experience in a data analysis role
3+ years of experience in Python, SQL, and visualization tools like Looker.
A proven track record of decision-making and problem-solving based on analytics.

Conceptual thinking skills must be complemented by a strong quantitative orientation.

Strong business judgment, leadership, and integrity. You should be a tenacious decision-maker, able to bring a healthy, aggressive, yet responsible approach to business.
Excellent written and oral communication skills, coupled with strategic influencing skills and the ability to drive agreement through intellect, interpersonal skills, and negotiation.
self-starter and adaptable. You’re energized and thrive in a fast-paced environment.
Skilled in using data mining techniques, including supervised and unsupervised learning.
Experienced in analysing and debugging data with Spark/PySpark
Solid understanding of databases and proficiency in writing SQL in systems like Hive, Snowflake, and Presto.
Strong skills in BI tools, Looker, and Excel.

Techedin is a global IT Services company complementing the efforts of technology-driven enterprises in developing cutting-edge solutions for humans. We offer services in enterprise app development, content management solutions (CMS), customer relationship management (CRM), cloud engineering, custom software development, and data engineering. Our services include IT Consulting, project management, Software Quality Assurance, and data and analytics services. We develop and maintain various software applications and all other computer-related ancillary services. We have excellent professionals working round the clock to build the best technology teams and products for our customers.","{""role_summary"":""A Data Analyst II / Data Engineer responsible for analyzing and interpreting complex data to drive business decisions, with a strong focus on problem-solving, leadership, and communication."",""key_terms"":[{""term"":""Looker"",""explanation"":""A business intelligence and analytics platform used for data visualization and exploration.""},{""term"":""Spark/PySpark"",""explanation"":""An open-source data processing engine used for large-scale data processing and analytics.""},{""term"":""Hive"",""explanation"":""A data warehousing and SQL-like query language used for managing and analyzing large datasets.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform used for storing, processing, and analyzing large datasets.""},{""term"":""Presto"",""explanation"":""An open-source distributed SQL engine used for fast and scalable data analytics.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Looker""],""nice_to_have"":[""Spark/PySpark"",""Hive"",""Snowflake"",""Presto"",""BI tools"",""Excel""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data analysis for a complex business problem?"",""example_answer"":""I would start by understanding the business requirements and identifying the key metrics to analyze. Then, I would use Python and SQL to extract and manipulate the data, and finally, I would use Looker to visualize the insights and present them to stakeholders.""},{""question"":""How do you handle data quality issues in your analysis?"",""example_answer"":""I would use data mining techniques, such as data profiling and data validation, to identify and address data quality issues. I would also use Spark/PySpark to debug and analyze the data.""}],""red_flags"":[""Lack of experience with cloud-based data warehousing platforms"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Tableau BI Data Analyst,"Summary
Paymentus leads the North American marketplace in electronic bill payment solutions and is looking for high performers to join our team, building SaaS Fintech solutions across a range of industries. You will contribute to a massively scalable data platform, that is built on top of a world-class enterprise platform, supporting thousands of clients and into the millions of transactions daily. Paymentus' success and rapid growth provides employees with opportunities for career advancement.

Objective
The Tableau BI Data Analyst will assist in growing our reporting and BI infrastructure. The ideal candidate is excited by learning new things, has a passion for applying innovative technology, has excellent problem-solving and communication skills, and also has significant experience within Tableau design and development.

Essential Functions & Responsibilities
Advanced hands-on design, development, and publishing of Tableau dashboards using Tableau Desktop and Tableau Server; experience in data modelling and visualization techniques
Be proficient in building aesthetically pleasing dashboards
Gather and document user requirements for new reports and dashboards
Assist stakeholders with data-related technical issues and support data infrastructure needs
Monitor the performance of reports and dashboards and take corrective action to optimize and improve dashboard performance as necessary
Work with data and analytics experts to achieve greater functionality in our data systems
Build DBT models to feed data to reporting structures

Education & Experience
A bachelor's degree in Software Engineering, Computer Science, or a related technical degree
Experience with cloud-based data warehousing, transformation, and ETL tools, such as Snowflake and DBT
Understanding of time series and relational databases (Oracle, Snowflake, InfluxDB)
High proficiency in SQL
Experience with ETL processes (bonus points for DBT experience)
Experience as a successful problem solver and communicator

Preferred but not Required
Software development and source code management (Git, etc.)
Knowledge of at least one programming language like Java or Python is plus

Supervisory Responsibility
This position does not have any supervisory responsibility or direct reports.

Work Environment
This job operates in a professional office environment. This role routinely uses standard office equipment such as laptop computers, photocopiers and smartphones.

Physical Demands
The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.

Specific vision abilities required by this job include close vision and ability to adjust focus. Prolonged periods sitting at a desk and working on a computer. Must be able to lift up to 15 pounds at times.

Position Type/Expected Hours of Work
This is a full-time position. Days and hours of work are Monday through Friday, during normal business hours. Occasional evening and weekend work may be required as job duties demand.

Travel
Little to no travel is expected for this position.

Other Duties
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.

EEO Statement
Paymentus is an equal opportunity employer. We enthusiastically accept our responsibility to make employment decisions without regard to actual or perceived race, creed, color, age, sex or gender (including pregnancy, childbirth and related medical conditions), gender identity or gender expression (including transgender status), sexual orientation, national origin, ancestry, citizenship status, religion, marital status, physical or mental disability, military service or veteran status, genetic information, protected medical condition as defined by applicable state or local law, genetic information, or any other classification protected by applicable federal, state, and local laws and ordinances. Our management is dedicated to ensuring the fulfillment of this policy with respect to hiring, placement, promotion, transfer, demotion, layoff, termination, recruitment advertising, pay, and other forms of compensation, training, access to facilities and programs and general treatment during employment.

Reasonable Accommodation
Paymentus recognizes and supports its obligation to endeavor to accommodate job applicants and employees with known physical or mental disabilities who are able to perform the essential functions of the position, with or without reasonable accommodation. Paymentus will endeavor to provide reasonable accommodations to otherwise qualified job applicants and employees with known physical or mental disabilities, unless doing so would impose an undue hardship on the Company or pose a direct threat of substantial harm to the employee or others.

An applicant or employee who believes he or she needs a reasonable accommodation of a disability should discuss the need for possible accommodation with the Human Resources Department, or his or her direct supervisor.","{""role_summary"":""The Tableau BI Data Analyst will contribute to the growth of Paymentus' reporting and BI infrastructure, designing and developing Tableau dashboards, and supporting data infrastructure needs."",""key_terms"":[{""term"":""Tableau"",""explanation"":""A data visualization tool used to create interactive dashboards.""},{""term"":""DBT"",""explanation"":""A data transformation tool used to build models and feed data to reporting structures.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process used to extract data from sources, transform it into a usable format, and load it into a target system.""},{""term"":""Cloud-based data warehousing"",""explanation"":""A type of data storage and processing that uses cloud computing resources to manage large amounts of data.""}],""skill_priorities"":{""must_have"":[""Tableau design and development"",""Data modeling and visualization techniques"",""SQL proficiency"",""Experience with cloud-based data warehousing and ETL tools""],""nice_to_have"":[""Software development and source code management (Git)"",""Knowledge of at least one programming language like Java or Python""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach designing a new Tableau dashboard to meet specific business requirements?"",""example_answer"":""I would start by gathering user requirements, then use data modeling and visualization techniques to create an aesthetically pleasing dashboard that meets the business needs.""},{""question"":""How do you optimize the performance of a slow-performing Tableau dashboard?"",""example_answer"":""I would analyze the dashboard's data sources, optimize the data model, and apply best practices for dashboard design to improve performance.""}],""red_flags"":[""Lack of experience with Tableau design and development"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
"ICQA Data Analyst - Bolton, ON, YYZ7","Description

At Amazon, we're working to be the most customer-centric company on earth. To get there, we need exceptionally talented, bright, and driven people. If you'd like to help us build the place to find and buy anything online, this is your chance to make history. Amazon Canada Fulfillment Services is hiring a Data Analyst to support the Inventory Control / Quality Assurance (ICQA) team. The Data Analyst assigned to ICQA will work closely with the ICQA and operations teams in Inbound and Outbound to provide data and analytical support for ACES initiatives, root cause investigation of defects, and will provide support to ensure compliance to ICQA-related SoX requirements. The Data Analyst will own the insights, set up analysis, and create automated dashboards and reporting. They will be responsible for identifying data sources (internal / external) to invent and simplify mechanisms and create custom reporting and analytics automation tools. Operating in a fast-moving and sometimes ambiguous environment, you will be required to work autonomously, taking full control and responsibility for achieving business objectives. This role provides real opportunity to develop original ideas, approaches and solutions in an ever-changing and competitive business climate.

Key job responsibilities

Development of data collection processes and data management systems
Maintenance of data integrity (0% error rate)
Designing of queries, compiling of data, and generation of reports in MS Excel
Charting and graphing of data for reporting purposes
In depth research of defect trends
Data collection and entry as needed
Data mining and problem solving
Back up for Process Assistant duties

Basic Qualifications

2+ years of professional or military experience
Experience with Microsoft Office products and applications

Preferred Qualifications

Experience with end-to-end project management

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, disability, age, or other legally protected status. If you would like to request an accommodation, please notify your Recruiter.


Company - Amazon Canada Fulfillment Services, ULC.

Job ID: A2684542","{""role_summary"":""Support the Inventory Control/Quality Assurance team as a Data Analyst, providing data and analytical support for initiatives, investigating defects, and ensuring compliance with ICQA-related requirements."",""key_terms"":[{""term"":""SoX"",""explanation"":""Sarbanes-Oxley, a set of regulations related to financial reporting and compliance.""},{""term"":""ACES"",""explanation"":""Amazon Customer Excellence System, an initiative focused on customer satisfaction and experience.""},{""term"":""ICQA"",""explanation"":""Inventory Control/Quality Assurance, a team responsible for managing inventory and ensuring quality standards.""}],""skill_priorities"":{""must_have"":[""Microsoft Office products and applications"",""2+ years of professional or military experience""],""nice_to_have"":[""End-to-end project management experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach identifying and resolving data discrepancies in a fast-paced environment?"",""example_answer"":""I would first identify the root cause of the discrepancy, then develop a plan to correct the issue, and finally implement a process to prevent similar issues from occurring in the future.""},{""question"":""Can you walk me through your experience with data mining and problem-solving?"",""example_answer"":""In my previous role, I used data mining techniques to identify trends and patterns in customer behavior, which helped inform business decisions and improve customer satisfaction.""}],""red_flags"":[""Lack of experience with data analysis and reporting tools"",""Inability to work autonomously in a fast-paced environment""],""confidence_score"":85.0}"
Junior Data BI Analyst,"This is a remote position.

Junior Data BI Analyst - Remote Job, 1+ Year Experience

Annual Income: $55K - $65K

A valid work permit is necessary in Canada

About us: Patterned Learning is a platform that aims to help developers code faster and more efficiently. It offers features such as collaborative coding, real-time multiplayer editing, and the ability to build, test, and deploy directly from the browser. The platform also provides tightly integrated code generation, editing, and output capabilities.

Are you a talented BI Analyst with a passion for data analysis and a strong background in business intelligence? We are seeking a skilled and motivated individual to join our team as a BI Analyst. As a BI Analyst, you will be responsible for analyzing complex data sets, generating insights, and providing actionable recommendations to drive business growth and efficiency.

Responsibilities:

Analyze large datasets to identify trends, patterns, and insights.
Develop and maintain data models, dashboards, and reports to support business decision-making.
Collaborate with cross-functional teams to understand business requirements and translate them into data-driven solutions.
Conduct ad-hoc analysis to answer specific business questions and provide actionable recommendations.
Stay up-to-date with industry trends and best practices in data analysis and business intelligence.

Requirements:

Bachelor's Degree required with an emphasis in business, economics, math, engineering, or analytics preferred. Advanced degree or certification preferred.
1+ years of experience, with at least 1 year of analytic experience.
Proficiency in interacting with various database and file storage systems (Examples: Oracle, Hadoop, NoSQL). Understanding of join types.
Experience with data manipulation languages, such as SQL, is required.
Knowledge of statistical concepts and analytic techniques, including descriptive statistics, forecasting, economic modeling, exploratory analysis, and variance analysis is required.
Ability to perform uni-variate analytic analytical techniques.
Experience using Microsoft Excel, including the use of pivot tables, formulas, macros, VBA, and charts/graphs.
Experience with visualization tools such as Tableau, PowerBi, or QlikView.
Strong analytical, critical, and systems thinking is required.

Skills:

Good understanding of Agile framework (SCRUM).
Familiarity with Salesforce is a plus.

Benefits:

Competitive salary based on skills, qualifications, and experience 1.
Comprehensive health, dental, and vision insurance plans.
Retirement program with lifetime pension benefits.
Paid time off and holidays.
Flexible work schedule and remote work options.
Opportunities for professional development and growth.
Collaborative and inclusive work environment.

Why Patterned Learning LLC?

Patterned Learning can provide intelligent suggestions, automate repetitive tasks, and assist developers in writing code more effectively. This can help reduce coding errors, improve productivity, and accelerate the development process.

Pattern recognition is particularly relevant in the context of coding. Neural networks, especially deep learning models, are commonly employed for pattern detection and classification tasks. These models simulate human decision-making and can identify patterns in data, making them well-suited for tasks like code analysis and generation.","{""role_summary"":""A Junior Data BI Analyst is responsible for analyzing complex data sets, generating insights, and providing actionable recommendations to drive business growth and efficiency."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""The practice of using data analysis and reporting to inform business decisions.""},{""term"":""Data Models"",""explanation"":""Conceptual representations of data structures and relationships, used to support business decision-making.""},{""term"":""Ad-hoc Analysis"",""explanation"":""The process of conducting unplanned data analysis to answer specific business questions.""},{""term"":""Descriptive Statistics"",""explanation"":""A branch of statistics that describes the basic features of a dataset, such as mean, median, and standard deviation.""},{""term"":""Agile Framework (SCRUM)"",""explanation"":""A project management approach that emphasizes iterative development, continuous improvement, and team collaboration.""}],""skill_priorities"":{""must_have"":[""SQL"",""Data Analysis"",""Business Intelligence"",""Statistical Concepts"",""Data Manipulation"",""Microsoft Excel""],""nice_to_have"":[""Tableau"",""PowerBi"",""QlikView"",""Salesforce"",""Agile Framework (SCRUM)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of variance analysis and how it's applied in business intelligence?"",""example_answer"":""Variance analysis is a statistical technique used to identify and quantify the differences between expected and actual outcomes. In business intelligence, it's used to analyze deviations in sales, revenue, or other key performance indicators, helping organizations identify areas for improvement.""},{""question"":""How do you stay up-to-date with industry trends and best practices in data analysis and business intelligence?"",""example_answer"":""I regularly read industry publications, attend webinars, and participate in online forums to stay current with the latest developments in data analysis and business intelligence.""}],""red_flags"":[""Lack of experience with database and file storage systems"",""Inability to perform uni-variate analytic techniques"",""Limited understanding of statistical concepts and analytic techniques""],""confidence_score"":85.0}"
SQL Developer / Data Analyst,"We are looking for a ""SQL Developer / Data Analyst"" in Canada. Please find the detailed job description below. This position provides full-time employment with remote work, though candidates must reside within Canadian borders.

Job Description

Bachelor’s degree or higher in a quantitative field
5+ years of experience in a data analysis role
3+ years of experience in Python, SQL, and visualization tools like Looker/PowerBI
A proven track record of decision-making and problem-solving based on analytics.
Conceptual thinking skills must be complemented by a strong quantitative orientation.
Self-starter and adaptable. You’re energized and thrive in a fast-paced environment.
Solid understanding of databases and proficiency in writing SQL in systems like Hive, Snowflake, and Presto.
Strong skills in BI tools and Excel and Knowledge of PowerBI is a plus.

Techedin is a global IT Services company complementing the efforts of technology-driven enterprises in developing cutting-edge solutions for humans. We offer services in enterprise app development, content management solutions (CMS), customer relationship management (CRM), cloud engineering, custom software development, and data engineering. Our services include IT Consulting, project management, Software Quality Assurance, and data and analytics services. We develop and maintain various software applications and all other computer-related ancillary services. We have excellent professionals working round the clock to build the best technology teams and products for our customers.","{""role_summary"":""A SQL Developer / Data Analyst responsible for analyzing data, making informed decisions, and solving problems using analytics, with a strong quantitative background and proficiency in SQL, Python, and visualization tools."",""key_terms"":[{""term"":""Hive"",""explanation"":""A data warehousing and SQL-like query language for Hadoop, used for data analysis and visualization.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and analyzing large datasets.""},{""term"":""Presto"",""explanation"":""An open-source, distributed SQL engine for querying large datasets.""},{""term"":""Looker"",""explanation"":""A business intelligence and analytics platform for data visualization and exploration.""},{""term"":""PowerBI"",""explanation"":""A business analytics service by Microsoft for data visualization and business intelligence.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Data analysis"",""Visualization tools"",""Quantitative skills""],""nice_to_have"":[""PowerBI"",""Looker""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize a slow-performing SQL query?"",""example_answer"":""I would analyze the query plan, identify the bottleneck, and consider indexing, rewriting the query, or optimizing the database configuration to improve performance.""},{""question"":""How do you approach data visualization for complex datasets?"",""example_answer"":""I would use visualization tools like Looker or PowerBI to create interactive dashboards, focusing on clear and concise storytelling, and ensuring the visualization effectively communicates insights to stakeholders.""}],""red_flags"":[""Lack of experience with cloud-based data warehousing platforms"",""Inability to write efficient SQL queries""],""confidence_score"":90.0}"
Technical Data Analyst,"Who We Are
We go beyond software. Carbon6 is building a community to support ecommerce sellers by removing the barriers to selling online and simplifying their path to success. Developed by the brightest minds in the marketplace ecosystem, our suite of software tools and resources help entrepreneurs succeed at every stage of their journey. We are a global company across North America, Europe and Asia, made up of passionate entrepreneurs, expert sellers, and innovative thought leaders.

Founded in 2021, we have raised close to $100 million and quickly grown into a market leader. We work with the largest and most successful sellers, brands, agencies, and aggregators around the world to drive growth, maximize profitability and manage with intelligence to scale their businesses. In addition to collaborating with global giants such as Amazon, Walmart, Alibaba, and others, we foster partnerships with key industry players like BigCommerce, Teikametrics, Jungle Scout, and more. Through our innovative solutions and strategic alliances, we empower businesses of all sizes to excel in today's competitive landscape, driving success and fostering long-term growth for both our clients and partners.

The Opportunity (Hybrid)

Do you look at spreadsheets and think… why is this clearer? More actionable? Enhanced with meaningful visualizations? Do you stare at rows of data and love looking for and finding patterns? Is there a joy you find when you take an unordered collection of raw information and turn it into something meaningful, and better yet, see others use what you’ve created to make great decisions? If these all ring true to you, then you just might be the Data Analyst that we’re looking for.

Carbon6 is searching for a Data Analyst for our best-of-breed, multi-million dollar Amazon reimbursements and recovery tool. In this role, you’ll have a massive influence on the decisions that our internal team and our customers make–many who are themselves million-dollar Amazon sellers. This role is hands-on, and far more than just creating charts and graphs through a BI tool. You’ll be deeply involved in our data collection, migration, aggregation, analysis, and automation.

Your Responsibilities

Metrics Development: Define and establish key metrics that matter to our organization, and drive toward calculating those metrics across massive and often disparate datasets, both internal and external.
Data Integration: Identify and integrate new data sources into our data ecosystem to enhance our analytical capabilities from key Amazon, Walmart, and key third parties across the ecommerce ecosystem
Cross-functional Collaboration: Work closely with sales, operations, and of course product and engineering to understand their data needs and prioritize them in line with business goals
Data Processing: Leverage SQL to transform raw data into actionable insights, continuously optimizing our data platform for improved performance and scalability
Automation and Quality Assurance: Build trust in our data through robust automation and data quality processes that ensure that we never expose invalid or inaccurate data to your internal and external consumers
Data Visualization: Use your skills in BI tools (PowerBI, Tableau, Sisense, or similar) to create compelling reports and dashboards that support data-driven decisions, going beyond basic informatics to reveal key insights and drive decision making
Ad-hoc Solutions: Develop quick, temporary data solutions for immediate needs while contributing to long-term data infrastructure
Documentation: Ensure that all data processes and solutions are well-documented and sustainable for future use




Your Qualifications

Practical Experience: Solid track record as an Intermediate/Senior Data Analyst for a minimum of 4 years, actively involved in crafting and sustaining data analytics in complex settings
SQL Expertise: Proficient in SQL, including data modeling and crafting advanced queries
Business Intelligence Tools: Experienced in using BI tools like PowerBI, Tableau, or Sisense to visualize data and build dashboards
Detail-oriented: Strong attention to detail, with a passion for solving complex data challenges and ensuring data accuracy
Best Practices: Comprehensive grasp of data analysis principles, methodologies, and tools, encompassing data retrieval, staging, and visualization
Analytical Skills: Exceptional analytical prowess, coupled with the capability to dissect intricate data compilations and extract significant interpretations
Teamwork and Communication: Adept at seamlessly collaborating with diverse teams and stakeholders
Agile: Proven experience working on an Agile team with 1- or 2-week sprints, Scrum, and daily standups.
BONUS: Amazon Vendor/Seller Central experience either directly or through APIs




Perks & Benefits
🚀 As an early member of our team, you'll receive competitive compensation and a generous stock option plan.

🦷 Extended health benefits including Medical, Dental, and Vision starting on Day 1.

🌴 Flexible paid time off that includes paid vacation days and paid personal days.

💻 You'll receive a laptop conveniently delivered to your door to get you started and set up for success Day 1.","{""role_summary"":""As a Data Analyst at Carbon6, you will be responsible for developing key metrics, integrating new data sources, and creating actionable insights to drive business decisions. You will work closely with cross-functional teams to understand their data needs and prioritize them in line with business goals."",""key_terms"":[{""term"":""BI tools"",""explanation"":""Business Intelligence tools used for data visualization and dashboard creation, such as PowerBI, Tableau, or Sisense.""},{""term"":""SQL"",""explanation"":""Structured Query Language used for managing and analyzing relational databases.""},{""term"":""Agile"",""explanation"":""An iterative approach to project management that emphasizes collaboration, flexibility, and continuous improvement.""},{""term"":""Scrum"",""explanation"":""A framework for implementing Agile principles in project management, emphasizing teamwork, accountability, and iterative progress.""}],""skill_priorities"":{""must_have"":[""4+ years of experience as an Intermediate/Senior Data Analyst"",""SQL expertise"",""Experience with BI tools"",""Strong attention to detail"",""Analytical skills"",""Teamwork and communication skills"",""Agile experience""],""nice_to_have"":[""Amazon Vendor/Seller Central experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach integrating new data sources into our data ecosystem?"",""example_answer"":""I would first identify the key data sources, assess their relevance to our business goals, and then develop a plan to integrate them into our data ecosystem using SQL and BI tools. I would also ensure data quality and accuracy throughout the process.""},{""question"":""How do you stay organized and prioritize tasks in a fast-paced Agile environment?"",""example_answer"":""I use tools like Jira or Trello to track my tasks and prioritize them based on business goals and deadlines. I also communicate regularly with my team and stakeholders to ensure everyone is aligned and informed.""}],""red_flags"":[""Lack of experience with BI tools"",""Inability to work in an Agile environment"",""Poor attention to detail""],""confidence_score"":90.0}"
Data Integrity Analyst,"At Rexall, we are community difference makers. We are leaders in health and wellness and a talent destination for over 7000+ Rexall team members. Together, we are defining better health through innovation, service, and living the “I2CARE”values. Talk about a dream team!


The Role:
Reporting directly to the Manager, Merchandising Systems and Data Integrity, you'll play a pivotal role in supporting the Category Management team. Your responsibilities will encompass a critical spectrum, including the accurate listing of new items, the meticulous maintenance of pricing details, and the unwavering commitment to data integrity within our merchandising systems.


What you are looking for:
A closely connected culture
A total rewards package meant to enhance your work-life flexibility
Fully utilizing your talent
Professional growth and development via challenging projects and assignments
Warm and fuzzy feelings knowing you have helped your community, your team, the business and social causes through the Rexall Care Network


The road ahead is one of adventure and heart. Are you our next all-star?


What you will be doing:
Responsible for the addition of all new items as well as the maintenance of pricing and item information into system to ensure the data integrity of our system are maintained at all times and items scan accurately at store level.
Investigates and resolves store issues regarding product inquiries in a timely manner reflecting corporate policy.
Researching and reviewing regulations such as taxation and environmental levies regularly and ensures that accurate data is captured in the system
Ensures the accuracy of the setup of all item information in the Merchandise systems
Perform data validation and providing results to the category management teams, for off shelf display, planogram and seasonal programs.
Perform other duties as assigned to support Rexall Pharmacy Group ULC


How you will succeed:
2-3 years’ experience working in a retail or merchandising environment.
Excellent time management and prioritization skills.
Excellent verbal and written communication skills.
Excellent organizational, financial and analytic skills.
Sophisticated Microsoft Office skills, including Excel
Must possess the right balance between being inquisitive and paying attention to detail.
Ability to work a fast paced and changing environment.
Quick learner who is motivated to learn new things can retain knowledge.
Demonstrated presentation skills.
Solutions oriented thinking.

At Rexall, we are better together. We serve our customers, partners, and patients best—we are our best—when everyone brings their true self to work. Our connected, inclusive culture celebrates our lived experiences, backgrounds, expertise, and self-expression to let us win as one team. Leveraging our differences distinguishes us and brings out our best performance.

Are you #ALLin?

Rexall Pharmacy Group ULC is committed to providing an accessible environment for all of our customers, employees, and job applicants. Rexall Pharmacy Group ULC will make available to any selected applicants’ accommodations and/or accessible formats should they require. Candidates are encouraged to discuss any accommodation they may need in order to allow for the most effective selection process.","{""role_summary"":""Support the Category Management team by ensuring data integrity within merchandising systems, accurately listing new items, and maintaining pricing details."",""key_terms"":[{""term"":""I2CARE"",""explanation"":""Rexall's values, which stand for Innovation, Integrity, Compassion, Accountability, Respect, and Excellence.""},{""term"":""Category Management"",""explanation"":""A retailing and merchandising concept that involves managing product categories as business units to maximize sales and profitability.""},{""term"":""Data Integrity"",""explanation"":""The maintenance and assurance of the accuracy, completeness, and consistency of data within a system or database.""},{""term"":""Merchandising Systems"",""explanation"":""Computer-based systems used to manage and analyze product information, pricing, and inventory in a retail environment.""}],""skill_priorities"":{""must_have"":[""Microsoft Office skills (Excel)"",""Time management and prioritization skills"",""Verbal and written communication skills"",""Organizational, financial, and analytic skills""],""nice_to_have"":[""Presentation skills"",""Solutions-oriented thinking""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a situation where you had to ensure data integrity in a previous role?"",""example_answer"":""In my previous role, I was responsible for maintaining product information in our database. I implemented a quality control process to ensure accuracy and consistency, which resulted in a significant reduction in errors.""},{""question"":""How do you stay organized and manage competing priorities in a fast-paced environment?"",""example_answer"":""I use project management tools and prioritize tasks based on urgency and importance. I also communicate regularly with my team and stakeholders to ensure everyone is aware of my progress and any challenges I'm facing.""}],""red_flags"":[""Lack of experience in a retail or merchandising environment"",""Inability to work in a fast-paced and changing environment""],""confidence_score"":90.0}"
Data Analyst-DA - Canada,"Role: Data Analyst-DA

Location: Alberta-Onsite

Duration: 6-12+ Months

Job Description

Roles, Responsibilities and Qualifications

Role Description

A Data Analyst provides expertise in instrumentation and data collection, data-driven storytelling, statistical analysis, modelling and data visualizations, developing data policies and governance standards, and developing service analytics standards and practices (inclusive of both digital and non-digital service implementation).

Responsibilities

Creates plans and strategies that will identify the various linkages between new and existing data forms, resulting in the integration of data models, development of data policies, and presentation of statistical analysis and data visualizations to help understand and improve service delivery online and offline.
Supports governance based on the service data model, service analytics standards, and the development of analytics tools, inclusive of both digital and non-digital service implementation.
Works to implement develop, and share service metrics and service performance dashboards for internal and public use.
Facilitates and informs program area workshops about current data and performance practices.
Uses the service journey to frame future measurement models.
Mentors team members and others to develop and grow their analytics fluency.
Researches best practices and makes recommendations for the direction of data-driven governance policies to support the adoption of digital services, and service delivery information management.
Creates data statistical analysis and data visualizations leveraging data querying languages within available data management technologies.
Supports corporate priorities based upon data-driven evidence by leveraging existing and new analytics, data visualizations, data modeling and storytelling.
Other responsibilities as required or requested.

Qualifications a) Experience leading data science and analytics work, including digital and non-digital services.

Experience with leadership, communications, relationship building, and planning.
Experience with current methodologies in analytics, data visualizations, data modeling and storytelling.
Experience working with cross-functional teams to understand detailed requirements and align these requirements with product vision and user needs.
Experience working in a complex enterprise environment (10,000 employees or greater).
Experience with agile projects in a public sector organization.
Experience with web development and digital product design.
Experience providing analytics support to user experience, customer experience, or service design teams.
Experience with quantitative research methods such as surveys.
Experience developing and maintaining relationships with multiple clients and stakeholders, including negotiating agreements and resolving conflicts.","{""role_summary"":""A Data Analyst provides expertise in data analysis, visualization, and governance to improve service delivery. They develop data policies, create statistical models, and present findings to stakeholders."",""key_terms"":[{""term"":""Instrumentation"",""explanation"":""The process of collecting and measuring data from various sources.""},{""term"":""Data-driven storytelling"",""explanation"":""Presenting data insights in a narrative format to communicate findings effectively.""},{""term"":""Service analytics standards"",""explanation"":""Established guidelines for analyzing and measuring service performance.""},{""term"":""Data governance"",""explanation"":""The management and regulation of data usage within an organization.""},{""term"":""Data visualizations"",""explanation"":""The presentation of data in a graphical format to facilitate understanding.""},{""term"":""Agile projects"",""explanation"":""An iterative approach to project management that emphasizes flexibility and collaboration.""}],""skill_priorities"":{""must_have"":[""Data analysis"",""Data visualization"",""Statistical modeling"",""Data governance"",""Leadership"",""Communication"",""Relationship building"",""Planning""],""nice_to_have"":[""Web development"",""Digital product design"",""Quantitative research methods"",""User experience design"",""Customer experience design"",""Service design""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would develop a data governance policy for a large organization?"",""example_answer"":""I would start by conducting a thorough analysis of the organization's current data management practices, identifying areas for improvement, and developing a policy that aligns with industry best practices and regulatory requirements. I would then work with stakeholders to implement the policy and provide training and support to ensure its adoption.""},{""question"":""How do you stay current with new methodologies in analytics and data visualization?"",""example_answer"":""I regularly attend industry conferences, participate in online forums and discussion groups, and read relevant publications to stay informed about the latest trends and best practices in analytics and data visualization.""}],""red_flags"":[""Lack of experience working in a complex enterprise environment"",""Inability to communicate technical information to non-technical stakeholders"",""Limited experience with agile project management""],""confidence_score"":90.0}"
Sr. Data Analyst,"Sr. Data Analyst -REMOTE
Need resource in Canada
NEED STRONG IN SQL AND EXPERTISE IN LOOKML/LOOKER.
SQL Query Optimization expertise is needed.

About the Role:
Client is looking for curious data analysts who are deft at working with SQL and who are comfortable with a variety of databases and raw data formats. We function in a fast-paced and friendly environment. You will collaborate and work with teams across the organization to ensure our data standards, pipelines and processes are held to high standards in order to guide finance, product, and marketing decisions.
This role is ideal for a highly technical, analytical and results-oriented professional with a passion for transforming healthcare data into actionable insights. This individual is passionate and proficient in data storytelling and dashboard design with a proven ability to create visually compelling, interactive reports and dashboards to communicate meaningful data.
Responsibilities
● Monitor database content and provide recommendations to ensure that data quality, sanity, and accuracy are upheld
● Collaborate with a range of cross-functional stakeholders in multiple departments to understand data content, clarify business requirements, and formulate recommendations
● Perform intensive investigation and analysis of data anomalies and determine root causes
● Perform statistical analysis of large datasets
● Develop and manage monthly reporting for a range of internal customers
● Develop reporting tools & content to identify data outliers and issues
● Develop Enterprise data pipelines & dashboards
● Build valuable insights for our stakeholders by performing the analytical work to enable fast and accurate attribution and adjudication of prescription claims and coupons as well as improve vendor & pharmacy relationships and maximize patient savings
● Monitor transaction performance, implement automated reporting and conduct deep dives on drivers behind trends and anomalies that impact GoodRx’s top key results dramatically
Skills & Qualifications
● The ideal candidate for this role is someone who enjoys both being in-the-weeds with data and synthesizing analyses for non-technical collaborators and product leadership
● Ability to work extensively with SQL
● Expertise in LookML - able to build complex Looker Visualization using custom scripts
● Experience working with AWS, dbt
● Proven ability to manipulate and interpret data to produce insights and recommendations across large/diverse datasets
● Ability to communicate complex ideas clearly and concisely, verbally and in writing
● Presentation-building skills (PowerPoint, Google Slides, etc.) and a good eye for concise data visualization (Excel, Google Charts, etc)
● Ability to triage suspected inconsistency with data and work through SQL scripts to determine root cause
● Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
● Ability to define and manage overall schedule and availability for a variety of data sets
● Use of data mining techniques to extract information from data sets and identify correlations and patterns to help build and improve our products
● Knowledge of statistics and experience using one or more statistical packages for analyzing datasets (Excel, SPSS, SAS, etc.)
● Proven working experience as a Data Analyst or Business Data Analyst
● 4+ years in strategy, analytics or finance role supporting multiple stakeholders","{""role_summary"":""A senior data analyst role that involves working with SQL, LookML, and various databases to analyze and transform healthcare data into actionable insights, and communicate findings to stakeholders through reports and dashboards."",""key_terms"":[{""term"":""LookML"",""explanation"":""A data modeling language used to build complex visualizations in Looker.""},{""term"":""SQL Query Optimization"",""explanation"":""The process of improving the efficiency and speed of SQL queries to retrieve data from databases.""},{""term"":""Data Storytelling"",""explanation"":""The ability to present complex data insights in a clear and compelling narrative.""},{""term"":""Data Pipelines"",""explanation"":""A series of processes that extract, transform, and load data from various sources into a target system.""}],""skill_priorities"":{""must_have"":[""SQL"",""LookML"",""Data Analysis"",""Data Visualization"",""Communication Skills""],""nice_to_have"":[""AWS"",""dbt"",""PowerPoint"",""Google Slides"",""Google Charts"",""Excel"",""SPSS"",""SAS""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize a slow-performing SQL query?"",""example_answer"":""I would first analyze the query to identify the bottleneck, then consider indexing, rewriting the query, or optimizing the database configuration to improve performance.""},{""question"":""How do you ensure data quality and accuracy in your analysis?"",""example_answer"":""I use a combination of data validation, data profiling, and data visualization techniques to identify and correct errors, and ensure that the data is accurate and reliable.""}],""red_flags"":[""Lack of experience with LookML or SQL query optimization"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Business Intelligence Analyst,"Company Overview & Job purpose:
Founded in 2002, Longbow advantage is a leading Supply Chain Technology Company built to provide best-in-class WMS, EWM, WM, LMS, and TMS implementation and integration services. Our team of supply chain professionals have experience and expertise that is unmatched throughout the industry. We have a 17-year track record of delivering successful logistics execution solutions and delivering on the commitments we make to customers. All of this has resulted in customer satisfaction scores that are world class
This position is responsible for gathering specific data extracts and developing, deploying, and maintaining widgets that dynamically and graphically represent the data. This role provides technical analysis and evaluation of clients’ requests.
Principle Responsibilities:
Design and implement metrics based on clients’ requests.
Responsible for developing polls and flows through data mining, data extraction and data analysis.
Assist in troubleshooting, resolution of data related issues as well as optimization of SQL queries.
Establish clear objectives for implementation and prioritize customer needs to respond with urgency to achieve customer expectations and ensure user adoption of the software.
Configure solutions to meet customers’ requirements.
Document solutions pertaining to customer set up, widget configuration, and polls and flows configuration.
Maintain a repository of process flows and polls for the Rebus team
Retrieve data from clients and manage data clean up
Comprehend, analyze, and solve highly complex technical problems involving system functionality, architecture, and relational databases
Strong ability to quickly understand scope and requirements and transform information into design and development
Meet with team members to configure and implement client’s requirements
Comply to policies and practices related to Longbow SOC2 compliance
Qualified Candidateswill possess most, if not, all of the following knowledge, skills, and abilities:
Minimum Bachelor’s degree in Computer Science or related University degree
Minimum 1+ year of experience with SQL Server, Oracle, or MySQL
Experience with MongoDB (aggregation pipeline) or another NoSQL database Preferred.
Knowledge and experience in JavaScript
Operating systems – Windows and UNIX
Microsoft Office suite
Knowledge of one major supply chain software system: Blue Yonder (formerly JDA), HighJump, Manhattan, SAP etc highly preferred.
Ability to work independently as well as multi-task","{""role_summary"":""Design and implement data-driven widgets and metrics to meet client requirements, providing technical analysis and evaluation of client requests."",""key_terms"":[{""term"":""WMS"",""explanation"":""Warehouse Management System, a software solution for managing warehouse operations.""},{""term"":""EWM"",""explanation"":""Extended Warehouse Management, a software solution for managing warehouse operations with advanced features.""},{""term"":""WM"",""explanation"":""Warehouse Management, a software solution for managing warehouse operations.""},{""term"":""LMS"",""explanation"":""Labor Management System, a software solution for managing labor operations in a warehouse.""},{""term"":""TMS"",""explanation"":""Transportation Management System, a software solution for managing transportation operations.""},{""term"":""SQL"",""explanation"":""Structured Query Language, a programming language for managing relational databases.""},{""term"":""NoSQL"",""explanation"":""Non-relational database management system, designed for handling large amounts of unstructured or semi-structured data.""},{""term"":""MongoDB"",""explanation"":""A NoSQL database management system, designed for handling large amounts of unstructured or semi-structured data.""},{""term"":""Aggregation pipeline"",""explanation"":""A series of data processing operations in MongoDB, used for data transformation and aggregation.""},{""term"":""SOC2"",""explanation"":""Service Organization Control 2, a compliance standard for service organizations, ensuring the secure management of data.""}],""skill_priorities"":{""must_have"":[""SQL Server"",""JavaScript"",""Microsoft Office suite"",""Operating systems - Windows and UNIX""],""nice_to_have"":[""MongoDB (aggregation pipeline)"",""Knowledge of one major supply chain software system: Blue Yonder (formerly JDA), HighJump, Manhattan, SAP etc""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize a slow-performing SQL query?"",""example_answer"":""I would analyze the query plan, identify the bottleneck, and apply indexing or rewriting the query to improve performance.""},{""question"":""Can you explain how you would design a data widget to meet a client's specific requirements?"",""example_answer"":""I would gather requirements, design a data model, and implement the widget using JavaScript and SQL, ensuring it meets the client's needs.""}],""red_flags"":[""Lack of experience with SQL Server, Oracle, or MySQL"",""Inability to work independently and multi-task""],""confidence_score"":90.0}"
Reference Data Analyst,"Why join the CanDeal Team?

CanDeal Group is a leading provider of electronic marketplaces and data services for Canadian dollar fixed income securities and derivatives. CanDeal’s Markets Division, provides access to a deep pool of liquidity for Canadian government, agency, provincial and corporate bonds, as well as money market instruments and interest rate swaps. CanDeal Data & Analytics (DNA) delivers data and analytics products and other services that support business, trading and technology needs for participants in the Canadian capital markets.

CanDeal Group is a growing and entrepreneurial organization with a solid foundation in the Canadian fixed income markets and an ownership group which includes: BMO Nesbitt Burns Inc., CIBC World Markets Inc., National Bank Financial Inc., RBC Dominion Securities Inc., Scotia Capital Inc., TD Securities Inc. and TMX Group.

This is an exciting time to join a growing organization led by visionary leaders who are helping to shape their industry’s future.

Job Purpose

The successful candidate will form a key part of the Reference Data team responsible for maintaining the smooth running of the day-to-day operations of bonds product and services as well as supporting the questions and requests of our internal and external clients. Their primary responsibilities are to ensure the accuracy of reference data of fixed income securities added to DNA’s Security Master (includes cross-checking accuracy of calculations). Will work closely with other functions within the wider team – product management, business analysis, technology, and testing.

Primary Duties

The candidate will perform a wide range of duties including but not limited to the following:

Researching and updating of newly issued deals into the database on a real time basis.
Operational maintenance of reference data for the trading and pricing products.
Cross-check fixed income calculations for accuracy. Identity and troubleshoot discrepancies in calculations. Document and communicate discrepancies to developers and follow through to resolution.
Manage client (internal and external) queries and client escalations.
Liaise with counterparts/stakeholders within the wider team.

Secondary Duties

User acceptance testing for new or enhanced product functionality. Execute test cases to confirm completion of technical, functional requirements for new fixed income product and system releases.
Identify data quality improvement projects and opportunities to enhance operational efficiency.

Knowledge, Skills, and Abilities

3 years+ of business-related experience in the fixed income financial services industry.
Experience related to fixed income reference data management an asset.
Strong knowledge and understanding of a range of fixed income products, including bonds, money market products and interest rate derivatives.
Strong knowledge of fixed income trading and familiarity with terms and conditions of fixed income securities, including settlement protocols.
Strong investigating and problem-solving skills - acute attention to detail.
Demonstrates analytical thinking and sound judgement when making decisions.
Outstanding organizational skills, highly motivated and adaptable to a changing business environment.
Must have exceptional time management skills.
Working knowledge of new bond issuance procedure desirable.
Working knowledge of corporate bonds and new bond issuance procedure desirable.
Bilingualism (French/English) is an asset.

Key Qualifications

Long term desire to stay focused on static data.
Knowledge of fixed income reference data (past experience at the banks – fixed income/syndicate desks).
Content in handling data entry and daily tasks (ex. Experience in handling Capital Market settlements).
Experience with Data Management and Governance.
Experience with SQL.

Education

University degree in a related discipline.
Canadian Securities Course (CSC) certification is an asset.

Please inform us if you require any accommodation during the hiring process.","{""role_summary"":""The Reference Data team member is responsible for maintaining the accuracy of fixed income securities data, supporting internal and external clients, and ensuring smooth day-to-day operations."",""key_terms"":[{""term"":""Fixed income securities"",""explanation"":""Financial instruments that provide a fixed return, such as bonds, money market products, and interest rate derivatives.""},{""term"":""Reference data"",""explanation"":""Standardized data used to support financial transactions, such as security master data.""},{""term"":""Security Master"",""explanation"":""A centralized database that stores and manages reference data for financial securities.""},{""term"":""Data Management and Governance"",""explanation"":""The process of managing and maintaining data quality, integrity, and security.""}],""skill_priorities"":{""must_have"":[""3+ years of business-related experience in the fixed income financial services industry"",""Strong knowledge and understanding of fixed income products"",""Strong investigating and problem-solving skills"",""Exceptional time management skills""],""nice_to_have"":[""Experience related to fixed income reference data management"",""Working knowledge of new bond issuance procedure"",""Bilingualism (French/English)"",""Canadian Securities Course (CSC) certification""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of accurate reference data in fixed income securities?"",""example_answer"":""Accurate reference data is crucial in fixed income securities as it ensures that trades are executed correctly, and clients receive accurate information. Inaccurate data can lead to financial losses and damage to the company's reputation.""},{""question"":""How would you troubleshoot discrepancies in fixed income calculations?"",""example_answer"":""I would first identify the source of the discrepancy, then cross-check the calculations with the relevant data sources. If necessary, I would collaborate with developers to resolve the issue and document the process for future reference.""}],""red_flags"":[""Lack of experience in fixed income reference data management"",""Inability to work in a fast-paced environment with changing priorities""],""confidence_score"":90.0}"
Marketing Data Analyst (12 month contract),"Why you’ll love working here:

high-performance, people-focused culture
our commitment that equity, diversity, and inclusion are fundamental to our work environment and business success, which helps employees feel valued and empowered to be their authentic selves
learning and development initiatives, including workshops, Speaker Series events and access to LinkedIn Learning, that support employees’ career growth
membership in HOOPP’s world class defined benefit pension plan, which can serve as an important part of your retirement security
competitive, 100% company-paid extended health and dental benefits for permanent employees, including coverage supporting our team's diversity and mental health (e.g., gender affirmation, fertility and drug treatment, psychological support benefits of $2,500 per year, and newly extended maternity/parental leave top of 26 weeks)
optional post-retirement health and dental benefits subsidized at 50%
yoga classes, meditation workshops, nutritional consultations, and wellness seminars
access to an annual wellness reimbursement program for health and wellness-related expenses for permanent and temporary employees
the opportunity to make a difference and help take care of those who care for us, by providing a financially secure retirement for Ontario healthcare workers

Job Summary

We are seeking a detail-oriented and versatile Data Analyst to join our Marketing Analytics function to enhance our data management and analytics capabilities. In this position, you will be responsible for handling a variety of data processes including extraction, cleaning, preparation, and validation of complex data sets to support comprehensive reporting. You will build data models and pipelines, advanced dashboards and visualizations, and SQL scripts to deliver meaningful insights, and assist IT in meeting the function’s short- and long-term data analytics needs.

If you are passionate about solving complex problems through analytical thinking and enjoy working with both technical and non-technical teams, we encourage you to apply for this role.

What you will do:

Assist in the collection, cleaning, and preparation of data from diverse sources for reporting purposes
Develop advanced dashboards and visualizations using data from different sources to provide meaningful insights
Create and maintain data models that ensures data consistency, accuracy, and accessibility
Provide ad-hoc reporting support to diverse stakeholders
Develop and maintain documentation for data infrastructure and data governance and actively monitor and execute data governance controls
Develop and document business processes and workflows for data preparation and marketing analytics processes
Collaborate with other departments and data vendors to coordinate data automation and data centralization initiatives
Design, develop, and deploy Power BI scripts and perform analysis that can help in decision-making
Create complex SQL queries, perform optimization of slow running queries incl. leveraging T-SQL data structures to complement report development
Trouble shoot and optimize Power BI and SQL Server report-based data solutions
Design, build, and maintain data pipelines and workflows that extract, transform, and load data from various sources into our data warehouse
Maintain, integrate, and update data sources to ensure data quality and accuracy
Develop and implement data integrity checks and processes, investigate, and resolve data quality issues
Structure the collected data into a well-organized format, creating metadata, and maintain a data catalog for easy access and discoverability
Implement and test new analytics tracking requirements for new elements and features on our digital properties
Maintain and optimize data analytics tools and platforms
Stay up-to-date with emerging trends and technologies in marketing analytics, machine learning and automation
Apply AI and machine learning concepts in relation to data and analytics initiatives

What you will bring:

Bachelor’s degree in computer science, mathematics, or a related field
Microsoft Data and/or BI certifications preferred
3-5 years of experience in data analytics preferred
Experience with data platforms such as GCP (as a BigQuery Viewer), Data Bricks and/or Snowflake
Experience with data Ingestion using Synapse Pipelines and/or Azure Data Factory
Intermediate level BI dashboarding and visualization experience with tools such as PowerBI, Tableau or similar; performance optimization tuning for Power BI
Strong experience with data manipulation and visualization languages such as T-SQL, DML, DDL, DAX, Python and/or R
Knowledge of data analysis, visualization principles, data modeling techniques and best practices
Experience developing data governance best practices, processes, and standards
Experience creating and documenting end-to-end reporting, data processes and ETL
Experience in managing digital marketing and web analytics platforms such as Google Analytics 4 (incl. building reports, dimensions, and calculated metrics) and Google Tag Manager
Empathetic, humble, and collaborative mindset with the ability to work well with both technical and non-technical teams
Ability to work closely with cross-functional teams, including developers, business analysts, and stakeholders
Strong communication skills, capable of presenting data insights to non-technical stakeholders in a clear and concise manner
Strong problem-solving and analytical skills
Ability to work independently and as part of a team","{""role_summary"":""A Data Analyst responsible for enhancing data management and analytics capabilities by handling data processes, building data models and pipelines, and delivering meaningful insights to support comprehensive reporting."",""key_terms"":[{""term"":""Data Governance"",""explanation"":""The process of managing and overseeing data management practices to ensure data quality, security, and compliance with regulations.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from various sources, transforming it into a standardized format, and loading it into a target system such as a data warehouse.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""T-SQL"",""explanation"":""A set of extensions to SQL that allows for more complex and powerful querying of relational databases.""},{""term"":""Data Pipelines"",""explanation"":""A series of processes that extract, transform, and load data from various sources into a target system such as a data warehouse.""},{""term"":""Machine Learning"",""explanation"":""A subset of artificial intelligence that involves training algorithms to learn from data and make predictions or decisions.""}],""skill_priorities"":{""must_have"":[""Data analysis and visualization skills"",""Experience with data platforms such as GCP, Data Bricks, and/or Snowflake"",""Intermediate level BI dashboarding and visualization experience with tools such as PowerBI, Tableau or similar"",""Strong experience with data manipulation and visualization languages such as T-SQL, DML, DDL, DAX, Python and/or R"",""Knowledge of data analysis, visualization principles, data modeling techniques and best practices""],""nice_to_have"":[""Microsoft Data and/or BI certifications"",""Experience with data Ingestion using Synapse Pipelines and/or Azure Data Factory"",""Experience developing data governance best practices, processes, and standards"",""Experience creating and documenting end-to-end reporting, data processes and ETL"",""Experience in managing digital marketing and web analytics platforms such as Google Analytics 4""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of data governance and how you would implement it in a marketing analytics function?"",""example_answer"":""Data governance refers to the process of managing and overseeing data management practices to ensure data quality, security, and compliance with regulations. To implement data governance in a marketing analytics function, I would first identify the key stakeholders and their data needs, then develop a data governance framework that outlines the policies, procedures, and standards for data management. I would also establish a data catalog to track data sources, ensure data quality, and implement data access controls to ensure data security.""},{""question"":""How would you optimize a slow-running Power BI report?"",""example_answer"":""To optimize a slow-running Power BI report, I would first identify the root cause of the performance issue by analyzing the report's data model, data sources, and visualization. I would then apply optimization techniques such as reducing data granularity, using data aggregation, and optimizing data refresh schedules. I would also consider using Power BI's built-in optimization features such as data caching and query optimization.""}],""red_flags"":[""Lack of experience with data platforms such as GCP, Data Bricks, and/or Snowflake"",""Inability to work with both technical and non-technical teams"",""Poor communication skills, unable to present data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Billing Data Analyst,"Enercare Inc. is one of Canada’s largest home and commercial services companies, providing leading products and services in heating, cooling, plumbing, electrical, water heating and water purification. Our purpose is to provide energy-efficient products and services to our customers, so together we can take action for a greener tomorrow, starting in our homes and buildings.

We are a company that believes strongly in the health, safety and wellness of our people. Enercare is a place where careers are made. We take pride in caring for and continually striving to make a positive impact in the communities we operate in. In our values and our ambitions, we embrace change, and support our team members along the way.

Nationally, Enercare Inc. operates under several brands including Enercare, Service Experts, HydroSolution, Pioneer Plumbing & Heating, and Syles Mechanical Services, servicing Canadians in Ontario, Manitoba, Saskatchewan, Alberta, British Columbia, Quebec and New Brunswick. We are united through our joint commitment to excellent customer service to the Canadians we service every day, and our mission to contribute to a resilient, sustainable future. Enercare Inc. Is wholly owned by Brookfield Infrastructure Partners LP (“Brookfield”), a global leader in the management of alternative assets across real estate, infrastructure, renewable power, and private equity.

Summary:

This position is responsible for executing tasks that will support various billing related operations with internal and external groups. The successful candidate’s primary responsibilities will include: configuring, managing and building SalesForce Marketing Cloud email notification journeys and fully supporting the end to end notification requirements. Will be responsible for conducting various functions such as processing transactions, monitoring system exceptions, analysis of files and batches related to billing or payments, billing and rate management as well as researching and resolving exceptions in these key areas. This role will also include analysis of system and user processes to propose and implement process, documentation and training for internal and external groups. The Analyst will also play a key role in contributing towards Enercare's success by meeting business objectives, improving the performance of internal operations, ensuring customer satisfaction and continuous improvement of operating practices and procedures to reduce risk and increase operational effectiveness.

Accountabilities:

Configure and manage Salesforce Marketing Cloud Notifications from build, design and complete execution of enabling a marketing cloud journey
Must be able to report on number of notifications delivered, identity errors and lead driving solutions forward
Maintain and update templates according to business needs or new notification journeys
Prepare process documentation and report on learning with the team by collaborating and knowledge sharing
Work closely with various departments to support the architecture and own configuring best-in-class implementations of Billing and Sales Cloud.
Configure Salesforce Solutions using point and click tools available on the platform ex. Process Builder and Visual Flows
Understand and leverage Salesforce Platform to implement scalable solutions
Work closely with reporting and analytics team to develop and monitor controls to ensure all exceptions from order to cash are monitored and actioned
Partner with Billing and Offline managers to ensure that all controls are being actioned according to defined processes
Create adhoc queries using SQL, PowerBI and other tools and reports in order to understand billing or system exceptions
Resolve exceptions by identifying root cause, implementing solutions and fixing customer accounts Conduct account research and support for Billing & Collections, which includes research in various systems and requests from various functions across the organization
Prepare, validate and execute any bill messaging, letters or inserts required in regular or ad hoc situations
Demonstrates a commitment to process improvement while provides recommendations and driving change
Foster and develop the capability to be a ‘Super User’ for internal systems while cultivating a position as a Subject Matter Expert within various Enercare systems
Maintaining documentation of internal processes to ensure processes are up to date
Work closely with Training and Quality Assurance teams to optimize Billing and revenue related processes
Provide analysis and present recommendations to leadership on system or process improvements Supporting other departments to achieve production service levels and any on-going project objectives Any other duties or initiatives required to maintain or enhance service levels

Qualifications:

Salesforce CPQ , Service Cloud, Community Cloud and Sales Cloud certifications
Experience with SaaS Billing and Revenue solutions such as Zuora Billing and Zuora Revenue
BBA or equivalent post-secondary education
Excellent written and oral communications skills
Superior working knowledge of Microsoft Applications such as Excel and Access.
Experience with PowerBI or SQL is an asset
Minimum three years of experience in an operational environment, financial analysis or other roles that focus on root cause analysis within the scope of billing and revenue systems, with the development and implementation of controls and procedures
Self-starter with strong interpersonal and conflict resolution skills Ability to quickly form relationships and interact effectively in a complex environment Strong desire to understand operations and root causes of issues
Strong organizational and time-management skills with ability to multi-task and work under tight timelines
Ability to understand financial impacts and back-end banking environments
Ability to prioritize deliverables and work with various people in all levels including customers to achieve personal and team objectives with the flexibility to adapt to changing priorities
Extensive experience handling multiple billing systems and exceptions management
Ability to create and formally present recommendations to all levels, including senior leadership teams

Enercare is an equal opportunity employer. We are committed to equal employment opportunity regardless of race, colour, ancestry, national origin, religion, sex, age, sexual orientation, gender identity, citizenship, marital status, disability, pregnancy, military status, protected veteran status or other characteristics protected by applicable law. Enercare’s recruitment process includes accommodation for applicants with disabilities in accordance with applicable provincial accessibility laws and regulations. All accommodations will take into account the applicant’s accessibility needs due to disability and are available upon request.","{""role_summary"":""This role supports billing operations by configuring and managing Salesforce Marketing Cloud email notifications, processing transactions, and analyzing system exceptions to improve internal operations and customer satisfaction."",""key_terms"":[{""term"":""Salesforce Marketing Cloud"",""explanation"":""A cloud-based marketing platform used for email notification journeys and customer engagement.""},{""term"":""SalesForce CPQ"",""explanation"":""Configure, Price, and Quote software used for sales automation and billing processes.""},{""term"":""SaaS Billing and Revenue solutions"",""explanation"":""Software as a Service solutions used for billing and revenue management, such as Zuora Billing and Zuora Revenue.""}],""skill_priorities"":{""must_have"":[""Salesforce CPQ, Service Cloud, Community Cloud and Sales Cloud certifications"",""Experience with SaaS Billing and Revenue solutions"",""BBA or equivalent post-secondary education"",""Excellent written and oral communications skills"",""Superior working knowledge of Microsoft Applications such as Excel and Access""],""nice_to_have"":[""Experience with PowerBI or SQL"",""Ability to create and formally present recommendations to all levels""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you configure and manage Salesforce Marketing Cloud email notification journeys to support billing operations?"",""example_answer"":""I would use point-and-click tools like Process Builder and Visual Flows to design and execute notification journeys, ensuring seamless integration with internal and external groups.""},{""question"":""Can you explain how you would analyze system exceptions and propose process improvements to reduce risk and increase operational effectiveness?"",""example_answer"":""I would use SQL, PowerBI, and other tools to identify root causes of exceptions, and then collaborate with teams to develop and implement controls and procedures to mitigate risks and improve operations.""}],""red_flags"":[""Lack of experience with Salesforce Marketing Cloud and SaaS Billing and Revenue solutions"",""Inability to work effectively in a complex environment with multiple stakeholders""],""confidence_score"":90.0}"
Data / BI Analyst,"Description

We are looking for a certified Data Analyst. To be successful in this role, you should be able to turn data into information, information into insight and insight into business decisions. Some responsibilities of the Data Analyst include conducting full lifecycle analysis to include requirements, activities and design, as well as developing analysis and reporting capabilities. The Data Analyst will also monitor performance and quality control plans to identify improvements.

Your responsibilities

Regularly examine data reports to identify and resolve mistakes throughout
Help various departments, including marketing and sales, reach their goals through analysis
Assemble data recording systems and business analysis for the department to use
Identify changes in financial and business trends by monitoring data
Assemble business reports that provide insight into key data points
Accurately analyze and collect data for various types of business reports
Communicate data analysis findings to managers in written and verbal form
Own the maintenance of databases and perform updates as necessary for accuracy

Requirements

Analytical skills that allow for the development of data-driven reports
Knowledge of object-oriented programming and other data analysis programs
Strong written and verbal communication skills to effectively relate data to coworkers
Able to notice small details that could impact results
Time management and prioritization skills to meet project deadlines
General knowledge of business operations, objectives, strategies, process and information flow
1 to 3 years of experience as a financial or business analyst
Superb critical thinking skills to make decisions and solve business problems
Skilled in creating pivot tables, graphs, and charts using data tools

Robert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.

Robert Half works to put you in the best position to succeed. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity - whenever you choose - even on the go.

Questions? Call your local office at 1.888.490.4429. All applicants applying for Canadian job openings must be authorized to work in Canada.

© 2024 Robert Half. By clicking “Apply Now,” you’re agreeing to","{""role_summary"":""A Data Analyst responsible for turning data into business decisions by conducting full lifecycle analysis, developing reporting capabilities, and monitoring performance to identify improvements."",""key_terms"":[{""term"":""Object-oriented programming"",""explanation"":""A programming paradigm that organizes software design around objects and their interactions.""},{""term"":""Pivot tables"",""explanation"":""A data analysis tool used to summarize and analyze large datasets.""}],""skill_priorities"":{""must_have"":[""Analytical skills"",""Knowledge of data analysis programs"",""Strong written and verbal communication skills"",""Time management and prioritization skills"",""General knowledge of business operations""],""nice_to_have"":[""Experience as a financial or business analyst"",""Skilled in creating graphs and charts using data tools""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data accuracy and quality control in your analysis?"",""example_answer"":""I implement data validation checks and perform regular audits to identify and correct errors. Additionally, I maintain detailed documentation of my analysis process to ensure transparency and reproducibility.""},{""question"":""Can you give an example of a time when you had to communicate complex data insights to a non-technical stakeholder?"",""example_answer"":""In my previous role, I had to present sales trend analysis to the marketing team. I created clear and concise reports with visualizations, and walked them through the key findings and recommendations. The team was able to understand the insights and make data-driven decisions as a result.""}],""red_flags"":[""Lack of experience with data analysis tools and programming languages"",""Inability to communicate complex data insights effectively""],""confidence_score"":85.0}"
Analista de Datos Junior,"Analista de Datos Junior Estamos en busca de un profesional motivado para formar parte de un nuevo proyecto en nuestro equipo. Tu principal función será colaborar con analistas más experimentados para recopilar, organizar y analizar datos, con el objetivo de obtener información valiosa que respalde la toma de decisiones estratégicas por parte del equipo de gerencia. En este rol, tendrás la oportunidad de utilizar herramientas y tecnologías de vanguardia para el análisis y visualización de datos y trabajar en un entorno dinámico y colaborativo, donde tu voz será escuchada y tus ideas valoradas. Responsabilidades: Ayudar en la recopilación y limpieza de datos de diversas fuentes. Asistir en la preparación de conjuntos de datos para análisis mediante la identificación y corrección de errores. Realizar análisis exploratorio de datos para descubrir patrones, tendencias y relaciones significativas. Apoyar en la creación de informes y visualizaciones para comunicar hallazgos a diferentes audiencias. Generar reportes automatizados que permitan analizar performance de los indicadores. Identificar tendencias, patrones y correlaciones dentro de los datos para respaldar los objetivos comerciales. Colaborar con otros miembros del equipo en proyectos de análisis de datos, proporcionando soporte y contribuyendo con ideas. Mantenerse al tanto de las últimas tendencias y herramientas en análisis de datos y participar en actividades de desarrollo profesional para mejorar habilidades. Requisitos: Título universitario en estadística, matemáticas, informática, economía u otro campo relacionado. Inglés B2-C1 (Requerido). Portugués básico (Preferible, no excluyente) Manejo intermedios / avanzados de herramientas de visualización, tales como Tableau, Power BI o DataStudio Conocimiento básico de técnicas de análisis de datos y herramientas como Excel, SQL, Python o R. Fuertes habilidades analíticas y capacidad para interpretar datos de manera efectiva. Capacidad de adaptación para trabajar de manera colaborativa en un entorno de equipo. Powered by JazzHR","{""role_summary"":""Collaborate with senior analysts to collect, organize, and analyze data to support strategic decision-making, using cutting-edge tools and technologies."",""key_terms"":[{""term"":""Análisis exploratorio de datos"",""explanation"":""A method of analyzing data to discover patterns, trends, and relationships.""},{""term"":""Visualización de datos"",""explanation"":""The process of creating graphical representations of data to communicate findings.""},{""term"":""Técnicas de análisis de datos"",""explanation"":""Methods and tools used to extract insights from data, such as Excel, SQL, Python, or R.""}],""skill_priorities"":{""must_have"":[""Título universitario en estadística, matemáticas, informática, economía u otro campo relacionado"",""Inglés B2-C1"",""Manejo intermedios / avanzados de herramientas de visualización"",""Conocimiento básico de técnicas de análisis de datos"",""Fuertes habilidades analíticas""],""nice_to_have"":[""Portugués básico"",""Experiencia con herramientas específicas como Tableau, Power BI o DataStudio""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a large dataset to identify trends and patterns?"",""example_answer"":""I would start by cleaning and organizing the data, then use visualization tools to identify correlations and relationships. I would also use statistical techniques to validate my findings and ensure they are statistically significant.""},{""question"":""How do you stay current with new tools and technologies in data analysis?"",""example_answer"":""I regularly read industry blogs and attend webinars to stay up-to-date on the latest developments in data analysis. I also participate in online forums and communities to learn from others and share my own knowledge.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to communicate complex data insights effectively""],""confidence_score"":85.0}"
Data Analyst with Python and ETL,"Requisition ID: 200666

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

The Team

This position belongs to a highly skilled development team that develops and supports various applications in growing Global Regulatory & Controls Technology team. The team is responsible for providing specialized analysis, design, development, and support of cost effective, mission critical, on-line, risk management and decision support systems for business users within Scotiabank IT group.

The Role

The incumbent will be responsible for supporting and building end-to-end technical solutions to support regulatory reporting of Scotia Capital Markets transactions. From root cause and business requirements analysis, aided by strong data and technical system analysis, to solutioning, development, testing, and release to production, the incumbent will ensure timely resolution of high priority Production Support tickets.
The incumbent will work closely with the broader project team, developers, scrum masters, regulatory stakeholders, trading systems, and downstream consumers to ensure high priority support tickets are resolved within SLAs with high quality. The incumbent will also be expected to develop application and business process subject matter expertise over the duration of the assignment.

Is this role right for you?

Work within a cross functional Agile team to analyse and troubleshoot technical issues and production support tickets and deliver solutions for the same.
Change request delivery – requirements gathering, design, implementation, and testing as part of new regulatory initiatives.
Support of advanced issue triage and ad-hoc data analysis and reporting
Work closely with business users and IT teams from multiple key trading systems in Canada, US, and Asia, in the design and prototyping of business solutions
Ad hoc inquiries from business stakeholders on G20 Regulatory Reporting logic (CFTC, SEC, CSA, MAS, HKMA, EMIR, UK, etc.), behaviour, and data requests
Keep current on rapidly changing technological trends, self-leaner on new technologies and maintain an understanding of the business and technology strategies.
Ability to look at a problem from both a business and technical angle.
Other projects and initiatives as required.

Do you have the skills that will enable you to succeed in this role?

Strong hands-on experience with data analysis and ETL (SQL, Python, Kafka, Jupyter, Java, XML, and JSON)
High levels of analytical, conceptual, problem solving and organizational skills
Excellent verbal and written communication skills
Attitude and willingness to learn fast, go above and beyond consistently and work independently without supervision.
Experience with Apache Kafka, Postman, ElasticSearch, Kubernetes, Airflow, and/or Linux
Ability to perform Java coding is a strong asset.
Knowledge of Capital Market products, front office trading, and back-office booking process globally.
Provide timely IT support to the enquiries from regulators in Canada and US and internal business stakeholders to meet critical timelines.
Excellent team building skills, working with diverse groups to resolve issues and identify efficiencies.
Ability to work in a project environment as required, with key deliverables and ensuring requirements of department are represented.
Strong ability to establish relationships with internal customers, as well as senior management.
A recognized degree in engineering, computer science, math, related discipline or experience

What's in it for you?

We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!
We provide you with the tools and technology needed to create beautiful customer experiences
You'll get to work with and learn from diverse industry leaders, who have hailed from top technology companies around the world
We offer a competitive total rewards package that includes a base salary, a performance bonus, company matching programs (on pension & profit sharing), generous vacation, personal & sick days, personal development funding, maternity leave top-up, parental leave and much more.

#Python

#ETL

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","{""role_summary"":""Support and build end-to-end technical solutions for regulatory reporting of Scotia Capital Markets transactions, ensuring timely resolution of high-priority production support tickets and developing application and business process subject matter expertise."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system for analysis and reporting.""},{""term"":""Agile"",""explanation"":""An iterative approach to project management and software development that emphasizes collaboration, flexibility, and rapid delivery.""},{""term"":""Kafka"",""explanation"":""A distributed streaming platform that enables high-throughput and provides low-latency, fault-tolerant, and scalable data processing.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating the deployment, scaling, and management of containerized applications.""},{""term"":""Regulatory Reporting"",""explanation"":""The process of submitting required reports to regulatory bodies, such as the CFTC, SEC, CSA, MAS, HKMA, EMIR, and UK, to ensure compliance with financial regulations.""}],""skill_priorities"":{""must_have"":[""Strong hands-on experience with data analysis and ETL"",""High levels of analytical, conceptual, problem-solving, and organizational skills"",""Excellent verbal and written communication skills"",""Experience with Apache Kafka, Postman, ElasticSearch, Kubernetes, Airflow, and/or Linux""],""nice_to_have"":[""Ability to perform Java coding"",""Knowledge of Capital Market products, front office trading, and back-office booking process globally""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach troubleshooting a complex technical issue in a production environment?"",""example_answer"":""I would start by gathering information about the issue, then use data analysis and ETL skills to identify the root cause. Next, I would collaborate with the team to design and implement a solution, ensuring timely resolution and high-quality delivery.""},{""question"":""Can you explain how you would stay current with rapidly changing technological trends in the regulatory reporting space?"",""example_answer"":""I would leverage online resources, attend industry conferences, and participate in training sessions to stay up-to-date on new technologies and regulatory requirements. I would also network with peers and experts to gain insights and share knowledge.""}],""red_flags"":[""Lack of experience with ETL and data analysis"",""Inability to work independently without supervision"",""Limited knowledge of regulatory reporting requirements""],""confidence_score"":90.0}"
Data Analyst - Entry Level,"Title: Data Analyst - Entry Level

Location: Remote Canada

Reports To: Supervisor



J.D. Power is a global leader in consumer insights, advisory services and data and analytics. A pioneer in the use of big data, artificial intelligence (AI) and algorithmic modeling capabilities to understand consumer behavior, J.D. Power has been delivering incisive industry intelligence on customer interactions with brands and products for more than 50 years. The world's leading businesses across major industries rely on J.D. Power to guide their customer-facing strategies.

Position Overview

The primary function of the Automotive Data Analyst 1 is to obtain, compile, analyze, interpret, research, code, and test for presentation all ordering, pricing, and technical information needed by JDP Systems from the Automotive Industry. The Automotive Data Analyst 1 must apply highly specialized knowledge of automotive vehicles and the variations of each manufacturer, as well as keep track of numerous details and their inter-relationships to develop a coding structure that makes the JDP products display accurate information with every possible set of variables. Each Data Analyst is ultimately responsible to ensure the JDP content “Gold Standard”.

Core Job Duties And Responsibilities

During the introductory training period, the Automotive Data Analyst 1 is responsible to access training tools and participate in practice content assignments in preparation to take the final assessment.
Gain an understanding of the department and automotive industry.
Develop personal priorities and timelines and hit deadlines within departmental schedule.
Participate in entry and testing updates to company products
Review and analyze source documents from the manufacturer to identify discrepancies, inaccuracies, or missing content.
Accurately enter and/or test incentive vehicle data
Enter and test up to mid-level complexity vehicles for multiple OEM’s
Responsible to help the team achieve established goals, as well as completing individual responsibilities in a timely manner
May work on special projects, depending upon available resources and appropriate skill levels
Receive and respond to customer reports of errors and proactively respond with corrections and status updates in a professional manner
Act as a positive team player
Perform other duties as assigned

Education, Experience And Qualifications

Excellent verbal and written communication skills
Post-secondary education or related work experience
Able to work well under pressure and to excel in a constantly changing environment
Strong self-management and analytical abilities
Very high accuracy and attention to detail is required
Self-motivated and able to work within a team
Computer skills – MS office tool suite
Time management skills, organized and able to meet deadlines
This role requires flexible hours (including OT) which may at times include early mornings, late nights and weekends

Company Mission

J.D. Power is clear about what we do to ensure our success into the future. We unite industry leading data and insights with world-class technology to solve our clients’ toughest challenges.

Our Values

At J.D. Power, we strive to be Truth Finders, Change Makers and Team Driven - the distinct behaviors that, together, define our unique culture.

Truth Finders - At J.D. Power, we are proud of the unbiased data and findings we provide. As individuals, each and every member of our team is dedicated to living this same objectivity and embodying the highest ethical and professional standards – the only ‘favorite’ we have is the truth.

Change Makers - At J.D. Power, we never stand still. We constantly seek better ways – innovating and evolving in everything we do to support our colleagues and our clients alike – and all in service of delivering data and insights that drive meaningful business impact.

Team Driven - At J.D. Power, we are one team and we are activated. Regardless of individual role, every member of our team is dedicated to supporting their immediate colleagues and our broader J.D. Power family to deliver on our collective purpose and make us greater than the sum of our parts. At J.D. Power, these values are more than words.

J.D. Power is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.

J.D. Power is an equal-opportunity employer and compliant with AODA/ADA legislation. Should you require accommodations during the recruitment and selection process, please reach out to tarecruitment@jdpa.com.



To all recruitment agencies: J.D. Power does not accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes.","{""role_summary"":""The Data Analyst - Entry Level role is responsible for obtaining, compiling, analyzing, and interpreting automotive industry data to ensure accurate information is displayed in JDP products."",""key_terms"":[{""term"":""Big data"",""explanation"":""Large and complex sets of data that require specialized analysis and modeling techniques.""},{""term"":""Algorithmic modeling"",""explanation"":""The use of mathematical and computational techniques to develop predictive models and analyze data.""},{""term"":""Automotive industry"",""explanation"":""The industry related to the design, manufacture, and sale of vehicles, including cars, trucks, and motorcycles.""}],""skill_priorities"":{""must_have"":[""Analytical skills"",""Attention to detail"",""Time management skills"",""MS Office tool suite"",""Verbal and written communication skills""],""nice_to_have"":[""Post-secondary education or related work experience"",""Experience in the automotive industry""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you ensure data accuracy and attention to detail in a fast-paced environment?"",""example_answer"":""I would prioritize tasks, break them down into smaller steps, and double-check my work to ensure accuracy. I would also communicate with my team and supervisor to clarify any doubts and ensure we are on the same page.""},{""question"":""Can you give an example of a time when you had to analyze complex data and present your findings?"",""example_answer"":""In my previous role, I analyzed customer feedback data and identified trends that helped our team improve our product offerings. I presented my findings to our team lead, and we implemented changes that resulted in a 20% increase in customer satisfaction.""}],""red_flags"":[""Lack of attention to detail"",""Inability to work under pressure"",""Poor communication skills""],""confidence_score"":85.0}"
Lead Data Analyst,"Role: Lead Data Analyst

Location: Remote/Canada

Duration: 6+ Months

Job Description

Lead Data Analyst minimum 15+ – 4 years lead exp

We are looking for Strong expereince on the following .

Total years of exp should be more tha

Expert in SQL (Most Advanced level) – SQL – Azure cloud migration
Data Models – expert level
Data Analysis (data identification, querying, cleaning, wrangling, checking quality)
Market Data Analysis background
Cloud Migration – Azure
On Premises Migration
data visualization tools such as Power BI, Tableau etc.

Write Up From Candidate Required .

What is the most complex Source to target mapping exercise that you have done?
What is the most complex SQL query you have done- is this for Data analyst?

This is a combination of (Data + Strong SQL background + On Perm and Cloud migration (Azure

The senior data analyst is responsible for analysing business requirements and converting them into data requirements such as reports, data lifecycle management. They will analyse and interpret complex data sets to inform business decisions. The senior data analyst will also be expected to lead and mentor junior data analysts as well as communicate findings and recommendations to stakeholders and management .

SQL/NoSQL databases, social media, surveys within organization, and additional, public domain, market data sources.
Collaborate with Business SMEs, Product owners, Data Stewards, and Data Architects to identify critical data elements, define business terms, capture metadata, define data schema, clean, and prepare data in an appropriate format to perform analysis.
Analyse data using statistical techniques to identify trends and patterns (e.g. growth/decline in key metrics) and create visualizations and reports to present findings to business stakeholders and/or data scientists for further actions.
Build expert knowledge of products, systems, data and data quality in order to provide high business impact analysis and consultation. Provide robust, data-driven customer insights and recommendations for strategic decision-making purposes by performing deep dives and providing meaningful analysis to the business units .
Assess and monitor the quality of data by working with the Data stewards, Data quality leads, and internal stakeholders and support the implementation of data quality rules and remediation of issues.
Provide guidance and mentorship to junior members of the team.
Build a culture of collaboration and innovation. Proactively identify pain points through the data and
formulate potential opportunities that can be pursued by the business units.
Collaborate/Partner with product owner and delivery teams to ensure that the project/product is
delivered with quality and in time. Assist the scrum master to provide estimate and impact assessment.
Interpret data models (Logical and Physical) and ensuring they align with the solution design. Design
reusable and scalable frameworks to achieve standardization and efficiency. Convert user requirement into technical specifications and design documents and identifying new data sources for the data warehouse.
Also responsible for other Duties/Projects as assigned by business management as needed.
Also responsible for other Duties/Projects as assigned by business management as needed.

Mandatory Skill set .

Experience in data identification, querying, cleaning, wrangling, checking quality, working with common relational and non-relational databases in big data environments on both on prem and cloud such as Azure .
Experience working with relational databases using SQL.
Experience with Data querying, cleaning, wrangling, working with common relational and non-relational databases in big data environments such as Azure .
Experience articulating and translating business questions and using statistical techniques to arrive
at an answer using data.
Experience writing and speaking about technical concepts to business, technical, and lay audiences and giving data-driven presentations .
Experience working with relational databases using SQL .
Experience with data visualization tools such as Power BI, Tableau etc.
Excellent presentation, communication, and organizational skills","{""role_summary"":""Lead a team of data analysts to analyze business requirements, convert them into data requirements, and provide insights to stakeholders and management."",""key_terms"":[{""term"":""Azure cloud migration"",""explanation"":""The process of moving data and applications from on-premises infrastructure to Microsoft Azure cloud computing platform.""},{""term"":""Data Models"",""explanation"":""Conceptual representations of data structures and relationships, used to organize and standardize data.""},{""term"":""On Premises Migration"",""explanation"":""The process of moving data and applications from one on-premises infrastructure to another.""},{""term"":""SQL/NoSQL databases"",""explanation"":""Types of databases that store and manage data, with SQL databases using structured query language and NoSQL databases using other query languages.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to communicate insights and trends.""}],""skill_priorities"":{""must_have"":[""Expert-level SQL skills"",""Experience with data analysis, querying, cleaning, and visualization"",""Cloud migration experience (Azure)"",""Data modeling expertise"",""Strong communication and presentation skills""],""nice_to_have"":[""Experience with Power BI and Tableau"",""Knowledge of NoSQL databases"",""Familiarity with data quality rules and remediation""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a complex data model you've designed and how it improved data analysis?"",""example_answer"":""I designed a data model for a customer analytics project that integrated data from multiple sources, including social media and surveys. The model enabled us to identify trends and patterns in customer behavior, leading to a 20% increase in sales.""},{""question"":""How do you ensure data quality in your analysis?"",""example_answer"":""I work closely with data stewards and quality leads to identify and remediate data quality issues. I also implement data quality rules and monitor data quality metrics to ensure accuracy and reliability.""}],""red_flags"":[""Lack of experience with cloud migration (Azure)"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Partnershipstaffing,"Our expertise has made us the preferred video agency and partner for a diverse range of clients, both nationally and internationally. We have valued partnerships with media and advertising agencies, publishers, and influential broadcasters, solidifying our position as a trusted name in the industry.

As part of our continued growth, we are excited to announce the opening of our new office in North America. We invite talented job candidates to join us on this journey and be at the forefront of our expanding operations

About The Role

As an Entry-Level Data Analyst you will have the chance to learn and develop essential data analysis skills while contributing to meaningful projects. You will work closely with experienced data analysts and collaborate with cross-functional teams to support our data-driven decision-making process.

Responsibilities

Data Collection and Analysis:

Assist in collecting, cleaning, and organizing data from various sources.

Learn to use data analysis tools and techniques to ensure data accuracy.

Reporting and Visualization:

Support the creation of reports and dashboards using tools like [Excel, Power BI].

Assist in visualizing data to communicate insights effectively.

Data Analysis

Work under the guidance of senior analysts to perform data analysis and generate insights.

Learn to use statistical methods to identify trends and patterns.

Collaborative Approach:

Collaborate with team members to understand data-related needs and provide assistance.

Communicate findings and insights to colleagues and stakeholders.

Continuous Learning:

Engage in ongoing training and development to enhance your data analysis skills.

Stay updated on industry best practices and emerging trends.

About You

Bachelor's degree in a related field (e.g., Data Science, Statistics, Mathematics, Computer Science) or relevant coursework.

Strong interest in data analysis and a desire to learn and grow in this field.

Basic knowledge of data analysis tools or programming languages is a plus (e.g., Excel, SQL, Python).

Excellent problem-solving skills and attention to detail.

Effective communication and a willingness to work collaboratively.

Eagerness to take on new challenges and a strong desire to develop as a data analyst.

What we offer

A Highly Competitive Remuneration

Comprehensive medical, dental, and vision insurance

401(k)

Paid parental leave

Flexible Work Arrangements

Gym memberships/yoga & meditation classes

How to apply

Please note that we prefer direct communication with candidates and have not engaged any recruitment agency for this position. Therefore, we will not accept CVs or applications submitted through any recruitment agency.

We are committed to providing equal employment opportunities to all individuals, regardless of race, gender, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information, or any other characteristic protected by applicable law. We value and celebrate the unique qualities that each team member brings to our organization, and we encourage all employees to embrace their true selves. We believe that diversity and individual differences enrich our team and contribute to our success. Join ustoday, and we are confident it will be a transformative experience!

Powered by Webbtree","{""role_summary"":""Assist in data collection, analysis, and visualization to support data-driven decision-making, while learning and developing essential data analysis skills."",""key_terms"":[{""term"":""Data Analysis"",""explanation"":""The process of extracting insights and patterns from data to inform business decisions.""},{""term"":""Data Visualization"",""explanation"":""The presentation of data in a graphical or visual format to communicate insights effectively.""},{""term"":""Statistical Methods"",""explanation"":""Mathematical techniques used to identify trends and patterns in data.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in a related field (e.g., Data Science, Statistics, Mathematics, Computer Science)"",""Strong interest in data analysis"",""Excellent problem-solving skills"",""Attention to detail"",""Effective communication""],""nice_to_have"":[""Basic knowledge of data analysis tools or programming languages (e.g., Excel, SQL, Python)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to analyze a complex data set and present your findings to a non-technical audience?"",""example_answer"":""In my previous internship, I was tasked with analyzing customer purchase behavior. I used Excel to clean and organize the data, and then created visualizations to present my findings to the marketing team. I was able to identify key trends and insights that informed their future marketing strategies.""},{""question"":""How do you stay updated on industry best practices and emerging trends in data analysis?"",""example_answer"":""I regularly read industry blogs and attend webinars to stay current on new tools and techniques. I also participate in online forums and discussion groups to learn from other professionals in the field.""}],""red_flags"":[""Lack of enthusiasm for learning and growing in data analysis"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Data Analyst – Information Management,"NES Fircroft is a leading global technical recruitment company providing professional contract and permanent staff to a diverse world-wide client base within the oil & gas Industry.

Job Title: Data Analyst – Information Management
Location: Calgary
Length: 12 Month contract to start
Rotation: Mon - Fri

Description:
We are looking for an experienced and detail-oriented IM Data Analyst. This position will be responsible for the management & control of the Superior Refinery master process safety data / drawings to be compliant with and support the Operational Integrity Management Element 4 Information Management (IM) practices and OSHA Process Safety Information requirements, including Management of Change (MOC).

Successful applicants will have a strong background in information management to provide quality control on project engineering drawing deliverables metadata handed over from projects to ensure company expectations are met and the drawings represent the asset engineering information expected.

Applicants must be passionate, dynamic, energetic, and persistent to drive change and transition refinery to modern data driven systems, including development of methodology and procedures.

Responsibilities
Review and quality check incoming process safety information and drawings packages to ensure all required drawings/technical/ safety / operations documents are received contain accurate information
Manage equipment & instrument databases, assign equipment & instrument numbers as requested
Ensure equipment tags contain the consistent and correct metadata, providing a way to quickly get process/asset/equipment documents in a timely manner for refinery’s daily operations.
Maintain control of Process Safety Information master copies of drawings, technical / operations / safety documents and technical documents issued to internal/external users.
Collaborate with technical services, maintenance, and operations function of the Superior Refinery.
Work effectively with staff at various levels, within the refinery and with the corporate head office with tact and diplomacy
Ensure current revision of all Process Safety Information, including Safe Operating Procedures, drawings, technical / operations / safety documents are available, issued and tracked. Assign document numbers as requested. Support management of concurrent engineering & redline processes
Maintain control of Process Safety Information master copies of drawings, technical / operations / safety documents and technical documents issued to internal/external users.
Review and quality check incoming process safety information and drawings packages to ensure all required drawings/technical/ safety / operations documents are received contain accurate information
Manage equipment & instrument databases, assign equipment & instrument numbers as requested
Provide training to Site team when required for Process Safety Information management. Collaborate with internal stakeholders and team members to identify and change current processes for more efficient working activities
Create value-add dashboards to track data quality across departments for accurate, timely information. Good data will help increase production time by limited asset downtime, Process Safety incidents which will ultimately reduce operational and incident costs

Required Skills and Experience
Understanding of taxonomy, metadata, and document management practices
Tracking record managing KPI and records retention compliance. Managing documents in a controlled environment, revision tracking
Demonstrated experience in writing and implementing information management standards, procedures, and processes
Understanding of various systems such as MSDP (procedural documents), SAP PM (Plant Maintenance data) and TechDocs (Engineering documents)
Demonstrated understanding of engineering and supporting documentation, revision control, review & approval process, understanding Project life cycle
Proficiency in identifying Engineering Drawing document types
Detail attention to data and the ability to create comparative analysis to identify and correct integrity issues
Proficient in MS Office and Livelink, and Share Point
Working Knowledge of petroleum/oil& gas industry; Engineering disciplines, Terminology/industry accepted file types (.dgn, .tif, etc)
Related Bachelor's or Technical College Diploma (information science, records management, archival science, engineering, science, process safety etc.) is an asset
ECMS, ECMM, RM or AIIM certification is a strong asset
Experience in process safety, records management, information management or document control (3-5 years)
Experience in oil and gas, Owner Operator, large Contractor, or EPC industry related experience (3-5 years)

Apply here or send your resume to trevor.parlee@nesfircroft.com","{""role_summary"":""Manage and control process safety data and drawings for a refinery, ensuring compliance with industry standards and company expectations, and driving change to modern data-driven systems."",""key_terms"":[{""term"":""Operational Integrity Management Element 4 Information Management (IM)"",""explanation"":""A set of practices and standards for managing information related to process safety and operational integrity in the oil and gas industry.""},{""term"":""Management of Change (MOC)"",""explanation"":""A process for managing changes to equipment, procedures, or other aspects of a refinery operation to ensure safety and compliance.""},{""term"":""Metadata"",""explanation"":""Data that provides information about other data, such as descriptions, tags, or categorizations, used to organize and manage large datasets.""},{""term"":""Taxonomy"",""explanation"":""A system for categorizing and organizing data or documents into a hierarchical structure, used for information management and retrieval.""},{""term"":""ECMS, ECMM, RM or AIIM certification"",""explanation"":""Certifications related to information management, records management, and document control, demonstrating expertise in these areas.""}],""skill_priorities"":{""must_have"":[""Understanding of taxonomy, metadata, and document management practices"",""Demonstrated experience in writing and implementing information management standards, procedures, and processes"",""Proficiency in identifying Engineering Drawing document types"",""Detail attention to data and the ability to create comparative analysis to identify and correct integrity issues"",""Proficient in MS Office and Livelink, and Share Point""],""nice_to_have"":[""ECMS, ECMM, RM or AIIM certification"",""Experience in oil and gas, Owner Operator, large Contractor, or EPC industry related experience"",""Related Bachelor's or Technical College Diploma (information science, records management, archival science, engineering, science, process safety etc.)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would ensure data quality and integrity in a large dataset of process safety information?"",""example_answer"":""I would implement a taxonomy and metadata structure to organize the data, and then use comparative analysis to identify and correct any integrity issues. I would also establish a revision tracking system to ensure that only the latest versions of documents are used.""},{""question"":""How would you drive change to modern data-driven systems in a refinery operation?"",""example_answer"":""I would work with stakeholders to identify areas for improvement, and then develop a methodology and procedures for implementing changes. I would also provide training and support to ensure a smooth transition to the new systems.""}],""red_flags"":[""Lack of experience in information management or document control"",""Inability to work effectively with staff at various levels"",""Limited understanding of engineering and supporting documentation""],""confidence_score"":90.0}"
Azilentechnologies,"About The Job

Important: You Will Receive An Email Within Next 24 hours, Check Your Inbox or Spam Folder For next steps.

Junior / Entry Level Data Analyst - Remote

Currently We are looking for individuals that possess strong analytical skills to join the commercial desk to help support day to day operations.

Job Description/Function:

The primary purpose of this position is to support all commercial operations functions in managing current and potential future assets. Analyst will be working in a team environment to increase the commercial value of the assets. Analyst will gain exposure to management and optimization of power generators across different ISOs while working alongside Asset Managers

Review and submit operational data to ISOs
Provide quantitative analysis support
Track and procure emissions allowances
Provide asset management functions such as gas nominations
Work with settlements to ensure margins are accurate
Support data aggregation efforts to assist fleet wide and site specific asset optimization
Improve/develop analytical tools for the commercial desk related to plant performance and market information
Assist other groups within company regarding budgeting and risk reporting
Other commercial duties as required
Establish relationships with plant operators and 3rd party suppliers

Requirements:

1-3 Years’ Experience
Bachelor’s Degree required, Finance, Business or Engineering preferred
Strong team player with solid analytical skills and strong attention to detail
Strong basics in Microsoft Office with a focus on Excel (VLOOKUPS, etc.)
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, and disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Powered by Webbtree","{""role_summary"":""Support commercial operations by analyzing data, optimizing assets, and providing quantitative analysis to increase commercial value."",""key_terms"":[{""term"":""ISOs"",""explanation"":""Independent System Operators, responsible for managing power grids and ensuring reliable electricity supply.""},{""term"":""Emissions allowances"",""explanation"":""Credits or permits that allow companies to emit a certain amount of greenhouse gases, used to manage environmental impact.""},{""term"":""Gas nominations"",""explanation"":""The process of scheduling gas deliveries to meet energy demands, ensuring a stable supply of natural gas.""},{""term"":""VLOOKUPS"",""explanation"":""A Microsoft Excel function used to look up and retrieve data from a table or range based on a specific value or criteria.""}],""skill_priorities"":{""must_have"":[""Strong analytical skills"",""Strong attention to detail"",""Microsoft Office skills (Excel)"",""Bachelor's Degree in Finance, Business, or Engineering""],""nice_to_have"":[""1-3 years of experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize asset performance using data analysis?"",""example_answer"":""I would use Excel to analyze operational data, identify trends, and develop recommendations to improve asset performance. I would also work closely with the asset management team to implement changes and track results.""},{""question"":""Can you explain how you would track and procure emissions allowances?"",""example_answer"":""I would use data aggregation tools to track emissions allowances, identify areas for improvement, and work with the commercial desk to procure additional allowances as needed. I would also ensure compliance with environmental regulations.""}],""red_flags"":[""Lack of experience with data analysis tools"",""Inability to work in a team environment""],""confidence_score"":85.0}"
Business Intelligence Analyst (Remote - Canada),"Summary

Yelp engineering culture is driven by our values: we’re a cooperative team that values individual authenticity and encourages creative solutions to problems. All new engineers deploy working code their first week, and we strive to broaden individual impact with support from managers, mentors, and teams. At the end of the day, we’re all about helping our users, growing as engineers, and having fun in a collaborative environment.

Are you strongly driven by a passion for data analysis, complex problem-solving, and designing business intelligence solutions? As a Business Intelligence Analyst at Yelp, you’ll work with partners and stakeholders across the company — including our Executive Leadership, Finance, BizOps, Product, Data Science, Data Engineering, Marketing, and People teams — to provide relevant data and visualization for key business decisions.

Yelp's Business Intelligence team is dedicated to empowering Yelp's leadership and analytics teams with trusted and reusable data visualizations, data warehousing products, and BI platform support. The work of our team continuously evolves with the company’s needs and is critical to Yelp’s data-driven decision making. We are looking for someone adept at engaging with business partners, who understands their needs, and who is passionate about diving into data, unraveling complexities, and designing business intelligence solutions.

This opportunity is fully remote and does not require you to be located in any particular area in Canada. We welcome applicants from throughout Canada. We’d love to have you apply, even if you don’t feel you meet every single requirement in this posting. At Yelp, we’re looking for great people, not just those who simply check off all the boxes.

What You'll Do

Build relationships with key business partners, lead requirement gathering sessions, analyze source data and systems, and provide feedback on detailed data analysis to guide data-driven decision making.
Become a subject matter expert on Yelp data and share knowledge with Engineering, Product, and other teams to refine business understanding, and identify areas of needed business improvement.
Plan and execute business intelligence/analytics projects by collaborating with business partners, data engineering, and data visualization teams.
Contribute to data strategy for data warehousing, reporting, dashboards, and self-service analytics.
Exercise advanced knowledge of SQL to extract critical information and business value from data spread across multiple databases and data formats.
Provide training and ongoing support to business users on business intelligence products.

What It Takes To Succeed

Ideally 3 years of experience in business intelligence or as a business systems analyst, data analyst/developer or similar role.
Experience with data visualization tools (Tableau preferred).
Experience documenting business and technical requirements and directly interacting with engineers on business intelligence projects.
Excellent collaboration, communication, negotiation, and presentation skills.
Working knowledge of statistics and KPIs (LTV, Churn, etc.).
Advanced SQL skills and experience writing complex queries.
Knowledge and working experience with dimensional data modeling.

What You'll Get

Compensation range is $82,000-230,000 annually. Depending on your role and level, you may also be offered a bonus, restricted stock units, and benefits.
This opportunity has the option to be fully remote in all locations across Canada.
You can find more information about Yelp's five star benefits here!

Closing

At Yelp, we believe that diversity is an expression of all the unique characteristics that make us human: race, age, sexual orientation, gender identity, religion, disability, and education — and those are just a few. We recognize that diverse backgrounds and perspectives strengthen our teams and our product. The foundation of our diversity efforts are closely tied to our core values, which include “Playing Well With Others” and “Authenticity.”

We’re proud to be an equal opportunity employer and consider qualified applicants without regard to race, color, religion, sex, national origin, ancestry, age, genetic information, sexual orientation, gender identity, marital or family status, veteran status, medical condition, disability, or any other protected status.

We are committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-recruiting@yelp.com or 1-415-969-8488.

Note: Yelp does not accept agency resumes. Please do not forward resumes to any recruiting alias or employee. Yelp is not responsible for any fees related to unsolicited resumes.

Recruiting and Applicant Privacy Notice","{""role_summary"":""As a Business Intelligence Analyst at Yelp, you'll work with various teams to provide data and visualization for key business decisions, empowering leadership and analytics teams with trusted data visualizations and BI platform support."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""The practice of using data analysis and visualization to inform business decisions.""},{""term"":""Data Warehousing"",""explanation"":""A system for storing and managing large amounts of data to support business intelligence and analytics.""},{""term"":""Dimensional Data Modeling"",""explanation"":""A technique for organizing data into structures that facilitate fast querying and analysis.""}],""skill_priorities"":{""must_have"":[""Experience with data visualization tools (Tableau preferred)"",""Advanced SQL skills and experience writing complex queries"",""Excellent collaboration, communication, negotiation, and presentation skills""],""nice_to_have"":[""Knowledge and working experience with dimensional data modeling"",""Working knowledge of statistics and KPIs (LTV, Churn, etc.)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to analyze complex data to inform a business decision?"",""example_answer"":""In my previous role, I analyzed customer purchase data to identify trends and opportunities for growth. I presented my findings to the executive team, which led to a change in our marketing strategy.""},{""question"":""How do you stay up-to-date with new tools and technologies in the business intelligence space?"",""example_answer"":""I regularly attend industry conferences and webinars, and I participate in online forums and communities to stay current with the latest developments in business intelligence.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
"Staff Data Analyst, Growth","Who we are

About Stripe

Stripe is a financial infrastructure platform for businesses. Millions of companies—from the world’s largest enterprises to the most ambitious startups—use Stripe to accept payments, grow their revenue, and accelerate new business opportunities. Our mission is to increase the GDP of the internet, and we have a staggering amount of work ahead. That means you have an unprecedented opportunity to put the global economy within everyone’s reach while doing the most important work of your career.

About The Team

Our GTM (Go-To-Market) Analytics team is on the mission to maximize revenue by providing actionable insights and reporting to our partners across Sales, Marketing, and Growth. GTM Analytics is situated within the broader Data Science organization at Stripe, which is home to a diverse team of data analysts and scientists, product managers, and engineers that span their focus across sales, marketing, and product-led growth. GTM Analytics leverages sales, marketing, and product data to build and provide a wide variety of tools that are utilized across the company to drive business decisions.

What you’ll do

As a senior member of the GTM Analytics team, you will lead analytical projects that shed light on our self-service business. You will increase our understanding of growth drivers and influence business outcomes by recommending solutions rooted in analyses and your deep understanding of Stripe’s users. You will partner closely with cross-functional Growth pods of product managers, marketers, engineers, and data analysts and scientists that obsess over the experience Stripe users have on their journey to become customers – from initial signup through onboarding and retention.

Responsibilities

Collaborate with Growth stakeholders to ideate, scope, and develop data products that shed light on Stripe’s self-service business.
Influence Stripe’s Growth roadmap by proactively identifying opportunities and emerging trends in Stripe’s Growth business in ongoing forums.
Develop frameworks that allow for analysis at scale across Stripe’s self-service experience.
Build and maintain data pipelines and dashboards that provide consistent and timely data and insights.
Work with finance partners on forecasting and planning models that provide visibility into the future of Stripe’s self-service business.
Define key Growth metrics, gain consensus around their definitions, and drive adoption of their usage.


Who you are

We’re looking for someone who meets the minimum requirements to be considered for the role. If you meet these requirements, you are encouraged to apply. The preferred qualifications are a bonus, not a requirement.

Minimum Requirements

8+ years of experience in analytical roles working with large datasets
Bachelor’s degree in Statistics, Economics, Mathematics, Engineering, Sciences or a related quantitative field
Proficiency in SQL and Python
Experience building self-serve dashboards or other scalable analytical tools for partner teams
Strong knowledge of statistics
Expertise in data storytelling and visualization, using data-driven insights to deliver actionable recommendations and drive business goals
Demonstrated ability to lead and deliver on multiple projects with a high attention to detail
Outstanding written and verbal communication skills


Preferred Qualifications

Master’s degree in Statistics, Economics, Mathematics, Engineering, Sciences or a related quantitative field and/or experience in working on data analytics in the tech field
Experience developing data-informed narratives and visualizations for external publication
Experience working with institutions that are respected by policymakers and the wider public for their economic insight
Experience building and maintaining data pipelines using a distributed data framework (e.g. Hadoop, Spark)


Hybrid work at Stripe

This role is available either in an office or a remote location (typically, 35+ miles or 56+ km from a Stripe office).

Office-assigned Stripes spend at least 50% of the time in a given month in their local office or with users. This hits a balance between bringing people together for in-person collaboration and learning from each other, while supporting flexibility about how to do this in a way that makes sense for individuals and their teams.

A remote location, in most cases, is defined as being 35 miles (56 kilometers) or more from one of our offices. While you would be welcome to come into the office for team/business meetings, on-sites, meet-ups, and events, our expectation is you would regularly work from home rather than a Stripe office. Stripe does not cover the cost of relocating to a remote location. We encourage you to apply for roles that match the location where you currently or plan to live.

Pay and benefits

The annual US base salary range for this role is $179,000 - $268,400. For sales roles, the range provided is the role’s On Target Earnings (""OTE"") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. This salary range may be inclusive of several career levels at Stripe and will be narrowed during the interview process based on a number of factors, including the candidate’s experience, qualifications, and location. Applicants interested in this role and who are not located in the US may request the annual salary range for their location during the interview process.

Additional benefits for this role may include: equity, company bonus or sales commissions/bonuses; 401(k) plan; medical, dental, and vision benefits; and wellness stipends.","{""role_summary"":""Lead analytical projects to drive business growth, providing actionable insights and recommendations to cross-functional teams, and develop data products to shed light on Stripe's self-service business."",""key_terms"":[{""term"":""GTM Analytics"",""explanation"":""Go-To-Market Analytics, a team that provides actionable insights and reporting to partners across Sales, Marketing, and Growth.""},{""term"":""Data pipelines"",""explanation"":""A series of processes that extract, transform, and load data into a usable format for analysis and reporting.""},{""term"":""Self-serve dashboards"",""explanation"":""Interactive data visualization tools that allow users to explore and analyze data without requiring technical expertise.""},{""term"":""Data storytelling"",""explanation"":""The process of communicating insights and findings from data analysis using a narrative approach to drive business decisions.""}],""skill_priorities"":{""must_have"":[""8+ years of experience in analytical roles working with large datasets"",""Bachelor's degree in Statistics, Economics, Mathematics, Engineering, Sciences or a related quantitative field"",""Proficiency in SQL and Python"",""Experience building self-serve dashboards or other scalable analytical tools for partner teams"",""Strong knowledge of statistics"",""Expertise in data storytelling and visualization""],""nice_to_have"":[""Master's degree in Statistics, Economics, Mathematics, Engineering, Sciences or a related quantitative field"",""Experience developing data-informed narratives and visualizations for external publication"",""Experience working with institutions that are respected by policymakers and the wider public for their economic insight"",""Experience building and maintaining data pipelines using a distributed data framework (e.g. Hadoop, Spark)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to develop a data product to drive business growth? What insights did you uncover, and how did you communicate them to stakeholders?"",""example_answer"":""In my previous role, I developed a dashboard to track customer churn. I analyzed customer behavior and identified key drivers of churn. I presented my findings to the product team, and we implemented changes that resulted in a 20% reduction in churn rate.""},{""question"":""How do you approach data storytelling, and what tools do you use to visualize complex data insights?"",""example_answer"":""I use a combination of data visualization tools like Tableau and Power BI to create interactive dashboards that tell a story. I focus on highlighting key insights and recommendations, and use clear and concise language to communicate complex data concepts to non-technical stakeholders.""}],""red_flags"":[""Lack of experience working with large datasets"",""Inability to communicate complex data insights effectively"",""Limited experience with data visualization tools""],""confidence_score"":90.0}"
Functional Data Analyst ,"A cybercrime investigator or a functional data analyst

The IT Delivery group supporting the Fight against Financial Crimes sector is currently looking for an analyst who wishes to contribute to the evolution of the sector's processes and application base and its business partners. This position is part of a sector transformation framework, including new working practices (agility) and various initiatives of all sizes.

Act as a functional analyst in the field of cybercrimes
Participate in highly strategic initiatives for the Bank relating to the prevention of money laundering and fraud
Understand the strategy, issues, and operational reality of business sectors to properly guide IT teams in developing innovative and efficient solutions
Identify and mitigate impacts in transformation projects, current programs as well as new initiatives
Ensure the link between business requirements and the development team

Requirements:
Minimum five years of experience in functional analysis for large-scale projects.
Experience in Agile Scrum delivery.
Knowledge of fraud and compliance areas is beneficial.
Strong communication skills and ability to simplify complex IT concepts.
Bilingualism (French and English) is essential.
Contribute to strategic planning and Agile transformation.
Participate in testing phases.

Matrix Global Services is a leading multinational corporation providing innovative and comprehensive technology, consulting, and outsourcing solutions. For over thirty years, Matrix has established itself as a trusted partner for businesses across various industries, consistently delivering exceptional results.
We're a network of firms in 10+ countries with over 13,000 people. At Matrix, we pride ourselves on our commitment to excellence and our ability to adapt to our clients' ever-changing needs. Our team of highly skilled professionals is adept at understanding complex business challenges and tailoring solutions that drive sustainable growth and profitability.
Our wide range of services includes cutting-edge technology solution services, strategic consulting, digital transformation, cloud computing, cybersecurity, and managed services. Whether it's developing customized software applications, streamlining business processes, implementing robust IT infrastructure, or managing complex projects, our expertise and industry knowledge enable us to deliver value-added solutions that meet each client's unique requirements.
Come and join a winning team! You'll be challenged, have fun, and be part of a highly respected organization! Matrix offers a competitive base salary and a complete benefit package. Benefits include medical, dental, 401 (k), STD, HSA, and PTO.

EQUAL OPPORTUNITY EMPLOYER: Matrix is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind. Matrix is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Matrix are based on business needs, job requirements, and individual qualifications, without regard to race, color, religion or belief, family or parental status, or any other status protected by the laws or regulations in our locations. Matrix will not tolerate discrimination or harassment based on any of these characteristics. Matrix encourages applicants of all ages.","{""role_summary"":""Support the Fight against Financial Crimes sector by contributing to process and application evolution as a functional data analyst or cybercrime investigator."",""key_terms"":[{""term"":""Agile Scrum delivery"",""explanation"":""A project management approach that emphasizes iterative progress, flexibility, and team collaboration.""},{""term"":""Functional analysis"",""explanation"":""A method of analyzing business needs to identify solutions, often involving IT systems and processes.""},{""term"":""Cybercrimes"",""explanation"":""Criminal activities carried out using computers or the internet, such as fraud, money laundering, and other financial crimes.""}],""skill_priorities"":{""must_have"":[""Five years of experience in functional analysis for large-scale projects"",""Experience in Agile Scrum delivery"",""Strong communication skills"",""Bilingualism (French and English)""],""nice_to_have"":[""Knowledge of fraud and compliance areas""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to simplify complex IT concepts for non-technical stakeholders?"",""example_answer"":""In my previous role, I worked with a cross-functional team to develop a new fraud detection system. I had to explain the technical aspects of the system to our business partners, using analogies and visual aids to ensure they understood the benefits and limitations.""},{""question"":""How do you stay up-to-date with the latest developments in fraud and compliance?"",""example_answer"":""I regularly read industry publications and attend webinars to stay current on emerging trends and regulations in fraud and compliance. I also network with peers and experts in the field to stay informed.""}],""red_flags"":[""Lack of experience in Agile Scrum delivery"",""Inability to communicate complex IT concepts effectively""],""confidence_score"":85.0}"
"Analyst, Contact Centre Reporting & Analytics","JOB SUMMARY

This position will be accountable for the day-to-day analytics of inbound, chat and outbound 3rd party vendor performance, including performance management and incentives. The role will focus on the analysis of performance metrics.

JOB DETAILS

Accountabilities

Provide meaningful analysis and performance insights to support business plans and maximize performance. Fosters a customer-centric attitude and builds effective relationships with anyone connected to the customer (support or front-line).
Critically evaluating information gathered from multiple sources, reconciling conflicts, interpreting high-level information to glean details, and abstracting upwards from low-level information to assemble a general understanding.
Support the launch of new programs through incentive models, business flow updates, and updating reporting dashboards and SQL tables.
Analyzes vendor performance (cost, quality, productivity, satisfaction), and identifies trends and opportunities, issues, concerns, and successes.
Provide feedback and market intelligence to Operations, CRM, Workforce Training, and Quality to improve tools and resources as it relates to support, pricing, and marketing initiatives.
Create and monitor Call Centre performance reports (aftermarket, conversion, OTM, etc.)
Analyses incentive programs, delivering key insights and strategic recommendations to the vendor management team.
Prepare detailed reports and trend analysis so that decision-makers can quickly react.
Provide qualitative and quantitative reporting on all issues identified.
Create reporting to clearly display insights and communicate findings to business partners.
Act as a liaison with Call Centre Operations, Aftermarket, Conversion, and Information Technology teams on system enhancement requirements
On-going auditing of systems to ensure data accuracy and agent compliance to processes.
Provide weekly recap of forecast based on planned activities through the issuance of dashboards and performance metrics.
Provide ad-hoc analysis reports to business units as required.

KNOWLEDGE AND SKILL REQUIREMENTS

Level of Education
Bachelor’s degree in data science, computer science, statistics, mathematics, or a related field.

Job Related Experience
2+ years of experience in data analysis, modelling, or governance. Prior experience with subscription-based services or call center analytics is highly beneficial.

Skills and Background
Proficiency in SQL and Python within cloud environments.
Experience with ETL processes, data modelling, and database querying.
Advanced proficiency in Excel and BI tools such as Power BI or Tableau.
Familiarity with machine learning and AI techniques as a strong asset.
Knowledge of automation tools and methodologies to streamline data processes.
Strong analytical and quantitative skills, including a thorough understanding of interpreting business needs and translation into application and operational requirements.
Working knowledge of database marketing mechanics.
Strong presentation skills.
Ability to simultaneously manage multiple analytics projects and deliverables.
Excellent communication skills (written and verbal).
Bilingual Spoken (English and French) is a definite asset.

COMMUNICATIONS

This position is frequently called upon to reach agreement with others in order to complete work activities; requires presenting a point of view at times and influence others to adopt a course of action.

SiriusXM Canada is committed to equity in employment and programming.","{""role_summary"":""This role is responsible for analyzing and reporting on vendor performance metrics, providing insights to support business plans, and identifying trends and opportunities for improvement."",""key_terms"":[{""term"":""ETL processes"",""explanation"":""Extract, Transform, Load processes used to manage data integration and migration.""},{""term"":""Data modelling"",""explanation"":""The process of creating a conceptual representation of data structures to organize and standardize data.""},{""term"":""Machine learning and AI techniques"",""explanation"":""Methods used to enable machines to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Cloud environments"",""explanation"":""Virtualized computing environments that provide on-demand access to a shared pool of computing resources over the internet.""},{""term"":""BI tools"",""explanation"":""Business Intelligence tools used to analyze and visualize data to support business decision-making.""}],""skill_priorities"":{""must_have"":[""SQL"",""Python"",""Excel"",""Data analysis"",""Strong analytical and quantitative skills""],""nice_to_have"":[""ETL processes"",""Data modelling"",""Machine learning and AI techniques"",""Power BI or Tableau"",""Bilingual Spoken (English and French)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would analyze vendor performance metrics to identify trends and opportunities for improvement?"",""example_answer"":""I would use SQL to extract relevant data, then apply data modelling techniques to create a conceptual representation of the data. Next, I would use Python to create visualizations and perform statistical analysis to identify trends and opportunities. Finally, I would present my findings and recommendations to stakeholders using Excel and BI tools.""},{""question"":""How do you stay current with new developments in data analysis and machine learning?"",""example_answer"":""I regularly read industry blogs and attend webinars to stay up-to-date on the latest techniques and tools. I also participate in online forums and communities to learn from others and share my own knowledge and experiences.""}],""red_flags"":[""Lack of experience with subscription-based services or call center analytics"",""Inability to communicate complex data insights effectively to non-technical stakeholders""],""confidence_score"":90.0}"
Mixedstaffingandrecruiting,"We are seeking a motivated and analytic individual to join our team as a Remote Digital Data Analyst. As a Data Analyst, you will be responsible for interpreting and analysing large data sets, making data-driven decisions, and presenting findings to management.

Responsibilities

Collect and analyse large data sets from various sources
Interpret data and identify trends and patterns
Create reports and visualisations to communicate findings
Collaborate with cross-functional teams to provide data-driven insights
Continuously monitor data for accuracy and completeness
Identify areas for improvement and make recommendations

Requirements

Proficient in SQL, Excel, and data visualisation tools such as Tableau or Power BI
Strong analytic skills with the ability to interpret complex data
Excellent communication and presentation skills
Ability to work independently and as part of a team
Attention to detail and accuracy

If you are a self-starter who is passionate about data and enjoys problem-solving, we encourage you to apply. This is an entry-level position with room for growth within the company.

To apply, please submit your resume and cover letter highlighting your qualifications and why you would be a great fit for this position. We look forward to hearing from you!

Powered by Webbtree","{""role_summary"":""A Data Analyst is responsible for collecting and analyzing large data sets, identifying trends and patterns, and presenting findings to management to drive data-driven decisions."",""key_terms"":[{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing data in relational database management systems.""},{""term"":""Data Visualisation"",""explanation"":""The process of creating graphical representations of data to communicate information and insights more effectively.""},{""term"":""Tableau/Power BI"",""explanation"":""Data visualization tools used to create interactive dashboards and reports to present data insights.""}],""skill_priorities"":{""must_have"":[""SQL"",""Excel"",""Data Visualisation tools (Tableau or Power BI)"",""Analytic skills"",""Communication and presentation skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to analyze a complex data set and present your findings to a non-technical audience?"",""example_answer"":""In my previous role, I was tasked with analyzing customer purchase behavior. I used SQL to extract the data, created visualizations in Tableau, and presented my findings to the marketing team. As a result, we were able to identify a new customer segment and adjust our marketing strategy accordingly.""},{""question"":""How do you ensure the accuracy and completeness of large data sets?"",""example_answer"":""I use a combination of data validation techniques, such as data profiling and data quality checks, to ensure the accuracy and completeness of large data sets. I also continuously monitor the data for any discrepancies or anomalies.""}],""red_flags"":[""Lack of experience with SQL or data visualization tools"",""Poor communication and presentation skills""],""confidence_score"":90.0}"
"Analyst, Data","Build Your Career at Aecon

Aecon is proud to build some of the most impactful infrastructure projects of this generation. From the roads and transit systems that connect our communities, to the communication networks that link us from coast-to-coast, and the water infrastructure that supplies our businesses and homes. Our integral work includes constructing the pipelines that join provinces with the energy that fuels the nation, and the airports and ports that connect us all. Aecon is there, safely and sustainably building the future.

We lead the infrastructure industry with purpose, and our people are at the heart of everything we do. Our business success relies on strong execution and continuous improvement – driven by the diversity, expertise and teamwork of our employees. We are always searching the globe for exceptional candidates to join the Aecon family and be a part of our forward-thinking, innovative, best-in-class organization!

What is the Opportunity?

Aecon Civil is a market leader with a self-perform competitive advantage and core local strength in key markets. We’re proud of our work helping to expand and improve Canada’s infrastructure and transportation networks, and we’re ready to build the future of our country.

We are currently seeking a Data Analyst to join our head office.

What You'll Do Here

Establish and maintain KPIs and supporting metrics to be used across the project to track performance
Develop reporting requirements with functional leads and utilize a standardized approach to performance reporting
Communicate with internal stakeholders to gather performance reporting data and share updates relevant to performance reporting and its processes
Support the use of reporting, cost, scheduling, and financial and other operational systems; develop reporting dashboards to inform performance of the project; and enable fast, easy, meaningful operational and business insights
Support the implementation and continuous improvement
Develop and maintain a comprehensive Performance Management Framework, including development of dashboards to monitor and analyze performance trends
Analyze, measure, and report on project goals and objectives, engineering and design performance, construction progress, schedule, financial performance, and other essential KPIs and metrics
Develop periodic and ad hoc performance reporting packages
Contribute to evidence-based decision-making to maximize the performance of the project
Analyze data from different sources (including SAP, Primavera P6, InEight (Hard Dollar) Estimating, Designers, Subcontractors, Aconex, etc.) to identify our challenges and opportunities
Experience with various data platforms such as Microsoft Power BI, Databricks, Apache Spark, Snowflake
Familiarity with data integration, ETL, visualization tools and technologies
Strong understanding of data governance, data quality and security best practices
Strong analytical and problem-solving skills, with the ability to troubleshoot complex issues
Ability to work in a fast-paced environment and managed multiple tasks simultaneously


What You Bring To The Team

Minimum of six (6) years’ related experience; or equivalent combination of education and experience in construction projects, including performance monitoring; information systems, financial systems, other construction performance management systems
Completion of a degree in Business Administration, Engineering, Science, Computer Science, Statistics, Economics, or Information Systems, or a related discipline, or a combination of education, training and experience deemed equivalent
Organizational skills to handle multiple tasks within a high-pressure work site environment
Excellent interpersonal and communication skills (written and oral)
Minimum 4 years experience with Power BI, Tableau, Qlik Sense
Experience with SQL, DAX, Python, R, SAP Webi, or other reporting and data analytics tools, an asset
Knowledge of Earned Value Management (EVM) Industry best practices: PMI, AACEI, etc.
Effective inter-personal communication and presentation skills to communicate effectively with stakeholders across different business units
Ability to work effectively with all levels of management and employees
Willingness for continuous learning and advancement of technical knowledge
Detail oriented
Must be able to travel to projects
Must possess valid G driver's license and have access to a vehicle


What Makes Us Aecon Proud

Engaging and agile workplace culture, collaborative and inclusive teams
Commitment to sustainability and to becoming a net-zero company by 2050
Investing in our people through a variety of learning and development programs such as Aecon University, BluePrint leadership program, and Project Management Academy
Variety of wellness benefits, access to virtual health care, 100% employer-paid health and dental premiums, Employee Assistance Program, Best Doctors Program, and more.
Tuition reimbursement opportunities
Recognition and rewards through Aecon Accolades, Aecon Achievement Awards and more
Employee Stock Options, Short Term Incentive Program, Retirement Savings and Pension Plan


Aecon fosters diversity , inclusion and belonging within and across our organization. We welcome all to apply including, women, visible minorities, Indigenous peoples, persons with disabilities, and persons of any sexual orientation or gender identity. If you require accommodation during any step of the application process, please click here.","{""role_summary"":""A Data Analyst responsible for establishing and maintaining KPIs, developing reporting requirements, and communicating with internal stakeholders to track project performance and provide insights for informed decision-making."",""key_terms"":[{""term"":""KPIs"",""explanation"":""Key Performance Indicators used to measure project performance and track progress.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process used to integrate data from multiple sources into a single platform for analysis.""},{""term"":""Data Governance"",""explanation"":""Policies and procedures that ensure the quality, security, and integrity of an organization's data.""},{""term"":""Earned Value Management (EVM)"",""explanation"":""A method used to measure project performance by comparing the value of work completed to the value of work planned.""}],""skill_priorities"":{""must_have"":[""6+ years of experience in construction projects, including performance monitoring"",""Experience with Microsoft Power BI, Databricks, Apache Spark, Snowflake"",""Strong analytical and problem-solving skills"",""Ability to work in a fast-paced environment and manage multiple tasks simultaneously""],""nice_to_have"":[""Experience with SQL, DAX, Python, R, SAP Webi, or other reporting and data analytics tools"",""Knowledge of Earned Value Management (EVM) Industry best practices"",""Experience with Tableau, Qlik Sense""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would establish and maintain KPIs for a construction project?"",""example_answer"":""I would work with functional leads to identify key metrics, develop a standardized approach to performance reporting, and establish a dashboard to track project performance. I would also ensure that the KPIs are regularly reviewed and updated to reflect changes in project goals and objectives.""},{""question"":""How do you ensure data quality and security in your analysis?"",""example_answer"":""I follow best practices in data governance, ensuring that data is accurate, complete, and secure. I also implement data validation and verification processes to detect and correct errors, and ensure that data is protected from unauthorized access.""}],""red_flags"":[""Lack of experience with data integration, ETL, and visualization tools"",""Inability to work in a fast-paced environment and manage multiple tasks simultaneously""],""confidence_score"":90.0}"
"Analyst, Business Intelligence and Reporting","Position Summary

Reporting to the Senior Specialist, Operations Business Intelligence, the Analyst, Business Intelligence and Reporting is integral to TPA’s success as a data informed organization. The Analyst works closely with all departments to maintain, implement, and drive a business intelligence and revenue management culture within the organization, while driving revenue growth, internal efficiencies and ensuring the continued growth of BI services. Key responsibilities of this position include analyzing complex business problems and providing strategic insight using internal and external data, identifying, and interpreting data trends, and producing reports. Through the use of BI tools, the Analyst uses data to provide insight, drive results and influence change across the organization.

Responsibilities

Data Analysis and Analytics

Analyze, manipulate, review and present large amounts of data to business partners and leaders
Ensure data quality throughout all stages, including data collection, normalization, and transformation
Develop and maintain key performance indicators, measuring performance of the business and relating findings to individual positions on various organizational levels
Maintain and create advanced dynamic data integrations to enable regular real time KPI reporting
Analyze performance results, identifying options of action and establish corrective initiatives to achieve better results.
Maintain and ensure accuracy of master data library, the one source of truth for entire organization, including inventory, pricing tables, pricing structures and hierarchies.
Increase revenue across the organization by analyzing and extracting insight from multiple sources of data

Data Mining and Statistical Modeling

Utilize machine learning and program languages to build mathematical models that apply to real-world scenarios in parking management. Document processes and outcomes
Generate revenue and transaction projections in collaboration with management, considering various data inputs. Ensure the integrity of data used for analysis through diligent processing and cleansing
Maintain and build occupancy, demand, and seasonality models to optimize pricing strategies for different customer segments.
Conduct dynamic competitor, venue, and sentiment analysis

Reporting

Create and maintain analytical reports and dashboards to monitor trends and detect outliers.
Responsible for the accuracy, quality & timeliness of fixed/ad hoc reporting and dashboards.
Monitor and analyze KPI results and help propose corrective actions for areas lagging behind targets
Explain insights, complex problems, solutions, or the essence of a quantitative model to non-technical staff
Leverage strong business acumen, presentation, and communication skills to create and present analysis in a relevant, consumable, meaningful and insightful ways.
Perform ad-hoc analysis and participate in special projects as necessary

Drive a Data Driven Culture

Build trust and adoption in Business Intelligence tools
Meet with internal BI stakeholders to provide coaching and onboarding. Motivate others; build commitment and excitement around shared goals and achievements.
Create organization impact and influence by leveraging networks and cross-functional partnerships.
Assist in the on-going development and deployment of advanced analytical tools within TPA, support training to all levels of competence
Other duties as assigned

QUALIFICATIONS:

Bachelor’s degree in business, Computer Science, Math, Statistics or Economics
1-3 years + of experience in a business intelligence, data science or revenue/yield management role
Experience converting large amounts of multi-faceted data into meaningful reports
Strong data visualization skills and experience using various visualization tools like PowerBI/Tableau/Looker or similar is required
Proficiency in open-source languages (R, Python), Excel, SQL, and relational databases is required
Advanced MS Office user, with a particular emphasis on advanced Excel skills (look-up functions, VBA macros, complex logical statements, charts pivot tables, etc.)
Experience using PHP, SAP, MS Fabric, Dax, and Google Analytics, considered an asset
Experience collecting large data from multiple sources including API and SFTP, considered an asset
Dynamic pricing experience and revenue management from parking, hotel, airline, or retail industries, considered an asset.
Experience designing, developing, implementing and maintaining a database, and programs to manage data analysis efforts
Strong project management skills with the ability to work on multiple concurrent projects
Ability to articulate analyses and communicate effectively with all levels of the organization
High level of curiosity and investigative mind-set with an attention to detail and accuracy
Team player with excellent organizational, evaluation and interpersonal skills
Internal candidates: No new or reclassified employee with less than one (1) year’s continuous on the job service may apply

Powered by JazzHR

x9m87GFSuc","{""role_summary"":""The Analyst, Business Intelligence and Reporting plays a crucial role in driving revenue growth, internal efficiencies, and promoting a data-informed culture within the organization by analyzing complex business problems, identifying trends, and producing reports."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""The practice of using data and analytics to inform business decisions and drive growth.""},{""term"":""Revenue Management"",""explanation"":""The process of analyzing and optimizing revenue streams to maximize profitability.""},{""term"":""Data Visualization"",""explanation"":""The process of presenting complex data in a clear and concise visual format to facilitate understanding.""},{""term"":""Machine Learning"",""explanation"":""A type of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed.""}],""skill_priorities"":{""must_have"":[""Experience with business intelligence tools"",""Strong data visualization skills"",""Proficiency in open-source languages (R, Python)"",""Experience with Excel, SQL, and relational databases"",""Strong project management skills""],""nice_to_have"":[""Experience with PHP, SAP, MS Fabric, Dax, and Google Analytics"",""Dynamic pricing experience and revenue management from parking, hotel, airline, or retail industries"",""Experience collecting large data from multiple sources including API and SFTP"",""Experience designing, developing, implementing and maintaining a database""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing complex business problems using internal and external data?"",""example_answer"":""I would start by identifying the key performance indicators and data sources relevant to the problem. Then, I would use tools like Excel, SQL, and Python to manipulate and analyze the data, and finally, present my findings in a clear and concise manner using data visualization techniques.""},{""question"":""How do you ensure data quality throughout all stages of data collection, normalization, and transformation?"",""example_answer"":""I would implement data validation checks at each stage, use data profiling techniques to identify anomalies, and perform regular data audits to ensure accuracy and consistency.""}],""red_flags"":[""Lack of experience with business intelligence tools"",""Inability to communicate complex data insights to non-technical stakeholders"",""Poor project management skills""],""confidence_score"":90.0}"
Data Analyst (Johnmaxwell Team),"The Johnmaxwell Team is seeking a talented Data Analyst to join our team. The ideal candidate will be responsible for analyzing data to help drive key business decisions and improve overall performance. If you have a passion for data and a keen eye for detail, we want to hear from you!

Major Responsibilities And Objectives

Collect, clean, and analyze data from various sources
Identify trends and patterns in data to provide insights for decision-making
Create reports and visualizations to communicate findings to stakeholders
Collaborate with cross-functional teams to support data-driven initiatives
Develop and maintain databases for data storage and retrieval

Qualifications, Skills, and Experience:

Bachelor's degree in Data Science, Statistics, Computer Science, or related field
2+ years of experience in data analysis or a related role
Proficiency in data visualization tools such as Tableau or Power BI
Strong analytical and problem-solving skills
Excellent communication and presentation abilities
Experience working with SQL and Python

Value","{""role_summary"":""The Data Analyst role is responsible for analyzing data to drive business decisions and improve performance, requiring a passion for data and attention to detail."",""key_terms"":[{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to communicate insights and trends.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing data in relational databases.""},{""term"":""Data-Driven Initiatives"",""explanation"":""Business decisions or projects that rely on data analysis and insights to inform their direction.""}],""skill_priorities"":{""must_have"":[""Data Analysis"",""Data Visualization"",""SQL"",""Python"",""Analytical Skills"",""Communication Skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you identified a trend in data that led to a business decision?"",""example_answer"":""In my previous role, I analyzed customer purchase data and found a correlation between product A and B. I presented my findings to the marketing team, and they used the insights to launch a targeted campaign, resulting in a 20% increase in sales.""},{""question"":""How do you ensure data quality and accuracy in your analysis?"",""example_answer"":""I use a combination of data validation techniques, such as data profiling and data normalization, to ensure data quality. I also perform regular data audits to identify and correct any errors or inconsistencies.""}],""red_flags"":[""Lack of experience working with data visualization tools"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Junior Business Data Analyst,"Role Overview

We have an exciting opportunity for a Business Data Analyst to join our Data team. In this role, you will have the opportunity to be at the forefront of applying data and analytics to tackle business problems. This role is a unique opportunity to join a dynamic team of analytical professionals that partners with business and Technology to design innovative, value-adding customer engagement solutions for our clients.

This position is a full-time opportunity and is primarily a remote role, with the ability to go onsite at Bruce Power if needed. You possess a specialty/background with business intelligence or data analysis and will work heavily with the Power Platform (Power BI, Power Apps, and Power Automate) and have proficiency with SQL, while working with an innovative and collaborative team.

Responsibilities

Constantly look for new and innovative approaches to provide customers with a point of view on their data.
Examine customer reporting requirements and develop proposals of technical solutions and build the report that supports the requirements.
Manage the balance between customer expectations and delivering projects to their original specification.
Collaborate with Customer Success to identify needs and opportunities for improving reports and dashboards.
Analyze data and synthesize raw information into insights, and recommendations on how our customers are using our reports and dashboards.
Design and develop data pipelines and Power BI dashboarding solutions to deliver insights and actionable intelligence based on the client's data.
Mentor other Developers on technical solutions and/or escalated matters.
Monitor new developments in the Power Platform and Power BI space.
Work as part of a multidisciplinary team, including product owners, product managers, UX designers, and IT.
Prepare technical documentation.

What you bring to the table?

Bachelor's degree in Computer Science, Information Technology, Business Analytics, or related field, or an equivalent combination of education and experience.
Experience with performing data analysis, developing data warehouse models, and deploying business intelligence dashboards and solutions.
2-3 years of experience with Power BI or other visualization tools.
Skilled in client requirements gathering, process analysis, and testing.
Highly proficient in reading and writing SQL queries.
Proficiency in SQL, Microsoft SSMS and SSDT, and Databricks.
Ability to develop high-quality documentation and provide user guidance and assistance.
Effective analytical and communication skills.
Strong track record of being able to develop relationships with a multitude of stakeholders/peers.
Knowledge of Maximo/P6.
Previous experience within the nuclear industry would be a plus.
Must be eligible to work in Canada.

Is NPX right for you?

Do you have an intellectual curiosity that causes you to explore, experiment and build?
Do you like working with cutting edge technology to find solutions or opportunities that push up the innovation curve?
Do you enjoy working in an open-concept start-up environment where collaboration, diversity, and knowledge sharing are key values?
Are you seriously passionate about giving back and supporting your community?

About us

NPX was founded on the premise that innovation is the most important key to sustaining the nuclear energy industry. We source, implement, and integrate innovative technologies to make things better at nuclear power plants. We think differently and work differently. We are customer obsessed rather than competitor focused, passionate for innovation, long-term thinking and committed to operational excellence. We are a family, driven by the excitement of building technologies, inventing products, and providing services that change lives and give back to our community.

At NPX we are committed to building a warm, inclusive, and diverse environment. We believe that people do their best work when they feel safe, empowered, and supported.

To this end, we offer an excellent compensation and benefits package including:

High-growth position in the early stage of a scaling company
Competitive salary + benefits package 💸
Career Growth & Development Program 🌱
Flexible vacation and work model 🌴
NPX Days Off
Company-wide days off to reset and recharge
Professional Development Fund 📈
Competitive Maternity & Parental Leave 🍼
Focus on Mental Health ❤️‍🩹
Investing in your Future with a RRSP Plan 💵
A company culture built on trust, autonomy, and independence🤝
Volunteer and Fun Events ❣️
Referral Rewards 👋
Enjoy our welcome NPX Swag 🎁","{""role_summary"":""A Business Data Analyst role that applies data and analytics to tackle business problems, partnering with business and Technology to design innovative customer engagement solutions."",""key_terms"":[{""term"":""Power Platform"",""explanation"":""A suite of Microsoft tools including Power BI, Power Apps, and Power Automate, used for business intelligence and data analysis.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational database management systems.""},{""term"":""Data Pipelines"",""explanation"":""A series of processes used to extract, transform, and load data from various sources into a target system, such as a data warehouse.""},{""term"":""Power BI Dashboarding"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""}],""skill_priorities"":{""must_have"":[""Experience with Power BI or other visualization tools"",""Skilled in client requirements gathering, process analysis, and testing"",""Highly proficient in reading and writing SQL queries"",""Ability to develop high-quality documentation and provide user guidance and assistance"",""Effective analytical and communication skills""],""nice_to_have"":[""Previous experience within the nuclear industry"",""Knowledge of Maximo/P6""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing customer reporting requirements and developing proposals for technical solutions?"",""example_answer"":""I would start by gathering requirements through stakeholder interviews and reviewing existing reports. Then, I would design a technical solution that meets the requirements, considering factors such as data sources, data quality, and report functionality. Finally, I would develop a proposal outlining the technical solution, including any assumptions, risks, and timelines.""},{""question"":""How do you stay current with new developments in the Power Platform and Power BI space?"",""example_answer"":""I regularly follow Microsoft's Power Platform and Power BI blogs, attend webinars, and participate in online forums to stay up-to-date with the latest features and best practices. I also network with other professionals in the field to learn from their experiences and share my own knowledge.""}],""red_flags"":[""Lack of experience with Power BI or other visualization tools"",""Inability to write complex SQL queries"",""Poor communication and analytical skills""],""confidence_score"":90.0}"
Advanced Excel Data and Reporting Analyst,"Long term contract position to start, work with Sales, Product Management and SCM to monitor and report.

Develop and provide daily program tracking / reporting
Flag to leadership / account team on program spend compliance
Conduct weekly touchpoints with the MXLT to review reporting
Support Carrier and Retail Sales teams with Live Display management process.
Prepare ad hoc analysis as required
Design business analysis and data recording systems for use throughout the department

Advantages

Work with a great team and a Global leader to make an impact to your career. Get a chance to navigate through internal process and data to report on sales programs in market

Responsibilities

Navigate through internal process and data to report on sales programs in market
Develop and provide daily program tracking / reporting
Flag to leadership / account team on program spend compliance
Conduct weekly touchpoints with the MXLT to review reporting
Support Carrier and Retail Sales teams with Live Display management process.
Prepare ad hoc analysis as required
Design business analysis and data recording systems for use throughout the department
Develop and maintain an internal database to create reporting frameworks
Maintain databases and perform updates as necessary to ensure accuracy
Regularly examine data reports to locate and resolve mistakes throughout
Accurately analyze and collect data for various types of business reports
Create business reports that provide insight into key data points
Communicate the results of data analysis in written and verbal form to managers
Support various departments, including marketing and sales, in reaching their goals through analysis

Qualifications

Advanced MS-Excel skills (pivot tables, vlookup, data tables, functions, macros)

Ability to use SQL and Microsoft Excel to create graphs and charts to summarize findings

Summary

If this aligns with your experience and skills, please apply asap

www.randstad.ca

Randstad Canada is committed to fostering a workforce reflective of all peoples of Canada. As a result, we are committed to developing and implementing strategies to increase the equity, diversity and inclusion within the workplace by examining our internal policies, practices, and systems throughout the entire lifecycle of our workforce, including its recruitment, retention and advancement for all employees. In addition to our deep commitment to respecting human rights, we are dedicated to positive actions to affect change to ensure everyone has full participation in the workforce free from any barriers, systemic or otherwise, especially equity-seeking groups who are usually underrepresented in Canada's workforce, including those who identify as women or non-binary/gender non-conforming; Indigenous or Aboriginal Peoples; persons with disabilities (visible or invisible) and; members of visible minorities, racialized groups and the LGBTQ2+ community.

Randstad Canada is committed to creating and maintaining an inclusive and accessible workplace for all its candidates and employees by supporting their accessibility and accommodation needs throughout the employment lifecycle. We ask that all job applications please identify any accommodation requirements by sending an email to accessibility@randstad.ca to ensure their ability to fully participate in the interview process.","{""role_summary"":""This role involves monitoring and reporting sales programs, providing daily tracking and reporting, and supporting sales teams with data analysis and management processes."",""key_terms"":[{""term"":""MXLT"",""explanation"":""MXLT likely stands for 'Market XLT' or a similar term, referring to a specific market or sales team.""},{""term"":""Live Display management process"",""explanation"":""This refers to the process of managing and maintaining live product displays in retail stores.""},{""term"":""Pivot tables"",""explanation"":""A pivot table is a data analysis tool in Microsoft Excel that allows users to summarize and analyze large datasets.""},{""term"":""Vlookup"",""explanation"":""Vlookup is a function in Microsoft Excel that allows users to look up and retrieve data from a table or range based on a specific value.""},{""term"":""SQL"",""explanation"":""SQL (Structured Query Language) is a programming language used for managing and analyzing relational databases.""}],""skill_priorities"":{""must_have"":[""Advanced MS-Excel skills"",""Ability to use SQL""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would create a pivot table in Microsoft Excel to summarize sales data?"",""example_answer"":""I would create a pivot table by selecting the data range, going to the 'Insert' tab, and clicking on 'PivotTable'. Then, I would drag and drop the relevant fields into the 'Rows', 'Columns', and 'Values' areas to create a summary of the sales data.""},{""question"":""How would you use SQL to extract specific data from a database?"",""example_answer"":""I would use a SELECT statement to specify the columns I want to extract, and then use a WHERE clause to filter the data based on specific conditions. For example, 'SELECT * FROM sales_data WHERE region='North' AND sales_date > '2022-01-01';'.""}],""red_flags"":[""Lack of experience with Microsoft Excel or SQL"",""Inability to analyze and interpret large datasets""],""confidence_score"":80.0}"
Business Analyst/Data Analyst,"10+ years previous work experience as a Business or Data Analyst, or in a technical/functional Role

Experience working on Risk Data projects (Agile methodologies), sourcing, standardization, and aggregation of risk in one of the functional risk areas such as Counterparty/Credit Risk

Understanding of financial Instruments including several types of Fixed Income and Equity Instruments and their valuation; Exposure to Banking Loan Book and other products

Skills acquired in a market and/or counterparty risk management environment are transferable

Documentation skills ability to succinctly articulate requirements, summarize data analysis and present to business users and development team

Use of Python, Anaconda, Pandas, Jupyter and support of Developers working with a technology stack including Linux, Hadoop, Hive, Spark, and other big data technologies

Strong data analysis skills are required including analyzing large data sets in using SQL queries and other modelling tools

Producing and using Data Catalogues, understanding data models and business process modeling

Experience building enterprise scale applications involving large data volumes and computations

Bachelor's degree in Sciences, Information Technology, Computer Science or other quantitative discipline","{""role_summary"":""A Business or Data Analyst responsible for working on Risk Data projects, analyzing large data sets, and developing enterprise-scale applications."",""key_terms"":[{""term"":""Agile methodologies"",""explanation"":""An iterative approach to project management that emphasizes flexibility and collaboration.""},{""term"":""Counterparty/Credit Risk"",""explanation"":""A type of financial risk that arises from the potential failure of a counterparty to meet its obligations.""},{""term"":""Fixed Income and Equity Instruments"",""explanation"":""Types of financial instruments that generate income or represent ownership in a company.""},{""term"":""Hadoop, Hive, Spark"",""explanation"":""Big data technologies used for storing, processing, and analyzing large datasets.""},{""term"":""Data Catalogues"",""explanation"":""A centralized repository that provides information about an organization's data assets.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Data analysis"",""Risk data project experience"",""Financial instruments understanding""],""nice_to_have"":[""Anaconda"",""Pandas"",""Jupyter"",""Linux"",""Hadoop"",""Hive"",""Spark""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data standardization and aggregation in a risk data project?"",""example_answer"":""I would first identify the relevant data sources and then use tools like Pandas to clean and transform the data. Next, I would develop a data model to standardize the data and finally, use aggregation techniques to summarize the data for analysis.""},{""question"":""How do you stay up-to-date with new developments in risk management and data analysis?"",""example_answer"":""I regularly read industry publications and attend webinars to stay current with new methodologies and tools. I also participate in online forums and discussion groups to learn from others in the field.""}],""red_flags"":[""Lack of experience with risk data projects"",""Inability to explain financial instruments and their valuation""],""confidence_score"":90.0}"
Junior Data Engineer,"About Citylitics

Citylitics delivers predictive intelligence on local utility & public infrastructure markets

What is Infrastructure? It is the roadways you rely on to safely get to Grandma's house, it's the potable water that comes out of your kitchen tap that you wash your family's food with and it's the energy that heats our homes and powers our digital lifestyles.

Every year, trillions of dollars are spent on all areas of infrastructure to maintain our quality life and move our economy forward. However, our infrastructure is no longer equipped to meet the needs of the future. We hear about infrastructure failures, whether bridge collapses, power blackouts, or water main breaks, every day in the news. Climate change and extreme weather events are disrupting the basic infrastructure we took for granted for years.

Citylitics is solving the hardest data problems in infrastructure while building the sales intelligence platform that enables a faster, more transparent, and more efficient infrastructure marketplace. We turn millions of unstructured documents into high value intelligence feeds and datasets that are available on an intuitive user experience. Our goal is to enable solution providers to connect with cities with relevant infrastructure needs in a faster and more digital way than historic market channels. As more companies adopt our platform, cities & utilities will be able to access solutions that deliver on the promise of moving towards a more resilient, sustainable, and equitable infrastructure future.

Who Are We Looking For?

We are seeking a Junior Data Engineer with an analytical mindset and a passion for using data to drive decision-making. As a member of our team, you will play a vital role in developing and interpreting data insights, as well as building and maintaining data pipelines and dashboards.

What Will You Accomplish?

Data Pipeline Development and Maintenance:
Design, develop, and maintain data pipelines using Airflow, Django and SQL to ensure efficient extraction, transformation, and loading (ETL) of data
Stakeholder Collaboration:
Collaborate with stakeholders to gather data requirements and translate them into technical solutions
Data Integrity and Quality Control:
Ensure the integrity, quality, and security of data throughout the ETL process.
Database Optimization:
Assist in the optimization and performance tuning of database queries and processes
Integration and Orchestration:
Support the integration of Airflow/Cloud Composer into existing data workflows
Dashboard Development:
Build and maintain dashboards (in Looker Studio and Dash) to visualize and communicate data insights
Documentation and Best Practices:
Contribute to the documentation of data pipelines, processes, and best practices
Continuous Learning:
Stay updated with industry trends and best practices in data science and related tools
Other duties as assigned.

Technologies We Use:

Backend: Python, Django, Cloud SQL, Airflow/Cloud Composer
Cloud Infrastructure: Google Cloud Platform
Data Visualization: Looker Studio, Dash
Other Tools: Javascript, React


Requirements

Bachelor's degree in Computer Science, Data Science, or a related field
At least 1 year of experience with Python and Django
Strong understanding of database design and development
Familiarity with Airflow/Cloud Composer is preferred
Experience with Google Cloud Platform and Docker is an asset
Excellent communication and interpersonal skills


Benefits

Why Citylitics?

Opportunity to work for one of the top 15 innovative analytics startups in Canada revolutionizing data intelligence
This is a rare opportunity to influence positive change within one of the biggest societal challenges of our generation: sustainable public infrastructure
You get to support a disruptive solution with a compelling value proposition into an industry that is eager to hear from you and in a market with no direct competition
We live at the cross section of infrastructure, scaleup and data science/AI. There is no other team like us in Toronto
There is no corporate bureaucracy here. You will accomplish more here in a few months than what you would in a few years at a large, entrenched technology company
We believe that Data and AI will play an outsized role in our future, so we equip every team member with access to Generative AI tools and our full Data Universe to enhance their productivity and encourage innovation through experimentation
We are proud to offer every CityZen an internal mentorship program, in-role professional growth, skill-based development & learning, and internal promotion opportunities
We work hard, we play together, we win as a team! We are on a mission to solve infrastructure while savoring the moment and celebrating the little details along the way

Citylitics is an equal opportunity employer. We are passionate about providing a safe workplace where everyone is accepted and has the opportunity to grow with us. We are committed to making diversity and inclusivity part of our culture!","{""role_summary"":""A Junior Data Engineer responsible for developing and interpreting data insights, building and maintaining data pipelines and dashboards, and collaborating with stakeholders to drive decision-making."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from sources, transforming it into a usable format, and loading it into a target system.""},{""term"":""Airflow"",""explanation"":""A platform used to programmatically schedule and monitor workflows, often used for data pipeline development and maintenance.""},{""term"":""Django"",""explanation"":""A high-level Python web framework used for building scalable and maintainable web applications.""},{""term"":""Cloud Composer"",""explanation"":""A fully managed service used to orchestrate workflows, including data pipelines, in the cloud.""},{""term"":""Looker Studio"",""explanation"":""A data visualization tool used to build and maintain dashboards to communicate data insights.""}],""skill_priorities"":{""must_have"":[""Python"",""Django"",""Database design and development"",""Excellent communication and interpersonal skills""],""nice_to_have"":[""Familiarity with Airflow/Cloud Composer"",""Experience with Google Cloud Platform"",""Experience with Docker""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize the performance of a slow database query?"",""example_answer"":""I would analyze the query to identify bottlenecks, consider indexing, and optimize the database schema to improve performance.""},{""question"":""Can you explain how you would design a data pipeline using Airflow?"",""example_answer"":""I would design a pipeline that extracts data from sources, transforms it into a usable format, and loads it into a target system, ensuring data integrity and quality throughout the process.""}],""red_flags"":[""Lack of experience with Python and Django"",""Inability to communicate technical solutions to stakeholders""],""confidence_score"":90.0}"
IT Data Analyst,"Company Description

Ubisoft’s 19,000 team members, working across more than 30 countries around the world, are bound by a common mission to enrich players’ lives with original and memorable gaming experiences. Their commitment and talent have brought to life many acclaimed franchises such as Assassin’s Creed, Far Cry, Watch Dogs, Just Dance, Rainbow Six, and many more to come. Ubisoft is an equal opportunity employer that believes diverse backgrounds and perspectives are key to creating worlds where both players and teams can thrive and express themselves. If you are excited about solving game-changing challenges, cutting edge technologies and pushing the boundaries of entertainment, we invite you to join our journey and help us create the unknown.

Job Description

The Data Analyst is responsible for researching, organizing, and analyzing data generated from our various business operations. This could include department operations, vendor contracts management, financial operations, customers knowledge. Your work will help our organization to make enlightened decisions, improve our financial efficiency and operational excellence. You ensure the quality of our various sources of data and make sure to report it in a useful format to various level of management and audiences.

Within the Engineering and Platform Departement, you will support our engineering teams working on a Cloud Management Platform to better understand their costs, efficiency and users’ behaviour by producing reports and data analysis about: usage metrics on our platforms, financial optimizations, contract management KPIs, internal billing data, teams’ velocity etc.

Responsibilities:

Create and maintain a map of our data sources and data models;
Consolidate management and partners reporting needs;
Collaborate with Data Engineering teams to create and maintain efficient data pipelines and models;
Design and implement metrics, indicators, reports, based on partners’ needs;
Identify and suggest opportunities and improvements of our various data schemas, reports and tools;
Provide input and compiling performance statistics from our teams and providers to the department directors;
Work closely with our Data Office teams to ensure that cross department processes and practices are aligned and optimized;

Qualifications

Excellent knowledge of data modeling and also excellent knowledge of data visualization tools and techniques;
Excellent knowledge of data Query Languages
Knowledge of Python is a plus
Ability to apply methods and standards to resolve complex problems and challenges
Great communication skills spoken and written to different entities, business, vendors and partners;
Good knowledge of IT Infrastructure and its working with other IT domains

Additional Information

Just a heads up: If you require a work permit, your eligibility may depend on your education and years of relevant work experience, as required by the government.

Skills and competencies show up in different forms and can be based on different experiences, that's why we strongly encourage you to apply even though you may not have all the requirements listed above.

At Ubisoft, we embrace diversity in all its forms. We’re committed to fostering an inclusive and respectful work environment for all. We know the importance of providing a pleasant interview experience, therefore if you need any accommodation, please let us know if there is anything we can do to facilitate the interview process.","{""role_summary"":""The Data Analyst is responsible for analyzing and reporting data to support business operations, improve financial efficiency, and enhance operational excellence."",""key_terms"":[{""term"":""Data Modeling"",""explanation"":""The process of creating a conceptual representation of data structures and relationships to organize and analyze data.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to communicate insights and trends.""},{""term"":""Data Query Languages"",""explanation"":""Programming languages used to manage and manipulate data in databases, such as SQL.""},{""term"":""Cloud Management Platform"",""explanation"":""A suite of tools and services used to manage and monitor cloud-based infrastructure and applications.""}],""skill_priorities"":{""must_have"":[""Data Modeling"",""Data Visualization"",""Data Query Languages""],""nice_to_have"":[""Python""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data modeling for a complex business operation?"",""example_answer"":""I would start by identifying the key stakeholders and their data needs, then create a conceptual data model to organize and structure the data. Next, I would design a logical data model to define the relationships between data entities, and finally, implement a physical data model to optimize data storage and retrieval.""},{""question"":""How do you ensure data quality and accuracy in your reports and analysis?"",""example_answer"":""I would implement data validation and verification processes to ensure data accuracy, and use data visualization techniques to identify and correct errors. I would also collaborate with stakeholders to ensure that data reports meet their needs and expectations.""}],""red_flags"":[""Lack of experience with data modeling and visualization tools"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Research Data Analyst,"Overview

Reporting to the Research Business Manager, the Research Data Analyst will be an integral part of the Department of Research & Innovation’s core services team, responsible for facilitating data access and analysis for research and quality improvement projects.

Additionally reporting to the Manager, Information Technology, the incumbent will closely partner with the Michael Garron Hospital (MGH) Information Technology Services (ITS) team to ensure alignment with MGH policies and practices.

The Research Data Analyst will be responsible for creating Cerner Command Language (CCL) reports to extract data from Cerner PowerChart (MGH’s electronic medical record); consult with research scientists and improvement leads to develop data analysis plans and ensure swift execution of data requests; interpret, identify, and analyze relevant variables from internal and external datasets; and prepare datasets for analysis and publication. Additional responsibility will include ad hoc report generation and data visualization to support data management activities, which may also include database validation, data review and quality control.

This is a contract position until March 31, 2026, with the potential to renew.

EDUCATION

A Bachelor’s degree in Statistics, Data Science, Computer Science, Industrial Engineering, Mathematics, Health Sciences or equivalent field.
Master’s degree, preferred.

Qualifications

Minimum of five (5) years of data analysis within a healthcare or research setting.
Minimum of five (5) years of programming experience in Microsoft SQL Server and Oracle environment.
Proficiency using SQL language, and experience using CCL and DA2; or a commitment to learn CCL.
Highly competent in computer programming using R or Python to perform data abstraction and reorganization.
Solid understanding of workflow analysis, requirements gathering, documentation and system design.
Knowledge and experience with Hospital Information Systems, (experience with Cerner HIS is preferred).
Experience using key software and databases such as: Oracle or SQL.
Solid understanding of testing methodologies and change management control.
Demonstrated ability to work independently and in a team environment.
Demonstrated flexibility with the ability to effectively and efficiently multi-task and prioritize work.
Must be able to maintain a high level of confidentiality with respect to all aspects of work being performed.
Familiarity with health care administrative datasets such as CIHI-DAD or NACRS is preferred.
Ability to work as part of a team and assist team members with tasks to keep projects on schedule.
Good interpersonal and communications skills, including the ability to express technical ideas that can be easily understood.
Good judgment and problem-solving skills, with the ability to make timely and sound decisions.
Able to prioritize responsibilities and organize workload to ensure that timeframes are met.
Strong interpersonal skills, proven leadership skills and exhibit a high level of professionalism.
Interest in the principles of Equity, Diversity, Inclusion, and Anti-racism.
All employees of Michael Garron Hospital (MGH), a division of Toronto East Health Network (TEHN) [formerly Toronto East General Hospital (TEGH)] agree to work within the legislated practices of the Occupational Health and Safety Act of Ontario.
All employees of MGH are responsible for contributing to a transparent culture of patient and staff safety by adhering to and abiding by patient and staff safety policies and procedures set by MGH.
All employees are accountable for protecting the psychological health and safety of themselves and their co-workers through adherence to MGH's policies and practices.

Vaccines (COVID-19 and others) are a requirement of the job unless you have an exemption pursuant to the Ontario Human Rights Code.","{""role_summary"":""The Research Data Analyst facilitates data access and analysis for research and quality improvement projects, ensuring alignment with hospital policies and practices."",""key_terms"":[{""term"":""Cerner Command Language (CCL)"",""explanation"":""A programming language used to extract data from Cerner PowerChart, an electronic medical record system.""},{""term"":""Cerner PowerChart"",""explanation"":""An electronic medical record system used by Michael Garron Hospital.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing data in relational database management systems.""},{""term"":""R/Python"",""explanation"":""Programming languages used for data abstraction, reorganization, and analysis.""},{""term"":""Hospital Information Systems (HIS)"",""explanation"":""Computer systems that manage and store hospital data, such as patient records and administrative information.""}],""skill_priorities"":{""must_have"":[""5+ years of data analysis experience in a healthcare or research setting"",""5+ years of programming experience in Microsoft SQL Server and Oracle environment"",""Proficiency in SQL language"",""Experience with CCL and DA2"",""Highly competent in computer programming using R or Python""],""nice_to_have"":[""Master's degree"",""Experience with Cerner HIS"",""Familiarity with health care administrative datasets such as CIHI-DAD or NACRS""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would extract data from Cerner PowerChart using CCL?"",""example_answer"":""I would use CCL to write a report that extracts the required data from Cerner PowerChart, ensuring that the data is accurate and relevant to the research or quality improvement project.""},{""question"":""How do you ensure data quality and integrity in your analysis?"",""example_answer"":""I use data validation and quality control techniques to ensure that the data is accurate and reliable. I also document my methods and results to ensure transparency and reproducibility.""}],""red_flags"":[""Lack of experience with Cerner PowerChart or CCL"",""Inability to work independently and prioritize tasks effectively"",""Poor communication and interpersonal skills""],""confidence_score"":90.0}"
Toyandsons,"Summary:

The Data Analyst Full Time will be responsible for analyzing and interpreting large datasets to provide valuable insights and recommendations to the business. They will work closely with cross-functional teams to gather and analyze data, develop reports, and provide customized solutions to help the organization gain a competitive edge.

Responsibilities:

Analyze large data sets using advanced statistical techniques and tools to uncover trends, opportunities, and insights.
Develop, maintain and analyze performance metrics and reports that support data-driven decision-making processes.
Collaborate with stakeholders to identify business questions and translate them into data and analysis requirements.
Develop models and algorithms to help optimize business processes and drive efficiencies.
Design and execute A/B tests and experiments to identify opportunities for optimization.
Identify data quality issues and help to develop solutions to improve data integrity, accuracy, and completeness.
Manage data collection, cleansing, and manipulation processes to ensure data is readily accessible and easy to work with.
Prepare and present data-driven reports and insights to stakeholders, highlighting key findings and recommendations.

Qualifications:

1+ years of relevant experience in data analysis, preferably in the Internet and New Media industry.
Proven experience in analyzing large and complex datasets using SQL, R, Python, or related tools.
Strong analytical, critical thinking, and problem-solving skills.
Excellent communication and collaboration skills, with the ability to work effectively in a team environment.
Experience with data visualization tools such as Tableau, Power BI, or related tools.
Knowledge of statistical modeling, hypothesis testing, and A/B testing methodologies.
Familiarity with data management and ETL processes.
If you are interested in this position, please send your resume, contact information and salary requirements to : hiring@jobsai.live

Powered by Webbtree","{""role_summary"":""The Data Analyst is responsible for analyzing large datasets to provide insights and recommendations to the business, working closely with cross-functional teams to develop reports and solutions."",""key_terms"":[{""term"":""Advanced statistical techniques"",""explanation"":""Methods used to analyze complex data, such as regression analysis, time series analysis, and hypothesis testing.""},{""term"":""ETL processes"",""explanation"":""Extract, Transform, Load processes used to manage and integrate data from various sources into a single, unified view.""},{""term"":""A/B testing"",""explanation"":""A method of comparing two versions of a product, web page, or application to determine which one performs better.""},{""term"":""Data visualization"",""explanation"":""The process of creating graphical representations of data to help stakeholders understand and interpret complex information.""}],""skill_priorities"":{""must_have"":[""SQL"",""R"",""Python"",""Data analysis"",""Statistical modeling"",""Communication skills"",""Collaboration skills""],""nice_to_have"":[""Tableau"",""Power BI"",""Data visualization"",""ETL processes""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of hypothesis testing and how you would apply it in a real-world scenario?"",""example_answer"":""Hypothesis testing is a statistical method used to determine whether a hypothesis is true or false. For example, if we wanted to test whether a new marketing campaign increased sales, we would set up a null hypothesis that the campaign had no effect and an alternative hypothesis that it did. We would then collect data and use statistical tests to determine whether the results support or reject the null hypothesis.""},{""question"":""How do you ensure data quality and integrity in your analysis?"",""example_answer"":""I ensure data quality by implementing data validation rules, checking for outliers and anomalies, and performing data profiling to identify inconsistencies. I also work closely with stakeholders to understand the data collection process and identify potential sources of error.""}],""red_flags"":[""Lack of experience with SQL, R, or Python"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Mbstaffingservicesllc,"We are seeking a highly motivated and detail-oriented Virtual Data Analyst to join our team. The Virtual Data Analyst will be responsible for analyzing large datasets, generating insights, and communicating findings to stakeholders. This is an entry-level position that offers the opportunity to work remotely and make a meaningful impact on our organization.

Responsibilities

Collect and analyze large datasets using a variety of tools and techniques

Identify trends, patterns, and anomalies in data and communicate findings to stakeholders

Develop and maintain dashboards and visualizations to provide stakeholders with a clear understanding of data trends

Assist with the development of data-driven strategies to improve business outcomes

Collaborate with cross-functional teams to support business needs and provide insights

Qualifications

Bachelor's degree in a related field such as Mathematics, Statistics, Economics, or Computer Science

Strong analytical and problem-solving skills

Proficiency in SQL, Python, and/or R

Knowledge of data visualization tools such as Tableau or Power BI

Excellent communication skills, both written and verbal

Ability to work independently and as part of a team

Benefits

Competitive salary and benefits package

Flexible work schedule

Opportunity for growth and advancement within the organization

Collaborative and inclusive work environment

Work from the comfort of your own home

Access to professional development and training opportunities

At our organization, we value diversity and are committed to creating an inclusive environment for all employees. We believe that everyone has a unique perspective to bring to the table and that our differences make us stronger. If you are a data-driven individual with a passion for problem-solving and a desire to make a meaningful impact, we encourage you to apply for this exciting opportunity.

Powered by Webbtree","{""role_summary"":""The Virtual Data Analyst analyzes large datasets, identifies trends, and communicates findings to stakeholders, working remotely to drive business outcomes."",""key_terms"":[{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing data in relational database management systems.""},{""term"":""Python"",""explanation"":""A high-level programming language used for data analysis, machine learning, and automation.""},{""term"":""R"",""explanation"":""A programming language and environment for statistical computing and graphics.""},{""term"":""Tableau"",""explanation"":""A data visualization tool used to create interactive dashboards and reports.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that provides interactive visualizations and business intelligence capabilities.""}],""skill_priorities"":{""must_have"":[""SQL"",""Python"",""R"",""Data visualization tools (e.g., Tableau, Power BI)"",""Analytical and problem-solving skills"",""Excellent communication skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach analyzing a large dataset to identify trends and patterns?"",""example_answer"":""I would first clean and preprocess the data, then use techniques such as regression analysis and clustering to identify trends and patterns. Finally, I would visualize the results using tools like Tableau or Power BI to communicate my findings effectively.""},{""question"":""Can you explain a time when you had to communicate complex data insights to a non-technical stakeholder?"",""example_answer"":""In my previous role, I had to present data insights to a marketing team. I created a clear and concise report, using visualizations to illustrate my points, and walked them through my findings and recommendations. The team was able to understand and act on my insights, which improved their campaign's performance.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to work independently and as part of a team""],""confidence_score"":90.0}"
Senior Data Analyst - Canada,"We have an immediate need for Senior Data Specialists*** who can work the full life cycle, from requirement gathering to reporting data. The business has continued to evolve, and this growing group is the central hub for analytics and reporting for the entire company.

Skills And Attributes Needed

MS SQL, Power BI and Azure skills.
Ability to work with the business and to get an understanding and what is needed and then produce
Ability to work with multiple stake holders.
Strong analytical and problem-solving skills.
The title is Senior Data Analyst though we have a few people on the team and they tell is it’s all encompassing… Data Analyst, Business Analyst, Data Scientist, Data Engineer, ect…","{""role_summary"":""A senior data specialist responsible for the full lifecycle of data analysis, from gathering requirements to reporting insights, to support business decision-making across the organization."",""key_terms"":[{""term"":""MS SQL"",""explanation"":""A relational database management system used for storing and managing data.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft for data visualization and business intelligence.""},{""term"":""Azure"",""explanation"":""A cloud computing platform by Microsoft for building, deploying, and managing applications and services.""}],""skill_priorities"":{""must_have"":[""MS SQL"",""Power BI"",""Azure"",""Analytical skills"",""Problem-solving skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with MS SQL and how you've used it to analyze complex data sets?"",""example_answer"":""I've used MS SQL to develop and maintain databases for various projects, including a recent project where I analyzed customer purchase behavior to inform marketing strategies.""},{""question"":""How do you ensure that your data visualizations in Power BI are effective in communicating insights to stakeholders?"",""example_answer"":""I focus on creating clear and concise visualizations that tell a story, and I work closely with stakeholders to understand their needs and preferences.""}],""red_flags"":[""Lack of experience with MS SQL, Power BI, or Azure"",""Inability to work with multiple stakeholders""],""confidence_score"":90.0}"
Staffingandrecruiting,"Minimum 1 year of work experience - fully remote position. Freshers are also encouraged to apply.

About us: The Future of AI is Patterned We are a stealth-mode technology startup that is revolutionizing the way AI is used. Our platform uses pattern recognition to train AI models that are more accurate, efficient, and robust than ever before.

We are backed by top investors and we are hiring for almost everything! If you are passionate about AI and want to be a part of something big, then we want to hear from you.

Make a positive impact on the world. Be a part of a fast-growing startup. If you are interested in learning more, please visit our website.

We Are Looking For People Who Are

Passionate about AI.

Excellent problem solvers.

Team players.

Driven to succeed.

Requirements

Role Responsibilities:

Work in close collaboration with the Business Intelligence Lead, Federal Data Lead, and other Program teams

Develop, maintain, and improve BI tools, build and enhance standard operating procedures (SOPs)

Manage various data sets and active Google workbooks with adjacent contract teams, monitor and analyze financial health information at the project and program levels

Communicate with client leadership to assess data needs and emerging requirements

Work with large data sets, workbooks, and spreadsheets to manipulate and manage program-level information using macros, queries, scripts, etc.

Gather requirements and lead the development of long-term data management tools, processes, and solutions based on organizational needs.

Be comfortable working with collaboration tools such as; Google Suite, Microsoft Office

Providing general support to the client including, but not limited to, analysis, data calls, financial management, risk management, audits, and project management-related tasks.

Qualifications

Bachelor's Degree in business, business intelligence, data or information management, or similar.

Proficient in Google Scripts

Minimum 1 year of data or information management and/or data analysis experience.

Experience using Microsoft Excel and Google Sheets (macros, imports, query functions).

Experience with developing Google App Script is a plus.

Experience using SQL Developer is a plus.

Excellent written and verbal communication skills.

Willing to work in an administratively manual environment while working towards automation of processes in the future.

Clearable (able to pass both a criminal background check and credit check).

Highly motivated, self-learner, and technically inquisitive

Benefits

Special Benefits you will love:

Flexible vacation paid unlimited holidays and paid sick days

401(k) with up to 2% employer match

Health, vision, and dental insurance

Why Patterned Learning AI?

Patterned Learning AI is made up of incredibly bright, mission-driven coworkers who are passionate about using technology to solve real-world problems---and we're growing quickly. In order to continue building an engaging and dynamic organization, we're committed to giving everyone the support they need to do great work.

We believe diverse perspectives and backgrounds are critical to building great technology, and our goal is to cultivate an environment where people feel equally valued and respected. Patterned Learning AI is proud to be an equal opportunity workplace, and we welcome applicants from all backgrounds regardless of race, color, ancestry, religion, gender identity or expression, sexual orientation, marital status, age, citizenship, socioeconomic status, disability, or veteran status.

Powered by Webbtree","{""role_summary"":""Collaborate with cross-functional teams to develop, maintain, and improve business intelligence tools, manage data sets, and provide general support to clients, while working towards automation of processes."",""key_terms"":[{""term"":""Pattern recognition"",""explanation"":""A machine learning technique used to train AI models to recognize and learn from patterns in data.""},{""term"":""Business Intelligence (BI) tools"",""explanation"":""Software applications used to analyze and present business data to help organizations make better decisions.""},{""term"":""Google Scripts"",""explanation"":""A scripting language used to automate tasks and create custom business logic within Google Apps.""},{""term"":""Google App Script"",""explanation"":""A cloud-based scripting platform used to automate tasks and create custom business logic within Google Apps.""},{""term"":""SQL Developer"",""explanation"":""A software tool used to design, develop, and manage databases using SQL.""}],""skill_priorities"":{""must_have"":[""Google Scripts"",""Microsoft Excel"",""Google Sheets"",""Data analysis"",""Communication skills""],""nice_to_have"":[""Google App Script"",""SQL Developer""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach developing a new business intelligence tool to improve data analysis for a client?"",""example_answer"":""I would start by understanding the client's requirements and data needs, then design a tool that leverages Google Scripts and Excel to automate data analysis and visualization. I would also ensure the tool is scalable and easy to maintain.""},{""question"":""Can you give an example of a time when you had to communicate complex data insights to a non-technical stakeholder?"",""example_answer"":""In my previous role, I had to present financial data to a client leadership team. I used clear and concise language, visualized the data using charts and graphs, and provided actionable recommendations to ensure they understood the insights.""}],""red_flags"":[""Lack of experience with Google Scripts and Excel"",""Inability to work in a fast-paced, dynamic environment"",""Poor communication skills""],""confidence_score"":85.0}"
Senior Marketing Data Analyst,"About KOHO

KOHO’s purpose is to empower Canadians to build a great financial foundation with products that are radically transparent and easy to manage. We first launched in 2017, and we have since built a community of over 1 million users . Leading investors around the globe believe in our vision, and we’ve successfully raised over $320M to make our vision a reality.

Discover our culture here and get the inside scoop from our team here !

About The Role

KOHO is seeking a highly motivated Senior Data Analyst to collaborate with various departments in leveraging data for informed decision-making. If you thrive on automating reports, crafting insightful dashboards, and extracting actionable insights from financial data, this role is tailored for you. As part of our team, you will immerse yourself in writing SQL queries, crafting Python scripts, and engaging in consultative sessions with stakeholders across the business.

What You'll Do

Analyze existing data sources to develop accurate and insightful reports.
Create and deliver visually compelling dashboards to showcase key findings and emerging trends.
Perform in-depth analysis of marketing data to drive strategic decision-making.
Prioritize and manage incoming data requests effectively within your workflow.
Collaborate closely with other members of the data team to execute projects and uphold the integrity of our data warehouse as the cornerstone of truth at KOHO.

Who You Are

Proven experience in a data or marketing analyst role.
Proficiency in SQL for data manipulation, including self-joins, window functions, and parameter usage.
Intermediate proficiency in Python, including user-defined functions, API requests, and writing efficient loops.
Demonstrated experience with dbt from previous roles.
Basic proficiency in Python.
Strong quantitative and analytical skills, coupled with adept data gathering abilities.
Quick grasp of business concepts, metrics, and KPIs.
Ability to effectively multitask and prioritize assignments.
Well-organized with excellent time management skills.

At KOHO, we are dedicated to providing pay transparency to all candidates. Compensation at KOHO is determined through various factors including but not limited to: comparable salary market data within Canada, technical skill assessment, a holistic view of previous work history, and internal pay equity with other KOHO team members.

Target Base Salary Range

$80,500 — $105,000 CAD

What's In It For You?

We Invest Time And Resources Into Making Sure KOHO Is As Good As The People We Hire. Here Are Some Of The Reasons We Attract The Best People

🧘‍♂️ Balance Your Life - Company-wide summer wellness days, winter holiday closure, personal days, a wellness spending account, and maternity & parental leave top-up

💻 Remote First - Work from anywhere in Canada with a budget to set up your home office

🆙 Level Up - Access to an in-house certified performance coach and an annual training budget

🥅 Reach Your Goals - Salary assessments twice per year

🙌 The KOHO Culture - We have won 7 ""Great Place to Work ®"" awards since 2019

🤝 Be an Owner - Every KOHO employee gets a generous amount of equity with a 10 year exercise window

The KOHO culture is one of collaboration, creativity, and diverse perspectives. We are committed to building and fostering an inclusive, accessible environment for everyone. If you have any questions, concerns, or requests regarding accessibility needs, please contact peopleaccessibility@koho.ca and the People and Culture team will be happy to help.","{""role_summary"":""Collaborate with various departments to leverage data for informed decision-making, automating reports, crafting insightful dashboards, and extracting actionable insights from financial data."",""key_terms"":[{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational database management systems.""},{""term"":""dbt"",""explanation"":""A data transformation tool used for building and managing data pipelines.""},{""term"":""API requests"",""explanation"":""A set of defined rules that enable different applications to communicate with each other.""},{""term"":""Window functions"",""explanation"":""A type of SQL function that performs calculations across a set of rows related to the current row.""}],""skill_priorities"":{""must_have"":[""Proven experience in a data or marketing analyst role"",""Proficiency in SQL"",""Intermediate proficiency in Python"",""Demonstrated experience with dbt""],""nice_to_have"":[""Basic proficiency in Python""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize a slow-performing SQL query?"",""example_answer"":""I would first analyze the query to identify the bottleneck, then consider indexing, rewriting the query, or optimizing the database configuration to improve performance.""},{""question"":""How do you ensure data quality and integrity in your data pipelines?"",""example_answer"":""I implement data validation checks, use data profiling techniques, and perform regular data audits to ensure data accuracy and consistency.""}],""red_flags"":[""Lack of experience with dbt"",""Inability to effectively multitask and prioritize assignments""],""confidence_score"":90.0}"
"Data Analyst, Enterprise Product","At Chime, we're passionate about creating products that help people Unlock Financial ProgressTM. We’re a financial technology company, not a bank*, founded on the idea that basic banking should be helpful, transparent, and fair.

At Chime Enterprise, we extend this mission to the workplace. We partner with forward-thinking employers across the U.S. to provide them with proven solutions to drive engagement, productivity, and organizational success within their teams. Our enterprise suite of products helps employers support their employees at any point in their financial journeys, creating a more financially healthy and engaged workforce, empowering them to own the long-term value of their work and achieve their financial goals.

We are a dynamic team of innovators driven by our mission. Joining Chime Enterprise means being part of a fast-moving startup culture within the larger organization at Chime, offering room for bold experimentation, big decisions, and exciting growth opportunities. We’re revolutionizing the future of work and unlocking potential for both employers and employees alike—want to join us?

About The Role

As a member of the Chime Enterprise Product team you will have the opportunity to help develop, test, launch and scale both member rewards and earned wage access products. Through experimentation, user behavior analysis, sophisticated statistical and data science modeling, and dashboard development, you will surface product insights to increase enrollment, adoption, and retention of our users.

In this role, you will work closely with product managers, user research, engineers, product & lifecycle marketing, and operational stakeholders to foster a data-driven product development culture, advise our product roadmaps, and build a deep understanding of member behavior.

In this role, you can expect to

Keep a pulse on performance metrics and KPIs. You will be positioned to have a view of the business, product, and member base and encouraged to understand and explain trends.
Drive predictive analytics and user behavior modeling, identifying trends and opportunities to improve user experiences, increase reward redemptions, and maximize engagement with key product features.
Take initiative in designing and executing experiments, including A/B testing and data-driven initiatives, to evaluate the effectiveness of features like personalized goal-setting and tiered rewards in influencing user behavior.
Own the measurement of product impact, developing frameworks for understanding causation, attribution, and incremental lift, ensuring alignment with the product’s engagement and retention goals.
Collaborate with product, marketing and operational teams to deliver actionable insights and ensure alignment on strategy, goals, and metrics, contributing to data integrity and the success of key initiatives.

To thrive in this role, you have

3+ years in data-focused roles (post-internship), building analytical infrastructure and data tools that support a wide audience and facilitate decisions of trade-offs. B2C product analytics and FinTech experience preferred.
Strong quantitative background (e.g., Statistics, Economics, Applied Mathematics) with experience in statistical analysis, causal inference, and hypothesis testing
Expertise in SQL - you innately translate business questions to queries, understand the edge cases of joins, and can explore a warehouse to find data most appropriate to the problem.
Experience leading experimentation, statistical analysis, and sophisticated measurement (e.g. causal inference) E2E to guide decision making.
Competence in Python or R for data analysis and modeling.
Hands-on experience with data visualization tools (e.g., Tableau, Looker) and the ability to create clear and impactful visualizations.
Familiarity with cloud and infrastructure services like AWS, Snowflake, DBT, etc. is preferred
Understanding of statistical concepts (e.g. regression, decision tree) and a willingness to learn experimental design.
Strong problem-solving skills and attention to detail.
Excellent communication skills, with the ability to explain technical concepts to non-technical audiences.
Interest in financial products and improving financial inclusivity.

The base salary offered for this role and level of experience will begin at $109,000 and go up to $136,500. Full-time employees are also eligible for a bonus, competitive equity package, and benefits. The actual base salary offered may be higher, depending on your location, skills, qualifications, and experience.

A Little About Us

At Chime, we believe that everyone can achieve financial progress. We created Chime—a financial technology company, not a bank*—on the premise that basic banking services should be helpful, transparent, and free. Through our user-friendly tools and intuitive platforms, we empower our members to take control of their finances and work towards their goals. Whether it's starting a savings account, purchasing a first car or home, launching a business, or pursuing higher education, we're proud to have helped millions unlock their financial potential.

We're a team of problem solvers, dreamers, and builders with one shared obsession: our members. From day one, Chimers have worked tirelessly to out-hustle and out-execute competitors to bring our mission to life. Their grit and determination inspire us to work harder every day to deliver the very best experience possible. We each bring an owner's mindset to our work, refusing to be outdone and holding ourselves accountable to meet and exceed the highest bars for our teams, our company, and our members.

We believe in being bold, dreaming big, and taking risks, while also working together, embracing our diverse perspectives, and giving each other honest feedback. Our culture remains deeply entrepreneurial, encouraging every Chimer to see themselves as stewards of our mission to help everyday Americans unlock their financial progress.

We know that to achieve our mission, we must earn and keep people's trust—so we hold ourselves to the highest standards of integrity in everything we do. These aren't just words on a wall—our values are embedded in every aspect of our business, serving as a north star that guides us as we work to help millions achieve their financial potential.

Because if we don't—who will?

Chime is a financial technology company, not a bank. Banking services provided by The Bancorp Bank, N.A. or Stride Bank, N.A., Members FDIC.

What We Offer

💰 Competitive salary based on experience
✨ 401k match plus great medical, dental, vision, life, and disability benefits
🏝 Generous vacation policy and company-wide Take Care of Yourself Days
🫂 1% of your time off to support local community organizations of your choice
👟 Annual wellness stipend to use towards eligible wellness related expenses
👶 Up to 24 weeks of paid parental leave for birthing parents and 12 weeks of paid parental leave for non-birthing parents
👪 Access to Maven, a family planning tool, with $15k lifetime reimbursement for egg freezing, fertility treatments, adoption, and more.
💚 A challenging and fulfilling opportunity to join one of the most experienced teams in FinTech and help millions unlock financial progress

We know that great work can’t be done without a diverse team and inclusive environment. That’s why we specifically look for individuals of varying strengths, skills, backgrounds, and ideas to join our team. We believe this gives us a competitive advantage to better serve our members and helps us all grow as Chimers and individuals.

We hire candidates of any race, color, ancestry, religion, sex, national origin, sexual orientation, gender identity, age, marital or family status, disability, Veteran status, and any other status. Chime is proud to be an Equal Opportunity Employer and will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance, Cook County Ordinance, and consistent with Canadian provincial and federal laws. If you have a disability or special need that requires accommodation, please let us know.

To learn more about how Chime collects and uses your personal information during the application process, please see the Chime Applicant Privacy Notice.","{""role_summary"":""As a member of the Chime Enterprise Product team, you will develop, test, launch, and scale member rewards and earned wage access products, using data-driven insights to increase enrollment, adoption, and retention."",""key_terms"":[{""term"":""Predictive analytics"",""explanation"":""Using statistical models to forecast future behavior or outcomes, in this case, to improve user experiences and increase reward redemptions.""},{""term"":""Causal inference"",""explanation"":""A statistical technique to establish cause-and-effect relationships between variables, used to measure the impact of product features on user behavior.""},{""term"":""A/B testing"",""explanation"":""A method of comparing two versions of a product or feature to determine which one performs better, used to evaluate the effectiveness of personalized goal-setting and tiered rewards.""},{""term"":""Data visualization"",""explanation"":""The process of creating graphical representations of data to communicate insights and trends, used to present findings to non-technical stakeholders.""}],""skill_priorities"":{""must_have"":[""3+ years of experience in data-focused roles"",""Strong quantitative background (e.g., Statistics, Economics, Applied Mathematics)"",""Expertise in SQL"",""Experience leading experimentation and statistical analysis"",""Competence in Python or R for data analysis and modeling""],""nice_to_have"":[""Familiarity with cloud and infrastructure services like AWS, Snowflake, DBT, etc."",""Experience with data visualization tools (e.g., Tableau, Looker)""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design an experiment to measure the impact of a new feature on user engagement?"",""example_answer"":""I would use A/B testing to compare the engagement metrics of users who have access to the feature versus those who do not. I would also ensure that the experiment is properly randomized and that the results are statistically significant.""},{""question"":""Can you explain how you would approach analyzing the effectiveness of a personalized goal-setting feature on user behavior?"",""example_answer"":""I would use predictive analytics to identify trends in user behavior and then apply causal inference techniques to measure the causal effect of the feature on user behavior. I would also consider using data visualization tools to present the findings to stakeholders.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to explain technical concepts to non-technical audiences""],""confidence_score"":90.0}"
"Consumer Insights, Analyst","Adecco Creative is partnering with one of NYC’s most iconic fashion brands to recruit for an Analyst, Brand Insights role. This position will be temp to perm and a hybrid schedule in Midtown Manhattan. This role will start immediately and relocation is not available.

Primary Purpose:
The Global Brand Analytics team is responsible for providing the insights, measurement frameworks, and self-serve tools to enable the Brand team to deliver its ambitious growth strategy.

As the Sr. Analyst, Brand Insights, you will play a critical role in supporting data driven decision-making through post-purchase surveys, brand lift studies, and creative pre-testing globally.

The successful individual will leverage their proficiency in Marketing Analytics to:
Design, implement, and analyze brand & campaign lift studies and creative pre-testing to assess marketing effectiveness and consumer sentiment in a timely manner.
Interpret survey results, identify trends, and generate actionable insights that inform marketing strategies, media planning, and creative optimizations.
Work closely with cross-functional teams to integrate marketing and consumer insights into campaign planning and brand strategy.
Develop and refine testing methodologies to assess creative impact, messaging effectiveness, and consumer engagement.
Create compelling reports and presentations that communicate insights and recommendations to stakeholders, including senior leadership.
Stay updated on post-purchase survey program, industry trends, emerging research methodologies, and best practices in marketing, creative and consumer insights.
Leverage marketing analytics tools, testing platforms, and data visualization tools to streamline processes and improve efficiency.

The accomplished individual will possess:
Bachelor’s degree in Marketing, Statistics, Business Analytics, or a related field
3+ years of experience in consumer insights, marketing analytics, or market research
Proficiency in survey tools (e.g., Medallia).
Familiarity with media measurement and brand tracking methodologies.
Strong knowledge of experimental design, A/B testing, and data interpretation.
Knowledge of statistical analysis and data visualization tools (Excel, SQL, Python, R, Tableau, Power BI).
Exceptional project management, analytical and problem-solving skills with keen attention to detail.
Excellent communication skills with the ability to convey complex findings to non-technical stakeholders.
Knowledge of ad effectiveness metrics and brand health tracking.
Experience working cross-functionally with marketing, data science/analytics, and creative teams","{""role_summary"":""Support data-driven decision-making by analyzing brand insights, conducting surveys, and providing actionable recommendations to inform marketing strategies and brand growth."",""key_terms"":[{""term"":""Brand lift studies"",""explanation"":""Measuring the effectiveness of marketing campaigns on brand awareness and perception.""},{""term"":""Creative pre-testing"",""explanation"":""Testing marketing materials before launch to gauge consumer response and sentiment.""},{""term"":""Marketing Analytics"",""explanation"":""Using data and statistical methods to measure and optimize marketing performance.""},{""term"":""A/B testing"",""explanation"":""Comparing two versions of a marketing material to determine which performs better.""},{""term"":""Data visualization tools"",""explanation"":""Software used to present complex data in a clear and understandable format.""}],""skill_priorities"":{""must_have"":[""Marketing Analytics"",""Survey tools (e.g., Medallia)"",""Experimental design"",""Data interpretation"",""Statistical analysis"",""Data visualization tools (Excel, SQL, Python, R, Tableau, Power BI)""],""nice_to_have"":[""Familiarity with media measurement and brand tracking methodologies"",""Knowledge of ad effectiveness metrics and brand health tracking""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for designing and implementing a brand lift study?"",""example_answer"":""I would start by defining the study's objectives and identifying the target audience. Then, I would design the survey questions and sampling methodology, ensuring that the results are representative of the target audience. Next, I would analyze the data using statistical methods and create a report highlighting the key findings and recommendations.""},{""question"":""How do you stay updated on industry trends and emerging research methodologies in marketing and consumer insights?"",""example_answer"":""I regularly read industry publications and attend conferences to stay current on the latest developments. I also network with peers and thought leaders in the field to learn from their experiences and share my own knowledge.""}],""red_flags"":[""Lack of experience with survey tools or marketing analytics platforms"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Senior BI Analyst,"About The Company

Albertsons Companies is at the forefront of the revolution in retail. With a fixation on raising the bar with innovation and building belonging through our culture, our team is rallying our company around a unique purpose: to create joy around each table and inspire a healthier tomorrow for every community.

Albertsons Companies is one of the largest food and drug retailers in the United States, with over 2,200 stores in 34 states and the District of Columbia. Our well-known banners include Albertsons, Safeway, Vons, Jewel-Osco, Shaw's, Acme, Tom Thumb, Randalls, United Supermarkets, Pavilions, Star Market, Haggen, Carrs, Kings Food Markets, and Balducci's Food Lovers Market. We support our stores with 22 distribution centers and 19 manufacturing plants.

Placing a premium on adaptability, safety and family well-being, our work model, Presence with a Purpose, offers a hybrid work environment between remote work and office time. A one-size-fits-all approach does not apply to everyone, and teams are empowered to make decisions best for them.

Bring your flavor

Building the future of food and well-being starts with you. Join our team and bring your best self to the table.

#bringyourflavor

What You Will Be Doing

The Own Brands Strategic Sourcing Department has an opening for a Senior BI Analyst.

The BI Analyst is responsible for delivering business solutions that collect, transform, analyze, and interpret data to draw key insights to support Strategic Sourcing in making an informed data-based and strategic decisions on category review and negotiations. Has a keen ability to extract data from a variety of sources across the Albertsons enterprise and use quantitative skill set to create dashboards, reports, metrics using a variety of business intelligence tools, techniques, and technology. This individual must have a unique combination of technical and business operations acumen and experience, coupled with strong emotional intelligence.

The position will be based in Boise, Idaho, or one of our main regional offices (Seattle, WA, Portland, OR, Pleasanton CA, Denver CO, Dallas TX, Chicago, IL, or Fullerton, CA, Phoenix, AZ).

Main Responsibilities

Partner with Own Brands Strategic Sourcing Team with business needs and provide solutions for data insights.
Analyze large and complex data sets and create optimized solutions to present actionable recommendations to Sourcing Managers.
Ability to take data with different ranges of complexity level from disparate sources across the enterprise and synthesize into meaningful business insights for Sourcing Managers.
Provide in-depth analytical support for a variety of sourcing initiatives including category reviews, new item cost analysis, and logistic assessments.
Aggregate data from RFI/RFP submissions and help create a decision matrix.
Prepare and present analytics results and recommendations to leaders by building visual charts, graphs, and process flows.
Create ad-hoc customized reports for a variety of needs/functions through platforms such as Power BI dashboard.
Lead creating training content for Strategic Sourcing Team such as excel tips and tricks.
Mentor BI Analysts.

The salary range is $82,900 to $115,000 annually. Starting salary will vary based on criteria such as location, experience, and qualifications. There may be flexibility for exceptional candidates.

What We Are Searching For

Preferred degree in: Business, Accounting, Supply Chain, Finance or equivalent.MBA preferred.
3- 5 years experience and /or the education listed above.
3+ years in business analytics and retail or backstage/corporate experience.
Knowledge in formal strategic sourcing processes and methodologies.
Excellent understanding of manufacturing, distribution and logistics.
Advanced ability to strategically plan data architecture and information needed to ensure relevant information is accessible.
Experience with Business intelligence visualization process Power BI or equivalent to create impactful reports and interactive dashboards
Ability to multi-task and manage a variety of business programs/initiatives in response to changing priorities
Ability to explain complicated or technical information in a streamlined manner to non-technical audiences
Strong analytical, quantitative, and problem-solving skills
Advanced computer skills including SQL, VBA, Excel, and PowerPoint. Ability to understand and work with multiple enterprise wide systems.
Experience pulling information or modifying/creating queries from database such as Snowflake, SSIMS and EDM.
Excellent oral, written and presentation communication skills.
Excellent relationship building and collaboration skills
High energy level and sense of urgency on executing initiatives.

What is it like at Albertsons?

Our 290,000 associates have a passion for great service and building lasting relationships with our customers. Through a companywide focus on innovation, we are continually enhancing our digital and product offerings, making it easy for customers to get what they need, wherever they are.

Albertsons is an Equal Opportunity Employer

This Company is an Equal Opportunity Employer, and does not discriminate on the basis of race, gender, ethnicity, religion, national origin, age, disability, veteran status, gender identity/expression, sexual orientation, or on any other basis prohibited by law. Consistent with applicable state and local law, the Company will consider for employment qualified applicants with arrest and conviction records.

We endeavor to make this site accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at 1-888-255-2269(option #4).","{""role_summary"":""The Senior BI Analyst will provide data insights to support Strategic Sourcing in making informed decisions on category review and negotiations. They will analyze complex data sets, create dashboards and reports, and present actionable recommendations to Sourcing Managers."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""The practice of collecting, transforming, and analyzing data to draw key insights and support business decisions.""},{""term"":""Strategic Sourcing"",""explanation"":""A process of finding and managing suppliers to obtain goods, services, or works at the best possible total cost of ownership, in terms of quality, quantity, time, and location.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""SQL"",""explanation"":""A programming language designed for managing and manipulating data in relational database management systems.""}],""skill_priorities"":{""must_have"":[""Business analytics and retail or backstage/corporate experience"",""Knowledge in formal strategic sourcing processes and methodologies"",""Advanced ability to strategically plan data architecture and information"",""Experience with Business intelligence visualization process Power BI or equivalent"",""Strong analytical, quantitative, and problem-solving skills"",""Advanced computer skills including SQL, VBA, Excel, and PowerPoint""],""nice_to_have"":[""MBA"",""Experience with Snowflake, SSIMS, and EDM databases""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing complex data sets to support Strategic Sourcing decisions?"",""example_answer"":""I would start by identifying the key business needs and requirements, then use my knowledge of business intelligence tools and techniques to extract and analyze the relevant data. I would create dashboards and reports to present actionable recommendations to Sourcing Managers, and ensure that my insights are actionable and impactful.""},{""question"":""How do you stay current with new tools and technologies in business intelligence and analytics?"",""example_answer"":""I regularly attend industry conferences and webinars, participate in online forums and communities, and take online courses to stay up-to-date with the latest trends and best practices in business intelligence and analytics.""}],""red_flags"":[""Lack of experience with business intelligence tools and techniques"",""Inability to communicate complex technical information to non-technical audiences""],""confidence_score"":90.0}"
Customer Data Analyst Intern (Summer 2025),"Job Summary

As an Intern with L’Occitane en Provence North America you will undertake work on our different Data projects. L'Occitane group has built an ambitious Datahub program with the set up of a Datalake (Snowflake solution) to cover the analytical needs and different Master data platforms for operational needs around referential data (customers, products, stores). To drive the development of our data, the Data Intern will have the role to develop diversified projects on different business domains : Customers, Supply, and Finance. The Data Intern will work on projects such as data information capture and extraction using ETL, data quality and monitoring and/or build Finance/Supply reporting.

Job Responsibilities

The candidate will work on the Snowflake platform to monitor and improve the Data Quality in our different channels (Retail, Clienteling, E-commerce, CRM) on customer, finance and supply domains
Build and maintain Data flow to capture and propagate data in Customers, Finance and Supply domains using SQL language, ETL solution such as DBT, SSIS or Knime
Build and maintain Datamart using SQL language and DBT
Analyze data sets using SQL language
Build reports using PowerBI
In Data Science, if the candidate is skilled and autonomous, she/he can propose use cases using Machine learning scores and Large Language Model to improve our customer knowledge and KPI, create actionable data and automate process using Python, PowerBI report, Knime or OpenAI. For this expertise area, we are expecting the candidate to be autonomous and bring his/her expertise to the company

Key Performance Indicators

Data accuracy
Project completion in timely manner
Project deliverables
Fast learning curve
Accuracy of data
Autonomy
Curious

Requirements

EDUCATION:

Currently pursuing a bachelor's / master's degree in Computer Science

EXPERIENCE:

Prior internship experience or students projects with data projects and development

Skills

SQL (good knowledge and experience)
Data Modelization
Data flows (ETL, API)
Data Science
Python
Reporting

Physical & Travel Requirements

Hybrid or on site at NY office

Benefits Include

Competitive Compensation at $19/hour
School Credit Offered
A warm, open, fun, and friendly work environment
Generous L’Occitane employee discounts

All Applicants

L'Occitane's Privacy Statement

United States Applicants Only

Employee Rights

FMLA: Posters

FMLA Special Rules for Returning Military Members (USERRA)","{""role_summary"":""Assist in developing data projects, including data quality monitoring, data flow creation, and report building, to support business domains such as Customers, Supply, and Finance."",""key_terms"":[{""term"":""Datalake"",""explanation"":""A centralized repository that stores all structured and unstructured data in its native format.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process used to extract data from multiple sources, transform it into a standardized format, and load it into a target system.""},{""term"":""Snowflake solution"",""explanation"":""A cloud-based data warehousing platform that enables fast, secure, and easy access to an organization's data.""},{""term"":""Master data platforms"",""explanation"":""A set of tools and processes that enable organizations to manage and maintain their critical data entities, such as customers, products, and stores.""},{""term"":""Datahub program"",""explanation"":""An initiative to create a centralized data management system that integrates data from various sources and provides a single source of truth.""},{""term"":""Datamart"",""explanation"":""A subset of a data warehouse that contains a specific portion of the data, organized for easy access and analysis.""},{""term"":""Machine learning scores"",""explanation"":""Algorithms that enable machines to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Large Language Model"",""explanation"":""A type of artificial intelligence that uses natural language processing to understand and generate human-like language.""}],""skill_priorities"":{""must_have"":[""SQL"",""Data Modelization"",""Data flows (ETL, API)"",""Python""],""nice_to_have"":[""Data Science"",""Machine learning scores"",""Large Language Model""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach data quality monitoring in a Snowflake platform?"",""example_answer"":""I would use SQL to create data quality checks, and then schedule them to run regularly using a tool like DBT. I would also create data validation rules to ensure data accuracy and completeness.""},{""question"":""Can you explain how you would build a Datamart using SQL and DBT?"",""example_answer"":""I would first identify the required data elements and create a data model. Then, I would use SQL to extract the data from the source system, transform it using DBT, and load it into the Datamart. Finally, I would create reports using PowerBI to visualize the data.""}],""red_flags"":[""Lack of experience with Snowflake platform"",""Inability to write complex SQL queries"",""Limited knowledge of data modeling and data flows""],""confidence_score"":85.0}"
Data Customer Insights Analyst,"About CAVA:
At CAVA we make it deliciously simple to eat well and feel good every day. We are guided by a Mediterranean heritage that’s been perfecting how to eat and live for four thousand years. We prioritize authenticity, curiosity and the pursuit of excellence in everything we do. We are working towards something big, together.

We foster a culture built on five core values:
Generosity First, Always: We lead with kindness. Our best work happens when we act in service of others.
Constant Curiosity: We are eager to learn, grow, and explore beyond the obvious.
Act with Agility: We welcome change; it’s the only constant. We embrace, adjust, adapt.
Passion for Positivity: We greet each day with warmth and possibility.
Collective Ambition: We have high aspirations that are achieved when we work together with a shared purpose.

The Role:
We are seeking a highly motivated and analytical Customer Insights Analyst to help drive analysis, strategy, and reporting – fueling customer related initiatives across the business. This position will report to the Customer Analytics Manager and requires a unique balance of strong technical skills and ability to synthesize results + creatively propose business solutions.

What You’ll Do:
Play a technical and strategic role in driving all things customer insights and analytics while partnering internally to evaluate the success of customer initiatives
Own discrete analyses focused on but not limited to: CAVA’s loyalty program, personalization tactics, customer lifecycle (CLV, churn, etc.), customer preferences, and much more
Develop and apply research methodologies that align with key strategic goals across different stages of the customer lifecycle
Support design, creation, and publication of reports and dashboards for enterprise consumption
Create compelling visualizations using advanced analytics tools and tell revealing stories about the CAVA customer
Support the development and calculation of key KPIs to evaluate the success of customer initiatives and campaigns
Get to know the customer inside and out and generate creative ideas on how to better serve the customer that can be tested empirically through data
Advise on data-driven ways to segment the customer base in order to track and measure success of initiatives by customer cohort
Package strategic and analytical insights into clear, concise, and stakeholder ready presentations
Abide by policies and procedures that support the service mindset
Manage timeline expectations within and across teams, deliver on our responsibilities accordingly
Earn the trust of Team Members and Managers by consistently embracing CAVA’s values
Show discipline in bringing consistent performance, communication, and attitude to the job every day
Actively contribute to your department in order to complete tasks and meet company goals
Recognize the emotional stake each Team Member has in personal and organizational success of this business

The Qualifications:
1-3 years of professional experience working as a data analyst with a focus on strategic insights, either in consulting or at a consumer-facing company
Hands on and demonstrable experience working with large-scale data sets
Highly proficient in Excel – both manipulation and presentation of data
Highly proficient in SQL – data manipulation, aggregation, calculations
Highly proficient in PowerPoint – efficient and compelling slide creation
Experience with popular data visualization tools such as Tableau, Power BI, and Looker
Experience with common relational databases such as SQL DB, Redshift, Snowflake
Preferred: proficiency in Python or R for automation, statistical analysis, and data manipulation
Preferred: Bachelor’s Degree


Physical Requirements:
Ability to maintain stationary position to be able to operate a computer and other office equipment
Must be able to identify, analyze and assess details
For certain positions, must be able to occasionally move or transport items up to 50 pounds
Ability to communicate with others and exchange information accurately and effectively
Constantly positions self and move about to support ordinary restaurant or food production support or office operations, as applicable
Ability to work in a constant state of alertness and in a safe manner

What we offer:
Competitive salary, plus bonus and long-term incentives*
Early Wage Access!
Unlimited PTO, paid parental leave, plus paid opportunities to give back to the community
Health, Dental, Vision, Telemedicine, Pet Insurance plus more!
401k enrollment with CAVA contribution
Company-paid STD, LTD, Life and AD&D coverage for salaried positions*
Free CAVA food
Casual work environment
The opportunity to be on the ground floor of a rapidly growing brand
All exempt and non-exempt employees are eligible for benefits. Benefits are effective the 1st of the month following 30 days of service and you have until the day before the effective date to enroll. A new hire can enroll in our benefit program by selecting a link that is emailed directly to the new hire at their personal email address once hired.
Please note that visa sponsorship is not available. The compensation range posted includes total cash.


*Indicates qualifying eligible positions only

CAVA – Joining “A culture, not a concept”

This job description is not intended to be a comprehensive list of all the duties and responsibilities of the position and such duties and responsibilities may change without notice.As an equal opportunity employer, CAVA considers applicants for all positions without regard to race, color, sex, religion, national origin, disability, age, height, weight, marital status, sexual orientation, familial status, genetic information or any other characteristic or protected classes as defined by federal, state, or local law.","{""role_summary"":""The Customer Insights Analyst plays a technical and strategic role in driving customer insights and analytics, partnering internally to evaluate the success of customer initiatives and developing research methodologies to support key strategic goals."",""key_terms"":[{""term"":""Customer lifecycle"",""explanation"":""The stages a customer goes through when interacting with a company, including acquisition, retention, and churn.""},{""term"":""CLV (Customer Lifetime Value)"",""explanation"":""The total value a customer is expected to bring to a business over their lifetime.""},{""term"":""Personalization tactics"",""explanation"":""Methods used to tailor a customer's experience to their individual preferences and needs.""},{""term"":""Data visualization tools"",""explanation"":""Software used to create interactive and dynamic visualizations of data, such as Tableau, Power BI, and Looker.""}],""skill_priorities"":{""must_have"":[""Hands-on experience working with large-scale data sets"",""High proficiency in Excel, SQL, and PowerPoint"",""Experience with data visualization tools""],""nice_to_have"":[""Proficiency in Python or R for automation, statistical analysis, and data manipulation"",""Bachelor's Degree""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for developing and applying research methodologies to support key strategic goals?"",""example_answer"":""I would start by identifying the key objectives and then design a research methodology that aligns with those goals. I would ensure that the methodology is scalable, efficient, and provides actionable insights. For example, in my previous role, I developed a methodology to measure customer churn, which helped the company to reduce churn by 20%.""},{""question"":""How do you stay up-to-date with the latest trends and tools in data visualization?"",""example_answer"":""I regularly follow industry blogs and attend webinars to stay current with the latest developments in data visualization. I also experiment with new tools and techniques to improve my skills.""}],""red_flags"":[""Lack of experience working with large-scale data sets"",""Inability to effectively communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Data Analyst Intern,"Farmer’s Fridge is on a mission to make it simple for everyone to eat well. We serve healthy, handcrafted meals and snacks from our growing network of 1700+ Smart Fridges (software-enabled vending machines). We are striving to change the food system from the ground up – one Fridge or delivery at a time.

We are a team that cares -– about the business, the impact our product makes, and each other. We are data-driven, innovative, and quick to move on a good idea. We are looking for people who want to collaborate in an entrepreneurial, inclusive culture and have a passion to succeed.

Farmer’s Fridge is entering a period of rapid growth, and we are looking for a a motivated Data Analyst Intern with strong technical skills and business acumen to help turn millions of potential data points into models and actionable insights that can drive product improvements, make our customer acquisition more efficient, improve our customer retention rates, and drive operating efficiencies on our production and logistics teams.

In a Typical Week/month, You Will

Develop and maintain dashboards and reports using Tableau and Hex
Assist Farmer’s Fridge in FAQ about our data structure
Pull ad-hoc reports via SQL for stakeholders
Assist in SQL and Python code reviews to improve query efficiency and maintainability
Help clean, validate, and organize datasets to ensure data accuracy and consistency.
Document data processes and best practices for internal knowledge sharing.

What are we looking for in a Data Analyst intern?

You are creative, flexible, and supremely detail-oriented but never lose sight of the big picture. It would never occur to you to say, “that’s not my job”.
You are comfortable in an environment of high-growth and ambiguity.
You strive for optimization, automation, and continuous improvement, knowing that what is currently being done can always be improved.
You believe learning should be fun and seek to empower each employee at Farmer’s Fridge with the information, benchmarks, metrics, and insights that they need to be independently successful in their roles.

What background are we seeking for a Data Analyst intern?

Currently pursuing or recently completed a degree in Data Science, Computer Science, Statistics, or a related field.
Experience in SQL for querying and manipulating large datasets.
Experience with Python for data analysis and scripting (Pandas, NumPy, etc.).
Familiarity with data visualization tools such as Looker, Tableau, or Power BI.
Familiarity with or willing to learn: version control systems, cloud platforms, and exposure to data warehousing or data pipeline concepts
Understanding of basic analytics engineering concepts (e.g., data modeling, ETL processes).
Strong analytical mindset and problem-solving skills.
Ability to work independently and manage multiple tasks in a fast-paced environment.
Detail oriented, organized, and able to effectively communicate
Minimal supervision needed

What You’ll Gain

Hands-on experience in a real-world analytics environment.
Exposure to cutting-edge data tools and methodologies.
Opportunity to collaborate with experienced analysts and engineers.
Potential for future full-time opportunities based on performance.

Farmer’s Fridge Diversity Statement

""Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply for jobs unless they meet every single qualification. At Farmer’s Fridge, we are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.”

Farmer’s Fridge is an equal-opportunity employer. We are committed to providing equal employment opportunity in all employment practices, including hiring, without regard to race, color, religion, national origin, sex, gender identity, sexual orientation, age, disability status, veteran status, or any other characteristic protected by federal, state or local law. View our disclosures related to External Agencies and Applicants below: https://www.farmersfridge.com/careerdisclosures","{""role_summary"":""Assist in turning large datasets into actionable insights to drive product improvements, customer acquisition, retention, and operating efficiencies as a Data Analyst Intern at Farmer's Fridge."",""key_terms"":[{""term"":""SQL"",""explanation"":""A programming language used for managing and querying large datasets.""},{""term"":""Tableau"",""explanation"":""A data visualization tool used to create interactive dashboards and reports.""},{""term"":""Python"",""explanation"":""A programming language used for data analysis, scripting, and automation.""},{""term"":""Data Warehousing"",""explanation"":""A system used to store and manage large datasets for reporting and analysis.""},{""term"":""ETL Processes"",""explanation"":""Extract, Transform, Load processes used to manage data flow from source systems to target systems.""}],""skill_priorities"":{""must_have"":[""SQL"",""Python"",""Data Visualization tools (e.g., Tableau, Looker, Power BI)""],""nice_to_have"":[""Version control systems"",""Cloud platforms"",""Data warehousing or data pipeline concepts""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize a slow-performing SQL query?"",""example_answer"":""I would analyze the query plan, identify performance bottlenecks, and apply indexing or rewriting techniques to improve query efficiency.""},{""question"":""How do you ensure data accuracy and consistency in your datasets?"",""example_answer"":""I would implement data validation rules, perform regular data quality checks, and maintain documentation of data processes and best practices.""}],""red_flags"":[""Lack of experience with SQL or Python"",""Inability to work independently in a fast-paced environment""],""confidence_score"":90.0}"
BI Data Analyst - Sales,"Foods you love. Brands you trust. And a career that empowers you to grow.

At Nestlé USA, we’re all working towards the same goal – to delight and deliver for our consumers. With a rich portfolio of beloved brands, including DiGiorno, Toll House, and Coffee mate, in 97% of U.S. households, we have a unique opportunity – and responsibility – to be there for every moment in our consumers’ lives.

Joining Nestlé means becoming part of an inclusive workplace that inspires innovation, encourages strategic thinking and creativity, and celebrates your achievements. No matter where you work within the organization, you are empowered to challenge the status quo, embrace risk-taking, and pioneer new ideas. Our supportive and collaborative environment encourages bold ambitions and continuous learning so that everyone can grow and thrive.

This position is not eligible for Visa Sponsorship.

You will be part of a multi-disciplinary team responsible for supporting Nestle’s Field Sales organization with the design, development and management of strategic, tactical and operational analytical solutions. As part of the Business Intelligence team you will focus on the management of the Large Format Retail Team reporting infrastructure by designing and building data models, data transfer routines, reports, dashboards and data visualizations using data management, reporting and automation tools. The solutions you implement will allow senior management and business stakeholders to analyze the performance of the Field Sales organization and its key initiatives by identifying, monitoring and predicting sales trends and outcomes.

In this role, you will serve as a trusted advisor to the Large Format Retail Team and drive understanding and adoption of Enable Hub’s analytics services. You will also provide input with the Enable Hub team in the definition of the analytics and technology roadmaps.

Responsibilities

Development of well-organized, insightful reports, dashboards, and other forms of data visualizations to support strategic, tactical and operational business decisions. Provide analysis in areas such as KPI performance against targets & goals, sales operations, forecast accuracy, segmentation, resource allocation, store compliance, merchandising, geospatial, and customer service. Ensuring that dashboards and visualizations adhere to UX best practices, design library and standards guide
Partnering with the Sales Field stakeholders to collect, document, and analyze business requirements and translating them into tangible reporting and system deliverables with a clearly defined acceptance criterion
Identifying the data sources that that will support reporting requirements and managing integration workflows to source, transform and load data into consumable datasets for reporting and analysis
Implementing data quality processes to ensure the integrity and accuracy of data sources and reports by leveraging automation and monitoring capabilities to proactively identify anomalies
Assisting members of analytics team and business stakeholders with ad-hoc and self-service reporting capabilities
Helping Business Intelligence and Enable Hub leadership identify business process efficiency/improvements
Provide training and support to end users to facilitate change management efforts and to drive adoption of report and dashboard solutions. These activities often require cross functional collaboration and the coordination of activities such as user acceptance testing, production deployments, training and post deployment support (hypercare)
Documenting technical requirements, data catalog, business definitions, architectural diagrams, source-to-target mappings, process dependencies, flows, and decisions related to the development cycle of analytical solutions.

Requirements

Bachelor's Degree, preferably in a quantitative discipline such as Computer Science, Information Systems, Mathematics/Statistics or another related major field of study
Prior experience with an integrated data management environment
Functional experience in CPG industry
Knowledge of data analysis/tools and data modeling with the ability to find and share trends from the data to make informed and objective recommendations.
2+ years of experience with a focus on data analytics including independent problem solving, and effective communication with peers and stakeholders at all levels.
2+ years of experience creating reports, dashboards, and/or summarizing large amounts of data from multiple data sources into actionable intelligence to drive business decisions
Proven experience with data management tools like Microsoft Data Flow/Factory, Alteryx, SSIS for data transfer and preparation
Experience creating detailed process documentation and conducting knowledge transfer
Experience implementing data quality solutions is a strong plus
Has a track record of successfully juggling multiple demands
Experience with process improvement (Six-Sigma) is a plus

Skills

Strong knowledge on Power Bi, Power Query and Report Builder
Working knowledge in Microsoft Power Platform; Power Apps, Power Automate
Proven knowledge in data warehousing, data modeling and data management concepts
End-to-end understanding of the data flow process of analytical solutions (from ingestion to consumption layer)
Experience using SQL to query and transform data from relational data sources. Knowledge of R, Python or other statistical analysis & data mining tools is a plus
Knowledge of Azure Data Lake is a plus
Strong knowledge of UX design best practices to present and visualize analytics
Familiarity with project management and agile methodology is a strong plus
Effective communicator at all levels and using different mediums. Formal training on story telling for analytics is a plus
Relentless problem solver who is curious and thrives in ambiguity and change
Takes smart calculated risks and fails forward
Thrives collaborating with others and is motivated by team success
An assertive team player, willing to take ownership of responsibilities, and possess a high level of positive energy and drive
Works well under pressure and has the ability to effectively handle multiple concurrent demands by prioritizing responsibilities
Self-starter, well organized, extremely detail-oriented

337467

It is our business imperative to remain a very inclusive workplace.

To our veterans and separated service members, you're at the forefront of our minds as we recruit top talent to join Nestlé. The skills you've gained while serving our country, such as flexibility, agility, and leadership, are much like the skills that will make you successful in this role. In addition, with our commitment to an inclusive work environment, we recognize the exceptional engagement and innovation displayed by individuals with disabilities. Nestlé seeks such skilled and qualified individuals to share our mission where you’ll join a cohort of others who have chosen to call Nestlé home.

The Nestlé Companies are an equal employment opportunity and affirmative action employer seeking diversity in qualified applicants for employment. All applicants will receive consideration for employment without regard to race, ethnicity, color, gender, gender identity, age, religion, national origin, ancestry, disability, perceived disability, medical condition, genetic information, veteran status, sexual orientation, or any other protected status, as defined by applicable law. Prior to the next step in the recruiting process, we welcome you to inform us confidentially if you may require any special accommodations in order to participate fully in our recruitment experience. Contact us at accommodations@nestle.com or please dial 711 and provide this number to the operator: 1-800-321-6467.

This position is not eligible for Visa Sponsorship.

Review our applicant privacy notice before applying at https://www.nestlejobs.com/privacy

#Salaried","{""role_summary"":""Support the Field Sales organization with analytical solutions, designing and building data models, reports, dashboards, and data visualizations to analyze sales trends and outcomes."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""The practice of using data and analytics to inform business decisions.""},{""term"":""Data Modeling"",""explanation"":""The process of creating a conceptual representation of data structures and relationships.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to communicate insights and trends.""},{""term"":""UX Design"",""explanation"":""The process of designing user interfaces to ensure a positive user experience.""},{""term"":""CPG Industry"",""explanation"":""Consumer Packaged Goods industry, which includes companies that manufacture and distribute consumer goods.""}],""skill_priorities"":{""must_have"":[""Power Bi"",""Power Query"",""Report Builder"",""Data analysis and modeling"",""Data management tools (e.g. Microsoft Data Flow/Factory, Alteryx, SSIS)"",""SQL"",""UX design best practices""],""nice_to_have"":[""Microsoft Power Platform (Power Apps, Power Automate)"",""R, Python or other statistical analysis & data mining tools"",""Azure Data Lake"",""Project management and agile methodology"",""Six-Sigma experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach designing a data model for a large-scale retail sales dataset?"",""example_answer"":""I would start by identifying the key entities and relationships in the dataset, and then use a tool like Power Bi to create a conceptual data model. From there, I would work with stakeholders to refine the model and ensure it meets their reporting needs.""},{""question"":""How do you ensure data quality in your analytical solutions?"",""example_answer"":""I use a combination of data validation rules, data profiling, and data monitoring to identify and correct data quality issues. I also work with stakeholders to establish clear data quality standards and ensure that data is properly documented and maintained.""}],""red_flags"":[""Lack of experience with data management tools and technologies"",""Inability to effectively communicate complex data insights to non-technical stakeholders"",""Poor problem-solving skills or inability to work independently""],""confidence_score"":90.0}"
Data Analysts,"Responsibilities

Kforce in Tampa, Florida is looking for Data Analysts. Qualified candidates will be analyzing user requirements, current business intelligence or trend data and defining functional specifications using Agile methodologies; Designing, building, and rolling out of high performing business intelligence tools or systems, including design of related master data management sets and maps for mining in a cloud (AWS/GCP) environment; Design and develop robust extract, transform, load (ETL) processes using Tableau, SQL, R, JavaScript, C#, Python, Jupyter, SAS, and SPSS; Developing and implementing complex business intelligence tools or data warehouse and systems using ETL tools, SQL, SQL Server, SQL Server Integration Services (SSIS) and SQL Server Reporting Services (SSRS) with Azure components; Creating dashboards using Snowflake SQL, Power BI and Visual Studio; Cleaning and analyzing large datasets for forecasting application usage utilizing Python, R and SQL; Maintaining or updating business intelligence tools, dashboards, or pipelines; Extracting and loading data between legacy systems; Building source-to-source target mapping to extract, transform and load (ETL) data into the data warehouse and cloud platforms; Designing reports and dashboards for the business intelligence solutions using Tableau; Deploying applications in Informatica and migrating the applications to different environments; and Documenting modifications and enhancements made to the applications, systems and databases as required by the project. Salary: $46.00 to $90.00/hr.

Requirements

Requirements: Bachelor's Degree or foreign degree equivalent in Computer Science, Computer Information Systems, Computer Applications, Information Technology, Information Systems and Technology or Engineering and six month's experience in position or six month's experience in IT or Data Analysis field. Special requirements: Experience with Tableau, SQL, R, JavaScript, C#, Python, Jupyter, SAS and SPSS. Up to 100% travel to various unanticipated domestic client sites in US required. Qualified candidates should apply online at: https://www.kforce.com/find-work/search-jobs and enter the Ref #16465 in Search field. Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.

We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.

Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.

This job is not eligible for bonuses, incentives or commissions.

Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

By clicking “Apply Today” you agree to receive calls, AI-generated calls, text messages or emails from Kforce and its affiliates, and service providers. Note that if you choose to communicate with Kforce via text messaging the frequency may vary, and message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You will always have the right to cease communicating via text by using key words such as STOP.","{""role_summary"":""The Data Analyst role involves analyzing user requirements, designing and building business intelligence tools, and developing complex data warehouse systems using various technologies such as Tableau, SQL, and Python."",""key_terms"":[{""term"":""Agile methodologies"",""explanation"":""An iterative approach to project management that focuses on flexibility and collaboration.""},{""term"":""ETL processes"",""explanation"":""Extract, Transform, Load processes used to extract data from sources, transform it into a usable format, and load it into a target system.""},{""term"":""Cloud environment"",""explanation"":""A virtual environment where data and applications are stored and accessed over the internet.""},{""term"":""Master data management"",""explanation"":""A process that ensures consistency and accuracy of an organization's critical data entities.""},{""term"":""Data warehouse"",""explanation"":""A centralized repository that stores data from various sources in a single location.""}],""skill_priorities"":{""must_have"":[""Tableau"",""SQL"",""R"",""JavaScript"",""C#"",""Python"",""Jupyter"",""SAS"",""SPSS""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of ETL and how you would implement it in a cloud environment?"",""example_answer"":""ETL stands for Extract, Transform, Load, which is a process used to extract data from sources, transform it into a usable format, and load it into a target system. In a cloud environment, I would use tools like AWS Glue or Google Cloud Data Fusion to design and implement ETL processes that can handle large datasets and scale as needed.""},{""question"":""How do you ensure data quality and consistency in a data warehouse?"",""example_answer"":""I would implement data validation rules, data normalization, and data cleansing processes to ensure data quality and consistency in a data warehouse. Additionally, I would use data profiling techniques to identify and fix data quality issues.""}],""red_flags"":[""Lack of experience with cloud-based data warehousing tools"",""Inability to design and implement ETL processes"",""Limited knowledge of data visualization tools like Tableau""],""confidence_score"":90.0}"
Customer Relationship Management Analyst,"Job Overview:
We are looking for a highly skilled and detail-oriented CRM Data Analyst to join the Bulgari North America CRM team. The ideal candidate will have a strong background in data analysis, CRM systems, and a passion for using data to drive business decisions. The CRM Analyst is vital to optimizing CRM strategies and identifying areas where the company can improve acquisition and retention of clients. This role will design, maintain, and analyze reporting that offers insights into customer behavior and that identifies trends and patterns to improve customer engagement. You will work closely with stores, merchandising, marketing, High-End and e-Commerce departments to ensure that our CRM system is effectively utilized to meet business objectives. The successful candidate will have excellent analytical skills and the ability to communicate complex data insights in a clear and concise manner.

Key Responsibilities:
Conduct analysis of customer data to identify trends, insights and opportunities that can inform customer acquisition and retention strategies and improve customer engagement.
Create and maintain comprehensive reports and visualizations on customer behavior and purchasing patterns, presenting findings to management to support strategic planning.
Analyze data to measure the effectiveness of CRM channels and provide actionable insights to drive continuous improvement and customer lifetime-value.
Monitor and report on key CRM metrics.
Identify opportunities for CRM system improvements and support the implementation of CRM-related projects.
Deliver timely and accurate reporting to stakeholders.
Work collaboratively with cross-functional teams to support identification of opportunities in customer engagement and loyalty.
Knowledge of data governance practices and a strong understanding of data privacy and ethical considerations, especially related to customer data.
Feed performance media product owners with key insights to ensure optimal journeys & Brand experience for brand.com and offline channels.
Execute ad hoc weekly, monthly, quarterly, and yearly reporting, with thoughtful analysis and recommendations.
Assist with CRM database hygiene as well as report maintenance and store portfolio rebalancing.
Manage client reallocation project using CRM tools.
Develop & manage reporting based on consumer profiles & shopping patterns and share insights to enhance the customer experience at every stage of the journey.
Develop and maintain process documentation for CRM reporting.
Stay up-to-date with industry trends, competitive landscape, and emerging technologies to recommend new approaches for customer engagement
Qualifications:
Bachelor's degree in business, marketing, data science, statistics or related field
Minimum of 3 years of experience in a customer analytics or CRM-related role within a corporate environment
Expertise in data analytics tools, such as PowerBI, SAP, BW, or similar reporting platforms
Advanced Excel skills, including pivot tables, dashboards, etc. with strong knowledge of all other Microsoft Office 365 programs (PowerPoint, Outlook)","{""role_summary"":""The CRM Data Analyst is responsible for analyzing customer data to inform customer acquisition and retention strategies, creating reports to support strategic planning, and identifying opportunities for CRM system improvements."",""key_terms"":[{""term"":""CRM"",""explanation"":""Customer Relationship Management, a system used to manage customer interactions and data.""},{""term"":""Data Governance"",""explanation"":""The practices and policies that ensure the quality, security, and integrity of an organization's data.""},{""term"":""PowerBI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""SAP"",""explanation"":""Systems, Applications, and Products in Data Processing, a German-based multinational software corporation that provides enterprise software to manage business operations and customer relations.""},{""term"":""BW"",""explanation"":""Business Warehouse, a data warehousing product from SAP that enables organizations to analyze and report on their business data.""}],""skill_priorities"":{""must_have"":[""Data analytics tools (e.g., PowerBI, SAP, BW)"",""Advanced Excel skills"",""Strong analytical skills"",""Excellent communication skills""],""nice_to_have"":[""Knowledge of data governance practices"",""Understanding of data privacy and ethical considerations""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for analyzing customer data to identify trends and opportunities?"",""example_answer"":""I would start by reviewing customer purchase history and behavior, then use data visualization tools to identify patterns and correlations. From there, I would develop recommendations for improving customer engagement and retention.""},{""question"":""How do you ensure the accuracy and integrity of your reporting and analysis?"",""example_answer"":""I follow a rigorous quality control process, including data validation and verification, to ensure that my reports are accurate and reliable. I also stay up-to-date with industry best practices and emerging trends in data governance.""}],""red_flags"":[""Lack of experience with CRM systems or data analytics tools"",""Poor communication skills or inability to present complex data insights clearly""],""confidence_score"":90.0}"
Junior Data Analyst,"Position Description

This is an exciting full-time opportunity to work in a fast-paced environment with a team of passionate technologists. We take an innovative approach to supporting our client, working side-by-side in an agile environment using emerging technologies. As a solution builder, you will be working to support the client’s mission and goals of growing an enterprise analytics platform

This position is located in our Fairfax, VA office with work performed at client site in Arlington, VA; however, a hybrid working model is acceptable.

Your future duties and responsibilities

As a solution builder, you will be working to support the client’s mission and goals of building an enterprise analytics platform
Demonstrate in-depth technical capabilities with the ability to support multiple work streams and drive assimilation of new techniques and solutions
Apply data and technical expertise in analysis, data mining and visualization of data using Business Intelligence tools and data development platforms
Evaluate data quality using SQL and data analysis techniques that improve client-reporting capabilities
Follow technology trends in data science and inform clients how this technology will benefit the future development platform
Participate in team problem solving efforts and offer ideas to solve client issues
Understand data needs and construct data pipelines for automating and accelerating data preparation

Required Qualifications To Be Successful In This Role

An interim Secret clearance is required to begin working onsite with our client, and a Secret clearance must be maintained throughout the project duration. Due to the nature of the government contract requirements and/or clearance requirements, US citizenship is required.

Basic Qualifications:

Bachelor’s degree or master’s degree in Computer Science, Mathematics or STEM related discipline
1+ Years of Experience working on Analytics and Business Intelligence focused initiatives, preferably in a consulting capacity
1+ Years of Experience using Python, R, or other languages to build statistical models or analyze data
1+ Years of Experience in creating complex SQL queries and functions, data structures and strong analytical problem solving skills
Experience working with various self-service business intelligence and data visualization tools such as Tableau, Power BI, Business Objects, etc
Strong technical troubleshooting techniques and analytical problem-solving skills
Experience working in an Agil

CGI is required by law in some jurisdictions to include a reasonable estimate of the compensation range for this role. The determination of this range includes various factors not limited to skill set, level, experience, relevant training, and license and certifications. To support the ability to reward for merit-based performance, CGI typically does not hire individuals at or near the top of the range for their role. Compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range for this role in the U.S. is $50,800.00 - $119,200.00.

CGI Federal's benefits are offered to eligible professionals on their first day of employment to include:

Competitive compensation
Comprehensive insurance options
Matching contributions through the 401(k) plan and the share purchase plan
Paid time off for vacation, holidays, and sick time
Paid parental leave
Learning opportunities and tuition assistance
Wellness and Well-being programs

Due to the nature of this government contract, US Citizenship is required.

#CGIFederalJob

Together, as owners, let’s turn meaningful insights into action.

Life at CGI is rooted in ownership, teamwork, respect and belonging. Here, you’ll reach your full potential because…

You are invited to be an owner from day 1 as we work together to bring our Dream to life. That’s why we call ourselves CGI Partners rather than employees. We benefit from our collective success and actively shape our company’s strategy and direction.

Your work creates value. You’ll develop innovative solutions and build relationships with teammates and clients while accessing global capabilities to scale your ideas, embrace new opportunities, and benefit from expansive industry and technology expertise.

You’ll shape your career by joining a company built to grow and last. You’ll be supported by leaders who care about your health and well-being and provide you with opportunities to deepen your skills and broaden your horizons.

Come join our team—one of the largest IT and business consulting services firms in the world.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status or responsibilities, reproductive health decisions, political affiliation, genetic information, height, weight, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com. You will need to reference the Position ID of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a Position ID will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. Dependent upon role and/or federal government security clearance requirements, and in accordance with applicable laws, some background investigations may include a credit check. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI’s legal duty to furnish information.","{""role_summary"":""Work as a solution builder in a fast-paced environment, supporting a client's mission to build an enterprise analytics platform using emerging technologies and agile methodologies."",""key_terms"":[{""term"":""Agile environment"",""explanation"":""A collaborative approach to project management that emphasizes flexibility, continuous improvement, and rapid delivery.""},{""term"":""Emerging technologies"",""explanation"":""New and innovative technologies that are still in the early stages of development and adoption, such as artificial intelligence, blockchain, or the Internet of Things.""},{""term"":""Business Intelligence tools"",""explanation"":""Software applications that help organizations analyze and visualize data to make better business decisions.""},{""term"":""Data science"",""explanation"":""A field that combines statistics, computer science, and domain expertise to extract insights and knowledge from data.""}],""skill_priorities"":{""must_have"":[""Bachelor's or master's degree in Computer Science, Mathematics, or STEM-related discipline"",""1+ years of experience working on Analytics and Business Intelligence focused initiatives"",""1+ years of experience using Python, R, or other languages to build statistical models or analyze data"",""1+ years of experience creating complex SQL queries and functions"",""Experience working with self-service business intelligence and data visualization tools""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building an enterprise analytics platform using emerging technologies?"",""example_answer"":""I would start by assessing the client's current data infrastructure and identifying areas for improvement. Then, I would design a scalable and flexible architecture that incorporates emerging technologies such as cloud-based data warehousing and machine learning. Finally, I would develop a roadmap for implementation and work closely with the client to ensure successful adoption.""},{""question"":""How do you stay current with new developments in data science and analytics?"",""example_answer"":""I regularly read industry publications and attend conferences to stay up-to-date on the latest trends and technologies. I also participate in online forums and communities to network with other professionals and learn from their experiences.""}],""red_flags"":[""Lack of experience working with government contracts or clearance requirements"",""Inability to work in a fast-paced, agile environment""],""confidence_score"":90.0}"
Data Analyst I,"Overview

Why GM Financial?

GM Financial is the wholly-owned captive finance subsidiary of General Motors and is headquartered in Fort Worth, U.S. We are a global provider of auto finance solutions, with operations in North America, South America, and the Asia Pacific region. Through our long-standing relationships with auto dealers, we offer attractive retail financing and lease programs to meet the needs of each customer. We also offer commercial lending products to dealers to help them finance and grow their businesses. At GM Financial, our team members define and shape our culture — an environment that welcomes new ideas, fosters integrity and creates a sense of community and belonging. Here we do more than work — we thrive.

Our Purpose: We pioneer the innovations that move and connect people to what matters

About The Role

The Data Analyst I is responsible for assisting in data collection, research, analysis, and presentation of trends and anomalies to support GM Financial audits, continuous business monitoring, and participation in corporate projects. This position will perform analyses and generate reports using advanced analytics tools to assist auditors in identify risks and control deficiencies. The Data Analyst I will work alongside Audit Data Analytics team members and auditors to develop and implement streamlined data analytics and decision-support solutions. This position will interact with other departments in the interest of achieving the overall company objectives.

Responsibilities

In this role you will:

Uses appropriate programming languages (Python, R, SQL, SAS) to develop reporting and data visualizations
Builds technical knowledge to support research and analytic responsibilities through independent learning
Maintains thorough understanding of relevant data sources and analytic tools
Document data analysis processes and methodologies to ensure clarity and reproducibility
Assists in developing data analytics to summarize results, assumptions, and conclusions for internal audit team members and audit clients
Support Continuous Audit in enhancing Continuous Business Monitoring by implementing effective processes, technologies, and strategies
Collaborates with Audit Data Analytic team members to provide recommendations on the appropriate application of analytics to enhance and expand the existing data analytics framework
Design and implement dashboards, reports, and visualizations to help the Internal Audit team identify risks and exceptions during audits
Ensures that the delivered products meet the auditors needs
Perform other duties as assigned
Conform with all company policies and procedures

Qualifications

What makes you a dream candidate?

Ability to wrangle large datasets, structured and non-structured data, including data mining and manipulation
Demonstrated understanding and experience with technical systems, datasets, data warehouses, data analysis techniques and data visualization
Knowledge of consumer auto lending / leasing portfolio preferred
Ability to design and implement process documentation and monitoring protocols, demonstrated understanding and experience with technical systems, relational and dimensional datasets, data warehouses, and data analysis techniques
Strong quantitative, analytical and data interpretation skills
Ability to summarize complex data into digestible information for management
Proficient in programming languages such as Python, SAS, R or similar preferred
Proficient in data visualization best practices and tools such as Power BI, Tableau, SAS Visual Analytics etc preferred
Ability to identify and seek needed information/research skills
Strong written and verbal presentation skills with an ability to communicate effectively with Management by making complex concepts easy to understand
Ability to be curious, ask questions, explore, and be creative when analyzing data and business problems
Ability to interact collaboratively with internal customers and external vendors
Capable of supporting multiple projects, including the ability to coordinate and balance numerous tasks in a time-sensitive environment, under pressure and meeting deadlines

Experience

Bachelor’s Degree in Economics, Mathematics, Business Analytics, Computer Science, Statistics or other quantitative field required
Master’s Degree in Economics, Mathematics, Business Analytics, Computer Science, Statistics or other quantitative field preferred
0-2 years of data mining and query tool experience preferred
0-2 years experience in auto finance preferred
0-2 years of experience in similar role preferred

What We Offer: Generous benefits package available on day one to include: 401K matching, bonding leave for new parents (12 weeks, 100% paid), tuition assistance, training, GM employee auto discount, community service pay and nine company holidays.

Our Culture: Our team members define and shape our culture — an environment that welcomes innovative ideas, fosters integrity, and creates a sense of community and belonging. Here we do more than work — we thrive.

Compensation: Competitive pay and bonus eligibility

Work Life Balance: Flexible hybrid work environment, 2-days a week in office","{""role_summary"":""Assist in data collection, research, analysis, and presentation of trends and anomalies to support GM Financial audits, continuous business monitoring, and participation in corporate projects."",""key_terms"":[{""term"":""Data Analytics"",""explanation"":""The process of examining data sets to draw conclusions and identify patterns and trends.""},{""term"":""Continuous Business Monitoring"",""explanation"":""An ongoing process of monitoring and reviewing business operations to identify areas for improvement and mitigate risks.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to communicate information more effectively.""},{""term"":""Audit Data Analytics"",""explanation"":""The use of data analytics techniques to support auditing processes and identify risks and control deficiencies.""}],""skill_priorities"":{""must_have"":[""Python"",""R"",""SQL"",""SAS"",""Data analysis techniques"",""Data visualization"",""Quantitative skills"",""Analytical skills"",""Data interpretation skills""],""nice_to_have"":[""Knowledge of consumer auto lending / leasing portfolio"",""Experience with Power BI, Tableau, SAS Visual Analytics"",""Master's Degree in Economics, Mathematics, Business Analytics, Computer Science, Statistics or other quantitative field""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a large dataset to identify trends and anomalies?"",""example_answer"":""I would first ensure that the data is clean and organized, then use tools such as Python or R to perform exploratory data analysis and identify patterns. I would also use data visualization techniques to communicate my findings effectively.""},{""question"":""How do you stay current with new developments in data analytics and visualization?"",""example_answer"":""I regularly read industry blogs and attend webinars to stay up-to-date with the latest tools and techniques. I also participate in online communities to learn from others and share my own knowledge.""}],""red_flags"":[""Lack of experience with data analysis and visualization tools"",""Inability to communicate complex data insights effectively"",""Limited experience in the auto finance industry""],""confidence_score"":90.0}"
People Data Analyst,"Ready to be pushed beyond what you think you’re capable of?

At Coinbase, our mission is to increase economic freedom in the world. It’s a massive, ambitious opportunity that demands the best of us, every day, as we build the emerging onchain platform — and with it, the future global financial system.

To achieve our mission, we’re seeking a very specific candidate. We want someone who is passionate about our mission and who believes in the power of crypto and blockchain technology to update the financial system. We want someone who is eager to leave their mark on the world, who relishes the pressure and privilege of working with high caliber colleagues, and who actively seeks feedback to keep leveling up. We want someone who will run towards, not away from, solving the company’s hardest problems.

Our work culture is intense and isn’t for everyone. But if you want to build the future alongside others who excel in their disciplines and expect the same from you, there’s no better place to be.
Data-backed decision making is core to Coinbase’s culture, and our People Analytics team strives to introduce data to inform, and ultimately drive, every people-related decision we make. We are looking for a People Data Analyst to realize this vision by building and enabling exceptional reporting on people data. , expanding the team’s We are looking for candidates who are builders: to define and build toward a best-in-class future, build our foundations (from the weeds to the clouds), and support in the scaling of our People Analytics practices for the next phase of Coinbase’s growth.

People Analytics works closely with our Executive Team, functional business leaders, and People leaders to ensure people data is accessible, valuable, and actionable. 

What you’ll be doing (ie. job duties): To be completed by all business teams except Eng.


Develop and maintain self-service reporting and analytics capabilities within Looker.

Respond to ad hoc report requests in support of BAU activities and special projects (e.g., executive dashboards)

Maintain and audit custom report and calculated field catalogs, ensuring cleanliness of dashboards across our Workday, Greenhouse, and Qualtrics datasets

Design, own, and deliver complex reporting and analysis solutions to provide rich insights on people challenges (e.g., performance, org health)

Collaborate with people leadership / teams to improve data quality and consistency within various HR platforms (especially Workday)

Maintain awareness of key HR platform feature releases/roadmap and the potential impact of those plans on current and future analytics functionality

Lead testing and analysis of new Looker reporting and analytics features

Manage cross-functional relationships with our partners in data engineering, data platform, and enterprise architecture

Provide excellent customer service in response to report requests and resolve requests accurately and in a timely manner


What we look for in you (ie. job requirements): To be completed by all business teams except Eng. 


Experience with various data analysis and visualization tools (Looker preferred)

Experience with Workday reporting

Proven expertise in building robust data models from complex data sources to generate insights

Experience interpreting and transforming business user requirements into dashboards to drive actionable insights

Hands-on experience querying with SQL 

Understanding of foundational statistical concepts and methods

Customer orientation and track record of delivering results against time tight timelines in a heavily XFN environment

Exterme attention to detail


Nice to haves:




Experience with other HR specific platforms and visualization tools (e.g., Qualtrics, Greenhouse, OneModel)




Job #: P68408
Pay Transparency Notice: Depending on your work location, the target annual salary for this position can range as detailed below. Full time offers from Coinbase also include target bonus + target equity + benefits (including medical, dental, vision and 401(k)).
Pay Range: : $130,900 USD - $154,000 USD
Please be advised that each candidate may submit a maximum of four applications within any 30-day period. We encourage you to carefully evaluate how your skills and interests align with Coinbase's roles before applying.

Commitment to Equal Opportunity
Coinbase is committed to diversity in its workforce and is proud to be an Equal Opportunity Employer.  All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, sex, gender expression or identity, sexual orientation or any other basis protected by applicable law. Coinbase will also consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state and local law.  For US applicants, you may view the Know Your Rights notice here.  Additionally, Coinbase participates in the E-Verify program in certain locations, as required by law. 

Coinbase is also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please contact us at accommodations[at]coinbase.com to let us know the nature of your request and your contact information.  For quick access to screen reading technology compatible with this site click here to download a free compatible screen reader (free step by step tutorial can be found here).

Global Data Privacy Notice for Job Candidates and Applicants
Depending on your location, the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. Our full notice outlining how data will be processed as part of the application procedure for applicable locations is available here. By submitting your application, you are agreeing to our use and processing of your data as required. For US applicants only, by submitting your application you are agreeing to arbitration of disputes as outlined here.    

 ","{""role_summary"":""The People Data Analyst will build and enable exceptional reporting on people data, working closely with the Executive Team, functional business leaders, and People leaders to ensure data-driven decision making."",""key_terms"":[{""term"":""Data-backed decision making"",""explanation"":""Using data to inform and drive business decisions.""},{""term"":""People Analytics"",""explanation"":""The practice of using data to analyze and improve people-related decisions within an organization.""},{""term"":""Looker"",""explanation"":""A data analytics and visualization tool used for reporting and analytics capabilities.""},{""term"":""Workday"",""explanation"":""A human capital management platform used for HR data and reporting.""}],""skill_priorities"":{""must_have"":[""Experience with data analysis and visualization tools (Looker preferred)"",""Experience with Workday reporting"",""Proven expertise in building robust data models from complex data sources"",""Hands-on experience querying with SQL"",""Understanding of foundational statistical concepts and methods""],""nice_to_have"":[""Experience with other HR specific platforms and visualization tools (e.g., Qualtrics, Greenhouse, OneModel)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with building robust data models from complex data sources?"",""example_answer"":""In my previous role, I worked on a project where I had to integrate data from multiple sources to create a comprehensive dashboard for HR leaders. I used SQL to query the data and built a data model that allowed for easy analysis and visualization.""},{""question"":""How do you ensure data quality and consistency within various HR platforms?"",""example_answer"":""I work closely with HR teams to understand their data needs and ensure that data is accurately and consistently reported across platforms. I also perform regular audits to identify and correct any data discrepancies.""}],""red_flags"":[""Lack of experience with data analysis and visualization tools"",""Inability to work in a fast-paced environment with tight timelines"",""Poor attention to detail""],""confidence_score"":90.0}"
Data Analyst III,"Overview

JOB DESCRIPTION

Fanatics Betting & Gaming is seeking a Senior Data Analyst to play a key role in optimizing and scaling our VIP program through data-driven insights. This position will focus on performance tracking, reporting, and ad-hoc analysis to drive strategic decision-making and enhance customer engagement. You will be responsible for building and maintaining Tableau dashboards, writing SQL queries, and leveraging automation and data engineering best practices to extract and analyze large datasets in a scalable fashion. Your insights will directly impact sales operations, customer reinvestment strategies, and VIP journey optimization, helping to create a seamless, high-value experience for our most engaged users.

Key Responsibilities

Build and maintain Tableau dashboards to visualize VIP program performance and key business metrics.
Develop SQL queries to extract, analyze, and manipulate large datasets, driving customer engagement insights.
Collaborate with data engineering teams to optimize pipelines and ensure data integrity and scalability.
Analyze sales operations, customer reinvestment trends, and engagement behaviors to inform VIP program strategy.
Develop predictive models to optimize customer segmentation, routing, and personalized VIP journeys.
Provide data-driven recommendations to improve customer relationships, maximize engagement, and enhance the VIP experience.
Automate reporting processes and streamline data workflows for efficiency and scalability.
Effectively communicate insights to commercial, marketing, operations, and executive leadership teams to drive strategic initiatives.

Experience & Skills

4+ years of experience in data analytics, business intelligence, or data engineering.
Advanced SQL proficiency, with experience handling large-scale datasets and optimizing queries.
Strong expertise in Tableau for dashboard development, visualization, and performance tracking.
Understanding of data engineering best practices, pipeline optimization, and automation.
Ability to think strategically and translate data into business insights and revenue-driving recommendations.
Experience with customer loyalty programs, engagement analytics, or VIP strategy is a plus.
Self-motivated, highly detail-oriented, and strong problem-solving mindset with the ability to work independently.
Excellent communication skills, with the ability to present data insights to both technical and non-technical stakeholders.

Salary range is listed in USD; ranges will change based on country and state of residence, which are reflected in Geographical Zones defined by Fanatics Betting and Gaming. *Salary Range: $130,000 to $160,000 (Salary range incorporates all of our Geographical Compensation Zones and is subject to change as the Zone associated with the actual Offer is confirmed). In addition to the base and bonus, full-time employees are eligible for Medical, Dental, Vision, 401K, paid time off, and other benefits like GymPass, Pet Insurance, Family Care Benefits, Free Shipt deliveries, and more. For information about our benefits, please visit https://benefitsatfanatics.com/

About Us

Fanatics is building a leading global digital sports platform. We ignite the passions of global sports fans and maximize the presence and reach for our hundreds of sports partners globally by offering products and services across Fanatics Commerce, Fanatics Collectibles, and Fanatics Betting & Gaming, allowing sports fans to Buy, Collect, and Bet. Through the Fanatics platform, sports fans can buy licensed fan gear, jerseys, lifestyle and streetwear products, headwear, and hardgoods; collect physical and digital trading cards, sports memorabilia, and other digital assets; and bet as the company builds its Sportsbook and iGaming platform. Fanatics has an established database of over 100 million global sports fans; a global partner network with approximately 900 sports properties, including major national and international professional sports leagues, players associations, teams, colleges, college conferences and retail partners, 2,500 athletes and celebrities, and 200 exclusive athletes; and over 2,000 retail locations, including its Lids retail stores. Our more than 22,000 employees are committed to relentlessly enhancing the fan experience and delighting sports fans globally.

About The Team

Launched in 2021, Fanatics Betting and Gaming is the online and retail sports betting subsidiary of Fanatics Holdings Inc., a global digital sports platform. The Fanatics Sportsbook is available to nearly 93% of the addressable online sports bettor market in the U.S. in the following states: Arizona, Colorado, Connecticut, Illinois, Indiana, Iowa, Kansas, Kentucky, Maryland, Massachusetts, Michigan, New Jersey, New York, North Carolina, Ohio, Pennsylvania, Tennessee, Vermont, Virginia, West Virginia and Wyoming. Fanatics Casino is currently available online in Michigan, New Jersey, Pennsylvania and West Virginia. Fanatics Betting and Gaming operates nineteen retail locations including retail sportsbooks outside of Progressive Field and Nationwide Arena and the only sportsbook inside an NFL stadium at Commanders Field. Fanatics Betting and Gaming is headquartered in New York with offices in Denver and Dublin, Ireland.","{""role_summary"":""A Senior Data Analyst responsible for optimizing and scaling the VIP program through data-driven insights, focusing on performance tracking, reporting, and ad-hoc analysis to drive strategic decision-making and enhance customer engagement."",""key_terms"":[{""term"":""Tableau"",""explanation"":""A data visualization tool used to build and maintain dashboards for performance tracking and key business metrics.""},{""term"":""SQL"",""explanation"":""A programming language used to extract, analyze, and manipulate large datasets for customer engagement insights.""},{""term"":""Data engineering"",""explanation"":""The process of designing, building, and maintaining the infrastructure for data storage, processing, and retrieval to ensure data integrity and scalability.""},{""term"":""VIP program"",""explanation"":""A loyalty program designed to provide a seamless, high-value experience for the most engaged users.""}],""skill_priorities"":{""must_have"":[""Advanced SQL proficiency"",""Strong expertise in Tableau"",""Understanding of data engineering best practices"",""Ability to think strategically and translate data into business insights""],""nice_to_have"":[""Experience with customer loyalty programs, engagement analytics, or VIP strategy""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize a Tableau dashboard for better performance tracking and key business metrics?"",""example_answer"":""I would use data visualization best practices, such as using aggregations and filters, to reduce the amount of data being processed and improve dashboard performance. I would also consider using data storytelling techniques to make the insights more actionable and easy to understand.""},{""question"":""Can you explain how you would approach building a predictive model to optimize customer segmentation and routing for a VIP program?"",""example_answer"":""I would start by analyzing customer behavior and transactional data to identify key segments and trends. Then, I would use machine learning algorithms to build a predictive model that can identify high-value customers and recommend personalized offers and experiences. Finally, I would validate the model using A/B testing and iterate on the results to improve its accuracy and effectiveness.""}],""red_flags"":[""Lack of experience with large-scale datasets and optimizing SQL queries"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Customer Data Analyst,"Position Summary:
The Customer Data Analyst will partner closely with the product team to optimize the learner experience and journey through testing, monitoring, and innovation. The primary measures of success for this role are improvements to learner persistence, progression and satisfaction. This analyst will join a highly skilled team focused on building Penn Foster’s next-generation analytics platform centered on learner needs.

Essential Job Functions:
Build and maintain analytics tools to continuously monitor and improve learner persistence
Advance the goal of ‘democratizing data’ by developing intuitive data visualizations and models that provide insights into learner experience
Perform A/B and multivariate tests for product course revisions and optimizations
Develop and test new features informed by learner research, feedback, and behavior data to enhance the learner journey
Summarize and present recommendations to optimize learner success based on customer research, product data and insights
Ensure integrity and accuracy of all analytics data by continually assessing and enhancing data quality

Knowledge, Skills, Abilities:
Undergraduate degree in business, data science or analytics
2+ years of experience in analytics roles optimizing digital products
Curiosity and problem-solving skills to uncover insights from user data
High-energy, collaborative, creative, and strategic
Strong communication skills
Experience with A/B Testing and statistical analysis
Technical Skills:
Proven experience using SQL or Python to pull and organize data from large databases
Proficient in Tableau or other data visualization tools

About Us: At Penn Foster Group, we are transforming online learning to help learners by bringing together Penn Foster, CareerStep, Ashworth College, James Madison High School, the New York Institute of Photography, the New York Institute of Art and Design, and other education platforms. Together, we create an accelerated path to greater economic mobility through real-world skills and knowledge that enable learners to achieve long-term success in the workplaces of the future. Our history dates back to 1890 when our founder, Thomas Foster, pioneered distance education by offering training by mail for coal miners to get the necessary skills for safer jobs. Today, with the partners who use our education and training programs, we continue that mission of providing accessible training and education for in-demand skills and are building a workforce that’s prepared for the future job market.

Equal Employment Opportunity: We strive toward Diversity, Equity, and Inclusion at Penn Foster Group by intentionally building diverse teams – in identities, lived experiences, and ideas to create a culture where people feel connected to each other and have a sense of belonging. We value diversity, equity, and inclusion because it is the foundation that enables us to achieve what we set out to do as an organization – from maximizing the number of learners who can reach their goals while giving them the kinds of experiences we want them to have, to becoming the type of company we want to work in.

What We Offer: We offer a robust benefits package that includes medical, dental, vision, flexible spending, generous paid time off, sponsored volunteer opportunities, a 401K with a company match, and free access to our online programs.

This position is fully remote in AL, AZ, CO, CT, DC, FL, GA, IA, ID, IL, IN, KS, KY, LA, MA, MD, MI, MN, MO, NC, NE, NH, NJ, NY, OH, OK, PA, SC, TN, TX, UT, VA, WA, WI only.","{""role_summary"":""The Customer Data Analyst will partner with the product team to optimize the learner experience and journey through testing, monitoring, and innovation, focusing on improving learner persistence, progression, and satisfaction."",""key_terms"":[{""term"":""A/B Testing"",""explanation"":""A method of comparing two or more versions of a product to determine which one performs better.""},{""term"":""Multivariate Testing"",""explanation"":""A method of testing multiple variables in a product to determine which combination performs better.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to help people understand and analyze it.""},{""term"":""SQL"",""explanation"":""A programming language used to manage and analyze data in relational databases.""},{""term"":""Python"",""explanation"":""A programming language used for data analysis, machine learning, and automation.""},{""term"":""Tableau"",""explanation"":""A data visualization tool used to create interactive dashboards and reports.""}],""skill_priorities"":{""must_have"":[""Experience with A/B Testing and statistical analysis"",""Proven experience using SQL or Python to pull and organize data from large databases"",""Proficient in Tableau or other data visualization tools""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach A/B testing for a new product feature?"",""example_answer"":""I would start by defining the goal of the test, then identify the variables to test, and finally analyze the results to determine which version performs better. I would also consider factors like sample size and statistical significance to ensure the results are reliable.""},{""question"":""How do you ensure data quality in your analytics work?"",""example_answer"":""I regularly assess and enhance data quality by checking for errors, inconsistencies, and outliers. I also implement data validation rules and perform data profiling to ensure data accuracy and completeness.""}],""red_flags"":[""Lack of experience with A/B testing and statistical analysis"",""Inability to work with large datasets"",""Poor communication skills""],""confidence_score"":90.0}"
Business Intelligence Specialist,"BI Developer (CRM Analytics & Power BI)
100% Remote
1 year contract (CDW Direct)
CDW is seeking a talented BI Developer with experience in CRM Analytics (formerly Tableau CRM) and Power BI to join our Data & Analytics team. In this role, you will develop, maintain, and optimize data visualizations and reports, leveraging both Salesforce-native CRM Analytics and Power BI platforms. You will work closely with business stakeholders to translate complex data into actionable insights and empower data-driven decision-making across the organization.

Key Responsibilities:
CRM Analytics (CRMA) Development:
Design, develop, and optimize data visualizations and dashboards using CRM Analytics (Tableau CRM).
Work with Salesforce data to create actionable insights that drive business outcomes.
Customize and enhance CRM Analytics features to meet evolving business needs.
Power BI Development:
Create and manage Power BI reports and dashboards, ensuring consistency with business objectives and KPIs.
Integrate Power BI with various data sources for comprehensive analysis.
Optimize Power BI performance and implement best practices for data modeling and visualization.
Data Integration & Transformation:
Collaborate with data engineers and IT teams to ensure proper data integration across systems.
Ensure data accuracy, consistency, and reliability across all reporting platforms.
Design and implement ETL processes to feed data into CRM Analytics and Power BI.
Stakeholder Collaboration:
Work closely with business units to understand requirements and translate them into effective visualizations.
Provide training and support to end-users for both CRM Analytics and Power BI tools.
Assist in the development of ad-hoc reports and dashboards as needed.
Continuous Improvement:
Stay updated with new features and best practices for both CRM Analytics and Power BI.
Recommend and implement improvements to reporting processes, dashboard design, and data flows.
Monitor and troubleshoot dashboard/reporting performance issues.

Qualifications:
Experience:
3+ years of experience as a BI Developer or Data Analyst with strong expertise in CRM Analytics (formerly Tableau CRM) and Power BI.
Proven experience working with Salesforce data and reporting tools.
Strong understanding of data modeling, ETL processes, and BI best practices.
Skills & Competencies:
Expertise in CRM Analytics (Tableau CRM) for Salesforce, including dashboard creation, custom queries, and app development.
Advanced knowledge of Power BI, including data modeling, DAX, and report/dashboard development.
Strong SQL skills and experience with data integration from multiple sources.
Excellent problem-solving and analytical skills with a focus on business insights.
Strong communication and collaboration skills to work with business stakeholders.

If you're passionate about leveraging CRM Analytics and Power BI to drive business insights and empower data-driven decision-making, we'd love to hear from you!","{""role_summary"":""Develop and maintain data visualizations and reports using CRM Analytics and Power BI, working closely with stakeholders to drive business insights and decision-making."",""key_terms"":[{""term"":""CRM Analytics"",""explanation"":""A Salesforce-native platform for data visualization and reporting.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft for data visualization and business intelligence.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""DAX"",""explanation"":""Data Analysis Expressions - a formula language used in Power BI for data modeling and calculations.""}],""skill_priorities"":{""must_have"":[""CRM Analytics (Tableau CRM)"",""Power BI"",""SQL"",""Data modeling"",""ETL processes"",""BI best practices""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data visualization and reporting in CRM Analytics and Power BI?"",""example_answer"":""I use best practices for data modeling and visualization, and leverage features like custom queries and app development in CRM Analytics, and data modeling and DAX in Power BI.""},{""question"":""Can you explain how you would integrate Power BI with various data sources for comprehensive analysis?"",""example_answer"":""I would use Power BI's data integration capabilities to connect to multiple sources, and then use data modeling and DAX to create a unified view of the data.""}],""red_flags"":[""Lack of experience with CRM Analytics and Power BI"",""Inability to work closely with business stakeholders""],""confidence_score"":90.0}"
Data Analyst (various levels open),"About the Job
[VVIP HRCap Clients] Start-ups, PEs, JVs, Global SMBs, Fortune 500s
[Industries] AI, Automotive, Beauty, Consumer Electronics, Cosmetics, Construction, E-Commerce, Energy, EV, Fashion, Financial Services, Healthcare, Investment, Manufacturing, Technology, and more.
[Location] CA, TX, MI, IL, GA, NJ, NY, PA, CT, and more (remote included)


Role Description
Our clients are seeking Data Analysts (various levels open depending on experience and relevant skills) to join their U.S. teams.

The ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users.


Responsibilities
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and mine data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Compile and analyze data specifically related to business' issues
Develop clear visualizations to convey complicated data in a straightforward fashion


Qualifications
Bachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience
Relevant Data Analysis experience
Proficient in SQL


===

About us
HRCap, Inc. is a Top 10 Executive Search & HR Consulting Company and the largest Global Asian American Search Firm in the world. Established in 2000, we partner with over 1500 VIP client organizations ranging across Fortune 500s, global medium-sized businesses, PE firms, venture capitals, and tech start-ups across all industries and operate globally with a focus in North America, Europe, and APAC regions. We offer customized workforce strategies, executive search, technical recruiting, succession planning, HR training & development, and executive coaching for effective globalization and localization. We are trusted HR advisors, strategic business partners, and cultural ambassadors to our clients, candidates, and community. www.hrcap.com","{""role_summary"":""The Data Analyst role involves using big data and analytics to provide insights to the business, conducting recurring and ad-hoc analysis, and developing clear visualizations to convey complex data."",""key_terms"":[{""term"":""Big Data"",""explanation"":""Large and complex sets of data that require specialized analysis and processing.""},{""term"":""Ad-hoc Analysis"",""explanation"":""Flexible and dynamic analysis of data to answer specific business questions or solve problems.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing relational databases.""}],""skill_priorities"":{""must_have"":[""SQL"",""Data Analysis experience"",""Bachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to analyze a complex data set to identify trends or patterns?"",""example_answer"":""In my previous role, I was tasked with analyzing customer purchase data to identify trends and opportunities for growth. I used SQL to extract the data, and then applied statistical techniques to identify correlations and patterns. I presented my findings to the business stakeholders, and they were able to use the insights to inform their marketing strategy.""},{""question"":""How do you ensure the accuracy and quality of your data analysis?"",""example_answer"":""I always verify the data sources and ensure that the data is clean and consistent before conducting any analysis. I also use data visualization tools to identify any outliers or anomalies, and I validate my findings by cross-checking with other data sources.""}],""red_flags"":[""Lack of experience with SQL or data analysis"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
"Data Analyst, Sr","Company

Qualcomm Technologies, Inc.

Job Area

Miscellaneous Group, Miscellaneous Group > Data Analyst

General Summary

General Summary The Master Data Analyst is responsible for developing processes, governance, policies, standards, and tools to consistently define and manage critical business data. This role ensures a single point of reference across all systems, streamlining data sharing among business functions, and linking records across systems. The objective is to harmonize data elements to provide quality and high-integrity data from a trusted single version of truth for decision-making.

Data Management

Principal Duties & Responsibilities

Manage product data by developing the ability and knowledge of creating and changing Oracle ERP master data in areas such as Item Master, BOMs, Routes, Sourcing, Attributes, and other required areas as defined through documented processes.
Identify data discrepancies, communicate with business partners, research discrepancies, and facilitate/coordinate resolution.
Ensure data accuracy to enable appropriate supply, demand, and capacity planning.
Understand how to gather, interpret, and interact with large and complicated datasets.
Collaborate and share knowledge with stakeholders to integrate information and drive better-informed data decision-making.
Perform manufacturing cost roll-ups to support PO placement, inventory transactions, WIP visibility, supplier and DC shipments to customers, quarterly re-quoting process, financial reconciliations, and inventory valuation.
Knowledge of B2B Messaging and Shop Floor Manufacturing with an understanding of data elements that impact these functions.
Maintain and monitor supplier attribute data to ensure accurate lot genealogy and traceability for quality control and customer-specific requirements.


Project Support/Identification Of Process Improvements

Participate in solution design and architect master data-related solutions for setup and data collection requirements.
Provide data for testing in IT Test Environments and participate in project readiness from POC to go-live.
Expected tasks include specification and IT case creation, script testing, and internal training, cross-functional collaboration, and documentation.
Act as an SME to assist in troubleshooting and performing corrective actions to support cross-functional teams throughout the organization.
Develop a working knowledge of multiple business processes and work as a system liaison for problem resolutions.
Understand upstream source of truth systems, such as PLM, Cognos, Program Management databases, to provide feedback and expertise on how they impact Oracle ERP data elements.
Be knowledgeable of key data elements from ERP to other downstream systems such as Rapid Response, Price Management, Salesforce, Model-N, Salesforce, and custom business systems, including knowledge of data hierarchies, data attributes, and data formats.
Develop ad hoc and weekly reporting using ETL processes in systems such as SharePoint, Business Objects, Tableau, Oracle, QlikView, and SharePoint.
Knowledge in New Product Introduction, Engineering Change Order approvals and implementation, Data Mining, and Lifecycle Management from Engineering to Obsolescence.


Required Competencies

IT Core Competencies no standard job description text

2+Years and experience dealing with data analysis, integrity, and reporting with a Bachelor's degree in Business, Supply Chain, Engineering and/or Operations.
Knowledge of manufacturing and Supply Chain and Operations procedures


Additional Competencies

Knowledge in Oracle ERP, Agile, SharePoint, Power Apps and BI tools such as Business Objects, Power BI and Tableau.
Semiconductor industry experience a plus
Self-motivated team contributor with the ability to work on multiple projects simultaneously.
Strong communications, interpersonal and organizational skills in a team environment
Ability to clearly convey technical and non-technical concepts to a wide audience to drive resolution/decisions.
Ability to work with minimal direction and supervision
Detail oriented and highly organized with a high skill level in time management, multi-tasking, and task prioritization.
Capability to provide data driven decisions and solutions.
Creative thinker with a flair for problem solving and out of the box ideas


Minimum Qualifications No Standard Job Description Text

Applicants: Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com or call Qualcomm's toll-free number found here. Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries).

To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications.

EEO Employer: Qualcomm is an equal opportunity employer; all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or any other protected classification.

Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law.

Pay Range And Other Compensation & Benefits

$100,800.00 - $151,200.00

The above pay scale reflects the broad, minimum to maximum, pay scale for this job code for the location for which it has been posted. Even more importantly, please note that salary is only one component of total compensation at Qualcomm. We also offer a competitive annual discretionary bonus program and opportunity for annual RSU grants (employees on sales-incentive plans are not eligible for our annual bonus). In addition, our highly competitive benefits package is designed to support your success at work, at home, and at play. Your recruiter will be happy to discuss all that Qualcomm has to offer – and you can review more details about our US benefits at this link.

If you would like more information about this role, please contact Qualcomm Careers.

3072456","{""role_summary"":""The Master Data Analyst is responsible for developing processes, governance, policies, standards, and tools to consistently define and manage critical business data, ensuring a single point of reference across all systems."",""key_terms"":[{""term"":""Oracle ERP"",""explanation"":""Enterprise Resource Planning system used for managing business operations and data.""},{""term"":""BOMs"",""explanation"":""Bills of Materials, a document used to specify the components and materials required to manufacture a product.""},{""term"":""ETL processes"",""explanation"":""Extract, Transform, Load processes used for data integration and migration.""},{""term"":""PLM"",""explanation"":""Product Lifecycle Management system used for managing product data and processes.""},{""term"":""Cognos"",""explanation"":""Business intelligence and analytics software used for reporting and data analysis.""}],""skill_priorities"":{""must_have"":[""Data analysis and reporting"",""Oracle ERP"",""Manufacturing and Supply Chain knowledge"",""Business, Supply Chain, Engineering and/or Operations degree""],""nice_to_have"":[""Agile"",""SharePoint"",""Power Apps"",""BI tools such as Business Objects, Power BI and Tableau"",""Semiconductor industry experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data accuracy and integrity in a complex dataset?"",""example_answer"":""I use data validation rules and data profiling techniques to identify and correct errors, and also collaborate with stakeholders to ensure data consistency across systems.""},{""question"":""Can you explain how you would approach data integration and migration using ETL processes?"",""example_answer"":""I would first identify the data sources and targets, then design and develop the ETL process using tools such as Oracle ERP and SharePoint, and finally test and validate the data migration.""}],""red_flags"":[""Lack of experience with Oracle ERP and manufacturing data management"",""Inability to work with complex datasets and perform data analysis"",""Poor communication and interpersonal skills""],""confidence_score"":90.0}"
Data Analyst - US004,"SMASH, Who we are?

We believe in long-lasting relationships with our talent. We invest time in getting to know them and understanding what they seek as their next professional step.
We aim to find the perfect match. As agents, we pair our talent with our US clients, not only by their technical skills but as a cultural fit. Our core competency is to find the right talent fast.

The Role

We are seeking a Data Analyst who will help support the financial operations. Success in this role hinges on your technical aptitude, quantitative abilities, and business acumen: you know how to plow through data with SQL and other analysis tools such as Excel.

What you’ll do:

Help monthly billing by running queries and ensuring completion.
Review and modify billing and other queries for the financial team.
Build SQL queries or Python code to automate financial process.
Provide support with audits, data validation and other system related needs.
Help investigate billing, reconciliation, and other system related issues needed to support the finance function.

What you’ll need:

1-2 years’ experience in an analytics position or equivalent
Experience with Excel
Proficient with SQL
Ability to meet deliverables under tight deadlines
Ability to work independently, and a strong sense of ownership
Proven experience analyzing, interpreting, and summarizing complex data (ideally related to financial services)
Ability to work in a dynamic, cross-functional environment, with a strong attention to detail
Effective communication and presentation skills and ability to explain complex analyses in simple terms to stakeholders
Strong relationship building and collaborative skills
Exceptional problem-solving skills

Nice to Have:

Experience with Python
VBA
BA/BS Degree required","{""role_summary"":""Support financial operations by analyzing data, building queries, and automating financial processes to ensure accurate billing and reconciliation."",""key_terms"":[{""term"":""SQL"",""explanation"":""A programming language used to manage and analyze data in relational database management systems.""},{""term"":""Python"",""explanation"":""A high-level programming language used for data analysis, automation, and other tasks.""},{""term"":""VBA"",""explanation"":""Visual Basic for Applications, a programming language used to create and automate tasks in Microsoft Office applications.""}],""skill_priorities"":{""must_have"":[""Excel"",""SQL"",""Data analysis"",""Problem-solving"",""Communication"",""Collaboration""],""nice_to_have"":[""Python"",""VBA"",""BA/BS Degree""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize a slow-performing SQL query?"",""example_answer"":""I would analyze the query to identify the bottleneck, then apply indexing, rewriting the query, or optimizing the database structure to improve performance.""},{""question"":""How do you ensure data accuracy and integrity in your analysis?"",""example_answer"":""I use data validation techniques, such as data profiling and data quality checks, to ensure accuracy and integrity. I also document my process and results to maintain transparency.""}],""red_flags"":[""Lack of experience with SQL or data analysis"",""Inability to work independently or meet deadlines"",""Poor communication or collaboration skills""],""confidence_score"":90.0}"
Data/BI Analyst,"Job Description

We are seeking a skilled and detail-oriented Power BI Analyst to join our dynamic team. The ideal candidate will be responsible for designing, developing, and maintaining reports and dashboards using Microsoft Power BI. This role involves transforming raw data into meaningful insights through interactive and user-friendly dashboards and reports.

*This is a hybrid role: 3 days/week in office*

Data Analysis: Proficiency in analyzing complex data sets to derive actionable insights.
Technical Proficiency: Expertise in Power BI, SQL and/or Snowflake, DAX (Data Analysis Expressions).
Data Modeling: Ability to create and manage data models, including relationships, hierarchies, and calculated columns.
ETL Processes: Experience with Extract, Transform, Load (ETL) processes to integrate data from various sources.
Data Visualization: Skills in designing and developing interactive and visually compelling reports and dashboards.
Problem-Solving: Strong analytical and problem-solving abilities to address business challenges.
Communication: Excellent verbal and written communication skills to present data findings clearly to stakeholders.
Business Acumen: Understanding of business operations and the ability to translate data insights into business strategies.





Requirements:

Minimum of 4+ years using PowerBI or Tableau
Experience with R or Python programming is a huge plus
Experience in the following:
Data Collection and Preparation: Extracting, cleaning, and transforming data from various sources to ensure it's ready for analysis.
Report and Dashboard Development: Designing and creating interactive reports and dashboards using Power BI.
Data Modeling: Developing and maintaining complex data models to support business analysis.
Performance Optimization: Optimizing the performance of reports and dashboards by improving data queries and model efficiency.
Data Analysis: Performing advanced data analysis using DAX functions to create calculated measures and solve business problems.
Collaboration: Working closely with business analysts, stakeholders, and end-users to gather and refine requirements for reports and dashboards.
Data Governance: Implementing data governance practices, including data access controls and ensuring data quality and integrity.
Documentation: Maintaining documentation for reports, data sources, and data transformation processes.





Your benefits at Sage:

Comprehensive health, dental, and vision coverage
401(k) retirement match (100% matching up to 4%)
21 days paid time off (+1 floating holiday)
5 days paid yearly to volunteer (through Sage Foundation)
Sage Wellness Rewards Program (flexible ways to use wellness credit and fitness reimbursement)
A library of on-demand career development options and ongoing training offerings





Dig deeper about who we are:

Who is Sage: https://www.sage.com/en-us/company/about-sage/

Life at Sage: https://www.sage.com/en-us/company/careers/

Our Values & Behaviors: https://www.youtube.com/watch?app=desktop&v=vt5JXf-Gwno&feature=youtu.be

How we make a difference: https://www.sage.com/en-us/company/sage-foundation/

Sage Business Cloud - SaaS for Every Business: https://www.sage.com/en-us/products/","{""role_summary"":""Design, develop, and maintain reports and dashboards using Microsoft Power BI, transforming raw data into meaningful insights for business stakeholders."",""key_terms"":[{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""DAX"",""explanation"":""Data Analysis Expressions, a formula language used in Power BI to create calculated columns and measures.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load, a process used to integrate data from various sources into a single platform.""},{""term"":""SQL"",""explanation"":""Structured Query Language, a programming language used for managing and analyzing relational databases.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform that allows users to store and analyze large amounts of data.""}],""skill_priorities"":{""must_have"":[""Power BI"",""SQL"",""DAX"",""Data Analysis"",""Data Modeling"",""ETL Processes"",""Data Visualization"",""Problem-Solving"",""Communication""],""nice_to_have"":[""R or Python programming"",""Tableau""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize the performance of a slow-performing Power BI report?"",""example_answer"":""I would first identify the bottleneck by analyzing the report's data model and query structure. Then, I would apply optimization techniques such as reducing data granularity, using aggregation tables, and optimizing DAX formulas to improve performance.""},{""question"":""How do you ensure data quality and integrity in your reports and dashboards?"",""example_answer"":""I implement data governance practices such as data access controls, data validation, and data cleansing to ensure data accuracy and consistency. I also maintain documentation for reports, data sources, and data transformation processes.""}],""red_flags"":[""Lack of experience with Power BI or similar business intelligence tools"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":95.0}"
Analista de Datos - Mercado Pago,"En Mercado Libre estamos democratizando el comercio y los servicios financieros para transformar la vida de las personas de América Latina. ¡Súmate a este propósito!

En el área de Risk & Compliance desarrollamos acciones para fortalecer la confianza de nuestros stakeholders. Desafiamos enfoques tradicionales mediante soluciones innovadoras y promovemos una cultura de excelencia y cumplimiento de las normas.
Nuestro equipo interdisciplinario trabaja #CodoACodo en la gestión integral de riesgos y compliance, y en el desarrollo de la resiliencia de nuestro negocio, cuidando a nuestro ecosistema emprendedor en cada uno de los países en los que estamos presentes.

Tenemos un desafío para quienes:

Vibran energía emprendedora: se mueven por la curiosidad, nunca se rinden y se enfocan en superar sus propios límites.
Dan el máximo porque les gusta trabajar con compromiso y dedicación.
Viven los cambios como oportunidades y aprenden de sus errores.
La excelencia y la ejecución son claves en su forma de hacer las cosas.
Promueven el buen clima, aportan alegría y diversión.
Saben cómo construir con otras personas y disfrutan trabajando en equipo.

Imagínate emprendiendo proyectos desafiantes, dinámicos e innovadores y siendo responsable de:

Desarrollar e implementar modelos analíticos para detectar patrones de lavado de dinero y financiamiento del terrorismo.
Realizar análisis de datos para identificar transacciones sospechosas y tendencias emergentes.
Investigar alertas generadas por los sistemas de monitoreo, determinando la naturaleza de la actividad.
Realizar pruebas de desempeño al ecosistema de controles de monitoreo transaccional, para identificar oportunidades de mejora, creación de nuevos controles, entre otros.
Brindar soporte al equipo de monitoreo con procesos de ETL.
Implementar automatizaciones que permitan mejorar la eficiencia de los procesos actuales.

Requisitos:
Ser profesional de Matemáticas, Estadística, Economía, Ciencias de la Computación o un campo relacionado.
Contar con 3 años de experiencia en análisis de datos en el sector financiero.
Tener experiencia en el uso de herramientas SQL, Python o R.
Capacidad para trabajar con grandes conjuntos de datos y extraer información relevante.
Tener algún conocimiento en PLD.

Te proponemos:

Ser parte de una compañía con espíritu emprendedor en la que nos encanta pensar en grande y a largo plazo.
Ser protagonista de tu desarrollo en un ambiente de oportunidades, aprendizaje, crecimiento, expansión y proyectos desafiantes.
Compartir y aprender en equipo junto a grandes profesionales y especialistas.
Un excelente clima de trabajo, con todo lo necesario para que vivas una gran experiencia. :)","{""role_summary"":""Develop and implement analytical models to detect money laundering and terrorism financing patterns, perform data analysis to identify suspicious transactions and emerging trends, and investigate alerts generated by monitoring systems."",""key_terms"":[{""term"":""Lavado de dinero"",""explanation"":""Money laundering, the criminal process of concealing the source of illegally obtained funds to make them appear legitimate.""},{""term"":""Financiamiento del terrorismo"",""explanation"":""Terrorism financing, the provision or collection of funds to support terrorist activities.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load, a process used to extract data from multiple sources, transform it into a standardized format, and load it into a target system for analysis.""},{""term"":""PLD"",""explanation"":""Probably referring to 'Prevención de Lavado de Dinero' (Money Laundering Prevention), a set of regulations and guidelines to prevent money laundering.""}],""skill_priorities"":{""must_have"":[""Data analysis"",""SQL"",""Python or R"",""Experience in the financial sector""],""nice_to_have"":[""Knowledge of PLD""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would develop an analytical model to detect money laundering patterns?"",""example_answer"":""I would start by collecting and preprocessing relevant data, then use machine learning algorithms to identify patterns and anomalies. I would also consider implementing a risk-based approach to prioritize transactions for further investigation.""},{""question"":""How do you stay up-to-date with emerging trends and suspicious transaction patterns in the financial sector?"",""example_answer"":""I regularly review industry reports and publications, attend webinars and conferences, and participate in online forums to stay informed about the latest developments and best practices in anti-money laundering and counter-terrorism financing.""}],""red_flags"":[""Lack of experience in data analysis in the financial sector"",""Inability to work with large datasets"",""No knowledge of SQL, Python, or R""],""confidence_score"":90.0}"
Data Analyst - Remote,"Join us in pioneering breakthroughs in healthcare. For everyone. Everywhere. Sustainably.

Our inspiring and caring environment forms a global community that celebrates diversity and individuality. We encourage you to step beyond your comfort zone, offering resources and flexibility to foster your professional and personal growth, all while valuing your unique contributions.

Conducts analyses of data using various methods and tools to extract information as basis for decision making.

As a Data Analyst you will be a foundational member in the creation of analytics that power our Service Operations. You will work cross-functionally with established analysts and developers within DX Global and SHS. This role requires you to work closely with leadership teams to understand and implement solutions.

Responsibilities

This role is well suited to an ambitious professional, looking for the next step in their career. As a Data Analyst your responsibilities include:

Researches, analyzes, consolidates and interprets data using statistical and data analytics methods to create information on business-relevant topics, e.g. market environment, operational process and equipment performance etc.
Acquires data from primary or secondary data sources and maintain databases/data systems.
Operates and optimizes pre-defined tools, applications and data bases/data management systems.
Creates reports and communicates results to various internal and/or external stakeholders (e.g. management, customers).

This position may suit you best if you are familiar with:

Python
Snowflake
Qlik
Power BI
Genesys Cloud, SAP, PEAK

Required skills to have for the success of this role

Exceptional Communication skills to support collaboration with our internal partners
Proficiency with programming languages such as Python
Ability to grow strong working relationships
Comfortable with flexible work environments and changing priorities
Strong Time and Priority management ability

The pay range for this position is $86,700 - $100,000 annually; however, base pay offered may vary depending on job-related knowledge, skills, and experience. The annual incentive target is 8% of base pay. Siemens Healthineers offers a variety of health and wellness benefits including paid time off and holiday pay. Details regarding our benefits can be found here: https://benefitsatshs.com/index.html. This information is provided per the required state Equal Pay Act. Base pay information is based on market location. Applicants should apply via Siemens Healthineers external or internal careers site.

Who we are: We are a team of more than 73,000 highly dedicated Healthineers in more than 70 countries. As a leader in medical technology, we constantly push the boundaries to create better outcomes and experiences for patients, no matter where they live or what health issues they are facing. Our portfolio is crucial for clinical decision-making and treatment pathways.

How we work: When you join Siemens Healthineers, you become one in a global team of scientists, clinicians, developers, researchers, professionals, and skilled specialists, who believe in each individual’s potential to contribute with diverse ideas. We are from different backgrounds, cultures, religions, political and/or sexual orientations, and work together, to fight the world’s most threatening diseases and enable access to care, united by one purpose: to pioneer breakthroughs in healthcare. For everyone. Everywhere. Sustainably.

To find out more about Siemens Healthineers businesses, please visit our company page here.

Siemens Healthineers offers a variety of health and wellness benefits to employees. Details regarding our benefits can be found here.

Equal Employment Opportunity Statement: Siemens Healthineers is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law: Applicants and employees are protected under Federal law from discrimination. To learn more, click here.

Reasonable Accommodations: Siemens Healthineers is committed to equal employment opportunity. As part of this commitment, we will ensure that persons with disabilities are provided reasonable accommodations.

If you require a reasonable accommodation in completing a job application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please fill out the accommodations form here. If you’re unable to complete the form, you can reach out to our HR People Connect People Contact Center for support at peopleconnectvendorsnam.func@siemens-healthineers.com. Please note HR People Connect People Contact Center will not have visibility of your application or interview status.

Pay Transparency Non-Discrimination Provision: Siemens Healthineers follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, click here.

California Privacy Notice: California residents have the right to receive additional notices about their personal information. To learn more, click here.

Export Control: “A successful candidate must be able to work with controlled technology in accordance with US export control law.” “It is Siemens Healthineers’ policy to comply fully and completely with all United States export control laws and regulations, including those implemented by the Department of Commerce through the Export Administration Regulations (EAR), by the Department of State through the International Traffic in Arms Regulations (ITAR), and by the Treasury Department through the Office of Foreign Assets Control (OFAC) sanctions regulations.”

Data Privacy: We care about your data privacy and take compliance with GDPR as well as other data protection legislation seriously. For this reason, we ask you not to send us your CV or resume by email. We ask instead that you create a profile in our talent community where you can upload your CV. Setting up a profile lets us know you are interested in career opportunities with us and makes it easy for us to send you an alert when relevant positions become open. Register here to get started.

Beware of Job Scams: Please beware of potentially fraudulent job postings or suspicious recruiting activity by persons that are currently posing as Siemens Healthineers recruiters/employees. These scammers may attempt to collect your confidential personal or financial information. If you are concerned that an offer of employment with Siemens Healthineers might be a scam or that the recruiter is not legitimate, please verify by searching for the posting on the Siemens Healthineers career site.

To all recruitment agencies: Siemens Healthineers does not accept agency resumes. Please do not forward resumes to our jobs alias, employees, or any other company location. Siemens Healthineers is not responsible for any fees related to unsolicited resumes.","{""role_summary"":""A Data Analyst responsible for conducting analyses of data to extract information for decision making, working cross-functionally with teams to implement solutions, and creating reports to communicate results to stakeholders."",""key_terms"":[{""term"":""Data Analytics"",""explanation"":""The process of extracting insights from data to inform business decisions.""},{""term"":""Python"",""explanation"":""A programming language used for data analysis and automation.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and processing large datasets.""},{""term"":""Qlik"",""explanation"":""A business intelligence software for data visualization and analytics.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft for data visualization and business intelligence.""},{""term"":""Genesys Cloud"",""explanation"":""A cloud-based customer experience platform for managing customer interactions.""},{""term"":""SAP"",""explanation"":""An enterprise resource planning software for managing business operations and customer relations.""},{""term"":""PEAK"",""explanation"":""A data management system for storing and processing large datasets.""}],""skill_priorities"":{""must_have"":[""Python"",""Exceptional Communication skills"",""Proficiency with programming languages"",""Ability to grow strong working relationships"",""Comfortable with flexible work environments and changing priorities"",""Strong Time and Priority management ability""],""nice_to_have"":[""Snowflake"",""Qlik"",""Power BI"",""Genesys Cloud"",""SAP"",""PEAK""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to analyze a complex dataset to inform a business decision?"",""example_answer"":""In my previous role, I analyzed customer purchase data to identify trends and recommend marketing strategies to increase sales. I used Python and Power BI to create visualizations and present my findings to the marketing team, resulting in a 20% increase in sales.""},{""question"":""How do you stay organized and manage competing priorities in a fast-paced work environment?"",""example_answer"":""I use project management tools like Trello and Asana to prioritize tasks and track progress. I also communicate regularly with my team and stakeholders to ensure everyone is aligned on goals and deadlines.""}],""red_flags"":[""Lack of experience with data analytics tools and programming languages"",""Poor communication skills"",""Inability to work in a fast-paced environment with changing priorities""],""confidence_score"":90.0}"
Qliksense / Data Analyst,"Role : Qliksense – Data Analyst

Location : Mountain View CA (Day 1 onsite)

Skills

5+ years of experience working in a data analytics/ BI role
Fluency in conducting data discovery and quality checks
Building dashboards using Qlik (preferred)
Demonstrates strong business acumen and curiosity
Excellent problem-solving skills and end-to-end quantitative thinking
Produce & maintain scalable business performance reports
Build and maintain data pipeline for existing reports
Summarize high level trends in KPIs and performance (optional)
Works directly with the internal or external client to identify analytical requirements.
May occasionally guide less experienced business data analysts","{""role_summary"":""This role is responsible for working with data to identify trends, build dashboards, and create reports to help the business make informed decisions."",""key_terms"":[{""term"":""Data discovery"",""explanation"":""The process of identifying and exploring data to understand its structure, quality, and potential insights.""},{""term"":""Qlik"",""explanation"":""A business intelligence software used to create interactive dashboards and reports.""},{""term"":""Data pipeline"",""explanation"":""A series of processes that extract, transform, and load data from various sources into a usable format for analysis.""},{""term"":""KPIs"",""explanation"":""Key Performance Indicators, which are measurable values that indicate how well an organization is achieving its objectives.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in data analytics/BI"",""Fluency in conducting data discovery and quality checks"",""Excellent problem-solving skills and end-to-end quantitative thinking""],""nice_to_have"":[""Building dashboards using Qlik""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for conducting data discovery and quality checks?"",""example_answer"":""I start by reviewing the data dictionary to understand the data structure, then I perform exploratory data analysis to identify trends and outliers. Finally, I validate the data against business rules and requirements to ensure data quality.""},{""question"":""How do you approach building a scalable business performance report?"",""example_answer"":""I start by understanding the business requirements and identifying the key metrics that need to be reported. Then, I design a data model that can handle large datasets and create a report that is easy to maintain and update.""}],""red_flags"":[""Lack of experience working with Qlik or similar BI tools"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Intermediate Data Analyst,"Join Our Mission: Help the Helpers with Jane

Let’s kick things off with a quick intro. Jane is a team that’s all about fostering growth, spreading delight, and serving our healthcare community. We’re looking for people who are ready to jump in and join us as we simplify the lives of healthcare practitioners and patients every day.

At Jane, success means collaborating with your team, delivering an aligned result with efficiency and quality, communicating clearly and openly, and embracing continuous improvement. And guess what? Jane is a remote-first company, so every role, including this one, gives you the freedom to work from anywhere in Canada.

Your Role In Our Journey

Jane is looking for a Data Analyst who will be responsible for delivering consistent, meaningful insights across the company with a focus on supporting our Product and Marketing teams. You will have strong experience with SQL, dbt, Looker and preferably experience in a fast growing software company. We're looking for someone who thrives in a fast-paced environment, enjoys working with stakeholders to solve business problems, and is excited about working with data that drives business impact. You’ll have the opportunity to shape how Jane uses data to improve product adoption, customer retention, and marketing efficiency. At Jane, we value transparency, ownership, and a problem-solving mindset. If you’re excited about working with data to unlock business insights and help shape decision-making, this could be the perfect role for you.

Learn More About Us

We're founder-led, which means we live our values while maintaining a clear vision for the future. Our product enables the likes of physiotherapists, mental health counsellors, chiropractors, and other allied health practitioners to run their practices in a digital-first way through features such as online booking, charting, scheduling, telehealth, secure payments and billing along with an evolving library of features. You can see more of them here .

We're a company that is growing rapidly, and with that comes the challenge of navigating an environment with many moving parts, often without a clear-cut path laid out in front of us. If you're the kind of person who gets a kick out of being resourceful and loves solving problems, we would love to hear from you.

No doubt, Jane's a special place to work. There is autonomy and flexibility to help integrate work into your life in a way that makes sense for you. Need to block out time to pick up the kids? Go for it. That's normal here. And yes, we have a Slack channel for parents, but we've also got channels dedicated to plants, furry friends, food, pride, wellness - you get the idea! While we love to connect virtually, the Jane team also connects in person throughout the year.

We believe in collaboration, humility, and keeping a growth mindset. We're looking for people who can embrace our way of working, which often means being flexible and open to change. So, if after reading this, you feel excited about the opportunity — all in the name of helping those who help others — reach out to us to learn more.

You can also learn more about Jane as a company and a product by checking out our Glassdoor reviews and our Capterra Reviews

If you're excited by our growth, ready to contribute to a challenging yet rewarding environment, and eager to be a disruptor alongside a team of talented individuals, we’d love to hear from you!

The impact you could have

Collaborate with Product and Marketing teams to create and improve existing metrics, models, and documentation across multiple subject areas.
Own analysis from concept to implementation, build Looker reports and dashboards and share results with relevant stakeholders.
Develop and optimize Looker dashboards to surface insights and track business performance.
Help build and refine data models using DBT and Snowflake.
Build and maintain data pipelines to drive decision-making.
Work with ambiguous or incomplete requirements — identify gaps, ask the right questions, and deliver valuable insights.

The Experience We Feel We Need

3+ years experience as a data analyst in a high growth environment
Strong experience with SQL, DBT, and Looker — able to write complex queries, model data effectively, and create insightful dashboards.
Excellent communication skills and the ability to explain technical insights to non-technical audiences.
Experience working with product or marketing teams to define business requirements and drive insights.
Ability to take initiative and ownership, comfortable working independently and seeing projects through to completion.
Strong analytical skills with attention to detail and accuracy.
Experience with Github/version control.

Bonus Points

Experience with Snowflake and Tableau
Familiarity with product and/or marketing KPIs (e.g., churn, LTV, CAC, feature adoption)
Experience with event tracking data like RudderStack.
Experience with SQL query optimization and performance tuning
Familiarity with different data architectures (e.g., star vs snowflake schema)

Compensation Expectations For The Role

Jane’s committed to paying our team members fairly, clearly, and above all, paying for growth. This role has a minimum annual salary of $75,200 and maximum annual salary of $112,800. As you may have noticed, this salary range is quite large, and this is intentional to account for the growth someone will experience in the role throughout their time at Jane (i.e., from building the skills, to accomplished, to highly proficient, all the way to achieving excellence in the role). When hiring talented folks to join the Jane team, we’ve found that new team members are best set up for success when hired with the expectation of being fully accomplished in the role, which for this role would reflect a starting salary of $89,300.

It's also possible to join Jane at a salary above or below this, which would mean a salary below $89,300 typically reflects someone who has all the potential to be fully accomplished in the role but doesn't yet possess all the skills required, while a salary above $89,300 is typically for individuals who are currently in this role at Jane and had the opportunity to make a significant positive impact on our customers, product and company with deep Jane knowledge. At Jane, we pay for growth, which means that you’ll continue to have conversations about your career development with your manager and see your compensation grow over time as you build an amazing career with us.

Paying clearly is one of our compensation fundamentals to help folks build trust in the compensation process at Jane. To better understand Jane’s compensation fundamentals and how this range is determined, click on this link here for a short video walkthrough of how it all works! We also welcome you to ask as many questions as you’d like about compensation throughout the interview process to ensure you feel confident and build trust through the process.

More information on our benefits can be found here !

At Jane, we’re committed to fostering an environment that allows you to come to work as your truest self. We believe it’s important to actively recognize, embrace, and celebrate our differences in order to make Jane an inclusive, equitable, and diverse workplace.

We want to build a team of people who make conversations rich with perspective and experience. We are committed to listening to every voice in order to learn and grow because doing this will allow us to meet the needs of the diverse community of helpers that Jane serves.

We do not tolerate discrimination, prejudice, or oppressive isms of any kind. Employment is decided on the basis of qualifications, merit, experience, and the needs of the Jane community. We encourage anyone who requires accommodation or adjustments throughout the interview process to let us know, and we will do our best to support you.","{""role_summary"":""Data Analyst responsible for delivering insights across the company, focusing on supporting Product and Marketing teams, with strong experience in SQL, dbt, Looker, and a fast-paced environment."",""key_terms"":[{""term"":""SQL"",""explanation"":""Structured Query Language, a programming language used for managing and analyzing data in relational database management systems.""},{""term"":""dbt"",""explanation"":""Data Build Tool, a software framework used for transforming and analyzing data in warehouses.""},{""term"":""Looker"",""explanation"":""A business intelligence and analytics platform used for data visualization and reporting.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform used for storing and processing large amounts of data.""}],""skill_priorities"":{""must_have"":[""3+ years experience as a data analyst in a high growth environment"",""Strong experience with SQL, DBT, and Looker"",""Excellent communication skills"",""Experience working with product or marketing teams""],""nice_to_have"":[""Experience with Snowflake and Tableau"",""Familiarity with product and/or marketing KPIs"",""Experience with event tracking data like RudderStack"",""Experience with SQL query optimization and performance tuning"",""Familiarity with different data architectures""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a data model using DBT and Snowflake?"",""example_answer"":""I would start by identifying the key business requirements and defining the data model structure. Then, I would use DBT to transform and load the data into Snowflake, ensuring data quality and integrity. Finally, I would create Looker reports and dashboards to surface insights and track business performance.""},{""question"":""How do you communicate technical insights to non-technical stakeholders?"",""example_answer"":""I would focus on using clear and concise language, avoiding technical jargon, and using visualizations to help stakeholders understand complex data insights. I would also ensure that my communication is tailored to the stakeholder's needs and goals.""}],""red_flags"":[""Lack of experience working with product or marketing teams"",""Inability to communicate technical insights to non-technical stakeholders"",""Limited experience with SQL, DBT, and Looker""],""confidence_score"":90.0}"
Data Analyst with Power BI experience,"This Boston-based home services firm is looking to hire a Data Analyst to join their Boston team. Located near Boston North Station, the role will be hybrid, 2-3 days in the office, so someone local to Boston. You will need at least 1 year of professional experience building dashboards and reports in Power BI. This person should have solid SQL skills and any experience working with Snowflake, doing data transformation and cleansing work would be a big plus. The company is growing and while you are the first data hire, the team will grow in the future!

Responsibilities
Understand the day-to-day issues that our business faces, which can be better understood with data
Compile and analyze data related to business issues
Develop clear visualizations to convey complicated data in a straightforward fashion
Ability to work with external consultants and learn quickly

Qualifications

Bachelor's or Master's degree in Analytics, Applied Mathematics, or equivalent experience
2+ years of professional Data Analysis experience working with Power BI
Ability to support Operations, Finance, Sales, and Marketing
Solid SQL experience in data transformation, data ingestion, and cleansing
Snowflake, Fivetran, or Databricks will be a big plus
Comfortable meeting with company executives and working as the sole internal data resource.
Proactive, someone who finds ways data can impact the business before being asked.

This company cannot support OPT, provide sponsorship, visa transfer, or C2C.","{""role_summary"":""Support business growth by analyzing data and creating visualizations to inform business decisions, working closely with various departments and executives."",""key_terms"":[{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing data in relational database management systems.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform that enables fast, secure, and easy access to an organization's data.""},{""term"":""Data transformation"",""explanation"":""The process of converting data from one format to another to make it more suitable for analysis or use in a specific system.""},{""term"":""Data ingestion"",""explanation"":""The process of transporting data from various sources to a target system, such as a database or data warehouse, for storage and analysis.""},{""term"":""Data cleansing"",""explanation"":""The process of identifying and correcting errors, inconsistencies, and inaccuracies in a dataset to improve its quality and reliability.""}],""skill_priorities"":{""must_have"":[""Power BI"",""SQL"",""Data Analysis""],""nice_to_have"":[""Snowflake"",""Fivetran"",""Databricks""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data transformation and cleansing in a real-world scenario?"",""example_answer"":""I would first identify the data sources and their formats, then use SQL to extract and transform the data into a suitable format for analysis. Next, I would use data visualization tools like Power BI to create interactive dashboards and reports to convey insights to stakeholders.""},{""question"":""How do you stay proactive in finding ways data can impact the business?"",""example_answer"":""I regularly review business reports and metrics to identify areas where data can provide valuable insights. I also collaborate with cross-functional teams to understand their data needs and develop solutions to address them.""}],""red_flags"":[""Lack of experience with Power BI or SQL"",""Inability to work independently as the sole internal data resource""],""confidence_score"":90.0}"
Data Analyst (Growth),"Confidence can sometimes hold us back from applying for a job. Here’s a secret: there's no such thing as a ""perfect"" candidate. Poshmark is looking for exceptional people who want to make a positive impact through their work and help create an organization where everyone can thrive. So whatever background you bring with you, please apply if this role would make you excited to come to work every day.

Job Description

Poshmark is seeking a Data Analyst to join our our Growth Analytics Team, where you'll play a key role in covering trends, optimizing performance, and delivering data-driven recommendations to key stakeholders across Growth Marketing, Retention Marketing, Marketing Operations, and Product.

This is an exciting opportunity for analyst who want to make a high impact by turning complex data into strategic decisions that fuel business success. You'll work in a fast-paced, collaborative environment where your insights will directly influence marketing strategies, customer retention, and overall business growth.

What You'll Do

Deliver Strategic Insights – Analyze large datasets to uncover trends, opportunities, and performance drivers, translating them into clear, actionable business recommendations
Monitor & Optimize Performance – Track key performance metrics, evaluate marketing and product initiatives, and proactively identify areas for improvement
Collaborate Across Teams – Partner closely with cross-functional teams (Growth Marketing, Retention, Marketing Ops, Product) to understand their needs and provide data-driven solutions
Enhance Data Infrastructure – Work with Data Engineering to refine data models, improve reporting structures, and ensure data accuracy
Develop Metrics & Reporting – Create and maintain dashboards, reports, and KPIs that offer transparency into business performance
Ensure Data Integrity – Perform rigorous QA testing to validate data accuracy and maintain documentation of key findings and insights

Your First 6 Months

Get up to speed with Poshmark’s platform, key stakeholders, data systems, and business goals Develop expertise in internal data tools and how they support different business functions Contribute to projects by conducting analyses and investigations, ensuring quality insights and data accuracy Provide input on improving reporting processes and defining business metrics

Your First 12+ Months:

Take ownership of projects with increasing independence, developing long-term insights and forecasting trends
Lead conversations and present data-driven analyses to business partners
Establish yourself as a subject matter expert in your domain, proactively answering questions and offering guidance

What You Bring

2-3 years of experience in data analytics, with a focus on marketing, growth, or product analytics
Advanced SQL skills and proficiency in Excel; experience with Python, R, or Spark SQL is a plus
Strong understanding of data modeling concepts and experience collaborating on data warehouse development
Experience in defining business metrics, creating reports, and data visualization (Looker or similar tools preferred)
Experience with data visualization through Looker (or similar tool) is preferred
Knowledge of statistical analysis and A/B testing methodologies
Ability to communicate complex data clearly and effectively to both technical and non-technical audiences
Business acumen with the ability to apply insights strategically to solve business problems
Strong interpersonal skills with a proactive, team-player mindset

Salary Range

$95,000.00 - $131,500.00 Annual

About Us

Poshmark is a leading fashion resale marketplace powered by a vibrant, highly engaged community of buyers and sellers and real-time social experiences. Designed to make online selling fun, more social and easier than ever, Poshmark empowers its sellers to turn their closet into a thriving business and share their style with the world. Since its founding in 2011, Poshmark has grown its community to over 130 million users and generated over $10 billion in GMV, helping sellers realize billions in earnings, delighting buyers with deals and one-of-a-kind items, and building a more sustainable future for fashion. For more information, please visit www.poshmark.com, and for company news, visit newsroom.poshmark.com.

Why Poshmark?

At Poshmark, we’re constantly challenging the status quo and are looking for innovative and passionate people to help shape the future of Poshmark. We’re disrupting the industry by combining social connections with e-commerce through data-driven solutions and the latest technology to optimize our platform. We’re nothing without our amazing team who deliver an unparalleled social shopping experience to the millions of people we connect each day.

We built Poshmark around four core values: 1) focus on people to create empowered communities that drive success; 2) together we grow to support each other to strive for our dreams; 3) lead with love to foster genuine connections built upon a foundation of respect; and 4) embrace your weirdness to accept and empower one another on their own unique journey. We’re invested in our team and community, working together to build an entirely new way to shop. That way, when we win, we all win together. Come help us build the most connected shopping experience ever. We will set you up with comprehensive global and in-country benefits to support you and your family needs.

Poshmark is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.

View Poshmark's Job Applicant Privacy Policy here.","{""role_summary"":""Data Analyst responsible for analyzing large datasets, delivering strategic insights, and providing data-driven recommendations to key stakeholders across Growth Marketing, Retention Marketing, Marketing Operations, and Product."",""key_terms"":[{""term"":""Data Modeling"",""explanation"":""The process of creating a conceptual representation of data structures to support business intelligence and analytics.""},{""term"":""Data Warehouse"",""explanation"":""A central repository that stores data from various sources in a single location, making it easier to analyze and report.""},{""term"":""A/B Testing"",""explanation"":""A method of comparing two versions of a product, web page, or application to determine which one performs better.""},{""term"":""Looker"",""explanation"":""A data visualization tool used to create reports, dashboards, and KPIs to provide transparency into business performance.""}],""skill_priorities"":{""must_have"":[""Advanced SQL skills"",""Proficiency in Excel"",""Strong understanding of data modeling concepts"",""Ability to communicate complex data clearly and effectively""],""nice_to_have"":[""Experience with Python, R, or Spark SQL"",""Knowledge of statistical analysis"",""Experience with data visualization through Looker or similar tools""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a large dataset to uncover trends and opportunities?"",""example_answer"":""I would start by understanding the business problem and identifying the key performance metrics. Then, I would use SQL to extract the relevant data, and apply data visualization techniques to identify trends and patterns. Finally, I would translate my findings into actionable business recommendations.""},{""question"":""How do you ensure data accuracy and integrity in your work?"",""example_answer"":""I perform rigorous QA testing to validate data accuracy, and maintain documentation of key findings and insights. I also collaborate with cross-functional teams to ensure that data is accurate and consistent across different business functions.""}],""red_flags"":[""Lack of experience with data modeling concepts"",""Inability to communicate complex data clearly and effectively""],""confidence_score"":90.0}"
Data Analyst 7,"Data Analyst

Location: Richmond, VA

Duration: 12+ Months

Client: VDH

Job Id: (756384)

Hybrid Job

Position will primarily be responsible for assisting with development of processes & architecture to support migration from VIIS to STC. This will include long-term collection of STC data & its integration with pre-existing VIIS data in the EDR.

This individual will be primarily responsible for assisting with development of processes and architecture to support migration from VIIS to STC. This will include the long-term collection of STC data and its integration with pre-existing VIIS data in the EDR.

Priority 1: Assisting with process development to migrate data to STC.

Priority 2: Assisting with process development to pull data from STC into EDR.

Priority 3: Assisting with designing both process and architecture for integration of STC with VIIS data.

Required skills: Oracle PL-SQL, Python, GCP cloud functions, ETL / ELT processing","{""role_summary"":""Assist in developing processes and architecture to support data migration from VIIS to STC, integrating STC data with pre-existing VIIS data in the EDR."",""key_terms"":[{""term"":""VIIS"",""explanation"":""A data system being migrated from.""},{""term"":""STC"",""explanation"":""A target system for data migration.""},{""term"":""EDR"",""explanation"":""A data repository where integrated data will be stored.""},{""term"":""GCP cloud functions"",""explanation"":""A cloud-based platform for deploying and managing functions.""},{""term"":""ETL / ELT processing"",""explanation"":""Extract, Transform, Load / Extract, Load, Transform processes for data integration.""}],""skill_priorities"":{""must_have"":[""Oracle PL-SQL"",""Python"",""GCP cloud functions"",""ETL / ELT processing""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach integrating STC data with pre-existing VIIS data in the EDR?"",""example_answer"":""I would first assess the data structures and formats of both systems, then design an ETL/ELT process to transform and load the data into the EDR. I would also ensure data quality and integrity throughout the process.""},{""question"":""What experience do you have with GCP cloud functions, and how would you utilize them in this role?"",""example_answer"":""I have experience deploying and managing cloud functions on GCP. In this role, I would use GCP cloud functions to create scalable and efficient data processing pipelines for the data migration.""}],""red_flags"":[""Lack of experience with Oracle PL-SQL or Python."",""Inability to design and implement ETL/ELT processes.""],""confidence_score"":90.0}"
Data Analyst - Neurosurgery - Holman,"Come lead with us at Houston Methodist Academic Institute

At Houston Methodist, the Data Analyst position is responsible for the provision of analytical support of data generated by the department. This position will assist in creating, designing and implementing processes to ensure accurate data collection and input. The Data Analyst position will assist with maintenance of department database and on-going training of end users. This position is responsible for gathering, analyzing and reporting statistical information and patient outcomes to both external and internal customers which may include statistical power and sample size determination, inferential hypothesis testing, algorithm development and numerical methods, data mining and knowledge discovery in databases. Reporting duties for the Data Analyst position will involve the provision of monthly departmental reports and ensuring timely regulatory reporting completion. Additional responsibilities for this position include making recommendations for the implementation of technology and processes required to support the goals of the department with emphasis on regulatory compliance. The Data Analyst position will complete or assign other data requests.

People Essential Functions

Communicates results of queries in database systems and upgrades regarding electronic protocol management system to coworkers, staff and management.
Completes and works directly with physicians, clinical staff and management on customized data queries and other requests for operational and research needs.
Fosters teamwork approach in all interactions with peers and team members. Anticipates needs of other team members; proactively offering assistance. Provides contributions towards improvement of department scores for turnover/retention/employee engagement.

Service Essential Functions

Provides troubleshooting logic in relation to technical support.
Provides and/or supervises gathering, entering and auditing of data in database.
Assists with design and implementation of processes to ensure accurate data collection and input.
Performs statistical analysis interpretation by preparing reports (monthly, quarterly and/or as needed) on productivity, quality activities, trends and other clinical or business metrics relevant to the department.

Quality/Safety Essential Functions

Conducts routine data processing and implementation of quality control methods.
Develops standard operating procedures. Ensures compliance with all HIPAA/confidentiality regulations.
In conjunction with management, participates in performance improvement program for department.

Finance Essential Functions

Conducts, as appropriate, statistical power and sample size determination, inferential hypothesis testing, data mining and knowledge discovery in databases.
Responsible for all aspects of clinical data analyses for multiple studies.
Programs and develops algorithms for numerical methods and develops workflow and data pipelines as needed for project(s).

Growth/Innovation Essential Functions

Collaborates with Technology regarding software system proposals, purchases, installations, upgrades, enhancements and modifications.
Identifies and assumes responsibility of own learning needs, consults with team experts and seeks continuing education opportunities to meet those needs. Completes and updates the individual development plan (IDP) on an on-going basis. Ensures own career discussions occur with appropriate management.

This job description is not intended to be all-inclusive; the employee will also perform other reasonably related business/job duties as assigned. Houston Methodist reserves the right to revise job duties and responsibilities as the need arises.

EDUCATION

Bachelor's degree in computer science, engineering, math, physics or related field

Work Experience

Three years in data analysis, preferably in a healthcare/research setting

Licenses And Certifications - Required

N/A

KNOWLEDGE, SKILLS, AND ABILITIES

Demonstrates the skills and competencies necessary to safely perform the assigned job, determined through on-going skills, competency assessments, and performance evaluations
Sufficient proficiency in speaking, reading, and writing the English language necessary to perform the essential functions of this job, especially with regard to activities impacting patient or employee safety or security
Ability to effectively communicate with patients, physicians, family members and co-workers in a manner consistent with a customer service focus and application of positive language principles
Strong background in computer programming
Proficiency in Excel, Access and shell scripting strongly and ability to utilize multiple software applications
Familiarity with common imaging tools and database experience and/or experience with neuroinformatic software beneficial
Previous database project management experience preferred
Experience in relational database design
Knowledge of medical practices and terminology strongly preferred
Excellent analytical / statistical skills
Experience with report writers preferred
Excellent communications skills and ability to interact well with medical staff
Self-motivated with the ability to work independently

Supplemental Requirements

WORK ATTIRE

Uniform No
Scrubs No
Business professional Yes
Other (department approved) No

ON-CALL*

Note that employees may be required to be on-call during emergencies (ie. DIsaster, Severe Weather Events, etc) regardless of selection below.
On Call* No

TRAVEL**

Travel specifications may vary by department**
May require travel within the Houston Metropolitan area Yes
May require travel outside Houston Metropolitan area No

Houston Methodist is an Equal Opportunity Employer.","{""role_summary"":""The Data Analyst is responsible for providing analytical support, creating and implementing processes for accurate data collection, and reporting statistical information to internal and external customers."",""key_terms"":[{""term"":""Inferential hypothesis testing"",""explanation"":""A statistical method to draw conclusions about a population based on a sample of data.""},{""term"":""Algorithm development"",""explanation"":""The process of creating a set of instructions to solve a specific problem or perform a particular task.""},{""term"":""Data mining and knowledge discovery"",""explanation"":""The process of automatically discovering patterns, relationships, and insights from large datasets.""},{""term"":""Neuroinformatic software"",""explanation"":""Software used to analyze and interpret data related to the brain and nervous system.""}],""skill_priorities"":{""must_have"":[""Strong background in computer programming"",""Proficiency in Excel, Access, and shell scripting"",""Excellent analytical/statistical skills"",""Ability to effectively communicate with patients, physicians, family members, and co-workers""],""nice_to_have"":[""Familiarity with common imaging tools and database experience"",""Experience with neuroinformatic software"",""Previous database project management experience"",""Experience with report writers""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of inferential hypothesis testing and how you would apply it in a healthcare setting?"",""example_answer"":""Inferential hypothesis testing is a statistical method used to draw conclusions about a population based on a sample of data. In a healthcare setting, I would use this method to analyze patient outcomes and make informed decisions about treatment options.""},{""question"":""How would you design and implement a process to ensure accurate data collection and input?"",""example_answer"":""I would first identify the key data elements required for the process, then design a data collection tool such as a form or survey. Next, I would implement data validation rules to ensure accuracy and completeness of the data. Finally, I would test the process with a small pilot group before rolling it out to the larger team.""}],""red_flags"":[""Lack of experience with database design and management"",""Inability to communicate complex technical information to non-technical stakeholders""],""confidence_score"":90.0}"
SR DATA ANALYST - ADVANCED ANALYTICS,"Job title : SR. DATA ANALYST - ADVANCED ANALYTICS
Location : Charlotte, NC | Scottsdale, AZ | Malvern, PA | Dallas, TX (Hybrid 2days/week)

Employment type : FULLTIME

Note : Client is hiring for individuals who, now or in future does not require sponsorship for employment visa status
Job Responsibilities:
Engage with internal partners to understand business strategy, questions, and goals. Bring structure to business requests, translate requirements into an analytical project approach, and complete analyses.
Acquire and compile structured and unstructured data and verify its quality, accuracy, and reasonableness.
Perform analyses of historical data to surface trends and insights using advanced analytical methods.
Prepare and deliver visualizations and internal presentations that translate analytic insights into tangible, actionable solutions for business partners to implement.
Develop, own, and manage recurring analytic or reporting processes.
Mentor, coach, train, and develop junior data analysts. Proactively expand knowledge of business and analytics and shares with team members.
Share and document best practices.
Participate in special projects and perform other duties as assigned.

Basic Qualifications:
Minimum of five years related data analysis/science work experience
Undergraduate degree or equivalent combination of training and experience.
Coding knowledge in SQL and Python
Experience with data storytelling through visualization
Experience in designing and executing end to end experiments, including A/B, Multivariate (MVT) and Multi Arm Bandit (MAB) testing.

Nice to have:
Experience working with the NLP packages/techniques
Experience utilizing Graph networks to analyze the web behaviors
Adobe Analytics report creation experience.
Working knowledge of web tagging implementation","{""role_summary"":""Collaborate with internal partners to understand business strategy, develop analytical projects, and provide actionable insights using advanced analytics methods."",""key_terms"":[{""term"":""Advanced Analytics"",""explanation"":""Using complex statistical and mathematical techniques to extract insights from data.""},{""term"":""Data Storytelling"",""explanation"":""Presenting data insights in a clear and compelling way to non-technical stakeholders.""},{""term"":""NLP Packages"",""explanation"":""Software libraries used for natural language processing, such as text analysis and sentiment analysis.""},{""term"":""Graph Networks"",""explanation"":""A type of data structure used to analyze relationships between objects, such as web behaviors.""},{""term"":""A/B, Multivariate (MVT) and Multi Arm Bandit (MAB) testing"",""explanation"":""Types of experiments used to measure the effectiveness of different versions of a product or feature.""}],""skill_priorities"":{""must_have"":[""SQL"",""Python"",""Data Storytelling"",""A/B, Multivariate (MVT) and Multi Arm Bandit (MAB) testing""],""nice_to_have"":[""NLP Packages"",""Graph Networks"",""Adobe Analytics report creation"",""Web tagging implementation""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach a complex data analysis project, and how you would communicate the insights to non-technical stakeholders?"",""example_answer"":""I would start by understanding the business problem and identifying the key metrics to analyze. Then, I would use advanced analytics methods to extract insights from the data. Finally, I would create a clear and compelling presentation to communicate the findings to stakeholders.""},{""question"":""How do you ensure the quality and accuracy of the data you work with?"",""example_answer"":""I would verify the data by checking for inconsistencies and outliers, and also validate the data against other sources to ensure its reasonableness.""}],""red_flags"":[""Lack of experience with advanced analytics methods"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
"Senior Data Analyst, Product Analytics","Recognized as the No. 1 site trusted by real estate professionals, Realtor.com® has been at the forefront of online real estate for over 25 years, connecting buyers, sellers, and renters with trusted insights and expert guidance to find their perfect home. Through its robust suite of tools, Realtor.com® not only makes a significant impact on the real estate industry at large, but for consumers, navigating the biggest purchase they will make in their life, by providing a user experience that is easy to use, easy to understand, and most of all, easy to make decisions.

Join us on our mission to empower more people to find their way home by breaking barriers to entry, making the right connections, and building confidence through expert guidance.

We’re looking for a data-driven, strategic thinker to join our Customer Product Analytics team as a Senior Data Analyst. This isn’t just about crunching numbers—it’s about influencing the future of real estate. You’ll play a critical role in shaping key business decisions across product, revenue, and more—with direct visibility from senior leadership.

As a hands-on executor and strategic thinker, you won’t just be analyzing data—you’ll be owning insights that impact revenue and drive company growth. And because real estate is the largest asset class in the world, you’ll have access to some of the most robust datasets in the industry, helping us unlock powerful trends and innovations for the real estate professionals we serve!

Top Reasons You Should Apply

High-Impact, High-Visibility Role – Join a critical team where your insights directly influence key business decisions and get showcased in front of senior leadership, driving revenue and customer experience improvements.
Broad & Strategic Growth Opportunities – Gain extensive experience across both product and revenue analytics, opening doors to multiple career paths in customer insights, pricing strategy, and experimentation.
Shape the Future of Customer & Revenue Analytics – Work at the intersection of customer product analytics and revenue strategy, contributing to pricing models, A/B testing, and data-driven decision-making that fuel company growth.

What You'll Do

Be a strategic partner – Work closely with business stakeholders to understand their challenges and opportunities. Leverage your analytical skills to develop high-impact solutions, from optimizing processes to creating insightful, decision-driving dashboards.
Uncover the ‘why’ behind the numbers – Conduct deep-dive analyses into user engagement, retention, conversion, and feature adoption, helping shape data-driven strategies that fuel Realtor.com’s success.
Turn raw data into actionable insights – Extract, clean, and analyze massive datasets to spot trends, uncover patterns, and drive key business decisions that enhance the consumer experience.
Build dynamic dashboards that tell a story – Design and maintain customer-centric and product-centric dashboards that empower teams to make smarter, faster decisions for Realtor.com’s subscription products.
Shape the future of our product – Collaborate with product teams to develop and measure impactful enhancements. Identify potential roadblocks before they happen and provide optimization insights to keep innovation moving forward.
Define success and track it relentlessly – Establish and monitor key performance indicators (KPIs) to measure the effectiveness of product features and initiatives, ensuring we stay ahead of the competition.
Run experiments that drive innovation – Design, execute, and analyze A/B tests to evaluate the impact of product changes, providing clear recommendations for optimization.
Influence leadership with compelling storytelling – Present data-driven insights and strategic recommendations to senior executives, translating complex analytics into clear, actionable business decisions.
Be a force for excellence – Foster a culture of innovation and data-driven decision-making by implementing best practices, streamlining processes, and mentoring others to elevate the team’s impact.

How We Work

We balance creativity and innovation on a foundation of in-person collaboration. For most roles, our employees work three or more days in our offices, where they have the opportunity to collaborate in-person, adding richness to our culture and knitting us closer together.

What You'll Bring

Bachelor’s degree in business Analytics, Math, Economics, or equivalent work experience required.
Proven experience as a Data Analyst, preferably in a product-focused environment.
Experience with SQL and data manipulation languages.
Experience with data visualization tools (e.g., Tableau, Looker, Power BI).
Experience with A/B testing and statistical analysis.
Strong communication skills as well as written and verbal presentation skills and experience presenting to diverse audiences.
Self-motivated and self-managing, with strong time management and organizational skills.

How We Reward You

Realtor.com is committed to investing in the health and wellbeing of our employees and their families. Our benefits programs include, but are not limited to:

Inclusive and Competitive medical, Rx, dental, and vision coverage.
Family forming benefits.
13 Paid Holidays.
Flexible Time Off.
8 hours of paid Volunteer Time off.
Immediate eligibility into Company 401(k) plan with 3.5% company match.
Tuition Reimbursement program for degreed and non-degreed programs.
1:1 personalized Financial Planning Sessions.
Student Debt Retirement Savings Match program.
Free snacks and refreshments in each office location.

Do the best work of your life at Realtor.com®

Here, you’ll partner with a diverse team of experts as you use leading-edge tech to empower everyone to meet a crucial goal: finding their way home. And you’ll find your way home too. People are our foundation—the core that drives us passionately forward. At Realtor.com®, you’ll bring your full self to work as you innovate with speed, serve our consumers, and champion your teammates. In return, we’ll provide you with a warm, welcoming, and inclusive culture; intellectual challenges; and the development opportunities you need to grow.

Diversity is important to us, therefore, Realtor.com® is an Equal Opportunity Employer regardless of age, color, national origin, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, marital status, status as a disabled veteran and/or veteran of the Vietnam Era or any other characteristic protected by federal, state or local law. In addition, Realtor.com® will provide reasonable accommodations for otherwise qualified disabled individuals.","{""role_summary"":""A senior data analyst role that influences key business decisions across product, revenue, and more, with direct visibility from senior leadership, by analyzing data, uncovering insights, and driving company growth."",""key_terms"":[{""term"":""A/B testing"",""explanation"":""A method of comparing two versions of a product or feature to determine which one performs better.""},{""term"":""Data visualization"",""explanation"":""The process of creating graphical representations of data to help people understand and analyze it.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing data in relational database management systems.""},{""term"":""KPIs"",""explanation"":""Key Performance Indicators, which are measurable values that demonstrate how effectively an organization is achieving its objectives.""}],""skill_priorities"":{""must_have"":[""Experience with SQL and data manipulation languages"",""Experience with data visualization tools"",""Strong communication skills"",""Proven experience as a Data Analyst""],""nice_to_have"":[""Experience in a product-focused environment"",""Experience with A/B testing and statistical analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for conducting deep-dive analyses into user engagement and retention?"",""example_answer"":""I would start by identifying the key metrics that need to be analyzed, then use SQL to extract the relevant data. Next, I would use data visualization tools to create dashboards that help stakeholders understand the insights. Finally, I would present my findings and recommendations to the team, ensuring that my insights are actionable and drive business decisions.""},{""question"":""How do you stay up-to-date with the latest trends and innovations in data analytics?"",""example_answer"":""I regularly read industry blogs and attend conferences to stay current on the latest tools and methodologies. I also network with other data analysts to learn from their experiences and share my own knowledge.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to communicate complex analytics to non-technical stakeholders""],""confidence_score"":90.0}"
PowerBI Analyst,"We have a current opportunity for a PowerBI Analyst on a temporary basis. The position will be based in Dublin For further information about this position please apply.

Develops and tracks metrics that provide data for process measurement, business operations or risk assessment.
Presents findings and makes recommendations to management or others within organization
Performs complex research internally and externally
Performs analysis on complex data models requiring customized reports and data and presents recommendations.
Identifies, analyzes and improves existing business processes within a department to meet new goals and objectives.
Leads the effort to identify, analyze and improve existing business processes within a department to meet new goals and objectives.
Works on complex problems having broad impact that require in depth analysis and judgment to obtain results or solutions. Making sense of complex, high quantity, and sometimes contradictory information to effectively solve problems
Adapts approach and demeanor in real time to match the shifting demands of different situations
Plans and prioritizes work to meet commitments aligned with organizational goals.
Applies knowledge of business and the marketplace to advance the organization's goals.

EOE Statement: Specialist Staffing Group is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.

To find out more about Madison Black, please visit www.madisonblack.com","{""role_summary"":""A PowerBI Analyst responsible for developing and tracking metrics, presenting findings, and making recommendations to management. The role involves complex research, data analysis, and process improvement to meet business goals and objectives."",""key_terms"":[{""term"":""PowerBI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""Metrics"",""explanation"":""Quantifiable measures used to track and assess the performance of business processes or operations.""},{""term"":""Complex data models"",""explanation"":""Advanced statistical or mathematical models used to analyze and interpret large datasets.""}],""skill_priorities"":{""must_have"":[""PowerBI"",""Data analysis"",""Business process improvement"",""Communication and presentation skills""],""nice_to_have"":[""Knowledge of business operations and risk assessment"",""Experience with complex research and data modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to develop and track metrics for process measurement?"",""example_answer"":""In my previous role, I created a dashboard in PowerBI to track sales performance across different regions. I worked with the sales team to identify key metrics and developed a reporting system that provided actionable insights for management.""},{""question"":""How do you approach complex data analysis and problem-solving?"",""example_answer"":""I use a structured approach to break down complex problems into manageable components. I then apply my knowledge of data analysis and statistical modeling to identify patterns and trends, and finally, I communicate my findings and recommendations to stakeholders.""}],""red_flags"":[""Lack of experience with PowerBI or similar business analytics tools"",""Inability to communicate complex data insights effectively""],""confidence_score"":80.0}"
Master Data Analyst,"Location: Mt. Sterling, IL; St. Louis, MO
Department: B2B Integrations and Master Data
Reports To: Master Data Team Leader
Salary Grade: $51,333 to $77,000 annually, plus bonus opportunity
You’re a creative, analytical, and detail-oriented person. You think logically but also dream up ideas outside of the box. You are curious, forward thinking, enjoy building strong relationships, and providing excellent customer service. If this sounds like you, Dot Foods wants you on our team!
As a Master Data Analyst, you are the expert on all things item related. Your vast knowledge of GS1 standards and product data will serve you well as you build strong relationships with our suppliers and guide them to publish quality product data and images through the Global Data Synchronization Network (GDSN). Quality product data will increase sales and drive efficiencies throughout the supply chain.
WHAT YOU’LL DO
Implement and support continuous product content synchronization with supplier and customer partners through the GDSN.
Proactively work with Dot’s suppliers to publish item data.
Host supplier meetings, providing education on best practices regarding data publication, and product content.
Provide education on Global Data Synchronization, and GTIN Allocation Rules to Dot departments and suppliers.
Create and maintain reporting to communicate progress on team’s strategic initiatives and goals.
Set up and maintain all supplier-provided item data in the system and ensure its accuracy.
Analyze supplier data to identify gaps in consistency and quality, develop strategies to make improvements, and work with supplier to take corrective action.
Participate on industry committees to help shape GDSN best practices, policies, and procedures.
Apply lean thinking and tools to identify and eliminate waste in all areas of the position.

YOU MUST HAVE
Bachelor’s degree in Business, Finance, Accounting, or Marketing
Experience with Product Data Governance, GS1 standards, GDSN, & PIM
1-3 years’ work experience, analyst experience preferred.
Strong analytical and problem-solving skills with medium level knowledge in Excel (V-lookup, Pivot Tables, etc.)

YOU MAY ALSO HAVE
Effective verbal and written communication
Excellent interpersonal skills when interacting with internal & external customers.
Exceptional leadership, organization, time management, and follow-up skills
Knowledge of the benefits of accurate data for the entire supply chain
Experience with Precisely EnterWorks or 1WorldSync
Complex and creative problem-solving skills

ROLE SPECIFICS
Occasional travel required. Must have ability to travel independently as needed, without restriction, by all modes of transportation, including car, plane, or train for customer/vendor calls, trainings, or meetings.

WHO WE ARE
Dot Foods makes products more accessible and affordable to the food industry. We streamline the supply chain and build valuable partnerships with distributors, suppliers, and operators. Our company was created on a foundation of respect and dependability. People who are open to input, ask questions, embrace diversity, and seek innovative solutions thrive here.
WHAT DOT CAN OFFER YOU
As a family-owned and -operated company since 1960, Dot Foods has created a strong family culture. We make everyone feel included and respected. In addition to an inclusive working environment, we will provide you with:
Competitive compensation package, including bonuses for successful performance
Extensive benefits including medical, dental, 401k, and profit-sharing
Significant advancement opportunities

Safety: This position assumes responsibility for the workplace safety of self and co-workers, and for the safety conditions of the work locations, exercise and promotes safe behaviors and show unyielding support of programs, rules and policies regarding safety.
EOE/AA Employer: Dot believes all persons are entitled to equal employment opportunities. Dot will not discriminate against its employees or applicants for employment because of sex, race, color, religion, national origin, age, sexual orientation, disability, or veteran status or other basic classes protected by applicable federal or state law provided they are qualified for employment or for existing positions.","{""role_summary"":""As a Master Data Analyst, you will be responsible for implementing and supporting continuous product content synchronization with supplier and customer partners through the Global Data Synchronization Network (GDSN), providing education on best practices, and analyzing supplier data to identify gaps in consistency and quality."",""key_terms"":[{""term"":""GS1 standards"",""explanation"":""Global Standards One, a set of standards for product data and identification.""},{""term"":""GDSN"",""explanation"":""Global Data Synchronization Network, a platform for sharing product data between suppliers and customers.""},{""term"":""PIM"",""explanation"":""Product Information Management, a system for managing and synchronizing product data.""},{""term"":""GTIN Allocation Rules"",""explanation"":""Global Trade Item Number Allocation Rules, a set of rules for assigning unique identifiers to products.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in Business, Finance, Accounting, or Marketing"",""Experience with Product Data Governance, GS1 standards, GDSN, & PIM"",""Analytical and problem-solving skills"",""Medium level knowledge in Excel (V-lookup, Pivot Tables, etc.)""],""nice_to_have"":[""Effective verbal and written communication"",""Excellent interpersonal skills"",""Exceptional leadership, organization, time management, and follow-up skills"",""Knowledge of the benefits of accurate data for the entire supply chain"",""Experience with Precisely EnterWorks or 1WorldSync""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach identifying and addressing gaps in consistency and quality in supplier data?"",""example_answer"":""I would use analytical tools to identify patterns and anomalies in the data, and then work with the supplier to understand the root cause of the issue and develop a plan to correct it.""},{""question"":""Can you explain the importance of GS1 standards in product data governance?"",""example_answer"":""GS1 standards provide a common language and framework for product data, ensuring that data is accurate, consistent, and easily shared between suppliers and customers.""}],""red_flags"":[""Lack of experience with GS1 standards and GDSN"",""Inability to analyze and identify gaps in supplier data"",""Poor communication and interpersonal skills""],""confidence_score"":90.0}"
Data Analyst/Engineer,"Hello All,

Greetings from Rootshell Inc.

Rootshell Enterprise Technologies Inc. is a recognized provider of professional IT Consulting services in the US. We are actively seeking Data Analyst/Engineer for one of our client, Please share your resume with current location & full contact info

Role:Data Analyst/Engineer
Location:Austin, TX (OR ) San Francisco Bay Area, CA - Onsite
Only W2


Job Summary:
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
Experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)
4+ years of experience querying non relational databases using SQL or Python.
4+ years of experience working in an analytical capacity developing insights, defining metrics, and making recommendations.
Presentation and communications experience with extracting insights from technical data sets to varied audiences.
Experience thinking strategically about complex issues, leading to thoughtful recommendations and action plans.

Responsibilities
Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way.
Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership.
Design, build and launch new data models and visualizations in production, leveraging common development toolkits.
Support existing processes running in production and implement optimized solutions with limited guidance.
Build dashboards and reports to track effectiveness and efficiency improvements over time, and guide future decisions.
Establish close working relationships with a variety of cross-functional stakeholders including deal leads, data engineering, and product development teams.

With regards
Naveen | Talent Acquisition
Rootshell Enterprise Technologies Inc.
Naveen@rootshellinc.com | www.rootshellinc.com","{""role_summary"":""Collaborate with cross-functional teams to analyze and present data insights, develop data models, and ensure data quality and security."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Data modeling"",""explanation"":""The process of creating a conceptual representation of data structures to organize and standardize data.""},{""term"":""Non-relational databases"",""explanation"":""Databases that do not use the traditional table-based relational model, instead using other data models such as key-value, document, or graph.""}],""skill_priorities"":{""must_have"":[""SQL"",""ETL"",""Data modeling"",""Python"",""4+ years of experience querying non-relational databases"",""4+ years of experience working in an analytical capacity""],""nice_to_have"":[""C++"",""C#"",""Scala""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data modeling for a complex dataset?"",""example_answer"":""I would start by understanding the business requirements and identifying the key entities and relationships. Then, I would design a conceptual data model, followed by a logical and physical data model. Finally, I would implement the data model using a suitable database management system.""},{""question"":""How do you ensure data quality and security in your data pipelines?"",""example_answer"":""I would implement data validation and data cleansing processes to ensure data accuracy and completeness. I would also ensure data encryption and access controls to maintain data security and compliance.""}],""red_flags"":[""Lack of experience with non-relational databases"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Data Analyst 1 – Data Analyst,"Job Description

This is a non-merit position. Candidates must follow the instructions in the ""To Apply"" section.

The Department of Management (DOM), Division of Data, Planning, and Improvement, is seeking a Data Analyst to join our team!

This individual will play a critical role in developing research plans, managing and analyzing data, conducting high-level data analysis, and contributing to the development of impactful research findings by creating a variety of deliverables such as technical reports, dashboards, and other data visualizations. If you're passionate about data analysis, problem-solving, and contributing to meaningful research, we want to hear from you!

Key Responsibilities

Collect and utilize data according to research plans.
Develop and maintain secure databases for research projects.
Ensure data quality, identify errors, and resolve inconsistencies.
Conduct data analysis using software applications (e.g., R, SPSS) and present meaningful conclusions from the analyses.
Create technical reports, visualizations, dashboards, and presentations for diverse audiences.
Strong interpersonal and communication skills including the ability to effectively communicate complex ideas and information to both technical and non-technical audiences.
Assist in developing research proposals and grant applications and participate in peer reviews of team reports.
Meet deadlines for all deliverables as set by the Research Coordinator.
Communicate regularly with the Research Coordinator and supervisor.
Attend relevant meetings and trainings as needed.
Promote a culture of professionalism, accountability, and teamwork

Please note, candidates for this position must reside

in the state of Iowa at the time of starting the role.

Employer Highlights

The Department of Management is a well-respected employer. We are focused on providing excellent customer service, while offering a wonderful team atmosphere, work-life balance, free parking, and casual attire. We have a great total compensation package for all our full-time employees, including:

Iowa Public Employees' Retirement System (IPERS)
Retirement Investors Club (RIC)
Flexible Working Environment- Work from Home Opportunities
Health, Dental and Vision Insurance
Vacation Leave
Sick Leave
Paid Holidays
Flexible Spending Accounts
Life Insurance
Long-Term Disability Insurance

Background Check Requirements

After a conditional offer of employment has been made, and as the final step in the hiring process, candidates for this position will be subject to a background investigation, which may include but may not be limited to a verification of a candidate’s education, previous employment/work history, contact of personal references, motor vehicle records, and a criminal history check (including through Federal, State, or Local criminal justice agencies).
Information gathered as part of such background investigation will be treated as confidential to the extent permitted by Iowa Code section 22.7, 8B.4A, and other applicable laws, rules, and regulations; provided that, to the extent permitted by applicable law, such information shall be available to candidates upon request.

Minimum Qualification Requirements

Applicants must meet at least one of the following minimum requirements to qualify for positions in this job classification:

Graduation from an accredited four-year college or university with a degree in business analytics, economics, data science, statistics, mathematics, management information systems, or industrial management.
All of the following (a and b):
A total of four years of education and/or full-time experience in business/data/statistical analytics, economic research, or data science, where thirty semester hours of accredited college or university coursework in any field equals one year of full-time experience.
Possession of a professional certificate in data science, business analytics, or data analytics.
All of the following (a and b):
A total of four years of education and/or full-time experience in business/data/statistical analytics, economic research, or data science, where thirty semester hours of accredited college or university coursework in any field equals one year of full-time experience; and
A total of one year of graduate-level education and/or full-time experience (as described in part a), where twenty-four semester hours of accredited graduate college or university coursework in business analytics, economics, data science, statistics, mathematics, management information systems, or industrial management equals one year of full-time experience.","{""role_summary"":""The Data Analyst will develop research plans, manage and analyze data, and create impactful research findings through various deliverables such as technical reports, dashboards, and data visualizations."",""key_terms"":[{""term"":""Data Analysis"",""explanation"":""The process of extracting insights and patterns from data using software applications such as R and SPSS.""},{""term"":""Data Visualization"",""explanation"":""The presentation of data in a graphical or visual format to communicate information effectively.""},{""term"":""Research Proposals"",""explanation"":""Detailed plans outlining the objectives, methods, and expected outcomes of a research project.""}],""skill_priorities"":{""must_have"":[""Data analysis skills"",""Experience with software applications such as R and SPSS"",""Strong interpersonal and communication skills""],""nice_to_have"":[""Graduate-level education in business analytics, economics, data science, statistics, mathematics, management information systems, or industrial management"",""Professional certificate in data science, business analytics, or data analytics""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would ensure data quality and resolve inconsistencies in a research project?"",""example_answer"":""I would develop a data validation process to identify errors, and then use data cleaning techniques to resolve inconsistencies. Additionally, I would maintain a data log to track changes and ensure transparency.""},{""question"":""How do you effectively communicate complex data insights to non-technical stakeholders?"",""example_answer"":""I would use data visualization tools to create clear and concise reports, and then present the findings in a way that focuses on the key takeaways and recommendations. I would also be prepared to answer questions and provide additional context as needed.""}],""red_flags"":[""Lack of experience with data analysis software applications"",""Inability to effectively communicate complex data insights""],""confidence_score"":90.0}"
DATA ANALYST - SUPPLY CHAIN ANALYTICS,"Req137838

Position Purpose

A Data Analyst Supply Chain leverages technical abilities to synthesize complex analytical tasks into easily understood data-driven stories. Responsible for working collaboratively with other analysts to apply established analytical processes on diverse datasets to deduce insights and solve real-world business problems. Also ensures that all reporting and analytical responsibilities are completed competently in a timely manner, continually seeking out opportunities to hone existing technical skills (e.g. writing SQL/code, statistics, machine learning, etc.) and learn new skills. Operates under the supervision and mentorship of more experienced managers and data scientists.

Key Responsibilities

30% Executes existing reporting and analytical responsibilities
20% Leverages data analytics tools to create new dashboards, reports, and any additional ad-hoc requests
20% Ensures the quality of work output by displaying a keen attention to detail
20% Develops additional technical competencies and subject matter expertise within core functional group
10% Presents findings in easily understood ways, focuses on how the data analytics fits into the bigger picture

Direct Manager/Direct Reports

This postion reports to Manager
This position has no Direct Reports

Travel Requirements

Typically requires overnight travel less than 10% of the time.

Physical Requirements

Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.

Working Conditions

Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.

Minimum Qualifications

Must be eighteen years of age or older.
Must be legally permitted to work in the United States.

Preferred Qualifications

Work experience with SQL Server, Teradata, Oracle, or comparable database systems
1-3 years work experience in data mining, statistical analysis, auditing, and/or forecasting.
Prior direct experience in analyzing the relevant subject matter (e.g. Supply Chain, Merchandising, Operations, etc.)
B.S. in Computer Science, Math, Engineering, Finance or related quantitative field

Minimum Education

The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.

Preferred Education

No additional education

Minimum Years Of Work Experience

0

Preferred Years Of Work Experience

No additional years of experience

Minimum Leadership Experience

None

Preferred Leadership Experience

None

Certifications

None

Competencies

Critical thinking skills to identify the strengths and weaknesses of alternative solutions; ability to understand and foresee implications of new information for current and future problems solving.
An unquenchable intellectual curiosity for getting at the underlying story being told within the data.
Strong written and verbal communications skills. Ability to persuade, inform, and influence others based on findings. A track record of taking complex results and communicating them in an easily understood way.
Superior interpersonal skills and ability to collaborate actively and work in a team environment.
Ability to quickly learn and adapt to new technologies, tools, and techniques.","{""role_summary"":""A Data Analyst Supply Chain synthesizes complex analytical tasks into easily understood data-driven stories, working collaboratively with other analysts to deduce insights and solve real-world business problems."",""key_terms"":[{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational database management systems.""},{""term"":""Machine Learning"",""explanation"":""A type of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Data Mining"",""explanation"":""The process of automatically discovering patterns, relationships, and insights from large datasets.""},{""term"":""Teradata"",""explanation"":""A relational database management system used for storing and managing large amounts of data.""},{""term"":""Oracle"",""explanation"":""A relational database management system used for storing and managing large amounts of data.""}],""skill_priorities"":{""must_have"":[""SQL"",""Data Analysis"",""Communication Skills""],""nice_to_have"":[""Machine Learning"",""Teradata"",""Oracle"",""Data Mining"",""Statistical Analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a complex dataset to identify insights and trends?"",""example_answer"":""I would start by understanding the business problem and the requirements of the stakeholders. Then, I would use SQL to extract the relevant data, and apply statistical techniques to identify patterns and trends. Finally, I would communicate my findings in a clear and concise manner, using visualizations and storytelling techniques to make the insights actionable.""},{""question"":""How do you stay current with new technologies and tools in the field of data analysis?"",""example_answer"":""I regularly read industry blogs and publications, attend webinars and conferences, and participate in online forums to stay up-to-date with the latest developments in data analysis. I also make it a point to learn from my colleagues and mentors, and to seek out opportunities to apply new skills and techniques in my work.""}],""red_flags"":[""Lack of experience with SQL or other database management systems"",""Inability to communicate complex technical concepts in a clear and concise manner""],""confidence_score"":90.0}"
BI Developer & Data Analyst,"First Media is a top-ten social media publishing and marketing company at the intersection of content and commerce, driving the shoppable content revolution. Based in Los Angeles, with over 200 employees, 180 million fans, and over 1.5 billion monthly views, we’re a powerhouse of creative strategy, production, omnichannel distribution, and data. We use a proprietary formula to drive real-world action across our lifestyle brands, So Yummy, Blossom, Blusher, and BabyFirst.

BI Developer & Data Analyst
Join our passionate team as a BI Developer & Data Analyst, and let your love for data analysis and storytelling shine! As an essential part of our Business Intelligence department, you’ll deliver powerful insights and reports that drive our Performance Marketing and other key divisions. We’re seeking a strategic thinker with sharp problem-solving skills who thrives on collaboration with both internal teams and external partners.

While this role can be WFH anywhere in the US, the chosen candidate must be available and responsive for Pacific Time meetings and requests. There may also be the occasional need to respond to the team on the weekend.

Key Responsibilities:
Reporting & Analysis: Keep our reports and dashboards up-to-date, tracking key metrics and insights to help guide important decisions in direct marketing.
Data Solutions Development: Create and set up efficient back-end data processes and pipelines that make it easier for dashboards and other team members to access the information they need.
Insights and Recommendations: Use your analytical skills and business knowledge to offer helpful suggestions on ad performance, addressing key business questions and identifying promising opportunities.
Strategic Collaboration: Team up with colleagues from different departments to identify and shape strategic decisions through thorough research, analytics, and valuable insights.
Communication: Share findings and recommendations with senior management in a clear, engaging, and impactful way.
Continuous Improvement: Focus on developing business processes and improving your analytics skills to create even better solutions and approaches.

Qualifications:
Education: Bachelor’s or Master’s degree in a quantitative field (e.g., Computer Science, Statistics, Economics, Applied Math, Analytics) preferred
Experience: 2+ years in analytics or a related role, preferably in performance or growth-driven industries.

Technical Skills:
Proficiency in programming languages (Python, SQL).
Experience with data visualization and management tools (Looker is mandatory).
Analytical Skills: Strong ability to conduct quantitative and qualitative analyses to address business challenges.
Business Acumen: Demonstrated understanding of business needs and ability to translate data insights into impactful recommendations.
Communication: Excellent presentation and interpersonal skills to convey insights to diverse audiences.
Project Management: Ability to prioritize and manage multiple projects in time-sensitive environments.
Attention to Detail: A careful and thorough approach to analysis, organization, and execution.

If you’re ready to make a meaningful impact and elevate our data-driven initiatives, we can’t wait to hear from you!

First Media provides competitive compensation and exceptional benefits, including top-shelf medical, dental, vision, unlimited PTO, 401K with match, and more.

First Media is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity/expression, national origin, disability, protected veteran status, or any other characteristic protected under federal, state, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.","{""role_summary"":""As a BI Developer & Data Analyst, you will deliver powerful insights and reports to drive business decisions, collaborating with internal teams and external partners to drive performance marketing and other key divisions."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""The practice of using data and analytics to inform business decisions.""},{""term"":""Performance Marketing"",""explanation"":""A type of marketing that focuses on measurable results and ROI, often used in digital marketing campaigns.""},{""term"":""Data Visualization"",""explanation"":""The process of presenting data in a graphical or visual format to help communicate insights and trends.""},{""term"":""Looker"",""explanation"":""A data visualization and business intelligence platform used to create and manage data dashboards.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Looker"",""Data Visualization"",""Analytical Skills"",""Business Acumen"",""Communication""],""nice_to_have"":[""Project Management"",""Attention to Detail""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for conducting quantitative and qualitative analyses to address business challenges?"",""example_answer"":""I would start by identifying the key business question, then gather relevant data and conduct statistical analysis to identify trends and insights. Finally, I would present my findings and recommendations to stakeholders in a clear and actionable way.""},{""question"":""How do you stay up-to-date with industry trends and developments in data analytics and visualization?"",""example_answer"":""I regularly read industry blogs and publications, attend webinars and conferences, and participate in online forums and communities to stay current on the latest tools and techniques.""}],""red_flags"":[""Lack of experience with Looker or similar data visualization tools"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Data Analyst (Remote),"Overview

GovCIO is currently hiring for Data Analyst. This position will be a fully remote position.

Responsibilities

Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information

Qualifications

Required Skills and Experience:

Bachelor's with 8+ years (or commensurate experience)
Proven working experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings

Clearance Required: Ability to obtain and maintain a Suitability/Public Trust clearance.

Company Overview

GovCIO is a team of transformers--people who are passionate about transforming government IT. Every day, we make a positive impact by delivering innovative IT services and solutions that improve how government agencies operate and serve our citizens.

But we can't do it alone. We need great people to help us do great things - for our customers, our culture, and our ability to attract other great people. We are changing the face of government IT and building a workforce that fuels this mission. Are you ready to be a transformer?

We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, disability, or status as a protected veteran. EOE, including disability/vets.

Posted Pay Range

The posted pay range, if referenced, reflects the range expected for this position at the commencement of employment, however, base pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, education, experience, and internal equity. The total compensation package for this position may also include other compensation elements, to be discussed during the hiring process. If hired, employee will be in an “at-will position” and the GovCIO reserves the right to modify base salary (as well as any other discretionary payment or compensation program) at any time, including for reasons related to individual performance, GovCIO or individual department/team performance, and market factors.

Posted Salary Range: USD $120,000.00 - USD $140,000.00 /Yr.","{""role_summary"":""The Data Analyst is responsible for interpreting and analyzing data, developing databases, and providing ongoing reports to management. The role requires strong analytical skills, technical expertise in data models and statistical packages, and the ability to communicate findings effectively."",""key_terms"":[{""term"":""Data models"",""explanation"":""A conceptual representation of data structures and relationships, used to organize and analyze data.""},{""term"":""Database design development"",""explanation"":""The process of creating and implementing a database structure to store and manage data.""},{""term"":""Data mining"",""explanation"":""The process of automatically discovering patterns and relationships in large datasets.""},{""term"":""Segmentation techniques"",""explanation"":""Methods used to divide a dataset into distinct groups or segments based on shared characteristics.""},{""term"":""ETL frameworks"",""explanation"":""Tools used to extract, transform, and load data from one system to another.""},{""term"":""SQL"",""explanation"":""A programming language used to manage and analyze relational databases.""},{""term"":""XML"",""explanation"":""A markup language used to store and transport data in a format that is both human-readable and machine-readable.""},{""term"":""Javascript"",""explanation"":""A programming language used to create interactive web pages and web applications.""},{""term"":""Business Objects"",""explanation"":""A business intelligence platform used to create and manage business reports and analytics.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree with 8+ years of experience"",""Proven working experience as a data analyst or business data analyst"",""Technical expertise in data models, database design development, data mining and segmentation techniques"",""Strong knowledge of reporting packages, databases, and programming languages"",""Knowledge of statistics and experience using statistical packages"",""Strong analytical skills with attention to detail and accuracy""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of data modeling and how you would apply it in a real-world scenario?"",""example_answer"":""Data modeling is the process of creating a conceptual representation of data structures and relationships. In a real-world scenario, I would use data modeling to design a database for a customer relationship management system, ensuring that the data is organized and easily accessible for analysis and reporting.""},{""question"":""How do you ensure data quality and accuracy in your analysis?"",""example_answer"":""I ensure data quality and accuracy by implementing data validation rules, performing data profiling, and conducting regular data audits to identify and correct errors or inconsistencies.""}],""red_flags"":[""Lack of experience with statistical packages and programming languages"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Operations Data Analyst,"Reports to: Vice President of Operations 
 About Aroris: 
 Aroris Health is a leading healthcare technology company. Our proprietary platform, Aroris360, empowers healthcare providers with data-driven insights to optimize payer negotiations, enhance operational efficiency, and improve healthcare outcomes. We are driven by innovation, committed to excellence, and focused on delivering measurable impact to our clients.  
 Aroris's mission is to preserve the spirit of medicine. One way of doing this is to provide independent medical practices access to the same payer contracting resources as the largest health systems. We operate as an extension of practices, leveraging decades of industry experience, cutting-edge data analytics capabilities, and dedicated legal and negotiation teams to help practices capture more revenue without expending additional resources. 
 At Aroris, we look for individuals who embody our core values of being driven, joyful, relentless, and team players. We believe these qualities are vital in achieving our collective goals and fostering a thriving work environment. 
 Job Overview: 
 We are seeking a talented and detail-oriented Operations Data Analyst to join our team. As an Operations Data Analyst, your primary responsibilities will revolve around collecting, cleaning, analyzing, and sharing data as well as uploading data to our SaaS platform. You will play a crucial role in supporting decision-making processes and improving business operations through data-driven insights. Additionally, you will collaborate closely with clients and the operations team, providing clear communication and routine updates to ensure the successful execution of data-related projects. Data sources will include Excel, PDFs, EMR/Practice Management, Clearing House Revenue Reports, as well as other types of reporting software.   
 Job Responsibilities: 
 Data Collection: Gather data from various sources, including databases, APIs, and spreadsheets, while ensuring data quality and integrity 
Data Cleaning: Perform data cleansing and transformation tasks to ensure accuracy, consistency, and completeness of the data 
Data Analysis: Utilize statistical techniques and analytical tools to analyze large datasets, identify trends, patterns, and anomalies, and extract meaningful insights that drive business decisions 
Data Sharing: Prepare and present reports, visualizations, and dashboards to communicate findings and recommendations effectively to stakeholders 
Client and Operations Partnership: Collaborate with clients and the operations team to understand their requirements, goals, and challenges. Provide regular updates on project progress and maintain open lines of communication 
Proposal Modeling: Model healthcare reimbursement proposals from payers and share insights with negotiation teams   
SaaS Platform Management: Upload data into the SaaS platform, ensuring accurate and timely data entry, and troubleshooting any issues that may arise 
Data Accuracy Assurance: Implement data quality checks and validation procedures to ensure data accuracy, completeness, and consistency across all data sources 
Process Improvement: Continuously evaluate and enhance data collection, analysis, and reporting processes to optimize efficiency and effectiveness 
 Required Experience, Qualifications and Skills: 
2+ years using Microsoft Excel - data collection, cleaning, standardization, mining, analysis, and visualization 
2+ years of experience in data analysis role 
Solid understanding of the US HealthCare reimbursement model, Fee Schedules, and Insurance Payer processes 
Demonstrated ability to use data as a tool for problem-solving 
Excellent communication skills, specifically as it relates to explaining technical concepts and data-driven findings 
 Preferred Experience, Qualifications and Skills: 
2+ years of experience in database engineering 
Tableau, Power BI, or other data visualization programs 
2+ year of experience building, maintaining, and implementing financial models 
 Compensation:
Salary: $55-75K
Bonus Eligible: 15-30%

Equal Employment Opportunity:  
Aroris is an equal opportunity employer. Aroris is committed to equal employment opportunity in accordance with applicable federal, state, and local laws. Aroris will not discriminate against applicants for employment on any legally recognized basis. This includes, but is not limited to veteran status, race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, age and physical or mental disability.  ","{""role_summary"":""Support business operations by collecting, analyzing, and sharing data to drive decision-making, and collaborate with clients and the operations team to ensure successful project execution."",""key_terms"":[{""term"":""Payer contracting resources"",""explanation"":""Resources used by healthcare providers to negotiate with insurance payers.""},{""term"":""Data-driven insights"",""explanation"":""Using data analysis to inform business decisions and improve operations.""},{""term"":""EMR/Practice Management"",""explanation"":""Electronic Medical Record and Practice Management systems used in healthcare to manage patient data and practice operations.""},{""term"":""Clearing House Revenue Reports"",""explanation"":""Reports generated by clearinghouses that provide revenue data to healthcare providers.""},{""term"":""SaaS platform"",""explanation"":""Software as a Service platform used to deliver software applications over the internet.""}],""skill_priorities"":{""must_have"":[""Microsoft Excel"",""Data analysis"",""Communication skills"",""US Healthcare reimbursement model knowledge""],""nice_to_have"":[""Database engineering"",""Tableau or Power BI"",""Financial modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would ensure data quality and integrity in a dataset?"",""example_answer"":""I would use data validation techniques, such as data profiling and data cleansing, to identify and correct errors, and implement data quality checks to ensure accuracy and consistency.""},{""question"":""How would you communicate complex data insights to non-technical stakeholders?"",""example_answer"":""I would use clear and concise language, avoiding technical jargon, and focus on the key findings and recommendations. I would also use data visualization tools to help illustrate the insights.""}],""red_flags"":[""Lack of experience with healthcare reimbursement models"",""Inability to communicate technical concepts effectively""],""confidence_score"":90.0}"
Data Analyst (Payments),"At SpotOn, we’re helping restaurants and small businesses compete and win with flexible payment and software technology—backed by real people who really care. From seamless point-of-sale systems to integrated restaurant management solutions, every SpotOn tool is designed to help local businesses increase profits and create better experiences for their customers and employees.  

Recently, SpotOn was:


Named one of Fast Company’s Most Innovative Companies of 2024

Awarded Great Places to Work and Built In’s Best Workplaces for the third year in a row

Selected as the Best Overall Restaurant POS by NerdWallet 

Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users


We’re committed to caring hard and moving fast so that we can continue to grow and make a positive impact together. 

That’s where you come in. 
Data Analyst (Payments data focus)
Ready to dive into the world of payments data and make a real impact? We're looking for a Data Analyst to join our growing team. You'll be analyzing payments data, building cool reports, and uncovering insights that optimize our pricing and payment systems. Your work will help us streamline processes, boost financial performance, and create a better experience for our merchants.

Your Mission:


Data Detective: Investigate payment glitches, sniff out financial risks (e.g. billing errors or unexpected rate changes), and serve up data-backed recs.

Merchant Mastermind: Get to the bottom of data discrepancies and merchant configuration issues to ensure smooth operations.

Churn Crusader: Dive deep into why merchants are churning, figure out ""what happened,"" and use those insights to help us improve.

Visualize Insights: Build intuitive reports to monitor payment revenue performance.

Improve Systems: Identify friction points in the payments platform and support efforts to improve processes.

Team Up: Collaborate with Finance, Operations, Engineering, and Product teams to maintain a reliable payments infrastructure.


What You'll Bring:


3-5 years of experience in business analytics, payments, finance, or a related field.

Strong SQL skills (ability to write complex queries to extract insights) and experience with BI tools.

Operating with a bias toward sharing, transparency and collaboration is your default!

Diving in, solving problems, and getting things done is second nature - no waiting for perfect conditions.

Thriving in fast-paced environments, embracing ambiguity, and taking initiative without a rulebook.


Bonus points: Experience in payments, finance, or e-commerce payment platforms.

Benefits:  

At SpotOn, we put people above everything else. We’re known for our innovative software and technology solutions, but we stand out because of the hard-working humans behind the tech. We can’t take care of our clients without taking care of our employees first, and that’s why we invest in you with a competitive benefits package which includes:


Medical, Dental and Vision Insurance 

401k with company match

RSUs

Paid vacation, 10 company holidays, sick time, and volunteer time off

Employee Resource Groups to build community and inclusion at work

Monthly cell phone and internet stipend

Tuition reimbursement for up to $2,000 per calendar year to assist with your professional development


Compensation:


Our base pay range starts at $107,000 -$140,000 for this role

Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan

Offers will be reflective of the candidate’s location and experience.

The base salary range listed will vary depending on location and experience.
Base salary range: $107,000 USD - $140,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.

SpotOn is an e-verify company.","{""role_summary"":""As a Data Analyst at SpotOn, you will analyze payments data, build reports, and uncover insights to optimize pricing and payment systems, streamlining processes, boosting financial performance, and creating a better experience for merchants."",""key_terms"":[{""term"":""Payments data"",""explanation"":""Data related to payment processing, including transactions, revenue, and payment methods.""},{""term"":""BI tools"",""explanation"":""Business Intelligence tools used for data analysis and visualization, such as Tableau or Power BI.""},{""term"":""SQL"",""explanation"":""Structured Query Language, a programming language used for managing and analyzing relational databases.""}],""skill_priorities"":{""must_have"":[""3-5 years of experience in business analytics, payments, finance, or a related field"",""Strong SQL skills"",""Experience with BI tools""],""nice_to_have"":[""Experience in payments, finance, or e-commerce payment platforms""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to investigate and resolve a complex payment issue?"",""example_answer"":""In my previous role, I identified a discrepancy in payment processing that resulted in a revenue loss. I worked with the finance team to analyze the data, identified the root cause, and implemented a solution that prevented similar issues in the future.""},{""question"":""How do you stay organized and prioritize tasks in a fast-paced environment?"",""example_answer"":""I use project management tools to track tasks and deadlines, and I prioritize tasks based on urgency and impact. I also communicate regularly with my team to ensure everyone is aligned and aware of dependencies.""}],""red_flags"":[""Lack of experience with SQL or BI tools"",""Inability to work in a fast-paced environment with ambiguity""],""confidence_score"":90.0}"
Senior Data Analyst - Payment Success,"Company Description

Checkout.com is one of the most exciting fintechs in the world. Our mission is to enable businesses and their communities to thrive in the digital economy. We’re the strategic payments partner for some of the best known fast-moving brands globally such as Wise, Hut Group, Sony Electronics, Homebase, Henkel, Klarna and many others. Purpose-built with performance and scalability in mind, our flexible cloud-based payments platform helps global enterprises launch new products and create experiences customers love. And it's not just what we build that makes us different. It's how.

We empower passionate problem-solvers to collaborate, innovate and do their best work. That’s why we’re on the Forbes Cloud 100 list and a Great Place to Work accredited company. And we’re just getting started. We’re building diverse and inclusive teams around the world — because that’s how we create even better experiences for our merchants and our partners. And we need your help. Join us to build the digital economy of tomorrow.

Job Description

Important note: Please submit CVs in English

The role

We empower businesses in the digital economy, and we know that every payment counts. Our Payment Performance team’s mission is to manage and optimise merchants’ payment flow, to achieve optimal conversion, compliance and cost.

Checkout.com is looking for a Senior Data Analyst to join our Payment Success team to craft an all-encompassing payments strategy tailored specifically for our Tier-1 merchants. You will be the main point of contact for a merchant regarding their payment performance. You will play a critical role in defining, delivering and building tools for the right insights to showcase the value of our optimal payment strategies.

You will work closely with Payment Performance engineers and data scientists leveraging cutting-edge technology and data insights. You will also collaborate regularly with other teams and cross-functional stakeholders to establish priorities and drive merchant performance improvements.

Hybrid Working Model: All of our offices globally are onsite 3 times per week (Tuesday, Wednesday, and Thursday). We’ve worked towards enabling teams to work collaboratively in the same space, while also being able to partner with colleagues globally. During your days at the office, we offer amazing snacks, breakfast, and lunch options in all of our locations.

How You’ll Make An Impact

Deliver expertise and guidance to our key merchants by crafting optimal payments strategy.
Conduct deep-dive exploratory data analysis to uncover insights and anomalies
Conduct experiments and A/B tests to improve performance, including ML based solutions.
Develop cutting-edge automation tools aimed at monitoring and optimising merchants’ performance.
Implement robust measurements to assess how proposed solutions impact merchants' performance and revenue, providing valuable insights for both internal and external ROI.
Collaborate with various teams across the company to ensure an outstanding merchant experience and feed requirements for product development
Elevate internal awareness, particularly within the executive team, regarding the full spectrum of merchant services and benefits provided
Drive a culture of cross-team learning and knowledge sharing

Qualifications

5+ years experience as data scientist, working with large and diversified data sets
Bachelor’s degree, preferably in Mathematics / Statistics / Computer Science / Engineering, Finance or equivalent
SQL/ Python knowledge to extract & analyse data from our Data Warehouse
Experience with Git & Spark, Databricks, Retool, API
Ability to find creative and effective solutions for business problems
Flexible, adaptable and has a willingness to learn
Payments or Fintech experience is a plus

If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values

Please submit CVs in English.

Additional Information

Additional Information

New York City law requires Checkout.com to include in job postings a reasonable estimated salary range for this position. However, exact compensation may vary subject to several factors such as a candidate’s level, relevant experience, qualifications, skills and proficiency for the role.

The information provided here is applicable to those working in the New York City office. However, this role may also open to applicants from other US locations and will be advised on the relevant pay for that location.

For regular full-time employees in New York City, the estimated base salary for this role is $138,720 -163,200 per year.

Our competitive salaries are just one component of Checkout.com’s total compensation package. Additional benefits include: health, vision, dental insurance, 401k, vacation and sick and safe time, learning days and volunteer days.

To view more details of what you can look forward to, visit our careers page: https://www.checkout.com/careers.

Apply Without Meeting All Requirements Statement

If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.

We believe in equal opportunities

We work as one team. Wherever you come from. However you identify. And whichever payment method you use.

Our clients come from all over the world — and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.

When you join our team, we’ll empower you to unlock your potential so you can do your best work. We’d love to hear how you think you could make a difference here with us.

We want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We’ll be happy to support you.

Take a peek inside life at Checkout.com via

Our Culture video https://youtu.be/BEwnpHuadSw
Our careers page https://www.checkout.com/careers
Our LinkedIn Life pages bit.ly/3OaoN1U
Our Instagram https://www.instagram.com/checkout_com/

Apply Without Meeting All Requirements Statement

If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.

We believe in equal opportunities

We work as one team. Wherever you come from. However you identify. And whichever payment method you use.

Our clients come from all over the world — and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.

When you join our team, we’ll empower you to unlock your potential so you can do your best work. We’d love to hear how you think you could make a difference here with us.

We want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We’ll be happy to support you.

Take a peek inside life at Checkout.com via

Our Culture video https://youtu.be/BEwnpHuadSw
Our careers page https://www.checkout.com/careers
Our LinkedIn Life pages bit.ly/3OaoN1U
Our Instagram https://www.instagram.com/checkout_com/","{""role_summary"":""A Senior Data Analyst responsible for crafting optimal payment strategies for Tier-1 merchants, leveraging data insights and cutting-edge technology to drive merchant performance improvements."",""key_terms"":[{""term"":""Payment Performance"",""explanation"":""The process of managing and optimizing merchants' payment flow to achieve optimal conversion, compliance, and cost.""},{""term"":""Tier-1 merchants"",""explanation"":""High-value merchants that require tailored payment strategies to optimize their performance.""},{""term"":""A/B testing"",""explanation"":""A method of comparing two versions of a product or service to determine which one performs better.""},{""term"":""Machine Learning (ML) based solutions"",""explanation"":""The use of machine learning algorithms to develop predictive models that improve payment performance.""}],""skill_priorities"":{""must_have"":[""5+ years of experience as a data scientist"",""SQL/Python knowledge"",""Experience with Git & Spark, Databricks, Retool, API""],""nice_to_have"":[""Payments or Fintech experience"",""Bachelor's degree in Mathematics/Statistics/Computer Science/Engineering, Finance or equivalent""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach crafting an optimal payment strategy for a Tier-1 merchant?"",""example_answer"":""I would start by conducting a deep-dive exploratory data analysis to uncover insights and anomalies in the merchant's payment flow. Then, I would use this information to develop a tailored payment strategy that optimizes conversion, compliance, and cost. I would also collaborate with cross-functional stakeholders to ensure that the strategy aligns with the merchant's business goals.""},{""question"":""How do you stay up-to-date with the latest developments in machine learning and its applications in payment performance?"",""example_answer"":""I regularly read industry publications and attend conferences to stay current with the latest advancements in machine learning. I also participate in online forums and discussion groups to learn from other professionals in the field.""}],""red_flags"":[""Lack of experience working with large and diversified data sets"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Full Time - Data Science Analyst,"Job Title: Data Science Analyst
Location: Mountain View, CA
Client: Cognizant
Duration: Contract

Job Summary
We are looking for a Data Science Analyst with expertise in mining data for insights, KPI trend analysis, ROI measurement, and data-driven decision-making. This role requires a strong analytical mindset, and the ability to work with structured and unstructured data to drive business impact.
Key Responsibilities
Analyze and mine large datasets to uncover trends, correlations, and actionable insights.
Develop models and statistical techniques to track KPI trends, ROI measurement, and forecasting.
Conduct data-driven analysis to optimize business strategies and operational efficiency.
Build, maintain, and optimize codebases analytics workflows.
Work cross-functionally with business, finance, and product teams to support data-backed decision-making.
Ensure data integrity, quality, and governance while handling large datasets.
Required Skills & Qualifications
Experience: 3-5+ years in data analytics, data science, or a related field.
Technical Skills: Proficiency in SQL, Python/R.
Analytics & Modeling: Strong understanding of data mining, statistical modeling, and predictive analytics.
Strong Business Acumen: Ability to translate data insights into strategic recommendations.
Excellent Communication: Strong storytelling and visualization skills for data presentation.
Preferred Qualifications
Experience with ETL, data warehousing.
Background in A/B testing, regression modeling, and statistical analysis.","{""role_summary"":""A Data Science Analyst responsible for mining data for insights, analyzing trends, and driving business impact through data-driven decision-making."",""key_terms"":[{""term"":""KPI trend analysis"",""explanation"":""Analyzing key performance indicators to identify patterns and trends.""},{""term"":""ROI measurement"",""explanation"":""Calculating return on investment to evaluate the financial impact of business decisions.""},{""term"":""Data mining"",""explanation"":""Extracting insights and patterns from large datasets.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from sources, transforming it into a usable format, and loading it into a target system.""},{""term"":""A/B testing"",""explanation"":""Comparing two versions of a product or service to determine which one performs better.""},{""term"":""Regression modeling"",""explanation"":""A statistical technique used to establish relationships between variables.""}],""skill_priorities"":{""must_have"":[""SQL"",""Python/R"",""Data mining"",""Statistical modeling"",""Predictive analytics"",""Business acumen"",""Communication skills""],""nice_to_have"":[""ETL"",""Data warehousing"",""A/B testing"",""Regression modeling"",""Statistical analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a large dataset to identify trends and insights?"",""example_answer"":""I would start by cleaning and preprocessing the data, then use techniques like clustering, decision trees, or regression to identify patterns and correlations. Finally, I would visualize the results to communicate the insights effectively.""},{""question"":""How do you ensure data quality and integrity when working with large datasets?"",""example_answer"":""I would implement data validation checks, handle missing values, and perform data profiling to ensure data accuracy and consistency. Additionally, I would establish data governance policies to maintain data quality over time.""}],""red_flags"":[""Lack of experience with SQL or Python/R"",""Inability to communicate complex data insights effectively"",""Limited understanding of statistical modeling and predictive analytics""],""confidence_score"":90.0}"
Business Data Analyst (US - Contract),"Business Data Analyst (US - Contract)

Salary/Hourly Rate:
$51 - $61 per hour

Onsite/Remote:
This is a hybrid role in either Seattle, WA, Austin, TX, or Springfield, MO; candidates will be required onsite 3 days per week (Tuesday – Thursday)

Position Overview:

Expedia Group brands power global travel for everyone, everywhere. We design cutting-edge tech to make travel smoother and more memorable, and we create groundbreaking solutions for our partners. Our diverse, vibrant, and welcoming community is essential in driving our success. We’re building a more open world. Join us.

Why Join Us?

To shape the future of travel, people must come first. Guided by our Values and Leadership Agreements, we foster an open culture where everyone belongs, differences are celebrated and know that when one of us wins, we all win.

Our Global Procurement organization is looking for a passionate, motivated Business Data Analyst. The successful candidate will turn data into information, and help turn information into insight that will drive business decisions. Their responsibilities will include conducting full lifecycle analysis, including requirements, activities and design. The successful candidate will develop analysis and reporting capabilities; they will also monitor performance plans to identify improvement opportunities. This is a temporary 12-month assignment.

Responsibilities of the Business Data Analyst:

Seek out, gather and interpret data, analyze results and provide both ongoing and custom/ad hoc reports
Participate in development and implementation of data collection techniques, data analytics and other strategies that optimize efficiency and enable reporting
Acquire data from primary and secondary data sources (combining and/or splitting as needed) and maintain databases, dashboards and other management resources
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and scrub data from various reports and raw data sources
Work with management to prioritize business and information needs, build analyses, reports and presentations that enable insight and decisions
Identify and define process improvement opportunities
Assist in the development implementation, monitoring and measurement of key performance indicators
Assist in translating findings into actionable and directional plans
Assist Leadership by synthesizing data into useable presentation material (PowerPoint, Excel, etc)

Qualifications of the Business Data Analyst:

Bachelor’s degree in Business, Technology, or another relevant field is preferred
Proven working experience as a Data Analyst or Business Data Analyst
Knowledge of and experience with reporting packages (e.g., Business Objects, Oracle Business Intelligence), and databases (e.g., SQL)
Knowledge of statistics and experience using statistical packages for analyzing datasets (e.g., Excel, Tableau, Power BI)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and compiling results in a cohesive and presentable format- including aptitude in Microsoft PowerPoint
Specific experience and proficiency in various business systems and applications
Critical: Excel, PowerPoint
Helpful: Salesforce, Oracle, Tableau
Experience working with a procurement/purchasing or payables function is a plus

Please note contractors are engaged to provide services to Expedia Group on a temporary basis in connection with a specific assignment. Contractors are hired and employed through Atrium, our third-party payrolling partner.

As a woman-owned firm, Atrium values diversity. We are an equal opportunity employer and will consider all applications without regard to race, sex, age, color, religion, national origin, veteran status, disability, genetic information or any other characteristic protected by law. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

This job posting is for a temporary role as an employee of Atrium on assignment at Expedia. The individual selected for this role will be offered the role as an employee of Atrium; compensation, medical benefits, fringe benefits and other terms and conditions of employment shall be presented by Atrium upon offer. The pay rate range provided is a reasonable estimate of the anticipated compensation range for this job at the time of posting. The actual pay rate will be based on a number of factors, including skills, competencies, experience, location and/or being pursued and other job-related factors permitted by law. In addition, this role will be eligible for overtime pay, in accordance with federal and state requirements.

No C2C or Third-Party Vendors","{""role_summary"":""The Business Data Analyst will turn data into information and insights to drive business decisions, conducting full lifecycle analysis, developing reporting capabilities, and identifying improvement opportunities."",""key_terms"":[{""term"":""Data Analytics"",""explanation"":""The process of examining data sets to draw conclusions and identify patterns or trends.""},{""term"":""Business Objects"",""explanation"":""A reporting package used to create and manage business intelligence reports.""},{""term"":""SQL"",""explanation"":""A programming language used to manage and manipulate data in relational database management systems.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""}],""skill_priorities"":{""must_have"":[""Excel"",""PowerPoint"",""SQL"",""Data Analysis"",""Reporting""],""nice_to_have"":[""Salesforce"",""Oracle"",""Tableau"",""Business Objects"",""Procurement/Purchasing or Payables function experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for identifying and analyzing trends in complex data sets?"",""example_answer"":""I typically start by gathering and cleaning the data, then use statistical packages like Excel or Tableau to identify patterns and trends. I also consider the business context and requirements to ensure my analysis is relevant and actionable.""},{""question"":""How do you prioritize business and information needs when building analyses and reports?"",""example_answer"":""I work closely with management to understand their requirements and identify key performance indicators. I then use this information to develop targeted analyses and reports that meet their needs and enable informed decision-making.""}],""red_flags"":[""Lack of experience with data analysis and reporting tools"",""Inability to communicate complex data insights effectively"",""Limited understanding of business operations and requirements""],""confidence_score"":90.0}"
"Data Analyst, Advertising","U.S. News & World Report is a multifaceted digital media company dedicated to helping citizens, consumers, business leaders and policy officials make important decisions in their lives. We publish independent reporting, rankings, data journalism and advice that has earned the trust of our readers and users for nearly 90 years. Our platforms on usnews.com include Education, Health, Money, Travel, Cars, News and 360 Reviews.
We reach more than 40 million people monthly during moments when they are most in need of expert advice and motivated to act on that advice directly on our platforms. Our signature franchises include our “Best” series of consumer guides on colleges, graduate schools, hospitals, diets, cars, financial services and more. These guides provide an easy-to-digest list for consumers to better understand and compare when making their decisions. We continue to publish annual guides of the authoritative Best Colleges and Best Hospitals rankings on our website and in print. And our U.S. News Live flagship conferences highlight important national conversations including Healthcare of Tomorrow and Healthiest Communities.

We believe in having a broad range of talent and backgrounds at U.S. News. We strive to maintain a welcoming workplace where everyone is given an opportunity to succeed and contribute to their fullest. Learn more about our Diversity, Equity and Inclusion initiative.

Your role in helping us shape the future:
U.S. News empowers everyone to thrive. We are hiring a Senior Data Analyst to help empower stakeholders and business units with clear data visualizations and actionable takeaways.
This hands-on role is ideal for someone with strong analytical skills and a strong understanding of the marketing landscape to distill insights from disparate data sets and uncover revenue-generating opportunities. The successful candidate will be exposed to many parts of the business, including product, marketing, software development and sales. You will directly contribute to top-line revenue growth within the robust and multi-dimensional advertising business at U.S. News.

Are you up to the challenge?
Build and maintain data visualization suites surfacing advertising revenue for internal teams and stakeholders
Oversee project management of new initiatives with advertising partners
Lead end-to-end integration of new ad tech partners
Analyze reporting & develop yield-driving insights across partners, wrappers and environments
Execute on cutting-edge monetization opportunities surfaced by ad tech partners including Amazon, Microsoft, Google and The Trade Desk.
Coordinate with stakeholders to facilitate troubleshooting integrations, launching new ad products and testing ad stack configurations
Present new business opportunities based on analysis of performance data
Leverage data unification tools to supply actionable insights with regard to industry trends
Conduct periodic training sessions to keep internal teams up-to-date on the digital advertising landscape

You should definitely have:
Three years to five years of experience in the digital advertising industry
Bachelor of Science or a Bachelor of Arts preferred; equivalent experience accepted
Working knowledge of Google Ad Manager and analytics tools such as Looker Studio, Google Analytics, and Supermetrics
Experience working with ad tech platforms including SSPs, DSPs and DMPs
Intermediate to advanced working knowledge of Microsoft Excel
Ability to analyze data and present a clear & compelling action plan based on your findings
Experience managing first-party audience data, including identifying new first-party data sources and audience segmentation opportunities
Effective time management skills - ability to juggle multiple tasks and prioritize to meet necessary deadlines
Exceptional troubleshooting, A/B testing and problem-solving abilities
Knowledge and awareness of current programmatic and digital ad technology trends; remain up to speed on new in-platform betas and testing opportunities
Understanding of ad tagging and site taxonomy

Preferred qualifications:
Fluency with SQL and ability to write queries and join siloed data sets
Familiarity with programming languages such as javascript, CSS and HTML
Knowledge of oRTB protocol
Understanding of common web data structures such as JSON
Experience with system integrations, data ingestion & ETL

What it’s like to work with us:
Talent is our best asset!
We invest in people with passion and potential who understand U.S. News’ dedication to our consumers.
Entrepreneurial, mission-driven culture with core values of quality and integrity
Focus on fostering personal and professional growth
Competitive benefits including paid vacation time, medical, tuition reimbursement, and training
Collaborative Work Environment ~ Fun, diverse, inclusive and ambitious co-workers

Other Job Info:
Candidates are encouraged to submit a cover letter.
These statements are intended to describe the general nature and level of work being performed by employees assigned to this job. This is not intended to be an exhaustive list of all responsibilities, duties, and skills required of employees assigned to this job.
U.S. News & World Report strongly encourages all employees to be fully vaccinated (including boosters).
The anticipated base salary for this position is $60,000 to $85,000. The actual base salary offered will depend on a variety of factors, including without limitation, the qualifications of the individual applicant for the position, years of relevant experience, level of education attained, certifications or other professional licenses held, interview performance, and if applicable, the location in which the applicant lives and/or from which they will be performing the job.","{""role_summary"":""A Senior Data Analyst role at U.S. News & World Report, responsible for empowering stakeholders and business units with clear data visualizations and actionable takeaways, contributing to top-line revenue growth in the advertising business."",""key_terms"":[{""term"":""Data Visualization"",""explanation"":""Presenting data in a clear and concise manner to facilitate understanding and decision-making.""},{""term"":""Ad Tech Partners"",""explanation"":""Companies that provide advertising technology solutions, such as Amazon, Microsoft, Google, and The Trade Desk.""},{""term"":""Yield-Driving Insights"",""explanation"":""Analyzing data to identify opportunities to increase revenue from advertising.""},{""term"":""Ad Stacks"",""explanation"":""A collection of technologies used to manage and optimize digital advertising.""},{""term"":""Programmatic and Digital Ad Technology Trends"",""explanation"":""Staying up-to-date with the latest developments and innovations in digital advertising.""}],""skill_priorities"":{""must_have"":[""Three to five years of experience in the digital advertising industry"",""Working knowledge of Google Ad Manager and analytics tools"",""Experience working with ad tech platforms"",""Intermediate to advanced working knowledge of Microsoft Excel"",""Ability to analyze data and present a clear action plan""],""nice_to_have"":[""Fluency with SQL"",""Familiarity with programming languages such as javascript, CSS and HTML"",""Knowledge of oRTB protocol"",""Understanding of common web data structures such as JSON"",""Experience with system integrations, data ingestion & ETL""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with data visualization and how you've used it to drive revenue growth in previous roles?"",""example_answer"":""In my previous role, I created data visualizations to showcase advertising revenue trends, which led to a 20% increase in revenue. I used tools like Looker Studio and Google Analytics to create interactive dashboards that stakeholders could easily understand.""},{""question"":""How do you stay current with the latest developments in programmatic and digital ad technology trends?"",""example_answer"":""I regularly attend industry conferences, read trade publications, and participate in online forums to stay up-to-date on the latest innovations and best practices in digital advertising.""}],""red_flags"":[""Lack of experience working with ad tech platforms"",""Inability to analyze data and present clear action plans"",""Limited knowledge of digital advertising industry trends""],""confidence_score"":90.0}"
Analista de datos,"¡Sé parte de Stefanini!
En Stefanini somos más de 30.000 genios, conectados desde 41 países, haciendo lo que les apasiona y co-creando un futuro mejor.

Estamos en búsqueda de nuestro próximo Data Analyst, responsable de la investigación y correcta documentación de las necesidades de datos que tenga el negocio. Será responsable de traducir los requerimientos de datos/información en solicitudes claras y entendibles para las áreas de Dominios de Datos, Tecnología y Producto para que puedan ser priorizados y atendidos.

Responsabilidades princiaples:
Realizar Data Assessment con áreas de Negocio para la conformación de dominios de datos:
Entrevistar al negocio, analizar del flujo de trabajo, estructura y procesos, en sesiones de observación
Matriz de Assessment/Matriz de Trazabilidad de datos
Interpretación y entrega de resultados
Construcción de consultas base (SQL, insumos) para su implementación por parte de los equipos de desarrollo
Asegurar que las soluciones de TI reflejen la efectividad necesaria para alcanzar los objetivos comerciales (validación y oportunidades de optimización)
Crear requisitos y documentos de flujo de trabajo claros y concisos
Incrementar la adopción del negocio de las soluciones de datos a través de la consistencia de datos
Validar la información mediante pruebas
Evaluación de calidad de datos
Diseño de modelos de datos (lógicos, BI)

Requisitos:
Análisis de negocios centrado en el dominio de datos y sistemas de inteligencia empresarial (>3 años)
Entrevistas con usuarios comerciales, recopilación de informes y requisitos de KPI (>3 años)
Análisis de datos, unión de diferentes fuentes con SQL (nivel avanzado)
Documentación de requisitos y flujos de trabajo
Diagramado de soluciones de datos (alto nivel)
Traducción de requisitos para Ingeniería y Arquitectura de datos, y soluciones BI
Crear, analizar y entregar métricas clave utilizando paneles, informes y presentaciones (pptx, Google Slides, BI dashboards)
Construir modelos analíticos avanzados (indispensable)
Habilidades sólidas de programación (deseable)
Experiencia con metodologías Agile (SCRUM, Kanban)

Herramientas:
Office Suite (avanzado)
SQL (avanzado)
Tableau/Looker/Power BI (intermedio)
Marco de trabajo Ágiles
Python (deseable)

Habilidades:
Comunicación efectiva con directivos y equipos técnicos, de desarrollo (indispensable)
Capacidad analítica financiera (prioritario)
Conocimientos sólidos en estadística y probabilidad (indispensable)
Pensamiento estructurado (indispensable)
Liderazgo (indispensable)
Autogestión (indispensable)
Análisis de ETL y flujos de datos (prioritario)

¿Qué obtendrás al laborar con nosotros?
Sueldo acorde a experiencia.
Prestaciones de Ley.
Prestaciones Superiores a la Ley.
Bonos mensuales y Vales de Despensa.
Cartelera de convenios y descuentos.
Plan de carrera y crecimiento profesional.","{""role_summary"":""The Data Analyst is responsible for investigating and documenting business data needs, translating data requirements into clear requests for Data Domains, Technology, and Product teams, and ensuring data solutions meet business objectives."",""key_terms"":[{""term"":""Data Assessment"",""explanation"":""A process of evaluating business data needs to inform data solutions.""},{""term"":""Dominios de datos"",""explanation"":""Data domains, referring to specific areas of data management and analysis.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load, a process of extracting data from sources, transforming it into a usable format, and loading it into a target system.""},{""term"":""KPI"",""explanation"":""Key Performance Indicators, metrics used to measure business performance.""},{""term"":""SQL"",""explanation"":""Structured Query Language, a programming language used for managing and analyzing relational databases.""}],""skill_priorities"":{""must_have"":[""Data analysis"",""SQL"",""Business acumen"",""Communication skills"",""Statistical knowledge"",""Leadership skills""],""nice_to_have"":[""Programming skills"",""Agile methodologies experience"",""Python knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach a data assessment for a new business area?"",""example_answer"":""I would start by conducting stakeholder interviews to understand their data needs, then analyze the workflow and processes to identify key data points. Next, I would create a data assessment matrix to prioritize data requirements and finally, present my findings to the relevant teams.""},{""question"":""How do you ensure data solutions meet business objectives?"",""example_answer"":""I work closely with business stakeholders to understand their objectives and develop data solutions that address their needs. I also validate data solutions through testing and evaluation to ensure they meet business requirements.""}],""red_flags"":[""Lack of experience with data analysis and SQL"",""Inability to communicate technical information to non-technical stakeholders"",""Limited understanding of business acumen and objectives""],""confidence_score"":90.0}"
Data Specialist,"About the Role
We are looking for a scientific data specialist to support efforts in computational drug discovery. This position offers the opportunity to work closely with researchers in machine learning, chemistry, and biology to curate, process, and analyze complex datasets. The ideal candidate will contribute to shaping data strategies for research applications in a collaborative and dynamic environment.
Key Responsibilities
Organize, process, and analyze biological and chemical datasets for research and development.
Collaborate with interdisciplinary teams to integrate machine learning approaches into drug discovery efforts.
Develop data workflows and ensure quality control across various research datasets.
Work within Linux-based environments and utilize Python for data processing.
Ideal Qualifications
Master’s or Ph.D. in medicinal chemistry, pharmacology, computational biology, or a related discipline.
Hands-on laboratory experience, with familiarity in assays and drug discovery techniques.
Proficiency in Linux environments and scripting languages such as Python.
Strong problem-solving skills and ability to work in an interdisciplinary setting.
Why Join?
This is an opportunity to contribute to cutting-edge research in molecular sciences while working alongside leading experts in the field. The position offers a competitive salary, performance-based bonuses, and comprehensive benefits, including relocation assistance.
For more information, get in touch with us!","{""role_summary"":""Support computational drug discovery by curating, processing, and analyzing complex datasets, collaborating with researchers in machine learning, chemistry, and biology."",""key_terms"":[{""term"":""Computational drug discovery"",""explanation"":""Using computational methods to identify and develop new drugs.""},{""term"":""Machine learning approaches"",""explanation"":""Using artificial intelligence and algorithms to analyze and make predictions from data.""},{""term"":""Interdisciplinary teams"",""explanation"":""Teams consisting of people from different fields of study, such as biology, chemistry, and computer science, working together.""},{""term"":""Data workflows"",""explanation"":""A series of steps to process and analyze data, ensuring quality control and efficiency.""},{""term"":""Linux-based environments"",""explanation"":""Computer systems using the Linux operating system, often used for data processing and analysis.""}],""skill_priorities"":{""must_have"":[""Python"",""Linux environments"",""Data analysis"",""Problem-solving skills""],""nice_to_have"":[""Hands-on laboratory experience"",""Familiarity with assays and drug discovery techniques""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to process and analyze a complex dataset? How did you approach it?"",""example_answer"":""In my previous role, I worked on a project where I had to analyze a large dataset of genomic data. I used Python and Linux to process the data, and then developed a workflow to ensure quality control. I was able to identify key patterns and trends in the data, which informed our research decisions.""},{""question"":""How do you stay current with new developments in machine learning and computational biology?"",""example_answer"":""I regularly read industry publications and attend conferences to stay up-to-date on the latest advancements in machine learning and computational biology. I also participate in online forums and discussion groups to learn from others in the field.""}],""red_flags"":[""Lack of experience working in interdisciplinary teams"",""Inability to work in a Linux-based environment""],""confidence_score"":90.0}"
Data Analytics Internship,"Who We Are:

Brightwell is a pioneering payments company dedicated to providing innovative solutions and technology for global money transfers while navigating the intricate landscape of regulatory requirements. Through strategic partnerships and technological advancements, Brightwell facilitates cross-border payments, offering a range of options including bank transfers, mobile wallets, and cash transactions. With a focus on unparalleled fraud detection and transaction monitoring supported by a team of global payment experts, Brightwell empowers businesses and individuals to seamlessly manage and move money worldwide.



What We Need:

We’re searching for a Data Analyst Intern to join our crew. As our Data Analyst Intern, you will work closely with the team to create automated reporting that will be used by internal and external stakeholders. Reporting is currently largely manual, so we are looking for someone ready to jump in to help create change.



Open to:

Undergraduate students majoring in Data Analytics or similar
Rising seniors and/or rising juniors only



What You’ll Do:

The goal for our Data Analyst Intern is to have a completed project(s) at the end of the internship that they can showcase. Here are some of the things you will be working on and will be able to take ownership of:

Building dashboards to identify trends
Analysis of various data points and their relationships to each other
Automation of manual reports
Building relationships with internal stakeholders to ensure alignment in reporting

As a Data Analyst Intern, you have:

Taken at least one finance course and have a basic understanding of financial principles
Experience working with SQL and SQL reporting
Strong working knowledge of Microsoft Office software, especially Excel
Experience with Tableau or PowerBI is nice to have but not required
Possess good critical thinking, communication, and presentation skills.
Flexibility and ability to adapt to changes quickly; always willing to roll up your sleeves and get things done.
Ability to take ownership of your work.
A coachable mentality and eagerness to learn more.



Details:

This internship will be part-time, on average 15-20 hours/week. Hours are flexible and will be decided between you and your director. Most time will be spent working on-site at our office in the Smyrna/Vinings area (4401 Northside Pkwy, Atlanta, GA 30327).
This is a PAID internship. Interns will be paid $20.00/hr.



Brightwell is an equal opportunity employer (EOE) committed to employing a diverse workforce and sustaining an inclusive culture.

Powered by JazzHR

iWgU34Yjo8","{""role_summary"":""Assist in creating automated reporting for internal and external stakeholders as a Data Analyst Intern, working closely with the team to identify trends, analyze data, and build relationships with stakeholders."",""key_terms"":[{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing data in relational database management systems.""},{""term"":""Tableau/PowerBI"",""explanation"":""Data visualization tools used to create interactive dashboards and reports.""},{""term"":""Financial principles"",""explanation"":""Basic understanding of financial concepts, such as accounting, budgeting, and financial analysis.""}],""skill_priorities"":{""must_have"":[""SQL"",""Microsoft Office (Excel)"",""Finance course"",""Critical thinking"",""Communication"",""Presentation skills""],""nice_to_have"":[""Tableau or PowerBI""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to analyze a complex data set and present your findings to a non-technical audience?"",""example_answer"":""In my previous internship, I was tasked with analyzing customer purchase behavior. I used SQL to extract the data, created visualizations in Excel, and presented my findings to the marketing team. They were able to use my insights to inform their campaign strategy.""},{""question"":""How do you stay organized when working on multiple projects with tight deadlines?"",""example_answer"":""I prioritize my tasks using the Eisenhower Matrix, focusing on the most critical tasks first. I also use project management tools like Trello or Asana to keep track of my progress and deadlines.""}],""red_flags"":[""Lack of experience with SQL or data analysis"",""Inability to communicate complex data insights effectively""],""confidence_score"":85.0}"
Senior Data Analysis Specialist,"Job Title: Senior Data Analysis Specialist I
Reports to: Sr. Director Operations Management
Job Location: Bellevue, WA
Job Status: Exempt, Full Time

About SHEIN
SHEIN is a global online fashion and lifestyle retailer, offering SHEIN branded apparel and products from a global network of vendors, all at affordable prices. Headquartered in Singapore, SHEIN remains committed to making the beauty of fashion accessible to all, promoting its industry-leading, on-demand production methodology, for a smarter, future-ready industry. Founded in 2012, SHEIN has more than 16,000 employees operating from offices around the world and continues to expand operations globally. Join SHEIN and be the future!

Position Summary
SHEIN is hiring the Senior Data Analysis Specialist I for OM Team based in Seattle. The OM team is a group of operational leaders driving KPI management, tracking actual operation performance versus plan, reporting the corresponding cost drivers, diving deep on savings opportunities, and helping to hold the business owners accountable. You will use solid operation knowledge and business acumen to build data analytical models, interpret data, draw conclusions, and make recommendations at an insightful level that brings the teams on the same page, prioritize programs and resources, drive improvements, and deliver results.

We’re seeking a full-time Senior Data Analysis Specialist I for our City-based corporate office.

Job Responsibilities
Analyze logistics performance metrics, including transportation spend, delivery times, inventory levels, and warehouse efficiency.
Develop and maintain dashboards and reports to visualize key logistics data for stakeholders.
Collaborate with cross-functional teams to identify data-driven solutions for logistics challenges.
Conduct in-depth analyses to support operational improvements and process optimization.
Monitor trends in logistics data and provide timely insights to management.
Ensure data accuracy and integrity by implementing best practices in data collection and analysis.
Assist in the development of forecasting models to predict logistics needs and performance.
Mentor and guide junior analysts in data analysis techniques and methodologies.

Job Requirements
Bachelor's degree in Data Science, Statistics, Logistics, Supply Chain Management, or a related field; Master's degree preferred.
5+ years of experience in data analysis, with a focus on logistics or supply chain metrics.
Proficiency in analytical tools and programming languages such as SQL, Python, or R.
Experience with data visualization tools like Tableau, Power BI, or similar platforms.
Strong knowledge of logistics and supply chain concepts and metrics.
Excellent problem-solving skills and attention to detail.
Strong communication skills, with the ability to present complex data insights to non-technical stakeholders.
Experience with statistical analysis and modeling techniques.
Pay
$86,600.00 min. – $132,600.00 max annually. Plus an annual bonus is offered.
Benefits and Culture
Healthcare (medical, dental, vision, prescription drugs)
Health Savings Account with Employer Funding
Flexible Spending Accounts (Healthcare and Dependent care)
Company-Paid Basic Life/AD&D insurance
Company-Paid Short-Term and Long-Term Disability
Voluntary Benefit Offerings (Voluntary Life/AD&D, Hospital Indemnity, Critical Illness, and Accident)
Employee Assistance Program
Business Travel Accident Insurance
401(k) Savings Plan with discretionary company match and access to a financial advisor
Vacation, paid holidays, floating holidays, and sick days
Employee discounts
Free weekly catered lunch
Free swag giveaways
Annual Holiday Party
Invitations to pop-ups and other company events
Complimentary daily office snacks and beverages


SHEIN is an equal opportunity employer committed to a diverse workplace environment.","{""role_summary"":""The Senior Data Analysis Specialist I will analyze logistics performance metrics, develop dashboards, and provide data-driven insights to support operational improvements and process optimization."",""key_terms"":[{""term"":""KPI management"",""explanation"":""Key Performance Indicator management, which involves tracking and analyzing metrics to measure business performance.""},{""term"":""On-demand production methodology"",""explanation"":""A production approach that allows for rapid response to customer demand, enabling just-in-time production and minimizing inventory.""},{""term"":""Cost drivers"",""explanation"":""Factors that contribute to the overall cost of a business operation, such as labor, materials, and transportation.""},{""term"":""Data analytical models"",""explanation"":""Statistical and mathematical techniques used to analyze and interpret complex data sets.""},{""term"":""Data visualization tools"",""explanation"":""Software platforms used to create interactive and dynamic dashboards and reports to communicate data insights effectively.""}],""skill_priorities"":{""must_have"":[""Data analysis"",""Logistics or supply chain metrics"",""SQL"",""Python or R"",""Data visualization tools"",""Statistical analysis and modeling techniques""],""nice_to_have"":[""Master's degree"",""Experience with forecasting models""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would analyze logistics performance metrics to identify areas for improvement?"",""example_answer"":""I would start by collecting data on transportation spend, delivery times, inventory levels, and warehouse efficiency. Then, I would use statistical techniques to identify trends and correlations, and finally, I would develop a dashboard to visualize the insights and present them to stakeholders.""},{""question"":""How do you ensure data accuracy and integrity in your analysis?"",""example_answer"":""I implement best practices in data collection and analysis, such as data validation, data normalization, and data quality checks. I also document my methodology and assumptions to ensure transparency and reproducibility.""}],""red_flags"":[""Lack of experience with logistics or supply chain metrics"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
CX Analyst,"Job title: Customer Experience Analyst
Other similar titles: CX Analyst, Voice of Customer Analyst, VoC Analyst, Customer Insights Analyst, Customer Support Analyst.
Description:
The Customer Experience (CX) team is focused on improving customer experiences across the end-to-end customer journey. As the Customer Experience Analyst you will be part of a global customer experience practice dedicated to listening and learning from our customers, harnessing the power of customer insights to drive and influence business improvements and bolster customer centric decision-making across the business. You will play a pivotal role in driving customer satisfaction and loyalty by analyzing insights and feedback, identifying areas for improvement, and partnering with cross-functional teams to develop and implement strategies that enhance the overall customer experience. Leveraging your strong background in CX/VoC and expertise in data analysis and storytelling, your passion for customer centricity, you will help shape the future of our customer experience program and contribute to the growth and success of our organization.
Responsibilities
Identify opportunities areas and customer experience gaps across support channels using various systems and data sources (customer tickets, customer feedback, etc.)
Work with customer support program managers and leaders to report on overall program performance and provide recommendations for program improvements
Monitor customer feedback to identify emerging trends and issues, performing deep dive analysis to uncover wins and opportunities.
Integrate customer feedback data with other transactional, operational, and behavioral data sources to create a comprehensive picture of experience drivers.
Advocate for customers and influence corrective actions through periodic and ad-hoc reporting, proactively evangelizing insights among key stakeholders.
Collaborate with cross-functional teams to identify root causes of customer issues within support functions and develop action plans to remediate and measure effectiveness.
Translate the customer support and VOC data and metrics into actionable insights that influence customer experience improvements and help increase the operation’s efficiency
Utilize various systems and tools (Tableau, Excel, Salesforce, Hive) to gather and analyze various sources of data to deliver insights
Gather business requirements and collaborate with internal and external cross-functional partners in operationalizing the insights
Design and build insight-driven reports and dashboards that provide real-time and easy access to customer insights
Bring insights and recommendations to the forefront of stakeholders and executives’ mindshare via engaging presentations
Required Qualifications
6+ years of experience in data analytics, including experience in customer feedback or survey analysis, statistical analysis, data science, or related fields
3+ years of experience in customer experience, customer support, customer care, or customer insights analytics
Proficiency in crafting compelling stories using multiple sources of data to provide actionable insights tailored to stakeholders’ needs
Experience creating reports, visualizations, and dashboards and communicating results and analyses to technical and non-technical audiences
Experience working with Customer Experience or Voice of Customer metrics (NPS, CSAT, etc.), surveys, and customer feedback
Experience working with customer support operational metrics
Strong analytical skills working with large datasets and statistical analysis methods; comfortable using SQL.
Experience with statistical analytics techniques and using R or Python or a similar scripting language/tool for analysis
Demonstrated ability to work collaboratively with cross-functional teams.
Excellent data-led storytelling with the ability to convey complex insights to non-technical stakeholders
Desired Qualifications
Degree in Analytics, Marketing, Business, Statistics, Mathematics, Finance, Computer/Data Science, Engineering, Economics, or related field
Experience working with Salesforce
Experience working with customer experience platforms (e.g., Medallia, Qualtrics)
Familiarity with consumer electronics or retail business
Knowledge of predictive analytics or ML/AL techniques is a plus","{""role_summary"":""The Customer Experience Analyst is responsible for analyzing customer feedback and data to identify areas for improvement and drive business improvements that enhance the overall customer experience."",""key_terms"":[{""term"":""CX"",""explanation"":""Customer Experience, referring to the overall experience a customer has when interacting with a company.""},{""term"":""VoC"",""explanation"":""Voice of Customer, referring to the process of collecting and analyzing customer feedback to understand their needs and preferences.""},{""term"":""NPS"",""explanation"":""Net Promoter Score, a metric used to measure customer satisfaction and loyalty.""},{""term"":""CSAT"",""explanation"":""Customer Satisfaction, a metric used to measure how satisfied customers are with a product or service.""},{""term"":""SQL"",""explanation"":""Structured Query Language, a programming language used for managing and analyzing data in relational database management systems.""},{""term"":""R/Python"",""explanation"":""Programming languages used for statistical analysis, data visualization, and machine learning.""}],""skill_priorities"":{""must_have"":[""Data analysis"",""Customer experience"",""Statistical analysis"",""Storytelling"",""SQL"",""R/Python""],""nice_to_have"":[""Salesforce"",""Customer experience platforms (e.g., Medallia, Qualtrics)"",""Predictive analytics or ML/AL techniques"",""Familiarity with consumer electronics or retail business""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for analyzing customer feedback and identifying areas for improvement?"",""example_answer"":""I would start by collecting and categorizing customer feedback from various sources, then use statistical analysis and data visualization techniques to identify trends and patterns. From there, I would work with cross-functional teams to develop action plans to address the identified areas for improvement.""},{""question"":""How do you stay up-to-date with the latest developments in customer experience analytics and metrics?"",""example_answer"":""I regularly read industry publications and attend conferences to stay current on the latest trends and best practices in customer experience analytics. I also network with other professionals in the field to learn from their experiences and share my own knowledge.""}],""red_flags"":[""Lack of experience working with customer feedback and survey analysis"",""Inability to communicate complex insights to non-technical stakeholders""],""confidence_score"":90.0}"
Analyst,"At TechOp Solutions, we are committed to delivering innovative technology and operational solutions that drive mission success. We are seeking a highly motivated Analyst to join our dynamic team. In this role, you will leverage data-driven insights, analytical expertise, and problem-solving skills to support critical business and operational initiatives. If you thrive in a fast-paced environment and are passionate about optimizing processes and driving strategic decisions, we want to hear from you!

The ERO Law Enforcement Systems and Analysis (LESA) division is responsible for helping inform the development of ERO strategies and supporting continuous enhancement of ERO business processes to execute those strategies. Through data collection and analysis and technology and process improvements, LESA delivers tools, studies, and recommendations that assist ICE's decision-making and planning (strategic, business, and operational). LESA studies ICE's operations and resources (personnel, processes, technology, and infrastructure) to find areas for continuous improvement.

Responsibilities Include:

Writing queries (in SQL or Python) via Databricks to wrangle data, compiling Excel reports, performing data validation on work products, performing code reviews (SQL, Python), and providing demonstrations to client stakeholders
Conducts research and prepares management, organizational and business analyses and forecasts using data science tools
Work independently as a part of a workstream to provide analytical and statistical support
Generate management tools that effectively control programs and generate reports; and supports the programmatic development of operational applications of the tools or analysis that are focused around operations research and document findings
Develop custom automation solutions to improve operational efficiencies
Prepare briefings and issue papers, studies, recommendation, responses and reports about the mission, activities, and related statistics
Develop, test, and deploy new data science models according to agency needs
Identify new data sets which would enhance the accuracy of existing models and dashboards
Analyze the impact of the effects of a regulation, policy, program, etc. and the effects of changes in budget, staffing or policy/priority changes on resources, performance, or schedule
Automate manual reports via Python scripts in Databricks following best practices


Requirements

Strong written and oral communication;
Bachelor's degree and 0-3 years of experience
SQL, Excel, Qlik, Python, Databricks, and other Business Intelligence tools","{""role_summary"":""Support critical business and operational initiatives by leveraging data-driven insights, analytical expertise, and problem-solving skills to optimize processes and drive strategic decisions."",""key_terms"":[{""term"":""Data-driven insights"",""explanation"":""Using data to inform business decisions and drive strategic initiatives.""},{""term"":""ERO strategies"",""explanation"":""Strategies developed by the Enforcement and Removal Operations (ERO) division to achieve its mission.""},{""term"":""Databricks"",""explanation"":""A cloud-based platform for working with big data and performing data engineering, analytics, and machine learning tasks.""},{""term"":""Operations research"",""explanation"":""The application of analytical methods and mathematical models to optimize decision-making and problem-solving in complex systems.""},{""term"":""Data science tools"",""explanation"":""Software and techniques used to extract insights and knowledge from data, such as machine learning, statistical modeling, and data visualization.""}],""skill_priorities"":{""must_have"":[""SQL"",""Excel"",""Python"",""Databricks"",""Strong written and oral communication""],""nice_to_have"":[""Qlik"",""Business Intelligence tools""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach optimizing a business process using data-driven insights?"",""example_answer"":""I would start by identifying the key performance indicators (KPIs) for the process and then use data visualization tools to analyze the current state of the process. Next, I would develop a hypothesis for improvement and design an experiment to test it. Finally, I would implement the changes and monitor the results to ensure the desired outcomes are achieved.""},{""question"":""How do you stay current with new developments in data science and analytics?"",""example_answer"":""I regularly read industry blogs and attend webinars to stay up-to-date on the latest trends and tools in data science. I also participate in online forums and discussion groups to learn from others and share my own knowledge and experiences.""}],""red_flags"":[""Lack of experience with Databricks or similar cloud-based data platforms"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":85.0}"
Data Analytics Analyst - US Based Remote,"Lensa is the leading career site for job seekers at every stage of their career. Our client, Anywhere Real Estate, is seeking professionals in Seattle, WA. Apply via Lensa today!

Job Title: Data Analyst / Data Operations

Company Overview

Join our dynamic team where we leverage cutting-edge technology to drive data-driven decisions. We are committed to empowering our customers with actionable insights and superior outcomes. We value innovation, integrity, and excellence.

Job Description

We are seeking a dedicated and analytical Data Analyst to work on data and analytics organizations’ operations with 1 to 3 years of experience in the data field. The ideal candidate will manage vendor relationships, handle billing and invoice validation, oversee contracts, and track key metrics. This role requires strong analytical skills, excellent written and oral communication and presentation skills, attention to detail, and the ability to work collaboratively with various stakeholders.

Key Responsibilities

Coordinate with vendors to resolve issues, escalations, action plans, etc.
Conduct surveys, gather feedback and present aggregated data in an organized way.
Review and validate invoices from different vendors to ensure accuracy and compliance with contracts.
Gather, maintain, and publish metrics for the organization working with the leadership team. Also, monitor performance and identify areas for improvement.
Analyze data to support decision making and provide actionable insights.
Prepare and present reports and presentations on organizational and operational areas.
Ensure data integrity by verifying data regularly.
Work closely with matrixed cross functional teams to identify opportunities for process and efficiency improvements.

Qualifications And Skills

Bachelor’s degree in Data Analytics, Information Systems, Computer Science, or a related field.
Proficiency in Excel, including functions and macros.
Strong analytical skills and attention to detail.
Strong organizational and time management skills.
Excellent verbal and written communication skills.
Creative skills to put together presentations in MS PowerPoint.
Ability to work effectively in a team environment and collaborate with various stakeholders at different levels in a matrixed team environment.
Ability to adapt to changing priorities and manage multiple tasks simultaneously.
Basic understanding of data governance, data quality, data engineering, data analytics, BI reporting, and data science is a plus.
Background in working with cloud platforms such as AWS, Azure, or GCP is a plus.
Familiarity with Agile methodology is a plus.

Additional Information

1-3 years’ experience in the field.
Eager to learn and adapt in a fast-paced environment.
Ability to aggregate and present data and communicate effectively to different levels of leadership.

Anywhere Real Estate Inc. (http://www.anywhere.re/)  (NYSE: HOUS) is on a mission to empower everyone’s next move. Home to some of the most recognized brands in real estate Better Homes and Gardens® Real Estate (https://www.bhgre.com/) , Century 21® (https://www.century21.com/) , Coldwell Banker® (https://www.coldwellbanker.com/) , Coldwell Banker Commercial® (https://www.cbcworldwide.com/) , Corcoran® (https://www.corcoran.com/) , ERA® (https://www.era.com/) , and Sotheby's International Realty® (https://www.sothebysrealty.com/eng)

The Anywhere portfolio includes franchise and brokerage operations as well as national title, settlement, and relocation companies and nationally scaled mortgage origination and underwriting joint ventures.  Supporting approximately 1.5 million home transactions in 2021, Anywhere is focused on simplifying, digitizing and integrating the real estate transaction for all consumers, no matter where they may be in their home buying and selling journey.  With innovative products and technology, Anywhere fuels the productivity of its approximately 196,200 independent sales agents in the US and approximately 136,400 independent sales agents in 118 other countries and territories.

At Anywhere Real Estate, diversity fuels success – for our company, for our employees, and for our industry. We strive to be a top destination for diverse talent, committed to creating a culture of belonging that empowers everyone’s next move. We pursue talent – strategic thinkers who are eager to always find a better way, relentlessly focus on talent, obsess about growth, and achieve exceptional results. We value diversity – respecting backgrounds, cultures, perspectives, and beliefs. We develop our diverse talent base – through increasing representation in executive key leadership roles with actions including mentorship programs and partnerships with real estate associations that promote diversity and inclusion. Read more about our company’s diversity, equity, and inclusion efforts in our annual Corporate Social Responsibility Report (https://assets.website-files.com/633f08923c4c519693723aa5/63f7690462db639dcd8b18de_Anywhere%20CSR%20Report%202022.pdf) .

You’ll find our commitment to diversity reflected in our achievements:

Recognized as one of the World’s Most Ethical Companies since 2011.
Anywhere has also been designated a Great Place to Work since 2019.
Recognized by Fortune as one of America’s Most Innovative Companies.
Honored by Forbes as one of the World’s Best Employers for Diversity and Top Female Friendly Companies.

With a diverse employee population, we know we will succeed together and move real estate to what’s next. We hope you’ll join us.

EEO Statement: EOE including disability/veteran","{""role_summary"":""The Data Analyst / Data Operations role at Anywhere Real Estate involves managing vendor relationships, handling billing and invoice validation, overseeing contracts, and tracking key metrics. The ideal candidate will have strong analytical skills, excellent communication and presentation skills, and the ability to work collaboratively with various stakeholders."",""key_terms"":[{""term"":""Data Governance"",""explanation"":""The process of ensuring the quality, security, and integrity of an organization's data.""},{""term"":""Data Quality"",""explanation"":""The process of ensuring the accuracy, completeness, and reliability of an organization's data.""},{""term"":""Data Engineering"",""explanation"":""The process of designing, building, and maintaining the infrastructure that stores, processes, and retrieves large datasets.""},{""term"":""BI Reporting"",""explanation"":""Business Intelligence reporting involves using data visualization tools to present complex data insights to stakeholders.""},{""term"":""Agile Methodology"",""explanation"":""An iterative approach to project management that emphasizes flexibility, collaboration, and continuous improvement.""},{""term"":""Cloud Platforms"",""explanation"":""Cloud computing platforms such as AWS, Azure, or GCP provide on-demand access to a shared pool of computing resources.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in Data Analytics, Information Systems, Computer Science, or a related field"",""Proficiency in Excel, including functions and macros"",""Strong analytical skills and attention to detail"",""Excellent verbal and written communication skills"",""Ability to work effectively in a team environment and collaborate with various stakeholders""],""nice_to_have"":[""Basic understanding of data governance, data quality, data engineering, data analytics, BI reporting, and data science"",""Background in working with cloud platforms such as AWS, Azure, or GCP"",""Familiarity with Agile methodology""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for validating invoices from different vendors?"",""example_answer"":""I would first review the contract terms to ensure accuracy, then verify the invoice details against the agreed-upon rates and services. If any discrepancies are found, I would escalate the issue to the vendor and work with them to resolve it.""},{""question"":""How do you ensure data integrity in your work?"",""example_answer"":""I regularly verify data against source systems, perform data quality checks, and implement data validation rules to ensure accuracy and consistency.""}],""red_flags"":[""Lack of experience working with data analytics tools and technologies"",""Inability to effectively communicate complex data insights to non-technical stakeholders"",""Limited experience working in a fast-paced, dynamic environment""],""confidence_score"":90.0}"
Data Analyst Consultant,"We are currently looking for a passionate Data Analyst Consultant to join our team in Boston! This role is hybrid and will require 1-2 days of onsite work in New Bedford, MA.

WHO ARE WE?
MIGSO-PCUBED is a consulting firm that focuses solely on Project, Program, and Portfolio Management and Change Management. We work with clients in a variety of sectors such as Financial Services, Energy, Aerospace and Defense, and Automotive. You will have the opportunity to vary your experience and support our leading clients in these areas!

We are looking for someone who is eager to learn and develop project plans to enable quality decision making while delivering added value. You should be a logical thinker, adept at collecting, compiling, analyzing and presenting data to key stakeholders. You should have the ability to build and foster client relationships , and focus on service delivery, quality work product, and exceeding project deliverables.

YOUR NEXT CHALLENGE:
· Creating dashboards in Power BI/Tableau/Qlik Sense or other relevant tools
· Gathering requirements from business stakeholders and translating into technical requirements
· Normalizing, cleaning, and procuring data from various sources (Internal/External)
· Creating, managing, and communicating data models
· Understanding commonly used business continuity and collaboration tools (SharePoint, MS Teams, Power Automate, etc)
· Knowledge of machine learning, natural language processing, robotic process automation, and statistical modeling are a huge plus
· Practical experience working in Waterfall and Agile project management settings

As an MIGSO-PCUBED consultant, you will deliver our expertise, adapt to new environments and work as part of a team. You will represent our brand on the client site and thanks to the materials that we provide, you will be prepared and polished to support our engagements.

WHO ARE YOU?
You should have a least a Bachelor’s Degree, 2-5 years of Data Analysis/Data Science experience working in a Project environment, and you want to develop yourself in consulting. You should also have experience with SharePoint web development. Comprehensive MS Project Online knowledge is required as well.

If this sounds like you, then we want to meet you!

MIGSO-PCUBED recognizes the civil right of every person to obtain and maintain employment without discrimination. We have a longstanding policy that no individual may be refused a job, discharged, or discriminated against in any way due to any protected characteristics established by local, state and Federal law. In all respects, MIGSO-PCUBED is committed to a policy of full and fair equal employment under the law and applies this in all employment decisions, including recruitment, hiring, compensation, engagement staffing, training, promotion, transfer, and termination.","{""role_summary"":""A Data Analyst Consultant responsible for collecting, analyzing, and presenting data to enable quality decision making, while building and fostering client relationships and delivering added value."",""key_terms"":[{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""Tableau"",""explanation"":""A data visualization tool that helps people see and understand data.""},{""term"":""Qlik Sense"",""explanation"":""A business intelligence software that provides data visualization and analytics capabilities.""},{""term"":""Machine learning"",""explanation"":""A subset of artificial intelligence that involves training algorithms to learn from data and make predictions or decisions.""},{""term"":""Natural language processing"",""explanation"":""A subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""},{""term"":""Robotic process automation"",""explanation"":""A technology that allows organizations to automate repetitive tasks by using software robots.""},{""term"":""Statistical modeling"",""explanation"":""The process of using mathematical and statistical techniques to analyze and understand data.""},{""term"":""Waterfall"",""explanation"":""A linear approach to project management, where each phase is completed before moving on to the next one.""},{""term"":""Agile"",""explanation"":""An iterative approach to project management, where requirements and solutions evolve through collaboration between cross-functional teams.""},{""term"":""SharePoint"",""explanation"":""A web-based collaborative platform that integrates with Microsoft Office, used for document management, workflow, and team collaboration.""},{""term"":""MS Teams"",""explanation"":""A communication and collaboration platform that integrates with Microsoft Office, used for team chat, video meetings, and file sharing.""},{""term"":""Power Automate"",""explanation"":""A cloud-based workflow automation platform that allows users to automate repetitive tasks and processes.""}],""skill_priorities"":{""must_have"":[""Data analysis"",""Data science"",""Project environment experience"",""SharePoint web development"",""MS Project Online knowledge""],""nice_to_have"":[""Machine learning"",""Natural language processing"",""Robotic process automation"",""Statistical modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data modeling for a complex project?"",""example_answer"":""I would start by understanding the project requirements and identifying the key stakeholders. Then, I would gather and normalize the data from various sources, and create a data model that meets the project needs. Finally, I would communicate the data model to the stakeholders and ensure it meets their expectations.""},{""question"":""How do you stay organized and manage multiple projects simultaneously?"",""example_answer"":""I use project management tools like MS Project Online to track progress and stay organized. I also prioritize tasks based on urgency and importance, and communicate regularly with the project team to ensure everyone is on the same page.""}],""red_flags"":[""Lack of experience with SharePoint web development"",""No experience working in a Project environment""],""confidence_score"":90.0}"
Data Engineer,"Company Description

You will join a world-class team of engineers and data scientists from Facebook, Uber, Amazon and Google. We are a fast growing consulting firm based in Toronto with clients ranging from leading startups building impactful technologies to Fortune 500 companies looking to scale their engineering and data capabilities.

Job Description

We are looking for a data engineer who is passionate about analytics and helping companies build and scale data. You enjoy working with data and are motivated to produce high quality data tools and pipelines that help empower other data scientists. You are experienced in architecting data ETL workflows and schemas. Critical thinking and problem-solving skills are essential for this role.

Qualifications

BS (or higher, e.g., MS, or PhD) in Computer Science, Engineering, Math, or Statistics
Hands on experience working with user engagement, social, marketing, and/or finance data
Proficient in Python (i.e. Pandas, Numpy, scikit-learn, etc), R, TensorFlow, amongst other data science related tools and libraries
Extensive experience working on relational databases, designing complex data schemas, and writing SQL queries
Deep knowledge on performance tuning of ETL Jobs, SQL, and databases
Working knowledge of Snowflake
Experience working with Airflow is a strong plus
Devops experiences is a plus

Additional Information

We have very competitive compensation.

Work on cool projects based on your interests and skills. We believe in accountability and NOT micro-management.","{""role_summary"":""Design and implement high-quality data tools and pipelines to empower data scientists, working with various data sources and technologies."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from sources, transforming it into a usable format, and loading it into a target system.""},{""term"":""Relational databases"",""explanation"":""Databases that organize data into one or more tables with defined relationships between them.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and analyzing large amounts of data.""},{""term"":""Airflow"",""explanation"":""A platform for programmatically defining, scheduling, and monitoring workflows.""},{""term"":""Devops"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""}],""skill_priorities"":{""must_have"":[""Python"",""Pandas"",""Numpy"",""scikit-learn"",""Relational databases"",""SQL"",""ETL workflows"",""Data schema design""],""nice_to_have"":[""R"",""TensorFlow"",""Snowflake"",""Airflow"",""Devops""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing a data schema for a complex dataset?"",""example_answer"":""I would start by understanding the data requirements and identifying the key entities and relationships. Then, I would design a schema that is scalable, flexible, and easy to maintain, using normalization and denormalization techniques as needed.""},{""question"":""Can you explain how you would optimize the performance of an ETL job?"",""example_answer"":""I would analyze the job's workflow and identify bottlenecks, then apply techniques such as parallel processing, caching, and query optimization to improve performance. I would also consider using distributed computing frameworks like Spark or Hadoop.""}],""red_flags"":[""Lack of experience with ETL workflows and data schema design"",""Inability to write efficient SQL queries""],""confidence_score"":90.0}"
"Data Engineer-SQL, Python, ETL- Canada","Role: Data Engineer-SQL, Python, ETL

Location: Remote/CANADA

Duration: 6+ Months

Job Description

Key Skills required:

We are looking for Senior Data Engineering Candidates based out of the US/Canada.

Expertise in SQL, Python and ETL flows is a must have. Medium expertise/working knowledge in Scala is also needed, as our data pipelines are written in both Scala and Hive/Spark SQL, with new pipelines being written in Scala and legacy ones on SQL (which require ongoing maintenance).

Minimum Requirements

5 years experience building scalable Spark data pipelines (preferably using Scala)

3-5 years experience in high level programming languages such as Java, Scala, or Python

Proficiency in Spark/MapReduce development and expertise with data processing (ETL) technologies to build and deploy production-quality ETL pipelines

Good understanding of distributed storage and compute (S3, Hive, Spark)

Experience using ETL framework (ex: Airflow, Flume, Oozie etc.) to build and deploy production-quality ETL pipelines

Demonstrated ability to analyze large data sets to identify gaps and inconsistencies, provide data insights, and advance effective product solutions

Working knowledge of relational databases and expertise in query authoring (SQL) on large datasets

Experienced with big data technologies such as Hadoop, Spark, Hive, etc.

Experience working with Git and Jira (or other source control and task management tools)

Good communication skills that allows smooth collaboration with stakeholders","{""role_summary"":""Design, build, and maintain scalable data pipelines using Spark, Scala, and Python, ensuring efficient data processing and insights."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from sources, transforming it into a usable format, and loading it into a target system.""},{""term"":""Scala"",""explanation"":""A programming language used for building scalable data pipelines and applications.""},{""term"":""Spark"",""explanation"":""An open-source data processing engine for large-scale data processing.""},{""term"":""Hive"",""explanation"":""A data warehousing and SQL-like query language for Hadoop.""},{""term"":""MapReduce"",""explanation"":""A programming model used for processing large data sets in parallel across a cluster of nodes.""},{""term"":""Airflow"",""explanation"":""A platform used to programmatically schedule and monitor workflows, often used for ETL pipelines.""}],""skill_priorities"":{""must_have"":[""SQL"",""Python"",""ETL"",""Scala"",""Spark"",""Data processing"",""Distributed storage and compute"",""Relational databases"",""Query authoring"",""Big data technologies""],""nice_to_have"":[""Java"",""Airflow"",""Flume"",""Oozie"",""Git"",""Jira""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize the performance of a Spark data pipeline?"",""example_answer"":""I would use techniques such as caching, broadcasting, and partitioning to reduce data shuffling and improve processing efficiency.""},{""question"":""Can you explain the difference between a left join and an inner join in SQL?"",""example_answer"":""A left join returns all records from the left table and the matching records from the right table, whereas an inner join returns only the records that have a match in both tables.""}],""red_flags"":[""Lack of experience with Scala and Spark"",""Inability to work with distributed storage and compute"",""Limited experience with ETL pipelines""],""confidence_score"":90.0}"
Data Engineer (x1)-Canada,"Role: Data Engineer (x1)

Location: Canada/Remote

Duration: Longterm

Job Description

Data Engineer (x1) who has experience with kafka streaming, flink SQL, and HL7 FHIR; and has experience with large scale data delivery to data consumers","{""role_summary"":""Design and implement data pipelines to deliver large-scale data to consumers, utilizing expertise in Kafka streaming, Flink SQL, and HL7 FHIR."",""key_terms"":[{""term"":""Kafka streaming"",""explanation"":""A distributed streaming platform for handling high-volume data feeds.""},{""term"":""Flink SQL"",""explanation"":""A SQL-like query language for processing large-scale data streams.""},{""term"":""HL7 FHIR"",""explanation"":""A standard for exchanging healthcare information electronically.""}],""skill_priorities"":{""must_have"":[""Kafka streaming"",""Flink SQL"",""HL7 FHIR"",""Large-scale data delivery""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize a Kafka streaming pipeline for high-throughput data processing?"",""example_answer"":""I would implement a distributed architecture, utilize Kafka's built-in partitioning and replication features, and optimize the producer and consumer configurations for efficient data processing.""},{""question"":""Can you explain how you would handle data quality issues in a Flink SQL pipeline?"",""example_answer"":""I would implement data quality checks using Flink's built-in validation features, and develop a data cleansing process to handle invalid or inconsistent data.""}],""red_flags"":[""Lack of experience with large-scale data delivery"",""Inability to work with distributed streaming platforms""],""confidence_score"":80.0}"
Data Engineer (x1)- Canada,"Role: Data Engineer (x1)

Location: Canada/Remote

Duration: Longterm

Job Description

Data Engineer (x1) who has experience with kafka streaming, flink SQL, and HL7 FHIR; and has experience with large scale data delivery to data consumers","{""role_summary"":""Design and implement data pipelines to deliver large-scale data to consumers, utilizing expertise in Kafka streaming, Flink SQL, and HL7 FHIR."",""key_terms"":[{""term"":""Kafka streaming"",""explanation"":""A distributed streaming platform for handling high-volume data feeds.""},{""term"":""Flink SQL"",""explanation"":""A SQL-like query language for processing large-scale data streams.""},{""term"":""HL7 FHIR"",""explanation"":""A standard for exchanging healthcare information electronically.""}],""skill_priorities"":{""must_have"":[""Kafka streaming"",""Flink SQL"",""HL7 FHIR"",""Large-scale data delivery""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize a Kafka streaming pipeline for high-throughput data processing?"",""example_answer"":""I would implement a distributed architecture, utilize Kafka's built-in partitioning and replication features, and optimize the producer and consumer configurations for efficient data processing.""},{""question"":""Can you explain how you would handle data quality issues in a Flink SQL pipeline?"",""example_answer"":""I would implement data quality checks using Flink's built-in validation features, and develop a data cleansing process to handle invalid or inconsistent data.""}],""red_flags"":[""Lack of experience with large-scale data delivery"",""Inability to work with distributed streaming platforms""],""confidence_score"":80.0}"
(Data Engineer),"Role: (Data Engineer)

Location: Remote/Canada

Duration: 12+ Months

Mandatory Skills

Tableau, SQL, python pandas, numpy, good to have experience with GCP is must (data analyst)","{""role_summary"":""Design, build, and maintain large-scale data systems to store, process, and retrieve data efficiently."",""key_terms"":[{""term"":""GCP"",""explanation"":""Google Cloud Platform, a suite of cloud computing services for data storage, analytics, and machine learning.""},{""term"":""pandas"",""explanation"":""A popular Python library for data manipulation and analysis, providing data structures and functions to efficiently handle structured data.""},{""term"":""numpy"",""explanation"":""A Python library for efficient numerical computation, providing support for large, multi-dimensional arrays and matrices.""},{""term"":""Tableau"",""explanation"":""A data visualization tool for creating interactive dashboards, reports, and charts to help organizations make data-driven decisions.""}],""skill_priorities"":{""must_have"":[""Tableau"",""SQL"",""python"",""pandas"",""numpy"",""GCP""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize the performance of a slow-running SQL query?"",""example_answer"":""I would analyze the query plan, identify performance bottlenecks, and apply indexing, caching, or query rewriting techniques to improve execution time.""},{""question"":""Can you explain how you would handle missing data in a pandas DataFrame?"",""example_answer"":""I would use the pandas `isnull()` function to detect missing values, and then apply imputation techniques such as mean, median, or mode replacement, or listwise deletion depending on the data context.""}],""red_flags"":[""Lack of experience with cloud-based data engineering, limited knowledge of data visualization tools""],""confidence_score"":80.0}"
"Data Engineer-Azure, SQL- Canada","Role: Data Engineer-Azure, SQL

Location: Canada/Remote

Duration: 6+ Months

Job Description

Must have Clinical/ Pharma Domain , SQL ,Azure

Preferred Clinical Research Organization (CRO) Exp

Below is the JD:

Working closely with the Management team, the Data Quality Analyst will provide quality assurance oversight (data error detection and correction) on business processes where data is collected, stored, transformed, or used.

Specifically person will have the opportunity to assist the team in integrating data assets from a variety of systems and sources (external and internal) into the Company's systems, ensuring and monitoring the final quality of our internal data stores and flows.

Person's strong data analysis skills will ensure clean data that can be enacted upon by analytic systems and application code, thereby maintaining the high-quality standards for products and services.

Analyze data, identify fix, implement for bulk data operations, batch jobs & data profile operations, etc.

Work on the PROD tickets on daily basis on data validations

Working on the Azure migration testing, Rackspace to Azure remediation migration validation etc.

Working on HCP, HCO and Address data profiling and DQ rules implementation etc.","{""role_summary"":""The Data Engineer-Azure, SQL role is responsible for ensuring data quality and integrity by analyzing, integrating, and monitoring data from various sources, and implementing data quality rules and standards."",""key_terms"":[{""term"":""Azure"",""explanation"":""A cloud computing platform used for data migration, testing, and remediation.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing data in relational databases.""},{""term"":""Clinical/Pharma Domain"",""explanation"":""The industry or sector related to clinical trials, pharmaceuticals, and healthcare.""},{""term"":""Clinical Research Organization (CRO)"",""explanation"":""A company that provides support to pharmaceutical, biotechnology, and medical device companies in the form of research and development services.""},{""term"":""Data Quality Analyst"",""explanation"":""A professional responsible for ensuring the accuracy, completeness, and consistency of data.""},{""term"":""PROD tickets"",""explanation"":""Production tickets or issues related to data validations and quality.""},{""term"":""HCP, HCO and Address data profiling"",""explanation"":""Healthcare provider, healthcare organization, and address data analysis and quality control.""}],""skill_priorities"":{""must_have"":[""Clinical/Pharma Domain"",""SQL"",""Azure""],""nice_to_have"":[""Clinical Research Organization (CRO) Exp""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data quality and integrity in a cloud-based data warehouse?"",""example_answer"":""I use a combination of data validation rules, data profiling, and data quality metrics to ensure data accuracy and consistency. In Azure, I leverage data quality features such as data validation, data profiling, and data cleansing to ensure high-quality data.""},{""question"":""Can you explain how you would integrate data from multiple sources into a single system?"",""example_answer"":""I would use Azure Data Factory to integrate data from various sources, such as on-premises databases, cloud storage, and APIs. I would then use data transformation and data quality rules to ensure data consistency and accuracy.""}],""red_flags"":[""Lack of experience in Clinical/Pharma Domain"",""Inability to work with Azure and SQL""],""confidence_score"":90.0}"
Data Engineer / Toronto,"Intersog® is a Chicago-based provider of ROI-driven custom web and mobile development specializing in the delivery of full-service, end-to-end solutions, and project resources to Fortune 500 companies, SMEs, and startups. We help our clients attack their ambitious business goals, solve skills shortage issues, and become innovative by building Dedicated Software Development Teams in Mexico, Canada, the U.S.A., and Ukraine and/or providing on-demand IT project resources to complete required skills on their in-house teams.

About The Role

We are looking for a Data Engineer passionate about shaping the future of data infrastructure and eager to tackle the challenges of big data in a dynamic, collaborative environment. A Data Engineer plays a pivotal role by developing and overseeing the frameworks and systems that process and store vast data volumes efficiently. This individual works in sync with data scientists, analysts, and various stakeholders to guarantee data accessibility, accuracy, and integrity for strategic insights and operational efficiency.

Requirements

Bachelor's degree or higher in Computer Science, Data Science, or a related field
Proficiency in languages such as Python, Java, or Scala and experience with big data frameworks (Hadoop, Spark, Kafka)
Familiarity with cloud platforms (AWS, Azure) and data integration tools
A strong foundation in data ingestion, storage, orchestration, and management on cloud platforms, with a preference for Azure or AWS
3 to 5 years of experience in Data Engineering role
Minimum 5+ relevant industry experience with Big data - Hive, Spark, Hadoop, queueing system like Apache Kafka/Rabbit MQ/AWS Kinesis
Hands on experience in building metadata-driven, reusable design patterns for data pipeline, orchestration, ingestion patterns (batch, real time);
Experience in designing and implementing solutions on distributed computing and cloud services platform (but not limited to) - AWS, Azure, GCP;
Hands on experience building CI/CD pipelines and awareness of practices for application monitoring","{""role_summary"":""Develop and maintain data infrastructure, ensuring data accessibility, accuracy, and integrity for strategic insights and operational efficiency in a collaborative environment."",""key_terms"":[{""term"":""Big Data"",""explanation"":""Large and complex data sets that require specialized processing and storage solutions.""},{""term"":""Hadoop"",""explanation"":""A distributed computing framework for storing and processing large data sets.""},{""term"":""Spark"",""explanation"":""An open-source data processing engine for large-scale data processing.""},{""term"":""Kafka"",""explanation"":""A distributed streaming platform for building real-time data pipelines.""},{""term"":""Cloud Platforms"",""explanation"":""On-demand computing resources and services provided over the internet, such as AWS, Azure, and GCP.""},{""term"":""CI/CD Pipelines"",""explanation"":""Automated workflows for building, testing, and deploying software applications.""}],""skill_priorities"":{""must_have"":[""Python, Java, or Scala programming languages"",""Experience with big data frameworks (Hadoop, Spark, Kafka)"",""Familiarity with cloud platforms (AWS, Azure)"",""Data integration tools"",""Data ingestion, storage, orchestration, and management on cloud platforms""],""nice_to_have"":[""Azure or AWS cloud platform preference"",""Experience with distributed computing and cloud services platform (AWS, Azure, GCP)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data processing and storage in a big data environment?"",""example_answer"":""I would use distributed computing frameworks like Hadoop and Spark to process large data sets, and implement data partitioning and caching to improve storage efficiency.""},{""question"":""Can you explain how you would design a metadata-driven data pipeline?"",""example_answer"":""I would use a metadata-driven approach to create reusable design patterns for data pipeline, orchestration, and ingestion patterns, ensuring flexibility and scalability in the pipeline.""}],""red_flags"":[""Lack of experience with big data frameworks and cloud platforms"",""Inability to design and implement scalable data pipelines""],""confidence_score"":90.0}"
Data Engineer (DE)- Canada,"Role: Data Engineer (DE)

Location: Remote/Canada

Duration: 12+ Months

Job Description

What you'll do:

Build and maintain scalable data infrastructure that offers a best-in-class experience for internal stakeholders including consistent extraction of value from the data
Drive data ingestion and processing in innovative ways that inform strategic priorities and decision-making across the organization
Build expertise in the team to expose efficiency insights across data platforms
Ensure data security and privacy are top considerations
Implement automation and monitoring tools through a test-driven approach and mindset
Drive the adoption of new cloud technologies to further advance TELUS Health's data transformation strategy

Qualifications

What you bring:

2+ years of experience as a Data Engineer
An expert understanding of data warehouses/cloud architectures and ETL processes and Tools(SSIS)
Advanced working SQL knowledge and experience working with relational databases and query authoring (SQL), as well as working familiarity with a variety of databases
Experience with cloud platforms: GCP, Amazon or Azure (GCP gives you an edge!)
Experience with Python and software engineering best practices
Knowledge in Dataflow, Spark and Kafka, as well as other data pipeline components
Experience with data pipeline and workflow management tools such as Airflow
Experience with Github and CICD processes
Ready to work in new and challenging work environments
Getting excited by the opportunity to build a team's capabilities to create value and innovate through data, and doing so in an agile manner with a bias for action and speed

Great-to-haves:

Post-graduate education in Data Engineering, Cloud DevOps or Advanced Analytics
Machine learning and data science knowledge","{""role_summary"":""Design and maintain scalable data infrastructure, drive data ingestion and processing, and ensure data security and privacy to inform strategic priorities and decision-making across the organization."",""key_terms"":[{""term"":""ETL processes"",""explanation"":""Extract, Transform, Load processes that extract data from various sources, transform it into a standardized format, and load it into a target system.""},{""term"":""Data warehouses"",""explanation"":""Centralized repositories that store data from various sources in a single location, making it easier to analyze and report.""},{""term"":""Cloud architectures"",""explanation"":""Design and structure of cloud-based systems, including infrastructure, applications, and data storage.""},{""term"":""Dataflow"",""explanation"":""A fully-managed service for processing and analyzing data in stream and batch modes.""},{""term"":""Spark"",""explanation"":""An open-source data processing engine that can handle large-scale data processing tasks.""},{""term"":""Kafka"",""explanation"":""A distributed streaming platform that enables high-throughput and provides low-latency, fault-tolerant data processing.""},{""term"":""Airflow"",""explanation"":""A platform used to programmatically schedule and monitor workflows, including data pipelines.""},{""term"":""CICD"",""explanation"":""Continuous Integration and Continuous Deployment, a set of practices that automate testing, building, and deployment of software.""}],""skill_priorities"":{""must_have"":[""Data Engineer experience"",""Data warehouses/cloud architectures knowledge"",""ETL processes knowledge"",""Advanced SQL knowledge"",""Cloud platforms experience (GCP, Amazon, or Azure)"",""Python experience"",""Software engineering best practices knowledge"",""Data pipeline and workflow management tools experience (Airflow)""],""nice_to_have"":[""Post-graduate education in Data Engineering, Cloud DevOps or Advanced Analytics"",""Machine learning and data science knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data security and privacy in a cloud-based data infrastructure?"",""example_answer"":""I implement encryption, access controls, and monitoring tools to ensure data security and privacy. I also ensure compliance with relevant regulations and standards.""},{""question"":""Can you explain how you would optimize data ingestion and processing in a scalable data infrastructure?"",""example_answer"":""I would use distributed processing frameworks like Spark and Dataflow to optimize data ingestion and processing. I would also implement automation and monitoring tools to ensure efficiency and scalability.""}],""red_flags"":[""Lack of experience with cloud platforms"",""Inability to work with relational databases and query authoring"",""No experience with data pipeline and workflow management tools""],""confidence_score"":90.0}"
Data Engineer - 10 Month Contract (Remote),"Firmex is a global software-as-a-service provider with corporate headquarters in Toronto, Canada. The company’s Firmex VDR service is the world’s most trusted virtual data room, having been used by over 140,000 companies worldwide to share confidential documents for due diligence, litigation and compliance.

Firmex is looking to hire a Data Engineer for our Information Management & Analytics program. We are looking for an individual to design and build processes to move data within our FBI DW (Firmex Business Intelligence Data Warehouse). FBI DW is a key strategic system that provides insight to all of Firmex’s departments for customer and product decision making.

As our Data Engineer you will be responsible for:

Data Requirements Gathering: Work with internal business and technology staff to accurately gather and interpret requirements and specifications to determine appropriate data models and data specifications
Data Modeling & Data Specifications: Working with various team members to design/document, architect, and build the appropriate S3, Staging, and Redshift tables to support various reporting and analytics projects. Collect and document the transformation rules in a source to target matrix
Building & Supporting Data Pipelines in AWS environment: Build the code required for extraction, transformation, and loading of data from a wide variety of data sources using Python, APIs, Airflow, and AWS Service(s) such as EC2, S3, RDS, Redshift, and Glue
AWS Data & Analytics Infrastructure Support: Configure and maintain the AWS Data & Analytics Infrastructure. (ie, Data Opps: Support of AWS services EC2, S3, RDS, Redshift, Glue, Airflow, and Tableau on AWS)


What you'll need to be successful as our Data Engineer:

Strong experience in creating & maintaining data pipelines and ETL/ELT processes using Python, SQL and Apache Airflow and connecting to different data sources
Strong experience coding in Python & SQL (creating reusable Python scripts, SQL stored procedures/scripts, APIs, functions, etc.)
Experience with AWS stack (SQS, Glue, S3, Lamda, Apache Airflow, RDS,Redshift)
Experience in building logical and physical design of data lakes, relational databases and data warehouses such as Snowflake/Redshift
Experience in configuration and maintenance of AWS Data & Analytics Infrastructure is an asset (ie. knowledge of CF templates)
Strong interpersonal and analytical skills, as well as detail oriented
Experience with BI Tool(s) such as Tableau & Looker is an asset
Ability to learn new technologies quickly
Strong initiative and self-direction, as well as excellent time management skills


*Note: The “Core Duties” is a summary of the duties that are essential to this role and is not an exhaustive list. Firmex reserves the right to add or amend duties as necessary.

At Firmex, we’re guided by our core values of respect and collaboration to create an equitable, diverse and inclusive environment where all employees and candidates alike can thrive. BIPOC, LGBTQIA2S+, women, people with disabilities, internationally trained professionals and historically disenfranchised groups are encouraged to apply. If you need any accommodations or adjustments throughout the interview process and beyond, we’ll be happy to assist you.","{""role_summary"":""Design and build data pipelines and processes to move data within Firmex's Business Intelligence Data Warehouse, providing insights to various departments for customer and product decision making."",""key_terms"":[{""term"":""FBI DW"",""explanation"":""Firmex Business Intelligence Data Warehouse, a key strategic system providing insights to various departments.""},{""term"":""ETL/ELT"",""explanation"":""Extract, Transform, Load/Extract, Load, Transform processes for data integration and migration.""},{""term"":""S3"",""explanation"":""Simple Storage Service, a cloud-based object storage system by Amazon Web Services.""},{""term"":""Redshift"",""explanation"":""A data warehousing and analytics service by Amazon Web Services.""},{""term"":""Airflow"",""explanation"":""A platform for programmatically defining, scheduling, and monitoring workflows.""},{""term"":""Glue"",""explanation"":""A fully managed extract, transform, and load (ETL) service by Amazon Web Services.""},{""term"":""Data Lakes"",""explanation"":""A storage repository that holds a large amount of raw, unprocessed data in its native format.""},{""term"":""CF templates"",""explanation"":""CloudFormation templates, used for infrastructure as code and configuration management.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Apache Airflow"",""AWS"",""Data pipeline creation and maintenance"",""ETL/ELT processes""],""nice_to_have"":[""Tableau"",""Looker"",""Snowflake"",""CF templates"",""BI tools""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you handle data quality issues in a data pipeline?"",""example_answer"":""I would identify the root cause of the issue, implement data validation and data cleansing processes, and monitor the pipeline for any further issues.""},{""question"":""Can you explain the difference between ETL and ELT?"",""example_answer"":""ETL stands for Extract, Transform, Load, where data is transformed before loading into a target system. ELT stands for Extract, Load, Transform, where data is loaded into a target system and then transformed.""}],""red_flags"":[""Lack of experience with AWS services"",""Inability to write reusable Python scripts"",""No experience with data modeling and data specifications""],""confidence_score"":90.0}"
Senior Data Engineer,"This position can work from Vancouver, Calgary and Toronto.

Job Description:
We are looking for an inquisitive, resourceful, and business-oriented Senior Data Engineer able to design, build and deploy solutions, review code from peers and be a technical lead for other data engineers. Primary skills are Databricks (Azure), Python and SQL, but a good understanding of Azure Data Services in general is also important.

Key Responsibilities:
Maintain existing and build new ETL/ELT pipelines on Azure Databricks
Build, Design and Model data objects in Databricks
Support a Python-based web app, by maintaining and augmenting its capabilities.
Work closely with Power BI and Data Science teams to empower them with the right data.
Collaborate with DevOps team on the CICD deployment of the DDL, DML and App code bases across multiple environments.
Review and approve code from other data engineers in the team, taking accountability results.

Required Skills:
Overall understanding of Azure Data Services
Databricks (Azure), SQL and Azure DevOps
Python, with Dash / Bootstrap / SQL Alchemy (Alembic)

Life at Capgemini
Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:
Collaborating with teams of creative, fun, and driven colleagues
Flexible work options enabling time and location-based flexibility
Company-provided home office equipment
Virtual collaboration and productivity tools to enable hybrid teams
Comprehensive benefits program (Health, Welfare, Retirement and Paid time off)
Other perks and wellness benefits like discount programs, and gym/studio access.
Paid Parental Leave and coaching, baby welcome gift, and family care/illness days
Back-up childcare/elder care, childcare discounts, and subsidized virtual tutoring
Tuition assistance and weekly hot skill development opportunities
Experiential, high-impact learning series events
Access to mental health resources and mindfulness programs
Access to join Capgemini Employee Resource Groups around communities of interest

About Capgemini
Capgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, cloud and data, combined with its deep industry expertise and partner ecosystem. The Group reported 2023 global revenues of €22.5 billion.
Get The Future You Want | www.capgemini.com

Disclaimer
Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.
Capgemini is committed to providing reasonable accommodations during our recruitment process.

If you need assistance or accommodation, please reach out to your recruiting contact.
Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law
Please be aware that Capgemini may capture your image (video or screenshot) during the interview process and that image may be used for verification, including during the hiring and onboarding process.

Applicants for employment in Canada must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in Canada by Capgemini.","{""role_summary"":""Design, build, and deploy data solutions as a technical lead, collaborating with teams to empower them with the right data."",""key_terms"":[{""term"":""Databricks (Azure)"",""explanation"":""A cloud-based Apache Spark platform for data engineering, analytics, and AI.""},{""term"":""ETL/ELT pipelines"",""explanation"":""Extract, Transform, Load/Extract, Load, Transform processes for data integration and processing.""},{""term"":""Azure Data Services"",""explanation"":""A suite of cloud-based data services for storage, processing, and analytics.""},{""term"":""CICD deployment"",""explanation"":""Continuous Integration and Continuous Deployment for automated testing, building, and deployment of code.""},{""term"":""Power BI"",""explanation"":""A business analytics service for data visualization and business intelligence.""},{""term"":""DevOps"",""explanation"":""A set of practices combining software development and IT operations for efficient collaboration and delivery.""}],""skill_priorities"":{""must_have"":[""Databricks (Azure)"",""Python"",""SQL"",""Azure Data Services""],""nice_to_have"":[""Dash"",""Bootstrap"",""SQL Alchemy (Alembic)"",""Azure DevOps""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data pipeline performance in Databricks?"",""example_answer"":""I use techniques like data partitioning, caching, and parallel processing to improve performance. I also monitor pipeline metrics and adjust as needed.""},{""question"":""Can you explain the difference between ETL and ELT pipelines?"",""example_answer"":""ETL pipelines transform data before loading it into a target system, whereas ELT pipelines load data first and then transform it. I choose the approach based on the specific use case and data requirements.""}],""red_flags"":[""Lack of experience with Azure Data Services"",""Inability to design and deploy scalable data pipelines""],""confidence_score"":95.0}"
"Engineer, Data","Connect with us LinkedIn, Instagram, Facebook, Twitter

Thinking about a change?

We recognize that the construction industry is changing at a rapid pace and we continually strive to be at the forefront. Our core values empower people to deliver great careers to one another and develop creative solutions for complex problems on some of the most exciting projects. It doesn’t matter what your expertise and craft is – there are no boundaries. We are a group of professionals with a variety of expertise within pre-construction, construction, and post-construction. To learn more, check out our Cradle to Grave services and hear from our team directly about what a career at EllisDon could look like for you. As you can see, we are a diverse bunch.

Above all, we are a group of individuals with unique experiences and at EllisDon, we choose to celebrate the strength in our differences, every day. EllisDon’s commitment to Inclusive Diversity is to work together to create an environment where every employee feels safe to be their true and authentic self. Ultimately, EllisDon’s purpose is to provide people with similar values the opportunity to achieve to their full potential; to deliver that opportunity for great careers to one another; and to contribute meaningfully to the community we share with others.

In case you’re curious, here’s what the industry thinks of us and some of the impacts we've made to the communities we work in.

You As a Data Engineer Will

Be a technical lead in the development of high-volume platforms and data pipelines
Work with relevant stakeholders to identify sources of data and map out processes/data flow while researching opportunities for data acquisition and innovative new uses for existing data
Design, construct, install, test, and maintain highly scalable data management systems while integrating new data management technologies into existing structures
Develop ETL processes to move internal and external data into EllisDon's external cloud-based data lake and data warehouse(s)
Provide input and feedback to support continuous improvement in team processes
Provide thought leadership for all data solutions, including designing data solutions that meet and exceed customer expectations
Continually improve our data pipelines and find innovative ways to maximize automation while recommending ways to improve data reliability, efficiency, and quality


Is this the right role for you?

Have knowledge and understanding of Programming Languages: Python and/or Java, SQL, ETL methodologies and toolsets, Azure/Google ecosystem, Database design, MS SQL, MySQL, Synapse/Big Query and NoSQL (MongoDB), Airflow, Kafka
Comfortable working in a fast-paced and collaborative environment
Have excellent communication, analytical, and problem-solving skills
Have a degree in Computer Science, Engineering, Mathematics, Statistics, or a related field
Have previous experience in data engineering, data warehousing, data modeling, or data analysis
Have a passion for data and innovation


EllisDon is proud to provide this unique career opportunity that provides continuous learning, opportunity for growth, and a competitive compensation package within an environment that is committed to inclusion and respects diversity.

Go ahead and be yourself. We'll pay you for it!

We are an equal opportunity employer. We welcome people of any age, culture, subculture, gender identity or expression, sexual orientation, nationality, ethnicity, race, size, mental or physical status, veteran status, religion, language, political opinion, working-style preference, family status, education, and socio-economic status. The EllisDon core values of Integrity and Mutual Respect welcomes everyone, at work and in the community, and our value of Mutual Accountability, means that we all have a role to play. As an EllisDon employee, this will ultimately be your commitment to Inclusive Diversity.

Accommodation for Applicants with disabilities will be made during the recruitment process when requested.

We are committed to providing a positive candidate experience and ensuring timely updates are provided to all candidates. If you haven’t already, be sure to create a profile on our Careers page here to remain up to date on the status of your application and learn about new career opportunities as they arise.","{""role_summary"":""As a Data Engineer, you will lead the development of high-volume platforms and data pipelines, working with stakeholders to identify data sources and map out processes, and designing scalable data management systems."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Data Lake"",""explanation"":""A centralized repository that stores all types of data in its native format, allowing for flexible and scalable data processing.""},{""term"":""Data Warehouse"",""explanation"":""A centralized repository that stores data in a structured and transformed format, optimized for querying and analysis.""},{""term"":""Azure/Google ecosystem"",""explanation"":""Cloud computing platforms provided by Microsoft Azure and Google Cloud, offering a range of services for data storage, processing, and analytics.""},{""term"":""NoSQL (MongoDB)"",""explanation"":""A type of database that does not use the traditional table-based relational model, instead using a variety of data models such as key-value, document, or graph.""},{""term"":""Airflow"",""explanation"":""A platform for programmatically defining, scheduling, and monitoring workflows, often used for data pipelines and ETL processes.""},{""term"":""Kafka"",""explanation"":""A distributed streaming platform for building real-time data pipelines and event-driven architectures.""}],""skill_priorities"":{""must_have"":[""Python and/or Java"",""SQL"",""ETL methodologies and toolsets"",""Azure/Google ecosystem"",""Database design"",""MS SQL"",""MySQL"",""Synapse/Big Query"",""NoSQL (MongoDB)"",""Airflow"",""Kafka""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of data lakes and data warehouses, and how they differ?"",""example_answer"":""A data lake is a centralized repository that stores all types of data in its native format, allowing for flexible and scalable data processing. A data warehouse, on the other hand, is a centralized repository that stores data in a structured and transformed format, optimized for querying and analysis.""},{""question"":""How would you approach designing a scalable data management system?"",""example_answer"":""I would start by identifying the data sources and mapping out the data flow, then design a system that can handle high volumes of data and integrate new data management technologies into existing structures.""}],""red_flags"":[""Lack of experience in data engineering, data warehousing, data modeling, or data analysis"",""Inability to work in a fast-paced and collaborative environment""],""confidence_score"":90.0}"
Sr Data Engineer,"JOB DESCRIPTION: Basic Qualifications�10+ years of experience with data pipelines �Experience managing a team of 5-8 junior developers.�Strong coding background, ideally in Java/ Python / Scala�Experience in at least one big data product: Databricks, Elasticsearch, Snowflake�Experience building batch / real time data pipelines for production systems.�Experience with Relational and Non-Relational DBs like DB2, MongoDB�Experience with various data formats: Parquet, CSV, JSON, XML, Relational Data�Experience working in Agile environment.�Experience with scripting languages�Experience with Linux/Unix Desired Qualifications �Experience with Rest based applications�Experience with Databricks/ Delta Lake / Kafka�Experience with client reference data sourcing from vendors","{""role_summary"":""Lead a team of junior developers to design, build, and manage large-scale data pipelines, ensuring efficient data processing and storage."",""key_terms"":[{""term"":""Data Pipelines"",""explanation"":""A series of processes that extract, transform, and load data from various sources to a target system, enabling data analysis and insights.""},{""term"":""Big Data Products"",""explanation"":""Software solutions that handle large and complex data sets, such as Databricks, Elasticsearch, and Snowflake.""},{""term"":""Relational and Non-Relational DBs"",""explanation"":""Types of databases that store and manage data, with Relational DBs (e.g., DB2) using structured data and Non-Relational DBs (e.g., MongoDB) using unstructured or semi-structured data.""},{""term"":""Agile Environment"",""explanation"":""A collaborative and iterative approach to project management, emphasizing flexibility and rapid delivery.""}],""skill_priorities"":{""must_have"":[""Data pipeline management"",""Team management"",""Java/Python/Scala programming"",""Experience with big data products (e.g., Databricks, Elasticsearch, Snowflake)"",""Batch and real-time data pipeline development"",""Relational and Non-Relational DBs (e.g., DB2, MongoDB)"",""Agile development experience""],""nice_to_have"":[""Experience with Rest-based applications"",""Databricks/Delta Lake/Kafka experience"",""Client reference data sourcing from vendors""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data pipeline performance for large-scale production systems?"",""example_answer"":""I would analyze the pipeline architecture, identify bottlenecks, and implement parallel processing, data caching, and efficient data storage solutions to improve performance.""},{""question"":""Can you explain the differences between Relational and Non-Relational DBs, and when to use each?"",""example_answer"":""Relational DBs use structured data and are suitable for complex transactions, while Non-Relational DBs use unstructured or semi-structured data and are ideal for handling large, variable data sets. I would choose the appropriate DB type based on the project requirements and data characteristics.""}],""red_flags"":[""Lack of experience with big data products"",""Inability to manage a team of junior developers""],""confidence_score"":90.0}"
Data/ML Engineer,"About Raydiant

Raydiant is on a mission to create amazing experiences for people everywhere they go.

Using a first-of-its-kind technology, Raydiant reimagines and transforms customer and employee experiences through dynamic and interactive digital signage. Some of the nation’s most recognizable brick-and-mortar companies, including Chick-Fil-A, First Bank, Harvard University, Thomson Reuters, and Wahlburgers use Raydiant to keep employees engaged and customers coming back, all while driving revenue.

Built with both people and businesses in mind, Raydiant focuses on the experience so companies can focus on their products. Franchise managers, IT, marketing, and communications executives can effectively scale their brick-and-mortar operations while eliminating outdated technology. Our superior product, service, and integrations seamlessly create more engaging and personalized in-store experiences that keep customers coming back and buying more.

Founded in April 2017, Raydiant is headquartered in San Francisco, California, and is the highest funded company of its kind. Raydiant currently works with 4,500+ brands. To learn more, visit www.raydiant.com.

About The Role

Join a team of Data Engineers to build the next-gen data platform at Raydiant; collaborate, manage, coach, and develop the members of the group to ensure that it is both effective and efficient in its mission. Fully hands-on position as Data Engineer.

The Data team is being built on lean and agile methodologies, promoting innovation, flexibility, and entrepreneurship. We are looking for an experienced Data Engineer who thrives in a fast-paced environment, with a passion for finding ways to extract unique value from data. You are someone who has a proven track record of architecting and solving complex data, math, and modeling problems with practical applications.

What You Will Be Doing

Hands-On data engineer and analyst to implement and verify production machine learning algorithms and pipelines
Design, build, and maintain data pipelines for both batch and real-time processing in a processing environment
Maintain and optimize the data infrastructure required for ETL workloads
Develop new ETL processes to help extract and manipulate data from multiple sources
Automate data workflows such as data ingestion, aggregation, and ETL processing
Process raw data in Data Warehouses into a consumable dataset for both technical and non-technical stakeholders
Partner with data scientists and functional leaders in sales, marketing, and product to deploy machine learning models in production
Build, maintain, and deploy data products for analytics and data science teams on cloud platforms (e.g. AWS, GCP)
Ensure data accuracy, integrity, privacy, security, and compliance through quality control procedures
Monitor data systems performance and implement optimization strategies
Leverage data controls to maintain data privacy, security, compliance, and quality for allocated areas of ownership
Create, qualify, and manage Big Data opportunities through to the completion
Build and maintain strong links with other engineering members, and product management to enable both understand and influence the company’s technology strategy
Develop approaches to establish, validate, and extend complex datasets used to train and evaluate statistical models

What We Are Looking For

Bachelor's degree in Computer Science or related field
A minimum of 5 years hands-on experience as a Data Engineer
Formal qualifications in one of the following disciplines Computer Science, Data Science, Statistics, Mathematical Modeling
Proven skill development and applying machine learning or algorithms to large-scale business problems.
Advanced SQL skills and experience with relational databases and database design
Experience working with cloud Data Warehouse solutions (e.g., Redshift, BigQuery, Snowflake, Databricks, etc.)
Experience working with data ingestion tools such as Kinesis Firehose, Kafka, Stitch, or Matillion
Working knowledge of public clouds (e.g. AWS, GCP)
Experience building and deploying data lakes
Experience building and deploying machine learning models in production
Strong proficiency in object-oriented languages: Python, Go
Strong proficiency in scripting languages like Bash
Strong proficiency in data pipeline and workflow management tools (e.g., AWS Glue, Airflow)
Experience working with IaC frameworks such as Terraform, AWS CDK
Good understanding of NoSQL databases like Redis, Cassandra, MongoDB, and DynamoDB
Expertise with popular off the shelf machine learning toolkits and APIs
Experience with R&D agile methodologies
Experience with CI/CD pipelines
Strong project management and organizational skills
Excellent problem-solving, communication, and organizational skills
Ability to explain/evangelize machine learning and statistical concepts to software engineers, project managers, team members, executives, and technical managers
Proven ability to work independently and with a team
Agile, enthusiastic self-starter who takes pride in being on top of the technology bleeding edge and recognized as a knowledge source within the community
Experience working with multiple customer and partner data sets
Experience building customer-facing data products

Bonus Point For

Strong knowledge of AWS Analytics services
Experience working with AWS Glue data pipeline services
Knowledge of building data mesh architectures with AWS lake formation.
Knowledge of data governance with AWS.
Experience working with Amazon SageMaker.
Experience with working on large data sets and distributed computing (e.g.Amazon EMR, Hive/Hadoop/Spark).
Experience with GenAI
Experience working with LLMs
Experience with RAG architectures

Perks/Benefits at Raydiant

Platinum medical, dental, & vision plan through Manulife
Flexible PTO and paid holidays
Be a part of low ego, high-performance team
Be one of the first 150 people in a very fast-growing company

Raydiant is proud to be an equal employment opportunity employer that values diversity in hiring and gives consideration to all candidates regardless of their race, age, creed, color, religion or religious belief, national origin or ancestry, disability, military or veteran status, genetic information, sex, gender, sexual orientation, gender identity or expression, pregnancy, or any other characteristic protected by local, state, or federal law.","{""role_summary"":""Lead a team of Data Engineers to build and maintain a next-gen data platform, collaborating with cross-functional teams to drive business growth through data-driven insights."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Machine Learning"",""explanation"":""A subset of Artificial Intelligence that enables systems to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Data Warehousing"",""explanation"":""A centralized repository that stores data from various sources in a single location, making it easier to analyze and report.""},{""term"":""Cloud Platforms"",""explanation"":""On-demand computing resources and services provided over the internet, such as AWS, GCP, or Azure.""},{""term"":""Data Lakes"",""explanation"":""A centralized repository that stores raw, unprocessed data in its native format, allowing for flexible schema definition and data exploration.""},{""term"":""IaC Frameworks"",""explanation"":""Infrastructure as Code frameworks, such as Terraform or AWS CDK, that enable the management and provisioning of infrastructure resources through code.""}],""skill_priorities"":{""must_have"":[""Hands-on experience as a Data Engineer"",""Advanced SQL skills"",""Experience with cloud Data Warehouse solutions"",""Working knowledge of public clouds (e.g., AWS, GCP)"",""Strong proficiency in object-oriented languages: Python, Go"",""Strong proficiency in scripting languages like Bash"",""Experience with data pipeline and workflow management tools""],""nice_to_have"":[""Knowledge of AWS Analytics services"",""Experience working with AWS Glue data pipeline services"",""Knowledge of building data mesh architectures with AWS lake formation"",""Knowledge of data governance with AWS"",""Experience working with Amazon SageMaker"",""Experience with working on large data sets and distributed computing"",""Experience with GenAI"",""Experience with LLMs"",""Experience with RAG architectures""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach designing a data pipeline for real-time processing in a cloud environment?"",""example_answer"":""I would start by identifying the data sources and sinks, then design a pipeline using tools like AWS Glue or Apache Beam, ensuring scalability, reliability, and data quality. I would also consider implementing data quality checks and monitoring to ensure data accuracy and integrity.""},{""question"":""Can you explain how you would optimize the performance of a data warehouse?"",""example_answer"":""I would start by analyzing the query patterns and data distribution, then apply optimization techniques such as indexing, caching, and data partitioning. I would also consider implementing data compression and columnar storage to improve query performance.""}],""red_flags"":[""Lack of hands-on experience with data engineering tools and technologies"",""Inability to explain complex data concepts to non-technical stakeholders"",""Limited experience with cloud-based data warehousing solutions""],""confidence_score"":95.0}"
Python Backend Developer (Airflow/ETL) - Remote,"We are seeking an experienced Python Backend Developer with a minimum of 7-8 years of expertise in backend development, particularly using Python. The ideal candidate will have strong experience in building robust and scalable applications, with at least 3 years of hands-on experience utilizing AWS technologies.

Key Responsibilities

Develop and maintain high-quality backend solutions using Python.
Design and implement well-tested applications, including unit tests, functional tests, and integration tests.
Work with third-party APIs and web services, and utilize API Gateways such as Apigee.
Build and optimize data ETL pipelines using technologies like Airflow, PySpark, MySQL, Hive, and Snowflake.
Collaborate with cross-functional teams in an Agile/Scrum environment, partnering with business analysts, developers, and testers to implement innovative solutions.

Qualifications

Minimum of 7-8 years of experience as a Backend Software Engineer.
Have strong development experience with Python.
At least 2-3 years of experience with AWS technologies.
Solid knowledge of building data ETL pipelines with tools such as Airflow, PySpark, MySQL, Hive, and Snowflake.
Proven experience in writing well-tested applications, including unit, functional, and integration tests.
Familiarity with third-party APIs, web services, and API Gateways like Apigee.
Experience with data catalog tools like Atlan is a plus.
Experience working in an Agile/Scrum setting, collaborating with business analysts, developers, and testers.

We are looking for a proactive and skilled individual who can contribute effectively to our dynamic team and help us achieve our goals through innovative solutions and best practices.

APPLY NOW!

Kindly share your upated resume at hr@techedinlabs.com

Techedin is a global IT Services company complementing the efforts of technology-driven enterprises in developing cutting-edge solutions for humans. We offer services in enterprise app development, content management solutions (CMS), customer relationship management (CRM), cloud engineering, custom software development, and data engineering. Our services include IT Consulting, project management, Software Quality Assurance, and data and analytics services. We develop and maintain various software applications and all other computer-related ancillary services. We have excellent professionals working round the clock to build the best technology teams and products for our customers.","{""role_summary"":""Develop and maintain high-quality backend solutions using Python, collaborating with cross-functional teams to implement innovative solutions."",""key_terms"":[{""term"":""API Gateways"",""explanation"":""Tools that act as an entry point for client requests, managing and securing API traffic, such as Apigee.""},{""term"":""ETL pipelines"",""explanation"":""Extract, Transform, Load processes that move data from one system to another, using tools like Airflow, PySpark, MySQL, Hive, and Snowflake.""},{""term"":""Agile/Scrum environment"",""explanation"":""A collaborative project management approach that emphasizes iterative progress, flexibility, and continuous improvement.""}],""skill_priorities"":{""must_have"":[""Python"",""AWS technologies"",""Building data ETL pipelines"",""Writing well-tested applications""],""nice_to_have"":[""Experience with data catalog tools like Atlan"",""Familiarity with third-party APIs and web services""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize a data ETL pipeline using Airflow and PySpark?"",""example_answer"":""I would analyze the pipeline's current performance, identify bottlenecks, and implement parallel processing using PySpark. I would also leverage Airflow's built-in features for task scheduling and monitoring to ensure efficient data processing.""},{""question"":""How do you approach writing unit tests, functional tests, and integration tests for a Python application?"",""example_answer"":""I follow a test-driven development approach, writing unit tests to ensure individual components function correctly. Then, I write functional tests to verify the application's overall behavior, and finally, integration tests to validate how components interact.""}],""red_flags"":[""Lack of hands-on experience with AWS technologies"",""Inability to write well-tested applications""],""confidence_score"":95.0}"
Azure Data Engineer-ADF,"Role: Azure Data Engineer-ADF

Location: Remote/Canada

Duration: 6+ Months

Job Description

Skills Required:

Azure Data Engineer
ADF
Azure Data Bricks
Snowflake (Advance level)
Programming Language Combination : Python with (Scala or Psyspark )
SQL
Azure SQL Data Warehouse
Reporting tool : Azure Synapse Analytics.
Experience Level: 8+ years
Azure Data Factory, Spark, SQL, Python, Databricks, Snowflake

Job Responsibilities

Design, develop, and implement robust and scalable data solutions using Azure technologies, including Azure Data Factory, Azure SQL Data Warehouse, Azure Databricks, and/or Azure Synapse Analytics.

Proficient in programming languages like Spark (with either Python or Scala), SQL

Experience With Databases Like Sql Server, Teradata, Snowflake, Synapse.

Good understanding of data engineering principles, data modelling, data warehousing, and ETL/ELT processes which includes data testing, validation and reconciliation processes.

Hands-on experience with data integration and data transformation frameworks, tools, and methodologies.

Experience With Version Control Systems Like Git, GitHub Etc

Collaborate with cross-functional teams and business teams to understand business requirements and translate them into technical designs and solutions.

Build and maintain data pipelines, data integrations, and data transformations to enable efficient data processing, storage, and retrieval.

Optimize data infrastructure and solutions for performance, scalability, and cost-efficiency, ensuring high availability and reliability.

Conduct data profiling, data validation, and data cleansing activities to ensure data integrity and accuracy.

Mentor and provide technical guidance to junior data engineers, freshers/interns, fostering knowledge sharing and skills development within the team.

Good To Have

Experience with version control systems, CI/CD pipelines, and automated testing frameworks.

Knowledge in streaming technologies, pipelines and frameworks like Kafka, EventHub, Azure Stream Analytics.","{""role_summary"":""Design, develop, and implement scalable data solutions using Azure technologies, collaborating with cross-functional teams to translate business requirements into technical designs and solutions."",""key_terms"":[{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service that allows users to create, schedule, and manage data pipelines.""},{""term"":""Azure Databricks"",""explanation"":""A fast, easy, and collaborative Apache Spark-based analytics platform.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform that enables fast, secure, and scalable data analysis.""},{""term"":""ETL/ELT"",""explanation"":""Extract, Transform, Load/Extract, Load, Transform processes used to extract data from sources, transform it into a standardized format, and load it into a target system.""},{""term"":""CI/CD pipelines"",""explanation"":""Continuous Integration/Continuous Deployment pipelines that automate testing, building, and deployment of software applications.""}],""skill_priorities"":{""must_have"":[""Azure Data Engineer"",""ADF"",""Azure Data Bricks"",""Snowflake (Advance level)"",""Python with (Scala or Pyspark)"",""SQL"",""Azure SQL Data Warehouse"",""Azure Synapse Analytics""],""nice_to_have"":[""Experience with version control systems, CI/CD pipelines, and automated testing frameworks"",""Knowledge in streaming technologies, pipelines and frameworks like Kafka, EventHub, Azure Stream Analytics""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize data infrastructure for performance, scalability, and cost-efficiency in an Azure-based data solution?"",""example_answer"":""I would use Azure Data Factory to create a scalable data pipeline, implement data partitioning and caching, and leverage Azure Synapse Analytics for reporting and analytics. I would also monitor performance metrics and adjust the infrastructure accordingly.""},{""question"":""Can you explain the difference between ETL and ELT processes in data engineering?"",""example_answer"":""ETL (Extract, Transform, Load) involves extracting data from sources, transforming it into a standardized format, and loading it into a target system. ELT (Extract, Load, Transform) involves extracting data, loading it into a target system, and then transforming it. ELT is often used in big data and cloud-based data warehousing.""}],""red_flags"":[""Lack of experience with Azure Data Factory, Azure Databricks, or Snowflake"",""Inability to explain data engineering principles, data modelling, or ETL/ELT processes""],""confidence_score"":90.0}"
Data Engineer (Azure),"Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning, and AI. We are the trusted analytics partner for multiple Fortune 500 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best global analytics consulting team in the world.

We are looking for a Data Engineer to join our growing team of analytics experts. The right candidate will have strong analytical skills and the ability to combine data from different sources and will strive for efficiency by aligning data systems with business goals.

Requirements

Bachelor's degree in Computer Science or similar field
4+ years of experience in IT industry
Expertise in Python and Pyspark
Experience building data pipelines using Azure stack
2+ years of experience using Apache spark
Good working experience on Delta Lake and ETL processing
Proficiency in SQL queries
Prior experience of working in a Unix environment
Experience in harmonizing raw data into a consumer-friendly format using Azure Databricks
Experience extracting/querying/joining large data sets at scale
Experience building data ingestion pipelines using Azure Data Factory to ingest structured and unstructured data
Experience in data wrangling, advanced analytic modeling is preferred
Exposure to Java is a plus
Strong communication and organizational skills


Benefits

This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.","{""role_summary"":""A Data Engineer responsible for combining data from different sources, building data pipelines, and aligning data systems with business goals to generate business value."",""key_terms"":[{""term"":""Data Pipelines"",""explanation"":""A series of processes that extract, transform, and load data from various sources into a target system for analysis and reporting.""},{""term"":""Azure Stack"",""explanation"":""A set of cloud computing services and tools offered by Microsoft Azure, used for building, deploying, and managing applications and services.""},{""term"":""Apache Spark"",""explanation"":""An open-source data processing engine used for large-scale data processing, machine learning, and graph processing.""},{""term"":""Delta Lake"",""explanation"":""An open-source storage layer that enables scalable, secure, and reliable data lakes, providing a unified view of data across various sources.""},{""term"":""ETL Processing"",""explanation"":""Extract, Transform, and Load process used to extract data from various sources, transform it into a standardized format, and load it into a target system.""},{""term"":""Azure Databricks"",""explanation"":""A fast, easy, and collaborative Apache Spark-based analytics platform used for data engineering, data science, and data analytics.""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service used to create, schedule, and manage data pipelines across different sources and destinations.""}],""skill_priorities"":{""must_have"":[""Python"",""Pyspark"",""Azure Stack"",""Apache Spark"",""Delta Lake"",""ETL Processing"",""SQL queries"",""Unix environment""],""nice_to_have"":[""Java"",""Data wrangling"",""Advanced analytic modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data pipelines for better performance and scalability?"",""example_answer"":""I use techniques like data partitioning, caching, and parallel processing to optimize data pipelines. I also ensure that the pipeline is well-documented and follows best practices for maintainability and scalability.""},{""question"":""Can you explain how you would handle data quality issues in a data pipeline?"",""example_answer"":""I would identify the root cause of the issue, implement data validation and data quality checks, and develop a data cleansing process to handle invalid or inconsistent data. I would also collaborate with stakeholders to ensure that the data meets business requirements.""}],""red_flags"":[""Lack of experience with Azure Stack and Apache Spark"",""Inability to write efficient SQL queries"",""Poor communication and organizational skills""],""confidence_score"":90.0}"
"Python Data Engineer, Sovereign","About Nascent…

Founded in 2020, Nascent exists to build, expand, and capture opportunity, in open markets and permissionless technologies. Building from a base of permanent capital, we deploy assets across a range of both liquid and long-term strategies that ensure we are among the most active users of the open financial system we are helping to build. We've made venture investments in 50+ early-stage teams that we believe have the potential to create substantive change, expand boundaries, and find new horizons. We are consistently on the hunt for the most competitive and curious minds exploring the edges of the crypto ecosystem and leverage our hyper flexible structure to accelerate ideas into fully deployed strategies.

About Sovereign

Sovereign is a leading-edge proprietary trading fund at the forefront of innovation and intellectual property (IP) rights incubated within Nascent. Sovereign is building a unique approach to IP that enables individuals to retain full rights to the IP they create, ensuring value alignment between the creator and the company. This distinctive approach permits researchers the autonomy to potentially spin-off their IP into an independent entity, of which Sovereign will have an option to acquire 20%.

This approach minimizes the need for conventional employment limitations and constraints, offering increased slack. Our goal is to assemble a team of high-variance individuals, affording them the time, freedom, and motivation to discover and attempt their visions.

In the context of financial markets, higher-variance can lead to extreme results—from wild successes to uninvestable failures.

This process also produces uncorrelated results, creating an ideal environment for debate in a field where intellectual honesty is a prerequisite. Variance will grow when individuals are unconstrained. We aim to build a lab where diversity of ideas obtained through independent exploration leads to quality collaborations and discussions.

The Opportunity

As a Data Engineer on Sovereign, leverage your skills to create impactful data solutions in a fast-moving and flexible environment. You'll drive critical projects within our team by maintaining extensive historical data repositories from diverse sources, ensuring data quality and developing versatile tools for researchers to access data in various formats. By joining us, you'll play a vital part in enabling data-driven insights and supporting progressive research.

Experience Required

Demonstrated abilities in one of the Python data frame libraries (Pandas|Polars)
Ability to automate data collection from many different sources (websocket, api, S3, etc…)
Ability to handle reasonably large quantities of data (>10 TB,
Ability to build and maintain an API for the researchers to query the data.
The ideal candidate would have a baseline understanding of simple financial data.

Our Team & Culture

At Nascent, we are an interdisciplinary team of investors, builders & creators, capable of achieving more together than we can as individuals. We offer the opportunity to contribute to building the future global economic system with a world-class team and culture that pairs the freedom to explore, experiment & play with a competitive drive to win. We invest in our people by providing the autonomy to build, coupled with accountability & honest feedback to help learn, grow, perform & win. We’re a fully distributed team that understands the value of in-person time—we host two team retreats per year and encourage team members to come together for more frequent in-person work.

Principles that drive our team & work

Compete to win
Own your shit
Explore, experiment, play
Always be building
Seek and speak truth

What We Offer

At Nascent, we offer a competitive total compensation package heavily weighted toward bonus, ensuring that when we perform at our best and the firm wins we all win.

The opportunity to learn, experiment and build in an entrepreneurial environment
Comprehensive health benefits package including dental, vision, and life
Generous paid parental leave & supported return to work
Annual Health & Wellness Stipend of up to $1,000
Retirement plan matching contributions
Open vacation policy as well as flexible work hours and location
Access to our internal performance coaching, technical experts and support for continuing your skill development and growth
Team activities and bi-annual in-person team retreats

We are an equal opportunity employer and celebrate diversity and differences of perspectives. We do not discriminate on the basis of any status, inclusive of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","{""role_summary"":""As a Data Engineer on Sovereign, you will create impactful data solutions in a fast-moving and flexible environment, driving critical projects by maintaining historical data repositories, ensuring data quality, and developing versatile tools for researchers."",""key_terms"":[{""term"":""IP rights"",""explanation"":""Intellectual Property rights, referring to the ownership and control of creative works and innovations.""},{""term"":""Hyper flexible structure"",""explanation"":""A business structure that allows for rapid adaptation and change, enabling the acceleration of ideas into fully deployed strategies.""},{""term"":""High-variance individuals"",""explanation"":""Individuals with diverse skills, experiences, and perspectives, capable of producing innovative and uncorrelated results.""},{""term"":""Uncorrelated results"",""explanation"":""Outcomes that are not directly related to each other, allowing for diverse perspectives and approaches.""},{""term"":""Polars"",""explanation"":""A Python data frame library used for data manipulation and analysis.""}],""skill_priorities"":{""must_have"":[""Python data frame libraries (Pandas|Polars)"",""Ability to automate data collection from diverse sources"",""Ability to handle large quantities of data (>10 TB)"",""Ability to build and maintain an API for researchers""],""nice_to_have"":[""Baseline understanding of simple financial data""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach automating data collection from multiple sources, such as websockets, APIs, and S3?"",""example_answer"":""I would use Python libraries like Pandas and Polars to create a data pipeline that can handle diverse data sources, and then implement a scheduling system to automate the data collection process.""},{""question"":""How do you ensure data quality when working with large datasets?"",""example_answer"":""I would implement data validation and cleaning scripts to ensure data consistency, and then use data visualization tools to identify and address any data quality issues.""}],""red_flags"":[""Lack of experience with Python data frame libraries"",""Inability to handle large quantities of data"",""Limited understanding of data quality and validation""],""confidence_score"":90.0}"
"Data Engineer, Advanced Analytics","Toronto, ON

Contract

The Data Engineer will enable the data infrastructure for Advanced Analytics team in Canadian Banking

Analytics (CBA) group ensuring business strategies, plans and initiatives are executed / delivered in

compliance with internal policies and procedures. The role will be responsible for leading the development and

execution of data pipelines and data assets supporting the CBA group. The role will also support the creation

of new enterprise data sources in coordination with other teams in CBA. The incumbent will report into the

Director, Advanced Analytics.

Accountabilities

Guides the data architecture for creation of data assets to be used for modelling, BI, Marketing

operations and other analytic functions within the scope of Canadian Banking Analytics

Performs data engineering activities to create and maintain the data assets required. Leads the

creation of data pipelines and design of ETL work to transform and manage data at scale. Responsible

for the orchestration of the data pipelines / ETL processes and monitoring of these processes for

accuracy, reliability and timeliness.

Enables the migration of data stores and analytical datasets from the data warehouse and enterprise

data lake to global data & analytics platform.

Executes data management activities to design and build dataset for analytics and bring in data from

multiple data platform and environments. Assemble large, complex data sets that meet functional / nonfunctional business requirements

Executes on data governance activities to ensure good data quality and integrity for critical datasets

used by the CBA team across the various analytical use cases.

Responsible for ingesting new/alternative sources of data to generate business value.

Champions a high-performance environment and contributes to an inclusive work environment.

Participate on special project teams as required to support the delivery of strategic Bank initiatives.

Actively pursues effective and efficient operations of his/her respective areas, while ensuring the

adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with

respect to operational risk, regulatory compliance risk, AML/ATF risk and conduct risk, including but not

limited to responsibilities under the Operational Risk Management Framework, Regulatory Compliance

Risk Management Framework, AML/ATF Global Handbook and the Guidelines for Business Conduct.","{""role_summary"":""The Data Engineer leads the development and execution of data pipelines and data assets, ensuring business strategies are executed in compliance with internal policies and procedures."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Data Lake"",""explanation"":""A centralized repository that stores all types of data in its native format, allowing for flexible schema-on-read analytics.""},{""term"":""Data Governance"",""explanation"":""The process of managing data quality, integrity, and security to ensure it is accurate, reliable, and accessible.""},{""term"":""AML/ATF"",""explanation"":""Anti-Money Laundering and Anti-Terrorist Financing - regulations aimed at preventing illegal financial activities.""}],""skill_priorities"":{""must_have"":[""Data engineering"",""Data pipeline development"",""ETL"",""Data governance"",""Data quality management""],""nice_to_have"":[""Experience with global data & analytics platforms"",""Knowledge of AML/ATF regulations""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach data quality management in a large-scale data pipeline?"",""example_answer"":""I implement data validation checks at each stage of the pipeline, and use data profiling to identify anomalies. I also work closely with stakeholders to understand business requirements and ensure data meets those needs.""},{""question"":""Can you describe your experience with data governance in a regulated industry?"",""example_answer"":""In my previous role, I worked with the data governance team to develop policies and procedures for data management. I ensured data quality and integrity by implementing data validation rules and data lineage tracking.""}],""red_flags"":[""Lack of experience with data engineering in a banking or financial services environment"",""Inability to explain data governance principles and practices""],""confidence_score"":90.0}"
Data Engineer - II,"We are looking for a ""Data Engineer"" in Montreal, QC, Canada. The position's description is given below. It is a Hybrid opportunity (2 days a week in office)

Responsibilities

Job description:

Advise on the optimal plan for the Genuine Optimized Campaign process.
Create foundational campaign tables into Hive and Snowflake using SQL, Python and Pyspark.
Help collect new data points from VWO via API access to assess the performance the campaigns.
Enable daily assignment to have fresh new non-compliant users into the campaign.
Create databases to enable Champion/Challenger philosophy.
Improve the current data stack for launching automated campaigns.
Help create the environment for deploying RL (Reinforcement Learning) algorithm to manage campaigns.

Minimum Qualifications

Bachelor’s degree or higher in a quantitative field
5+ years of experience in data analysis role
3+ years of experience in Python, SQL, and visualization tools like PowerBI
A proven track record of decision making and problem solving based on analytics. Conceptual thinking skills must be complemented by a strong quantitative orientation.
Experienced with AWS and proficient in coding with Spark/PySpark
Strong business judgment, leadership, and integrity. You should be a tenacious decision maker, able to bring a healthy, aggressive, yet responsible approach to business.
Excellent written and oral communication skills, coupled with strategic influencing skills and the ability to drive agreement through intellect, interpersonal and negotiation.
Strong skills in BI tools and Excel. Knowledge of PowerBI a plus
Skilled in using data mining techniques, including supervised and unsupervised learning
Familiar with Airflow for workflow management
Able to collaborate effectively within a cross-functional, matrix environment.

Techedin is a global IT Services company complementing the efforts of technology-driven enterprises in developing cutting-edge solutions for humans. We offer services in enterprise app development, content management solutions (CMS), customer relationship management (CRM), cloud engineering, custom software development, and data engineering. Our services include IT Consulting, project management, Software Quality Assurance, and data and analytics services. We develop and maintain various software applications and all other computer-related ancillary services. We have excellent professionals working round the clock to build the best technology teams and products for our customers.","{""role_summary"":""The Data Engineer will design and implement data solutions to optimize campaign performance, leveraging tools like Hive, Snowflake, and Python. They will also develop databases, improve data stacks, and deploy reinforcement learning algorithms."",""key_terms"":[{""term"":""Hive"",""explanation"":""A data warehousing and SQL-like query language for Hadoop, used for storing and processing large datasets.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and processing large datasets, providing scalability and performance.""},{""term"":""Pyspark"",""explanation"":""A Python library for Apache Spark, used for large-scale data processing and machine learning tasks.""},{""term"":""Reinforcement Learning (RL)"",""explanation"":""A machine learning approach focused on training agents to make decisions based on rewards or penalties, used in this role for campaign management.""},{""term"":""Champion/Challenger philosophy"",""explanation"":""A data-driven approach to testing and optimizing campaign performance by comparing different strategies.""},{""term"":""Airflow"",""explanation"":""A workflow management system for automating and scheduling data pipelines and tasks.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Pyspark"",""AWS"",""Data analysis"",""Problem-solving"",""Communication skills""],""nice_to_have"":[""PowerBI"",""BI tools"",""Excel"",""Data mining techniques"",""Supervised and unsupervised learning"",""Airflow""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize the data pipeline for a large-scale campaign?"",""example_answer"":""I would use Pyspark to process the data, and then leverage Snowflake for data warehousing and Hive for data storage. I would also implement data quality checks and monitoring to ensure data integrity.""},{""question"":""Can you explain how you would deploy a reinforcement learning algorithm for campaign management?"",""example_answer"":""I would use Python to develop the RL algorithm, and then deploy it using Airflow for workflow management. I would also ensure data quality and monitoring to optimize campaign performance.""}],""red_flags"":[""Lack of experience with cloud-based data warehousing platforms"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":85.0}"
Data Engineer - Data Platform,"Mark43 is approved to hire in Canada, the UK, and 40 U.S states, including AL, AZ, CA-excluding San Francisco, CO, CT, DC, DE, FL, GA, IA, ID, IL, IN, KS, LA, MA, MD, ME, MI, MN, MO, NE, NV, NH, NJ, NM, NY, NC, OH, OR, PA, SC, SD, TN, TX, UT, VA, VT, WA, and WI. Before applying to a remote role, please ensure that you are able to perform the position in one of the states listed above. State locations and specifics are subject to change as our hiring requirements shift.

Applicants must be authorized to work for any employer in the country in which the role is being hired. We are unable to sponsor or take over sponsorship of an employment visa at this time.

At Mark43, our mission is to empower communities and their governments with new technologies that improve the safety and quality of life for all. We build powerful, scalable, and elegant software that sets a new standard for the tools upon which our first responders rely. Our users are diverse, and we are therefore committed to embracing diversity of thought and experience within our team.

Role Overview:

We're looking for an experienced and innovative Data Engineer to join our team and help propel our data platform to enterprise capabilities. In this role, you'll take ownership of architecting and implementing scalable infrastructure and data pipelines dedicated to providing analytic systems to our customers.

What You'll Do:

If you were a part of our team, here are some things you would have done last week:

Collaborated with Product Managers to understand requirements for new data features.
Utilized technologies such as SQL, Python, DMS, Redshift, Glue, S3, Lambdas, PySpark, Google Looker, Terraform.
Participated in on-call rotation to ensure the reliability and performance of our data platform.
Owned end-to-end technical solutions for data products or subsets.
Reviewed code submitted by other engineers and provided valuable feedback.
Improved the architectural strategy of our data platform to meet the growing needs of our customer base.
Tested out new technologies and contributed to discussions on improving our engineering practices.

What You'll Need:

We are seeking engineers with at least 4 years of professional experience in data focused engineering roles. You should have experience building infrastructure with technologies like SQL, DMS, Redshift, Glue, S3, Lambdas, PySpark, Google Looker, Terraform. Experience with cloud-based development, such as AWS or Azure, is essential. Additionally, you should have strong proficiency in building and managing RESTful APIs, automated testing, and Agile methodologies.

Characteristics We Look For:

Humble, open, and curious mindset.
Attentive, active listener who values collaboration.
Resilience and proactive problem-solving abilities.
Comfortable with uncertainty and eager to learn and grow.
Enthusiastic collaborator who values shared ownership and knowledge sharing.

Compensation:

We believe in equal pay for equal work, and transparency in compensation is a core value. Total compensation for this role is market competitive, including a target base annual salary range of $115,000 - $140,000, plus bonus opportunity, company stock options, and a full benefits package, including health insurance, paid time off, and a 401k.

Our Privacy Notice describes how Mark43 uses and protects the personal information of prospective employees during the recruitment process. It informs you about our handling of the personal information you provide to us when you apply for a position in our organization and in general when you express your interest in joining our team.

As a part of Mark43's security measures all employees must: Engage in appropriate use of the company's electronic information resources; Become knowledgeable about and follow relevant security policies and guidelines; Protect the resources under their control, such as passwords, computers, and data that they create, receive, or download; and Promptly report security-related incidents and violations, and responding to official reports of security incidents involving their systems or accounts.

Mark43 is committed to the full inclusion of all qualified individuals. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex disability, age, sexual orientation, gender identity, national origin, veteran status, or genetic information. As part of this commitment, we will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed, please email recruiting@Mark43.com requesting the accommodation.","{""role_summary"":""Design and implement scalable infrastructure and data pipelines to provide analytic systems to customers as a Data Engineer at Mark43."",""key_terms"":[{""term"":""Data Engineer"",""explanation"":""A technical expert responsible for designing, building, and maintaining large-scale data systems.""},{""term"":""Scalable infrastructure"",""explanation"":""A system or architecture that can handle increased load or demand without compromising performance.""},{""term"":""Data pipelines"",""explanation"":""A series of processes that extract, transform, and load data from one system to another.""},{""term"":""SQL"",""explanation"":""A standard language for managing relational databases.""},{""term"":""DMS"",""explanation"":""Data Management System, a software tool for managing and integrating data from various sources.""},{""term"":""Redshift"",""explanation"":""A data warehousing and analytics service by Amazon Web Services (AWS).""},{""term"":""Glue"",""explanation"":""A fully managed extract, transform, and load (ETL) service by AWS.""},{""term"":""S3"",""explanation"":""A cloud-based object storage service by AWS.""},{""term"":""Lambdas"",""explanation"":""A serverless computing service by AWS that runs code in response to events.""},{""term"":""PySpark"",""explanation"":""A Python library for big data processing that provides high-level APIs.""},{""term"":""Google Looker"",""explanation"":""A cloud-based business intelligence and analytics platform.""},{""term"":""Terraform"",""explanation"":""An infrastructure as code (IaC) tool for managing and provisioning cloud and on-premises resources.""}],""skill_priorities"":{""must_have"":[""4+ years of professional experience in data-focused engineering roles"",""Experience building infrastructure with technologies like SQL, DMS, Redshift, Glue, S3, Lambdas, PySpark, Google Looker, Terraform"",""Strong proficiency in building and managing RESTful APIs, automated testing, and Agile methodologies"",""Experience with cloud-based development, such as AWS or Azure""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a scalable data pipeline to handle high volumes of data?"",""example_answer"":""I would use a combination of technologies like AWS Glue, S3, and Redshift to create a scalable data pipeline. I would also implement automated testing and monitoring to ensure data quality and performance.""},{""question"":""Can you explain how you would optimize the performance of a slow-running data query?"",""example_answer"":""I would use tools like SQL query optimization and indexing to improve performance. I would also consider rewriting the query to take advantage of parallel processing and caching.""}],""red_flags"":[""Lack of experience with cloud-based development"",""Inability to work collaboratively in an Agile environment""],""confidence_score"":90.0}"
Associate Engineer - Data,"ZS is a place where passion changes lives. As a management consulting and technology firm focused on transforming global healthcare and beyond, our most valuable asset is our people. Here you’ll work side-by-side with a powerful collective of thinkers and experts shaping life changing solutions for patients, caregivers and consumers, worldwide. ZSers drive impact by bringing a client first mentality to each and every engagement. We partner collaboratively with our clients to develop products that create value and deliver company results across critical areas of their business including portfolio strategy, customer insights, research and development, operational and technology transformation, marketing strategy and many more. Bring your curiosity for learning; bold ideas; courage and passion to drive life changing, impact to ZS.

Our most valuable asset is our people.

At ZS we honor the visible and invisible elements of our identities, personal experiences and belief systems—the ones that comprise us as individuals, shape who we are and

make us unique. We believe your personal interests, identities, and desire to learn are part of your success here. Learn more about our diversity, equity, and inclusion efforts and the networks ZS supports to assist our ZSers in cultivating community spaces, obtaining the resources they need to thrive, and sharing the messages they are passionate about.

Associate Engineer - Data

Overview

The Data Engineer is a critical member of the engineering team, responsible for designing, building, and maintaining robust data systems and infrastructure. This role focuses on enabling efficient data processing, collection, storage, and analysis at scale to support data-driven decision-making and operational optimization.

Responsibilities

Data Engineering:

Build, Orchestrate and optimize data pipelines to extract, transform, and load (ETL) data from various sources into the organization's data warehouse or data lake.
Integrate data from diverse sources such as databases, APIs, streaming platforms, and file systems into cohesive data pipelines
Implement data integration solutions that support real-time, batch, and incremental data processing.
Implement data quality checks and validation processes to ensure the accuracy, completeness, and consistency of data.
Develop and maintain high-performance data pipelines that seamlessly integrate data from various sources into data warehouses, data lakes, and other storage solutions.
Develop monitoring and alerting mechanisms to identify and address data quality issues proactively.
Optimize ETL (Extract, Transform, Load) processes for efficiency, reliability, and data quality.
Implement and manage data storage solutions, including relational databases, NoSQL databases, and distributed file systems.
Manage the infrastructure and resources required to support data engineering workflows, including compute clusters, storage systems, and data processing frameworks.
Implement security controls and data governance measures for an application to protect sensitive data and ensure compliance with regulatory requirements such as GDPR, CCPA, HIPAA, and PCI-DSS. Implement encryption, access controls, and auditing mechanisms to safeguard data privacy and integrity.

Data Engineering Best Practices:

Write production-ready, testable code that adheres to engineering best practices and accounts for edge cases and error handling.
Develop comprehensive unit tests and integration tests to validate data pipeline functionality and data integrity.
Stay up to date with the latest data engineering tools, technologies, and methodologies, and evaluate their applicability to the team's needs.

Technical Collaboration:

Collaborate with business analysts, and other stakeholders to understand data requirements and translate them into robust engineering solutions.
Work closely with other engineering teams to integrate data solutions seamlessly into the overall technology ecosystem.
Participate actively in agile ceremonies, communicate progress, and manage dependencies effectively.

Education / Skills / Experience Education: A relevant bachelor’s or master’s degree in computer science, Data Engineering, or a related technical field.

Technical Skills:

Proficiency in programming languages such as Python, Java, or Scala.
Extensive experience with big data technologies (e.g., Hadoop, Spark, Kafka) and cloud-based data platforms (e.g., AWS, Azure).
Expertise in data integration and ETL tools (e.g., Talend, Informatica, Apache NiFi).
Strong understanding of data warehousing, and data lake concepts and best practices.
Familiarity with CI/CD pipelines and application monitoring practices.
Certifications in data engineering (e.g., Azure Data Engineer, AWS Certified Data Engineer) are a plus.

Experience:

1-3 years of experience in a data engineering role, with a focus on building scalable, reliable, and high-performance data systems.
Proven track record of designing and implementing data pipelines, data storage solutions, and data processing workflows.
Hands-on experience with distributed computing frameworks and cloud-based data services.
Demonstrated ability to collaborate with cross-functional teams and communicate technical solutions effectively.
Ability to travel to other client offices or locations as needed.
Strong communications skills.

Perks & Benefits:

ZS offers a comprehensive total rewards package including health and well-being, financial planning, annual leave, personal growth and professional development. Our robust skills development programs, multiple career progression options and internal mobility paths and collaborative culture empowers you to thrive as an individual and global team member.

We are committed to giving our employees a flexible and connected way of working. A flexible and connected ZS allows us to combine work from home and on-site presence at clients/ZS offices for the majority of our week. The magic of ZS culture and innovation thrives in both planned and spontaneous face-to-face connections.

Considering applying?

At ZS, we're building a diverse and inclusive company where people bring their passions to inspire life-changing impact in global healthcare and beyond. We are most interested in finding the best candidate for the job and recognize the value that candidates with all backgrounds, including non-traditional ones, bring. If you are interested in joining us, we encourage you to apply even if you don't meet 100% of the requirements listed above.

ZS is an equal opportunity employer and is committed to providing equal employment and advancement opportunities without regard to any class protected by applicable law.

To Complete Your Application:

Candidates must possess or be able to obtain work authorization for their intended country of employment.

ZS is committed to providing and maintaining a safe workplace. Must have received full COVID-19 vaccination by date of hire to be considered. Proof of vaccination will be required upon acceptance of offer of employment. Exemption process available on a limited basis.

NO AGENCY CALLS, PLEASE.

Find Out More At:

www.zs.com","{""role_summary"":""Design, build, and maintain robust data systems and infrastructure to support data-driven decision-making and operational optimization."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, and Load data from various sources into a data warehouse or data lake.""},{""term"":""Data pipeline"",""explanation"":""A series of processes that extract, transform, and load data from various sources into a data warehouse or data lake.""},{""term"":""Data governance"",""explanation"":""The process of managing and controlling data to ensure its accuracy, completeness, and consistency.""},{""term"":""Data lake"",""explanation"":""A centralized repository that stores all types of data in its native format.""},{""term"":""Data warehousing"",""explanation"":""A system used for reporting and data analysis, which stores data in a structured and formatted way.""}],""skill_priorities"":{""must_have"":[""Programming languages such as Python, Java, or Scala"",""Experience with big data technologies (e.g., Hadoop, Spark, Kafka)"",""Expertise in data integration and ETL tools (e.g., Talend, Informatica, Apache NiFi)"",""Strong understanding of data warehousing and data lake concepts and best practices""],""nice_to_have"":[""Certifications in data engineering (e.g., Azure Data Engineer, AWS Certified Data Engineer)""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize ETL processes for efficiency, reliability, and data quality?"",""example_answer"":""I would use techniques such as parallel processing, data partitioning, and data caching to optimize ETL processes. I would also implement data quality checks and validation processes to ensure the accuracy, completeness, and consistency of data.""},{""question"":""How do you ensure data security and compliance with regulatory requirements?"",""example_answer"":""I would implement security controls and data governance measures such as encryption, access controls, and auditing mechanisms to safeguard data privacy and integrity. I would also ensure compliance with regulatory requirements such as GDPR, CCPA, HIPAA, and PCI-DSS.""}],""red_flags"":[""Lack of experience with big data technologies"",""Inability to communicate technical solutions effectively""],""confidence_score"":90.0}"
Data Engineer - Tableau,"Work and develop in the Data Science and Data Engineering area


Required

2-5 years of experience with the following
Alteryx
Tableau
Data story telling experience
Desired

Data Management and Data warehouse knowledge
Technical writing experience
Data Governance Skills
JIRA knowledge
Agile Knowledge


GalaxE is a professional IT services firm that specializes in platform-driven solutions and the use of automation to achieve enterprise business transformation and mission-critical change for some of the largest companies in the world. Using our proprietary solution set, GxFource®, we apply machine learning techniques and predictive analytics tools as part of a broad artificial intelligence strategy that provides effective impact and data-driven business transformation.

Since its founding, GalaxE has been dedicated to advancing the benefits of technology. As we continue that legacy and look to the future, a focus on business enablement through agile, cost-efficient, and effective integration of people, process, and technology anchors our success. We revolutionize change in the costs of doing business that transform companies and their ability to leap beyond the competition.

At GalaxE we value people and are committed to diversity and inclusion where our employees are made to feel comfortable and are encouraged to be authentic. We focus on cultivating both traditional IT and non-traditional, new collar, workers through our Outsource to America®, program.

We are always looking for passionate, entrepreneurial-minded innovators and disrupters; game-changers that take ownership of the work they produce and bring it each and every day. Working with like-minded team members you will get a chance to discover, develop, and use cutting-edge technologies to transform the way we deliver creative business solutions.

Sound like you? Join us and find out for yourself what it means for you, and your career, to be part of the GalaxE team. Let’s build something, together. #WeAreGalaxE

Equal Opportunity Employer/Veterans/Disabled
Pay is based on several factors including market location and may vary depending on actual job-related knowledge, skills, and experience.


Physical Requirements

Prolonged periods of remaining stationary at a desk and working on a computer
Must be able to lift to 15 lbs., as needed
Must be able to work on-site (corporate/client offices), as needed (not applicable for 100% remote roles)
Occasionally required to bend, kneel, crouch, and reach overhead.
Hand-eye coordination necessary to operate computers and various pieces of office equipment.
Specific vision abilities required include close vision, the ability to tolerate fluorescent lighting, and the ability to adjust focus.


Employees must be able to perform the physical requirements of the position satisfactorily and, if requested, reasonable accommodations will be made to enable employees requiring accommodations to perform the essential functions of their jobs, absent undue hardship.

For more information, please visit https//www.galaxe.com/","{""role_summary"":""Work on data science and data engineering projects, developing and applying data storytelling skills to drive business transformation."",""key_terms"":[{""term"":""Alteryx"",""explanation"":""A data analytics platform used for data preparation, analysis, and reporting.""},{""term"":""Tableau"",""explanation"":""A data visualization tool used to create interactive dashboards and reports.""},{""term"":""Data Governance"",""explanation"":""The process of managing and overseeing the availability, usability, integrity, and security of an organization's data.""},{""term"":""JIRA"",""explanation"":""A project management tool used for tracking and managing software development projects.""},{""term"":""Agile"",""explanation"":""An iterative approach to project management that focuses on flexibility, collaboration, and continuous improvement.""}],""skill_priorities"":{""must_have"":[""Alteryx"",""Tableau"",""Data storytelling""],""nice_to_have"":[""Data Management and Data warehouse knowledge"",""Technical writing experience"",""Data Governance Skills"",""JIRA knowledge"",""Agile Knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data storytelling for a complex business problem?"",""example_answer"":""I would start by understanding the business problem and identifying the key stakeholders. Then, I would collect and analyze the relevant data, and use tools like Tableau to create interactive dashboards that effectively communicate the insights. Finally, I would present the findings in a clear and concise manner, using data visualization to support my narrative.""},{""question"":""How do you stay organized and manage multiple projects simultaneously using Agile methodologies?"",""example_answer"":""I use JIRA to track and manage my projects, and prioritize tasks based on their urgency and impact. I also collaborate closely with my team to ensure that everyone is aligned on the project goals and objectives, and that we're working together to achieve them.""}],""red_flags"":[""Lack of experience with data visualization tools like Tableau"",""Inability to effectively communicate complex data insights to non-technical stakeholders""],""confidence_score"":85.0}"
Data Engineer (Canada),"Title: Data Engineer

Location: Remote

Duration: Contract

Rate: $Open

Requirements

Technical expertise :

BSc/MSc in Computer Science, Computer Science, Information Systems or related Technical Discipline
1-4 years' experience in Data Engineer role (5-10 years for senior data engineer)
Deep knowledge of Python, SQL, and PySparkis required.
Experience working with data pipelines, architecture principles, batch and stream processing systems, and DataOps.
Experience working with large data sets, Azure cloud services including Azure Data Lake, Data factory, Databricks, Azure DevOps.
Background in programming in Python, Scala, C, C++, Java is beneficial


Agile experience :

Experience working in AI startup environment or organisationswith an agile culture
Professional attitude and service orientation; superb team player


Benefits

Note: If interested please send your updated resume to ajith.anthoniraj@two95intl.com and include your rate requirement along with your contact details with a suitable time when we can reach you. If you know of anyone in your sphere of contacts, who would be a perfect match for this job then, we would appreciate if you can forward this posting to them with a copy to us.

We look forward hearing from you at the earliest!","{""role_summary"":""Design, build, and maintain large-scale data pipelines and architectures, ensuring efficient data processing and storage."",""key_terms"":[{""term"":""PySpark"",""explanation"":""A Python library for large-scale data processing, used for building data pipelines and architectures.""},{""term"":""DataOps"",""explanation"":""A set of practices that combines DevOps and data engineering to improve the speed, quality, and reliability of data pipelines.""},{""term"":""Azure Data Lake"",""explanation"":""A cloud-based data storage and analytics platform, used for storing and processing large amounts of data.""},{""term"":""Databricks"",""explanation"":""A cloud-based platform for working with big data, providing a collaborative workspace for data engineers and scientists.""},{""term"":""Azure DevOps"",""explanation"":""A set of services for collaborative software development, delivery, and collaboration, used for managing the development lifecycle of data pipelines.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""PySpark"",""Data pipelines"",""Data architecture principles"",""Batch and stream processing systems"",""Azure cloud services""],""nice_to_have"":[""Scala"",""C"",""C++"",""Java"",""Agile experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data pipeline performance in a cloud-based environment?"",""example_answer"":""I would use techniques such as data partitioning, caching, and parallel processing to optimize data pipeline performance. Additionally, I would leverage cloud-based services such as Azure Data Lake and Databricks to improve data processing efficiency.""},{""question"":""Can you explain the concept of DataOps and how it improves data pipeline development?"",""example_answer"":""DataOps is a set of practices that combines DevOps and data engineering to improve the speed, quality, and reliability of data pipelines. It involves automating data pipeline development, testing, and deployment, and provides a collaborative workspace for data engineers and scientists. This approach improves data pipeline development by reducing errors, increasing efficiency, and enhancing collaboration.""}],""red_flags"":[""Lack of experience with cloud-based data services"",""Inability to work in an agile environment""],""confidence_score"":90.0}"
Python ETL Developer/Data Engineer - Remote,"Specific Duties

-Reviewing, designing, developing ETL jobs to ingest data into Data Lake, load data to data marts;
-extract data to integrate with various business applications.
-Parse unstructured data, semi structured data such XML etc.
-Design and develop efficient Mapping and workflows to load data to Data Marts
-Map XML DTD schema in Python (customized table definitions)
-Write efficient queries and reports in Hive or Impala to extract data on ad hoc basis for data analysis.
-Identify the performance bottlenecks in ETL Jobs and tune their performance by enhancing or redesigning them.
-Responsible for performance tuning of ETL mappings and queries.
-import tables and all necessary lookup tables to facilitate the ETL process required to process daily XML files in addition to processing the very large (multi-terabytes) historical XML data files","{""role_summary"":""Design, develop, and maintain ETL jobs to ingest data into a Data Lake, load data to data marts, and extract data for business applications."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from various sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Data Lake"",""explanation"":""A centralized repository that stores all types of data in its native format, allowing for flexible and scalable data processing.""},{""term"":""Data Marts"",""explanation"":""A subset of a data warehouse, containing a specific portion of the overall data, optimized for querying and reporting.""},{""term"":""XML"",""explanation"":""Extensible Markup Language - a markup language used to store and transport data in a format that is both human-readable and machine-readable.""},{""term"":""DTD"",""explanation"":""Document Type Definition - a set of rules that defines the structure and organization of an XML document.""},{""term"":""Hive"",""explanation"":""A data warehousing and SQL-like query language for Hadoop, used for data analysis and reporting.""},{""term"":""Impala"",""explanation"":""A high-performance, distributed SQL engine for Hadoop, used for fast data analysis and reporting.""}],""skill_priorities"":{""must_have"":[""ETL development"",""Data Lake architecture"",""Data Mart design"",""XML parsing"",""Python programming"",""Hive or Impala query writing""],""nice_to_have"":[""Performance tuning"",""Data analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize the performance of an ETL job that is experiencing bottlenecks?"",""example_answer"":""I would identify the bottleneck by analyzing the job's logs and metrics, then apply optimization techniques such as parallel processing, data partitioning, or query rewriting to improve performance.""},{""question"":""How do you handle parsing unstructured or semi-structured data in an ETL process?"",""example_answer"":""I would use a combination of techniques such as regular expressions, data profiling, and data quality checks to extract relevant information from the data, and then transform it into a structured format for further processing.""}],""red_flags"":[""Lack of experience with ETL development and data warehousing"",""Inability to write efficient queries in Hive or Impala""],""confidence_score"":90.0}"
Big Data Engineer - Canada,"Role: Big DATA Developer

Location: Mississauga, ON/Canada-Onsite from Day one

Duration: Full time with Altimetrik

Job Description

Technical & Other Skills:

7+ years of working experience in scalable data pipeline using Scala, Python, pyspark, Hadoop, Apache Spark, Spark SQL, Kafka, Nifi, ETL and Incremental Data Load with Big data technologies.

Experience of working with Databases like Oracle, Netezza and have strong SQL knowledge

Developing scalable streaming solutions based on Hadoop/ Big Data stack such as HDFS, Ozone, Hive/ Impala, Apache Spark and Kafka.

Experience in Data Engineering and implementing multiple end-to-end DW projects in Big Data environment

Experience of building data pipelines through Git, Shell, Spark with Java/Python on Hadoop or Object storage (S3/CEPH)

Strong analytical skills required for debugging production issues, providing root cause and implementing mitigation plan

Strong communication skills - both verbal and written and strong relationship, collaboration skills and organizational skills

Flexible enough to stretch and work in India time to coordinate with India team

Experiences

Nice to have development experience in Python based AI/ML workloads on Hadoop.

Experience of working on Nifi, APIs and Unix Environment will be an added advantage

Experience of working in Agile teams

Ability to multi-task across multiple projects, interface with external / internal resources and provide technical leadership to junior team members

Ability to be high-energy, detail-oriented, proactive and able to function under pressure in an independent environment along with a high degree of initiative and self-motivation to drive results

Ability to quickly learn and implement new technologies, and perform POC to explore best solution for the problem statement

Contribute ideas to help ensure that required standards and processes are in place and actively look for opportunities to enhance standards and improve process efficiency

Perform assigned tasks and production incident independently

Proven track record of delivering and willingness to roll up sleeves to get the job done.","{""role_summary"":""Develop scalable data pipelines and streaming solutions using big data technologies, ensuring strong analytical and communication skills to debug production issues and collaborate with teams."",""key_terms"":[{""term"":""Scala"",""explanation"":""A programming language used for building scalable data pipelines.""},{""term"":""pyspark"",""explanation"":""A Python library for Apache Spark, used for data processing and analysis.""},{""term"":""Hadoop"",""explanation"":""A big data technology used for storing and processing large datasets.""},{""term"":""Apache Spark"",""explanation"":""An open-source data processing engine used for big data analytics.""},{""term"":""Spark SQL"",""explanation"":""A module in Apache Spark for structured data processing.""},{""term"":""Kafka"",""explanation"":""A distributed streaming platform used for real-time data processing.""},{""term"":""Nifi"",""explanation"":""A data integration tool used for building data pipelines.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process used for data integration and migration.""},{""term"":""Incremental Data Load"",""explanation"":""A process of loading data in increments, used for efficient data processing.""},{""term"":""Ozone"",""explanation"":""A scalable object store used for big data storage.""},{""term"":""Hive/Impala"",""explanation"":""Data warehousing and SQL-like query engines used for big data analytics.""},{""term"":""Git"",""explanation"":""A version control system used for managing code repositories.""},{""term"":""Shell"",""explanation"":""A command-line interface used for executing scripts and commands.""},{""term"":""S3/CEPH"",""explanation"":""Cloud-based object storage solutions used for big data storage.""},{""term"":""AI/ML"",""explanation"":""Artificial Intelligence and Machine Learning - used for building intelligent systems.""},{""term"":""Agile teams"",""explanation"":""Collaborative teams that follow agile methodologies for project management.""},{""term"":""Unix Environment"",""explanation"":""A operating system environment used for executing scripts and commands.""}],""skill_priorities"":{""must_have"":[""Scala"",""Python"",""pyspark"",""Hadoop"",""Apache Spark"",""Spark SQL"",""Kafka"",""Nifi"",""ETL"",""Incremental Data Load"",""Oracle"",""Netezza"",""SQL"",""Data Engineering"",""Big Data"",""Git"",""Shell"",""HDFS"",""Ozone"",""Hive/Impala""],""nice_to_have"":[""Python based AI/ML"",""Nifi"",""APIs"",""Unix Environment"",""Agile teams""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data pipelines for scalability and performance?"",""example_answer"":""I use techniques like data partitioning, caching, and parallel processing to optimize data pipelines. I also ensure that the pipeline is designed to handle incremental data loads and can scale horizontally.""},{""question"":""Can you explain how you would debug a production issue in a big data pipeline?"",""example_answer"":""I would use tools like Spark UI, Spark History Server, and log analysis to identify the issue. Then, I would use techniques like data sampling and debugging to isolate the problem and implement a mitigation plan.""},{""question"":""How do you ensure data quality and integrity in a big data pipeline?"",""example_answer"":""I use data validation and data quality checks at each stage of the pipeline to ensure data integrity. I also implement data profiling and data lineage to track data provenance and quality.""}],""red_flags"":[""Lack of experience with big data technologies like Hadoop and Apache Spark."",""Inability to work in an Agile team environment."",""Limited experience with data engineering and implementing end-to-end data warehousing projects.""],""confidence_score"":90.0}"
Data Engineer (Snowflake),"We are looking for experienced Data Engineers with knowledge of Snowflake platform.

Responsibilities

Creating and managing data in the Snowflake environment
Designing and implementing ETL (Extract, Transform, Load) solutions for transferring data between various sources and platforms
Optimizing the performance of Snowflake databases, including designing and implementing data structures and using indexes appropriately
Automating data processing workflows using tools such as Airflow or other workflow management tools
Deploying and configuring tools to monitor and report on the performance of the Snowflake system

Requirements

Minimum 1 year of experience as a Data Engineer
Ability to use Snowflake
Very good knowledge of SQL and programming in Python
Ability to work with databases, including the Snowflake platform
Knowledge of ETL tools and data integration
Ability to work in a team and good communication skills
Fluent English in speaking and writing

We Offer

B2B contract type
Full-time job
Remote and flexible working hours","{""role_summary"":""Design, implement, and manage data solutions on the Snowflake platform, ensuring efficient data processing and performance."",""key_terms"":[{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and processing large datasets.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of transferring data between systems, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Airflow"",""explanation"":""A workflow management tool for automating and scheduling data processing tasks.""}],""skill_priorities"":{""must_have"":[""Snowflake"",""SQL"",""Python"",""ETL tools"",""Data integration""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize the performance of a Snowflake database?"",""example_answer"":""I would analyze the database structure, identify bottlenecks, and implement indexing strategies to improve query performance. Additionally, I would monitor and adjust resource allocation to ensure optimal performance.""},{""question"":""Can you explain the concept of ETL and how you would implement it in a data integration project?"",""example_answer"":""ETL stands for Extract, Transform, Load. I would design an ETL solution to extract data from various sources, transform it into a standardized format, and load it into a target system. I would use tools like Snowflake, Python, and Airflow to automate and schedule the process.""}],""red_flags"":[""Lack of experience with Snowflake or ETL tools"",""Inability to write efficient SQL queries""],""confidence_score"":90.0}"
Data Bricks/ETL Developer,"Data Bricks/ETL Developer
Brampton, ON
""Required Skills:
• Strong knowledge of Data Management and Principles
• At least over 3 years of experience in Azure Enterprise data lake development, with 6- 8 years of total experience in Data Warehousing.
• Hands-on experience designing and delivering solutions using Azure Data Lake
• Experience in building ETL/ELT/ data warehouse.
• Experience of building data pipelines using Azure Data Factory and Apache Spark (preferably PySpark in Databricks).
• Experience in working with structured and semi-structured data from various sources like blob (json/avro | delimited flat files | parquet... etc.) , rdbms etc.
• Adept in Structured Query Language.
• Ability to apply spark Dataframe api to complete data manipulation within Spark Session
• Good understanding of Spark Architecture including spark core, spark sql, dataframe, driver node, worker node, fault tolerance, collection, executors and tasks
• Experience in Delta Lake API.

Roles and responsibilities:

• Designing and implementing efficient data ingestion pipelines from multiple sources using Azure Data factory and/or Azure Databricks
• Integrating the end-to-end data pipeline to take data from different source systems to target data repositories ensuring the quality and consistency of data.
• Processing performance analysis and code optimization.","{""role_summary"":""Design and implement efficient data ingestion pipelines from multiple sources, integrating end-to-end data pipelines to ensure data quality and consistency."",""key_terms"":[{""term"":""Azure Enterprise data lake development"",""explanation"":""Developing large-scale data storage solutions using Azure's enterprise data lake technology.""},{""term"":""ETL/ELT"",""explanation"":""Extract, Transform, Load/Extract, Load, Transform processes for data integration and warehousing.""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service for creating, scheduling, and managing data pipelines.""},{""term"":""Apache Spark"",""explanation"":""An open-source, distributed computing system for large-scale data processing.""},{""term"":""PySpark"",""explanation"":""A Python library for Apache Spark, allowing Python developers to work with Spark.""},{""term"":""Delta Lake API"",""explanation"":""An open-source storage layer that provides ACID transactions, scalable metadata handling, and unified data management.""},{""term"":""Spark Dataframe API"",""explanation"":""A high-level API in Apache Spark for data manipulation and analysis.""},{""term"":""Spark Architecture"",""explanation"":""The internal architecture of Apache Spark, including components like Spark Core, Spark SQL, and DataFrames.""}],""skill_priorities"":{""must_have"":[""Azure Enterprise data lake development"",""ETL/ELT"",""Azure Data Factory"",""Apache Spark"",""PySpark"",""Data Warehousing"",""Structured Query Language""],""nice_to_have"":[""Delta Lake API""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize data pipeline performance using Azure Data Factory and Apache Spark?"",""example_answer"":""I would analyze the pipeline's data flow, identify bottlenecks, and apply optimization techniques such as data partitioning, caching, and parallel processing using Spark's Dataframe API.""},{""question"":""Can you explain the concept of fault tolerance in Spark Architecture?"",""example_answer"":""Fault tolerance in Spark refers to its ability to recover from node failures during data processing. This is achieved through mechanisms like speculative execution, re-execution of failed tasks, and data replication.""}],""red_flags"":[""Lack of hands-on experience with Azure Data Lake and Apache Spark"",""Inability to explain Spark Architecture components and their roles""],""confidence_score"":90.0}"
Data Engineer [Scotiabank],"Requisition ID: 200905

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

This role requires a blend of a Data Engineer and a Developer who will be responsible for designing, building, monitoring, tuning, and troubleshooting data pipelines for Global Finance & Risk Technology.

Is this role right for you? In this role, you will:

Design, Develop and maintain robust data pipelines for the ingestion, transformation, and distribution of large datasets.
Utilize services and tools to automate data workflows and streamline the data engineering process.
Collaborate with other stakeholders to support data analysis, data mapping and reporting needs.
Monitor application performance, identifying bottlenecks, and implementing improvements to enhance efficiency.
Conduct data quality checks and implementing measures to ensure data accuracy and integrity.
Stay current with emerging technologies and data engineering practices to recommend and adopt innovations that improve data systems.
Provide technical expertise and support for data-related issues, including troubleshooting and resolving data pipeline failures.
Document data engineering processes, creating data flow diagrams, and maintaining metadata for data lineage and cataloging.

Skills

Do you have the skills that will enable you to succeed in this role? We'd love to work with you if you have experience with:

Proficiency in Java is crucial.
Experience using Streaming Architecture (Kafka) and Big Data Platform (Hadoop) is required.
Strong SQL knowledge is needed.
Experience in NiFi is desired.
General Understanding of continuous integration/continuous deployment (CI/CD) pipelines
Experience building CI/CD pipelines using GitHub, Artifactory etc. to reduce cycle times and ensure quality.
Strong scripting skills (i. e. shell scripting for automation.
Working experience with source control systems like Git.
Exposure to working on cloud platforms like Azure/GCP/AWS
Experience with Agile/Scrum development methodologies
Team player with effective communication skills (verbal and written)
Able to see tasks through to completion without significant guidance.
Self-managed and results-oriented with sense of ownership is required.
A university degree in Mathematics, Science, Engineering, Management or relevant.

What's in it for you?

We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!
We provide you with the tools and technology needed to create meaningful customer experiences.
An opportunity for mentorship from experienced and knowledgeable technologists
You'll get to work with and learn from diverse industry leaders, who have hailed from top technology companies around the world.
We offer a competitive total rewards package that includes a base salary, a performance bonus, company matching programs (on pension & profit sharing), generous vacation, personal & sick days, personal development funding, maternity leave top-up, parental leave and much more.

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here . Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","{""role_summary"":""Design, build, and maintain data pipelines for Global Finance & Risk Technology, collaborating with stakeholders to support data analysis and ensuring data quality and integrity."",""key_terms"":[{""term"":""Data Engineer"",""explanation"":""A professional responsible for designing, building, and maintaining large-scale data systems.""},{""term"":""Streaming Architecture (Kafka)"",""explanation"":""A method of processing and analyzing data in real-time, using tools like Kafka to handle high-volume data streams.""},{""term"":""Big Data Platform (Hadoop)"",""explanation"":""A suite of tools for storing, processing, and analyzing large datasets, including Hadoop.""},{""term"":""NiFi"",""explanation"":""An open-source data integration tool for managing and processing data flows.""},{""term"":""CI/CD pipelines"",""explanation"":""Automated workflows for building, testing, and deploying software, using tools like GitHub and Artifactory.""}],""skill_priorities"":{""must_have"":[""Proficiency in Java"",""Experience with Streaming Architecture (Kafka) and Big Data Platform (Hadoop)"",""Strong SQL knowledge""],""nice_to_have"":[""Experience in NiFi"",""General Understanding of continuous integration/continuous deployment (CI/CD) pipelines"",""Experience building CI/CD pipelines using GitHub, Artifactory etc."",""Strong scripting skills (e.g. shell scripting for automation)"",""Working experience with source control systems like Git"",""Exposure to working on cloud platforms like Azure/GCP/AWS"",""Experience with Agile/Scrum development methodologies""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize data pipeline performance using Kafka and Hadoop?"",""example_answer"":""I would use Kafka's built-in performance monitoring tools to identify bottlenecks, and then implement data partitioning and parallel processing to increase throughput. Additionally, I would leverage Hadoop's distributed computing capabilities to scale data processing.""},{""question"":""Can you explain how you would implement data quality checks in a data pipeline?"",""example_answer"":""I would use a combination of data validation rules, data profiling, and data quality metrics to ensure data accuracy and integrity. I would also implement data quality checks at multiple stages of the pipeline to catch errors early on.""}],""red_flags"":[""Lack of experience with Java, Kafka, or Hadoop"",""Inability to work collaboratively with stakeholders"",""Limited understanding of data engineering principles and best practices""],""confidence_score"":90.0}"
Data Processing Specialist - Python Developer,"Hello! We're FortNine. We are one of North America’s fastest growing e-commerce stores in the powersports industry, and are looking to grow our ranks!

We are currently seeking a dedicated and skilled Intermediate Data Processing Specialist with a strong focus on web scraping and python development to join our dynamic team. This role requires a deep understanding of web technologies, data extraction techniques, and data formatting. The ideal candidate will have a proven track record of developing efficient web scraping solutions and processing large datasets with accuracy.

This position offers a hybrid work model, allowing for a balance between in-office collaboration and remote flexibility. Therefore, only Montreal and surrounding area applicants are being considered.

Key Responsibilities:

Design, develop, and maintain web scraping scripts and tools to extract data from various online sources efficiently
Implement advanced data parsing, cleaning, and formatting techniques using Python and regular expressions
Work closely with data analysts and other stakeholders to understand data requirements and deliver structured data in usable formats
Ensure data integrity and reliability of scraped data through rigorous testing and validation processes
Optimize existing scraping and data processing scripts for performance and scalability
Stay updated with the latest web technologies and scraping methodologies to ensure best practices are followed
Participate in code reviews, contributing to the team's continuous improvement in code quality and best practices

Qualifications:

Minimum of 1 year of professional experience in Python programming, specifically focused on web scraping and data processing
Strong understanding of HTML, CSS, JavaScript, and other web technologies relevant to web scraping
Experience with Python frameworks such as Scrapy, Beautiful Soup, Selenium or Flask/Django
Familiarity with database systems (MySQL) and data storage formats (JSON, CSV, XML)
Advanced skills in writing complex regular expressions for efficient data parsing and validation
Solid understanding of best practices in web scraping, including respect for robots.txt, rate limiting, and user-agent string usage
Solid understanding of version control (Git)
Excellent problem-solving abilities, with attention to detail and accuracy in data handling
Strong communication skills and the ability to work effectively in a team environment
Proactive in staying current with new technologies and programming techniques

Additional Requirements:

Availability to work in a hybrid setting, with a schedule that includes both in-office and remote work
Willingness to participate in team meetings and collaborate with colleagues both in-person and virtually

What We Offer:

A collaborative and supportive work environment where innovation and creativity are encouraged
Opportunities for professional growth and development
Competitive salary and benefits package
Flexible hybrid work arrangements to support work-life balance

Application Instructions:

Interested candidates should submit relevant project examples or GitHub repositories that demonstrate expertise in web scraping and data processing.

Powered by JazzHR

qzdg43Z8qX","{""role_summary"":""An Intermediate Data Processing Specialist is needed to design, develop, and maintain web scraping scripts and tools to extract data from various online sources efficiently."",""key_terms"":[{""term"":""Web scraping"",""explanation"":""The process of automatically extracting data from websites, often using programming languages like Python.""},{""term"":""Python development"",""explanation"":""The process of building software applications using the Python programming language.""},{""term"":""Data parsing"",""explanation"":""The process of breaking down data into smaller, more manageable parts to extract useful information.""},{""term"":""Regular expressions"",""explanation"":""A pattern-matching language used to search, validate, and extract data from strings.""},{""term"":""Scrapy"",""explanation"":""A Python framework used for building web scrapers.""},{""term"":""Beautiful Soup"",""explanation"":""A Python library used for parsing HTML and XML documents.""},{""term"":""Selenium"",""explanation"":""An open-source tool used for automating web browsers.""},{""term"":""Flask/Django"",""explanation"":""Python web frameworks used for building web applications.""},{""term"":""JSON, CSV, XML"",""explanation"":""Data storage formats used to store and exchange data.""},{""term"":""Git"",""explanation"":""A version control system used to track changes in code.""}],""skill_priorities"":{""must_have"":[""Python programming"",""Web scraping"",""Data processing"",""HTML, CSS, JavaScript"",""Regular expressions"",""Git""],""nice_to_have"":[""Scrapy"",""Beautiful Soup"",""Selenium"",""Flask/Django"",""MySQL""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the difference between Scrapy and Beautiful Soup?"",""example_answer"":""Scrapy is a full-fledged web scraping framework, while Beautiful Soup is a library used for parsing HTML and XML documents. I've used both in my previous projects to extract data from websites.""},{""question"":""How do you ensure data integrity and reliability in your web scraping projects?"",""example_answer"":""I use rigorous testing and validation processes to ensure data accuracy. I also implement data parsing, cleaning, and formatting techniques to ensure data quality.""},{""question"":""Can you give an example of a complex regular expression you've written for data parsing and validation?"",""example_answer"":""In my previous project, I wrote a regular expression to extract specific data from a website. The expression was [insert example].""}],""red_flags"":[""Lack of experience with web scraping and data processing"",""Inability to work in a hybrid setting"",""Poor problem-solving abilities""],""confidence_score"":90.0}"
Business Intelligence Engineer,"Our client, a rapidly expanding global technology partner, is looking for a highly skilled Business Intelligence Engineer to join their exceptional Technology and Development team. If you are passionate about demonstrating your expertise and thrive on collaborating with a group of talented engineers, then this role was made for you!
At the heart of technology innovation, our client specializes in delivering cutting-edge solutions to clients across a wide array of sectors. With a strategic focus on finance, banking, and corporate verticals, they have earned a stellar reputation for their commitment to excellence in every project they undertake.

Are you a highly motivated and seasoned Business Intelligence Engineer (BIE) with a remarkable track record in harnessing the capabilities of AWS Redshift, excelling in ETL processes, and mastering reporting tools within a serverless AWS cloud environment? If you're a self-starter who thrives in the face of ambiguity, we seek someone like you to join our dynamic team.

As a BIE, you will be responsible for setting the vision, defining the roadmap, and collaborating with stakeholders to deliver impactful results. This role offers a unique opportunity to have an immediate and lasting impact on internal and external customers by harnessing the power of data to drive key business insights.

What you will be doing:
 Data Modeling and Analysis: Develop and maintain multidimensional data models that enable complex analyses and reporting, utilizing AWS Redshift and other relevant technologies.
ETL Process Optimization: Design, implement, and enhance ETL processes to ensure efficient data extraction, transformation, and loading from various sources into data warehouses.
Reporting and Visualization: Create and maintain visually compelling dashboards, reports, and data visualizations to communicate key insights and performance metrics.
Business Collaboration: Collaborate with business leaders to understand their data needs and provide analytical support in answering critical business questions.
Roadmap and Vision: Define the long-term vision and roadmap for business intelligence solutions, aligning them with organizational goals and strategies.
Automated Processes: Develop and maintain automated processes for data extraction, transformation, and reporting to improve efficiency and accuracy.
Data Quality Assurance: Implement data validation and quality checks to ensure data accuracy and consistency.
Stakeholder Engagement: Engage with stakeholders across various departments to gather requirements, provide insights, and deliver data-driven solutions.
Performance Optimization: Optimize queries, reports, and ETL processes for performance and scalability, ensuring timely access to data.
Documentation: Create and maintain documentation for data models, ETL processes, and reporting solutions to facilitate knowledge sharing.

What we are looking for
Bachelor's or Master's in Computer Science, Data Science, Business Analytics, or a related field.
Proven experience as a Business Intelligence Engineer with expertise in AWS Redshift, ETL processes, and reporting tools.
Proficiency in SQL and data modeling for analytics and reporting.
Strong proficiency in business intelligence and data visualization tools (e.g., Tableau, Power BI).
Excellent problem-solving and analytical skills, with the ability to translate complex data into actionable insights.
Experience with AWS serverless technologies (e.g., AWS Lambda, AWS Glue) is highly desirable.
Strong scripting skills (e.g., Python) for process automation.
Effective communication and collaboration skills to work closely with cross-functional teams.
Comfortable working in an agile, dynamic, and rapidly evolving environment.
A self-starter with a passion for innovation and a track record of delivering results.
AWS certifications (e.g., AWS Certified Data Analytics - Specialty) are a bonus
 What's In It For You?
Join an inclusive, collaborative work environment that fosters creativity and curiosity and celebrates success!
Receive access to the latest tools and technology to create exceptional customer experiences.
Enjoy career advancement opportunities. Your talent is valued, and they want to see you succeed, not just in your current role but throughout your career.
After-work socials
 We encourage you to apply today if you're ready to take the reins of your career and be a driving force behind transformative data solutions—a chance to unlock the power of data to make a real difference.
 Location: North York, Onsite 3/4 days a week
Permanent, Full-time/ Contract","{""role_summary"":""A Business Intelligence Engineer responsible for developing and maintaining data models, optimizing ETL processes, and creating reports to drive business insights, collaborating with stakeholders to deliver impactful results."",""key_terms"":[{""term"":""AWS Redshift"",""explanation"":""A data warehousing and analytics service provided by Amazon Web Services (AWS) that allows for complex data analysis and reporting.""},{""term"":""ETL processes"",""explanation"":""Extract, Transform, Load processes that extract data from various sources, transform it into a standardized format, and load it into a data warehouse for analysis.""},{""term"":""Serverless AWS cloud environment"",""explanation"":""A cloud computing environment provided by AWS that allows for the deployment of applications and services without the need to manage underlying infrastructure.""},{""term"":""Data modeling"",""explanation"":""The process of creating a conceptual representation of data structures and relationships to facilitate data analysis and reporting.""},{""term"":""Data visualization"",""explanation"":""The process of creating graphical representations of data to communicate insights and trends.""}],""skill_priorities"":{""must_have"":[""AWS Redshift"",""ETL processes"",""Reporting tools"",""SQL"",""Data modeling"",""Business intelligence"",""Data visualization""],""nice_to_have"":[""AWS serverless technologies"",""Python scripting"",""AWS certifications""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize ETL processes for performance and scalability?"",""example_answer"":""I would analyze the current ETL process, identify bottlenecks, and implement parallel processing, data partitioning, and caching to improve performance and scalability.""},{""question"":""How do you ensure data quality and accuracy in your data models and reports?"",""example_answer"":""I implement data validation and quality checks, perform regular data audits, and collaborate with stakeholders to ensure data accuracy and consistency.""}],""red_flags"":[""Lack of experience with AWS Redshift and ETL processes"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Analytics Engineer,"Job Description:

Rakuten International oversees 7 businesses with over 4,000 employees globally. The brand is recognized for its leadership and innovation in e-commerce, digital content, advertising, entertainment, and communications, bringing the joy of discovery and access to more than 1 billion members across the world. Our teams deliver on the company’s mission to delight merchants and customers through innovation, optimism, and teamwork.

Rakuten Rewards is a leading e-commerce company that enhances the way people shop by offering Cash Back, deals and rewards from more than 3,500 merchants. Founded in 1999, Rakuten has grown to become the go-to shopping destination for consumers, having paid out nearly $2 billion in Cash Back to its 15 million members. The company also operates ShopStyle, a leading fashion discovery destination, and Cartera Commerce, a top rewards platform for airlines and banks. For more information, visit www.rakuten.com.

As a Product Analyst/Analytics Engineer, you will collaborate with product, engineering, and other teams as you translate complex data into strategic recommendations. You will develop solutions to complex business problems, and present data to enable data-driven decision making. You will help shape product development initiatives, optimize user experiences, and improve overall product performance. You will also own projects to elevate KPI reporting and be the expert on the data sets and data tools that are available.

KEY RESPONSIBILITIES:

Collaborate with Product and Engineering teams to identify opportunities, estimate impact, implement, and analyze tests.
Develop and maintain key performance indicators (KPIs) and dashboards to monitor product performance, identify trends, and generate actionable insights for stakeholders.
Perform ad hoc analysis to quickly solve time sensitive funnel conversion issues.
Collaborate with the development team to track and resolve data quality issues or discrepancies.
Support the development of data products and tools to facilitate self-service and enable analytics to scale across the company.
Provide technical expertise in extracting, integrating, and analyzing critical data.

MINIMUM REQUIREMENTS:

Strong SQL skills, comfortable working with large data sets like clickstream data on Snowflake.
2+ years of experience with Python or any other programming languages.
Experience working with reporting and visualization tools (Tableau preferred)
Strong interpersonal skills, both written and verbal, with the ability and confidence to succinctly convey complex information to senior management.
Strong analytical and problem-solving skills, with a keen attention to detail.
Experience with A/B testing is a plus.

QUALIFICATION REQUIREMENTS:

Bachelor’s or master’s degree in a relevant field (e.g., Data science, Statistics or Data Analytics).
2+ years professional experience in data analytics.
Ability to translate data-driven learnings into stories, actionable insights and communicate to key stakeholders.
Excellent team player and ability to work in a fast-paced environment, manage multiple tasks and meet deadlines.

Five Principles for Success

Our worldwide practices describe specific behaviors that make Rakuten unique and united across the world. We expect Rakuten employees to model these 5 Shugi Principles of Success.

Always improve, Always Advance - Only be satisfied with complete success - Kaizen

Passionately Professional - Take an uncompromising approach to your work and be determined to be the best

Hypothesize - Practice - Validate – Shikumika - Use the Rakuten Cycle to succeed in unknown territory

Maximize Customer Satisfaction - The greatest satisfaction for our teams is seeing their customers smile

Speed!! Speed!! Speed!! - Always be conscious of time - take charge, set clear goals, and engage your team

Rakuten provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type. Rakuten considers applicants for employment without regard to race, color, religion, age, sex, national origin, disability status, genetic information, protected veteran status, sexual orientation, gender, gender identity or expression, or any other characteristic protected by federal, state, provincial or local laws.","{""role_summary"":""Collaborate with cross-functional teams to translate complex data into strategic recommendations, develop solutions to business problems, and present data to enable data-driven decision making."",""key_terms"":[{""term"":""Cash Back"",""explanation"":""A rewards program that offers cash rewards to customers for shopping through Rakuten Rewards.""},{""term"":""KPIs"",""explanation"":""Key Performance Indicators used to measure product performance and identify trends.""},{""term"":""A/B testing"",""explanation"":""A method of comparing two versions of a product or feature to determine which one performs better.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform used for storing and analyzing large datasets.""},{""term"":""Tableau"",""explanation"":""A data visualization tool used for creating interactive dashboards and reports.""}],""skill_priorities"":{""must_have"":[""Strong SQL skills"",""2+ years of experience with Python or other programming languages"",""Experience working with reporting and visualization tools"",""Strong interpersonal skills"",""Strong analytical and problem-solving skills""],""nice_to_have"":[""Experience with A/B testing""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach analyzing a complex business problem and presenting data-driven recommendations to stakeholders?"",""example_answer"":""I would start by identifying the key metrics and data sources relevant to the problem, then use SQL to extract and analyze the data. I would create visualizations using Tableau to communicate my findings and recommendations to stakeholders.""},{""question"":""Can you give an example of a time when you had to troubleshoot a data quality issue and how you resolved it?"",""example_answer"":""In my previous role, I noticed a discrepancy in our clickstream data. I worked with the development team to identify the root cause and implement a solution, which involved creating a data pipeline to ensure data accuracy and integrity.""}],""red_flags"":[""Lack of experience working with large datasets"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Data Engineer - Spark Streaming,"Data Engineer (Spark)
Duration: Fulltime with Intelliswift Software Inc
Location: Canada 100% remote (Needs to work in PST Hours)
Description:
Must know Big Data in depth, handled large datasets
Doing Spark Streaming
Scala good but not required
Java Exp is a must","{""role_summary"":""Design and develop large-scale data systems, handling big data and implementing Spark Streaming."",""key_terms"":[{""term"":""Big Data"",""explanation"":""Handling and processing large datasets.""},{""term"":""Spark Streaming"",""explanation"":""A scalable fault-tolerant streaming processing system.""},{""term"":""Scala"",""explanation"":""A programming language used for building scalable systems.""}],""skill_priorities"":{""must_have"":[""Big Data"",""Java"",""Spark Streaming""],""nice_to_have"":[""Scala""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data processing for large datasets?"",""example_answer"":""I use distributed computing frameworks like Spark to process large datasets in parallel, ensuring efficient data processing.""},{""question"":""Can you explain how you handle real-time data processing with Spark Streaming?"",""example_answer"":""I use Spark Streaming to process real-time data, leveraging its micro-batching capabilities to handle high-volume data streams.""}],""red_flags"":[""Lack of experience with big data and Spark Streaming"",""Inability to work in PST hours""],""confidence_score"":90.0}"
Senior Data Engineer(Databricks) - Toronto,"Data Engineer with Databricks & Spark Experience

We are looking for a data engineer who has strong experience in building scalable and reliable data pipelines using Databricks and Spark. You will be working with various data sources and formats, and transforming them into valuable insights for our business.

Responsibilities

Design, develop, and maintain data pipelines using Databricks and Spark, and other cloud technologies as needed
Optimize data pipelines for performance, scalability, and reliability
Ensure data quality and integrity throughout the data lifecycle
Collaborate with data scientists, analysts, and other stakeholders to understand and meet their data needs
Troubleshoot and resolve data-related issues, and provide root cause analysis and recommendations
Document data pipeline specifications, requirements, and enhancements, and communicate them effectively to the team and management
Create new data validation methods and data analysis tools, and share best practices and learnings with the data engineering community
Implement ETL processes and data warehouse solutions, and ensure compliance with data governance and security policies

Please Note: This is a hybrid position and will require at least 2 days in the office per week. Successful candidates will need to complete a background check.

Requirements

Qualifications

Bachelor's degree in Computer Science, Engineering, or related field, or equivalent work experience
5+ years of experience in data engineering with Databricks and Spark
Proficient in SQL and Python, and familiar with Java or Scala
Experience with cloud platforms, such as Azure or AWS
Experience with big data technologies, such as Kafka, Hadoop, Hive, etc
Experience with data warehouse and data lake concepts and architectures
Experience with data integration and ETL tools, such as Azure Data Factory or Talend
Experience with data visualization and reporting tools, such as Power BI or Tableau
Strong analytical and problem-solving skills
Excellent communication and teamwork skills


Benefits

Benefits

We are a collective group of people and collaboration is key to our process
We don't work for our clients, we work with them
A Flexible Hybrid Working Environment
Easily accessible downtown location
Competitive compensation commensurate with experience
Everyone brings something valuable to the table in our supportive, challenging, and collaborative, diverse work environment


All Employees Can Participate in:

Company paid health benefits: 100% medical, dental and vision coverage
Corporate-discounted Gym Membership through GoodLife
Company discount program including Travel, Shopping, Attractions, Wellness, & Sporting events, just to name a few
Access to an Employee & Family Assistance program (EAP)
Employee Referral Program
Employee Opportunity Program
Professional Development Program
Philanthropic Events
Social Events


Inclusion & Diversity

We foster an inclusive and diverse workforce, believing our strength stems from our individual differences. Our employees, partners, and clients continuously benefit from the innovation and creativity grounded in these values. We strive to be a company that attracts a diverse group of highly skilled people who know that their contributions will be valued and that they will be heard. We are committed to building a corporate culture with people who are excited to join our team, do their best work, and grow with us!","{""role_summary"":""Design, develop, and maintain scalable and reliable data pipelines using Databricks and Spark, and collaborate with stakeholders to meet their data needs."",""key_terms"":[{""term"":""Databricks"",""explanation"":""A cloud-based Apache Spark platform for data engineering and analytics.""},{""term"":""Spark"",""explanation"":""An open-source data processing engine for large-scale data processing.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Data Lake"",""explanation"":""A centralized repository that stores raw, unprocessed data in its native format.""},{""term"":""Data Warehouse"",""explanation"":""A centralized repository that stores processed and transformed data for reporting and analytics.""}],""skill_priorities"":{""must_have"":[""Databricks"",""Spark"",""SQL"",""Python"",""Cloud platforms (Azure or AWS)"",""Big data technologies (Kafka, Hadoop, Hive)"",""Data warehouse and data lake concepts"",""Data integration and ETL tools""],""nice_to_have"":[""Java or Scala"",""Data visualization and reporting tools (Power BI or Tableau)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data pipelines for performance, scalability, and reliability?"",""example_answer"":""I use techniques such as data partitioning, caching, and parallel processing to optimize data pipelines. I also monitor pipeline performance using metrics such as latency and throughput, and make adjustments as needed.""},{""question"":""Can you explain how you ensure data quality and integrity throughout the data lifecycle?"",""example_answer"":""I use data validation methods such as data profiling and data quality rules to ensure data quality. I also implement data testing and data monitoring to detect and resolve data issues.""}],""red_flags"":[""Lack of experience with Databricks and Spark"",""Inability to work in a hybrid environment"",""Limited experience with cloud platforms and big data technologies""],""confidence_score"":90.0}"
"Data Engineer - Scarborough, ON","An opportunity to join a growing multi-national company|Ability for internal mobility and career progression


About Our Client

Our client is an international company, that designs, manufactures, and distributes packaging solutions.

Job Description

Design, build, and automate data flows while improving existing data systems.
Proficient in constructing SQL data warehouses from scratch.
Analyze business requirements for business intelligence, converting them into technical specifications and task timelines.
Design and implement data models and schemas to support data analysts and stakeholders.
Lead the development of centralized data storage for our transition to a data lake.
Perform data analysis across multiple sources to provide insights for informed decisions.
Evaluate data access control practices and develop remediation strategies.
Create and update technical documentation.
Visualize data with charts and explain algorithms, parameters, models, and relationships.
Manage and maintain data warehouse development.
Build multi-dimensional data models.
Document algorithms, parameters, and models comprehensively.
Design new systems by analyzing existing ETL processes.
Implement technical improvements for business intelligence systems.
Develop and manage data warehousing solutions for structured and unstructured data.
Use Git for version control of code and data pipeline configurations.

MPI does not discriminate on the basis of race, religion, sex, sexual orientation, gender identity or expression, age, disability, marital status, or based on an individual's status in any group or class otherwise protected under applicable human rights legislation. MPI encourages applications from minorities, women, the disabled and all other qualified applicants

The Successful Applicant

Bachelor's degree in Computer Science, Statistics, or a related field.
More than 5 years of experience in database development and administration.
Profound understanding of database management systems and ELT (Extract, Load, Transform) processes.
Extensive experience with crafting SQL queries, SQL Server Reporting Services (SSRS), and SQL Server Integration Services (SSIS).
Advanced skills in query optimization, index management, statistics, and partitioning.
Proven track record in developing intricate scripts, queries, and stored procedures without compromising data integrity, privacy, or security.
Proficiency in infrastructure automation and scripting for streamlined operations.
Hands-on experience with big data architectures and modeling for efficient data processing.
Comprehensive knowledge of data platform architecture, database optimization, and data management practices.
Familiarity with data governance, ingestion and extraction frameworks, and data security protocols.
Proficiency in programming languages such as SAS, R, Python, MATLAB, Java, VBA, and Excel.
Competence in managing both SQL and NoSQL databases.
Ability to collaborate effectively with stakeholders and assess potential risks.
Strong emphasis on documentation and adherence to well-defined procedures.
Familiarity with Domo or Power BI considered advantageous.
Experience working with cloud Data Lake platforms like AWS and Azure seen as beneficial.

What's On Offer

An opportunity to join a leading Canadian company
A hybrid position
Competitive compensation
Opportunity for growth and internal mobility


Contact: Jaco Venter

Quote job ref: JN-062024-6466398","{""role_summary"":""Design, build, and automate data flows, and improve existing data systems to support business intelligence and informed decision-making."",""key_terms"":[{""term"":""Data Lake"",""explanation"":""A centralized repository that stores structured and unstructured data in its native format, allowing for scalable and flexible data processing.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""SQL"",""explanation"":""Structured Query Language - a programming language used for managing and manipulating data in relational database management systems.""},{""term"":""Data Governance"",""explanation"":""The practices and policies that ensure the quality, security, and integrity of an organization's data assets.""},{""term"":""Data Modeling"",""explanation"":""The process of creating a conceptual representation of data structures and relationships to support business intelligence and data analysis.""}],""skill_priorities"":{""must_have"":[""Database development and administration"",""SQL query optimization"",""ETL processes"",""Data modeling"",""Data governance"",""Cloud Data Lake platforms""],""nice_to_have"":[""Domo or Power BI"",""AWS and Azure"",""SAS, R, Python, MATLAB, Java, VBA, and Excel programming languages""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of data lake and how it differs from a traditional data warehouse?"",""example_answer"":""A data lake is a centralized repository that stores raw, unprocessed data in its native format, allowing for flexible and scalable data processing. It differs from a traditional data warehouse, which stores processed and transformed data in a structured format.""},{""question"":""How do you approach data modeling for a complex business intelligence system?"",""example_answer"":""I follow a iterative approach, starting with understanding business requirements, then designing a conceptual data model, and finally implementing a logical and physical data model that meets the business needs.""}],""red_flags"":[""Lack of experience with cloud Data Lake platforms"",""Inability to collaborate effectively with stakeholders""],""confidence_score"":90.0}"
Data Engineer (Airflow),"Position: Apache Airflow Data Engineer
Client: Financial Services Client
Location: Toronto – Hybrid
Duration: 3 Months initial contract
Security Clearance: N/A
Language: English
Background:

Kyndryl Canada is supporting our Financial Services client and their project to build and maintain ETL pipelines to process and move data more efficiently.


Qualifications:

Extensive experience working with Apache Airflow.
Experience working with data process automation.
Ability to work on-site in downtown Toronto, multiple days a week.


Responsibilities could entail:
• Data Pipeline Development: Build and maintain ETL pipelines to process and move data efficiently.
• Workflow Orchestration: Use Apache Airflow to schedule and manage complex data workflows.
• Automation: Automate data processing tasks to ensure they run reliably and on time.
• Performance Optimization: Optimize data pipelines for speed and efficiency.
• Monitoring and Logging: Monitor pipeline performance and maintain detailed logs for troubleshooting.
• Collaboration: Work with data scientists and analysts to meet data needs.","{""role_summary"":""Design, build, and maintain efficient data pipelines using Apache Airflow, ensuring reliable and timely data processing, and collaborating with data scientists and analysts to meet data needs."",""key_terms"":[{""term"":""Apache Airflow"",""explanation"":""An open-source platform used to programmatically schedule and monitor workflows, often used for data pipeline development and workflow orchestration.""},{""term"":""ETL pipelines"",""explanation"":""Extract, Transform, Load pipelines used to process and move data from one system to another, often used for data integration and migration.""},{""term"":""Workflow Orchestration"",""explanation"":""The process of automating and managing complex workflows, often involving multiple tasks and dependencies, to ensure efficient and reliable execution.""}],""skill_priorities"":{""must_have"":[""Apache Airflow"",""Data pipeline development"",""Automation""],""nice_to_have"":[""Data process automation""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data pipelines for speed and efficiency in Apache Airflow?"",""example_answer"":""I use techniques such as parallel processing, caching, and optimizing task dependencies to improve pipeline performance. I also monitor pipeline performance and adjust as needed.""},{""question"":""Can you explain how you would automate data processing tasks using Apache Airflow?"",""example_answer"":""I would use Airflow's built-in operators and sensors to automate tasks, and create custom operators as needed. I would also implement retry mechanisms and error handling to ensure reliable execution.""}],""red_flags"":[""Lack of experience with Apache Airflow"",""Inability to work on-site in downtown Toronto""],""confidence_score"":90.0}"
Big Data Engineer,"Location : Austin TX or Sunnyvale, CA

JD: In the role of Lead Data Engineer, you will interface with key stakeholders and apply your technical proficiency across different stages of the Software Development Life Cycle including Requirements Elicitation, Application Architecture definition and Design. You will play an important role in creating the high-level design artifacts. You will also deliver high quality code deliverables for a module, lead validation for all types of testing and support activities related to implementation, transition and warranty. You will be part of a learning culture, where teamwork and collaboration are encouraged, excellence is rewarded, and diversity is respected and valued. Required Qualifications: Bachelor's degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education At least 6 years of experience in Information Technology. At least 3 years of hands on experience with Hadoop distributed frameworks while handling large amount of big data using Spark and Hadoop Ecosystems. At least 3 years of experience with Spark/PySpark required. At least 2 years of experience with Scala required. At least 3 years of experience with SQL with any RDBMS. Preferred Qualifications: At least 1 years of AWS development experience is preferred Ability to work within deadlines and effectively prioritize and execute on tasks. Strong communication skills (verbal and written) with ability to communicate across teams, internal and external at all levels. Experience in Drive automations DevOps Knowledge is an added advantage.","{""role_summary"":""Lead a team of data engineers to design, develop, and implement high-quality data solutions, collaborating with stakeholders and ensuring timely delivery."",""key_terms"":[{""term"":""Hadoop distributed frameworks"",""explanation"":""A set of tools for processing large datasets across a cluster of computers, used for handling big data.""},{""term"":""Spark"",""explanation"":""An open-source data processing engine for large-scale data processing, often used with Hadoop.""},{""term"":""PySpark"",""explanation"":""A Python library for Spark, allowing Python developers to work with Spark.""},{""term"":""Scala"",""explanation"":""A programming language used for building scalable and concurrent systems, often used with Spark.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""}],""skill_priorities"":{""must_have"":[""Hadoop"",""Spark"",""PySpark"",""Scala"",""SQL""],""nice_to_have"":[""AWS development experience"",""DevOps knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data processing using Spark and Hadoop?"",""example_answer"":""I would use techniques like data partitioning, caching, and parallel processing to optimize data processing. I would also ensure data serialization and deserialization are efficient.""},{""question"":""Can you explain how you would design a data pipeline using Scala and Spark?"",""example_answer"":""I would design a data pipeline using Scala and Spark by creating a scalable and fault-tolerant architecture. I would use Spark's DataFrames and DataSets to process data and Scala's strong type system to ensure data integrity.""}],""red_flags"":[""Lack of hands-on experience with Hadoop and Spark"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Azure Data Engineer,"About Wipro
Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs.
We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses.
A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries.
We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world.
· A PROUD HISTORY OF OVER 75 YEARS
· FY22 REVENUE 10.4 BN USD
· WE’RE PRESENT IN 66 COUNTRIES
· OVER 1,400 ACTIVE GLOBAL CLIENTS

JD:
Must-have skills
• Cloud certified in one of these categories
• Azure Data Engineer
• Azure Data Factory , Azure Data bricks Spark (PySpark or scala), SQL
• Experience in Azure ingestion from on-prem source, e.g. mainframe, SQL server, Oracle.
• Experience in Sqoop / Hadoop
• Microsoft Excel (for metadata files with requirements for ingestion)
• Any other certificate in Azure/AWS/GCP and data engineering hands-on experience in cloud
• Strong Programming skills with at least one of Python, Scala or Java
• Strong SQL skills ( T-SQL or PL-SQL)
• Data files movement via mailbox
• Source-code versioning/promotion tools, e.g. Git/Jenkins
• Orchestration tools, e.g. Autosys, Oozie
• Source-code versioning with Git.
Nice-to-have skills
• Experience working with mainframe files
• Experience in Agile environment, JIRA/Confluence tools.

Wipro is an Equal Employment Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation.","{""role_summary"":""A cloud-certified data engineer responsible for ingesting data from on-premises sources to cloud platforms, with expertise in Azure, data engineering, and strong programming skills."",""key_terms"":[{""term"":""Azure Data Engineer"",""explanation"":""A professional certified in designing and implementing data engineering solutions on Azure cloud platform.""},{""term"":""PySpark"",""explanation"":""A Python library for big data processing, used for data engineering tasks.""},{""term"":""Sqoop"",""explanation"":""A tool for transferring data between Hadoop and structured data stores such as relational databases.""},{""term"":""T-SQL"",""explanation"":""A SQL dialect used for managing relational databases in Microsoft SQL Server.""},{""term"":""Autosys"",""explanation"":""A job scheduling tool used for automating and managing batch processes.""}],""skill_priorities"":{""must_have"":[""Cloud certification (Azure, AWS, or GCP)"",""Azure Data Engineer skills"",""Azure Data Factory skills"",""Azure Databricks skills"",""SQL skills"",""Programming skills (Python, Scala, or Java)"",""Experience with data ingestion from on-premises sources"",""Experience with Sqoop and Hadoop""],""nice_to_have"":[""Experience working with mainframe files"",""Experience in Agile environment"",""Experience with JIRA/Confluence tools""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you handle data ingestion from on-premises sources to cloud platforms?"",""example_answer"":""I use Azure Data Factory to ingest data from on-premises sources such as mainframe, SQL Server, and Oracle. I also use Sqoop to transfer data between Hadoop and structured data stores.""},{""question"":""Can you explain the difference between PySpark and Scala for data engineering tasks?"",""example_answer"":""PySpark is a Python library for big data processing, while Scala is a programming language used for building data engineering solutions. Both can be used for data engineering tasks, but PySpark is more suitable for data processing, while Scala is more suitable for building data pipelines.""}],""red_flags"":[""Lack of cloud certification"",""No experience with Azure Data Engineer or Azure Data Factory"",""Limited programming skills""],""confidence_score"":90.0}"
"Associate Software Engineer, Domain Data Engineering","Candidates for this position are preferred to be based in Toronto and will be expected to comply with their team's hybrid work schedule requirements.

Associate Software Engineer, Domain Data Engineering

Who We Are:

Wayfair Data Engineering is the engine that powers our data-obsessed eCommerce enterprise. We move fast, iterating quickly on big business problems. We work smart, applying technology to unlock insights and provide outsized value to our customers. We swing big, knowing our customers won't benefit from micro optimizations. Leveraging the largest data set for products sold in the Home space, this team treats data as an asset and determines how to maximize its business value and extend our competitive advantage.

You will be instrumental in designing and delivering Data Warehouses, Data Lake, Self-Service Tooling, Real-time Streaming and Big Data Solutions for multiple functional areas using modern cloud technologies. You will have the chance to combine a deep knowledge of business and technical mastery to own and deliver the right solution for the right business problem. Most importantly, you will have the opportunity to move fast, adapt quickly, and leave a lasting mark through the new solutions you deliver!

What You'll Do:

Own technical design and implementation of big data platforms and self-service solutions
Collaborate with stakeholders and other engineering leaders to define and develop the data architecture roadmap.
Act as a subject matter expert to leadership for technical guidance around solution design and best practices.
Keep current on big data and data visualization technology trends, evaluate, work on proof-of-concepts and make merit-based recommendations on technologies

We Are a Match Because You Have:

An expert at SQL-based ETL development, and experienced with Python, Java, or equivalent scripting language.
Experienced developing in cloud platforms such as Google Cloud Platform (preferred), AWS, Azure, or Snowflake at scale.
Comfortable designing and implementing OLTP and OLAP data solutions.
Experience with real-time data streaming tools like Kafka, Kinesis, Apache Storm or any similar tools is a plus.
Experience with big data technologies like Hadoop, Spark, Cassandra, MongoDB or other open source big data tools is a plus.
Experience architecting data solutions utilizing Bl tools like Looker, Tableau, AtScale, PowerBI, or any similar tools is a plus.
Excellent communication and presentation skills, strong business acumen, critical thinking, and ability to work cross functionally through collaboration with engineering and business partners. Previous e-commerce experience is a plus.
Experience working with large data sets (5+TB highly desired)
Bachelor's or Masters in Computer Science, Computer Engineering, Statistics, or another quantitative discipline

Why You’ll Love Wayfair:

Time Off:
Paid Holidays
Paid Time Off (PTO)
Health & Wellness:
Full Health Benefits (Medical, Dental, Vision, HSA/FSA)
Life Insurance
Disability Protection (Short Term & Long Term Disability)
Global Wellbeing: Gym/Fitness discounts (including US Peloton, Global ClassPass, and various regional gym memberships)
Mental Health Support (Global Mental Health, Global Wayhealthy Recordings)
Caregiver Services
Financial Growth & Security:
RRSP (Registered Retirement Savings Plan)
Tuition Reimbursement
Financial Health Education (Knowledge of Financial Education - KOFE)
Tax Advantaged Accounts
Family Support:
Family Planning Support
Parental Leave
Global Surrogacy & Adoption Policy
Professional Development & Recognition:
Rewards & Recognition
Global Employee Anniversary Awards
Paid Volunteer Work
Unique Perks:
Employee Discount
Global Pod Outings
Work/Life Balance:
Emphasizing a supportive & flexible work environment that encourages a balance between personal and professional commitments
We are looking forward to your application!

About Wayfair Inc.

Wayfair is one of the world’s largest online destinations for the home. Whether you work in our global headquarters in Boston or Berlin, or in our warehouses or offices throughout the world, we’re reinventing the way people shop for their homes. Through our commitment to industry-leading technology and creative problem-solving, we are confident that Wayfair will be home to the most rewarding work of your career. If you’re looking for rapid growth, constant learning, and dynamic challenges, then you’ll find that amazing career opportunities are knocking.

No matter who you are, Wayfair is a place you can call home. We’re a community of innovators, risk-takers, and trailblazers who celebrate our differences, and know that our unique perspectives make us stronger, smarter, and well-positioned for success. We value and rely on the collective voices of our employees, customers, community, and suppliers to help guide us as we build a better Wayfair – and world – for all. Every voice, every perspective matters. That’s why we’re proud to be an equal opportunity employer. We do not discriminate on the basis of race, color, ethnicity, ancestry, religion, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, veteran status, genetic information, or any other legally protected characteristic.

Your personal data is processed in accordance with our Candidate Privacy Notice (https://www.wayfair.com/careers/privacy). If you have any questions or wish to exercise your rights under applicable privacy and data protection laws, please contact us at dataprotectionofficer@wayfair.com.","{""role_summary"":""Design and deliver data warehousing, data lake, self-service tooling, real-time streaming, and big data solutions for multiple functional areas using modern cloud technologies."",""key_terms"":[{""term"":""Data Warehouses"",""explanation"":""Centralized repositories that store data from various sources in a single location, making it easier to analyze and report on.""},{""term"":""Data Lake"",""explanation"":""A storage repository that holds raw, unprocessed data in its native format, allowing for flexible and scalable data analysis.""},{""term"":""Self-Service Tooling"",""explanation"":""Software applications that enable users to perform tasks independently, such as data analysis and reporting, without relying on IT support.""},{""term"":""Real-time Streaming"",""explanation"":""The process of processing and analyzing data as it is generated, allowing for immediate insights and decision-making.""},{""term"":""Big Data Solutions"",""explanation"":""Systems and technologies designed to handle large amounts of structured and unstructured data, providing insights and business value.""},{""term"":""Cloud Technologies"",""explanation"":""On-demand computing resources and services provided over the internet, allowing for scalability, flexibility, and cost-effectiveness.""},{""term"":""OLTP and OLAP"",""explanation"":""OLTP (Online Transactional Processing) is a system that supports transaction-oriented applications, while OLAP (Online Analytical Processing) is a system that supports analytical and reporting applications.""},{""term"":""Real-time Data Streaming Tools"",""explanation"":""Software applications that enable the processing and analysis of data in real-time, such as Kafka, Kinesis, and Apache Storm.""},{""term"":""Big Data Technologies"",""explanation"":""Systems and tools designed to handle large amounts of structured and unstructured data, such as Hadoop, Spark, Cassandra, and MongoDB.""},{""term"":""BI Tools"",""explanation"":""Business Intelligence tools that enable data analysis, reporting, and visualization, such as Looker, Tableau, and PowerBI.""}],""skill_priorities"":{""must_have"":[""SQL-based ETL development"",""Experience with Python, Java, or equivalent scripting language"",""Experience developing in cloud platforms such as Google Cloud Platform, AWS, Azure, or Snowflake at scale"",""Comfortable designing and implementing OLTP and OLAP data solutions""],""nice_to_have"":[""Experience with real-time data streaming tools like Kafka, Kinesis, Apache Storm or any similar tools"",""Experience with big data technologies like Hadoop, Spark, Cassandra, MongoDB or other open source big data tools"",""Experience architecting data solutions utilizing BI tools like Looker, Tableau, AtScale, PowerBI, or any similar tools"",""Previous e-commerce experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the differences between OLTP and OLAP systems?"",""example_answer"":""OLTP systems are designed for transactional processing, focusing on fast data insertion, update, and deletion, whereas OLAP systems are designed for analytical processing, focusing on fast data retrieval and aggregation.""},{""question"":""How would you approach designing a data warehousing solution for a large-scale e-commerce platform?"",""example_answer"":""I would start by understanding the business requirements and identifying the key performance indicators. Then, I would design a scalable and flexible data warehousing solution using cloud technologies, ensuring data quality, security, and compliance.""}],""red_flags"":[""Lack of experience with cloud platforms"",""Inability to communicate technical concepts to non-technical stakeholders"",""Limited experience with big data technologies""],""confidence_score"":90.0}"
Co-op Engineer- Data Science,"Our team has an immediate Co-op opening for Data Science

Responsibilities:

Research & Build (and/or Prototype) Gen AI model(s) using LLMs
Design, develop and fine-tune scalable LLMs (Large Language Model)
Collaborate with UX designer and front-end developer to incorporate UI design to the Gen-AI platform
Collaborate with platform software engineers for integrating Gen-AI model into existing solution
Conduct technical research and present to the team

Job requirements

What you’ll bring to the team:

Strong background in mathematics and statistics.
A strong foundation in algorithms, data structure, and object-oriented-programming along with proficiency in Python, R, and Java.
Experience in using ML algorithms (i.e., supervised, unsupervised, and Reinforcement Learning) and exploratory data analysis (EDA) tool and libraries including Numpy, Pandas, Matplotlib, Seaborn, and Scikit-learn.
Solid knowledge of Artificial neural networks like CNN, RNN, LSTM, and GRU, along with expertise in DL frameworks such as PyTorch, TensorFlow.
Deep understanding of various NLP tasks and concepts in both NLU (e.g, text/token classification) and NLG (e.g., text generation) domains as well as hands-on experience with NLP libraries like SpaCy, and NLTK.
Theoretical knowledge of advanced NLP concepts including transformers, pre-training with self-supervised techniques, and transfer learning, along with experience in fine-tuning Auto-encoder, Autoregressive and Seq2Seq Language Models from Hugging Face.
Familiarity with Generative AI concepts and tools including (Mutlimodal) Large Language Models, Retrieval Augmented Generation, Vector databases and Langchain.
Prior internship expeirnece in AI/ML development","{""role_summary"":""Conduct research, build, and fine-tune large language models, and collaborate with cross-functional teams to integrate AI models into existing solutions."",""key_terms"":[{""term"":""LLMs"",""explanation"":""Large Language Models, a type of artificial intelligence model used for natural language processing tasks.""},{""term"":""Gen-AI"",""explanation"":""Generative Artificial Intelligence, a type of AI that involves generating new content, such as text or images.""},{""term"":""NLU"",""explanation"":""Natural Language Understanding, a subfield of natural language processing that deals with the ability of computers to understand and interpret human language.""},{""term"":""NLG"",""explanation"":""Natural Language Generation, a subfield of natural language processing that deals with the ability of computers to generate human-like language.""},{""term"":""Transformers"",""explanation"":""A type of neural network architecture used in natural language processing tasks, particularly in language models.""}],""skill_priorities"":{""must_have"":[""Strong background in mathematics and statistics"",""Proficiency in Python, R, and Java"",""Experience with ML algorithms and exploratory data analysis tools"",""Solid knowledge of Artificial neural networks and DL frameworks"",""Deep understanding of NLP tasks and concepts""],""nice_to_have"":[""Prior internship experience in AI/ML development""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of transfer learning in the context of natural language processing?"",""example_answer"":""Transfer learning is a technique where a pre-trained language model is fine-tuned on a specific task, allowing it to adapt to the new task with less data and computation. This is particularly useful in NLP tasks where large amounts of data are required to train a model from scratch.""},{""question"":""How would you approach fine-tuning a large language model for a specific NLP task?"",""example_answer"":""I would start by selecting a pre-trained language model, then adjust the hyperparameters and training data to suit the specific task. I would also experiment with different fine-tuning techniques, such as gradual unfreezing or layer-wise learning rates, to achieve optimal results.""}],""red_flags"":[""Lack of experience with large language models or NLP libraries"",""Inability to explain complex NLP concepts, such as transformers or transfer learning""],""confidence_score"":90.0}"
Data WareHouse Engineer-Canada,"Role: Data WareHouse Engineer

Location: Montreal, Canada-Hybrid (3 days to office)

Duration: 6+ Months

Job Description

Leading provider of platforms; digital innovation; artificial Intelligence and end-to-end IT services and solutions for Global 1000 companies.
We are transforming corporations through deep domain expertise; knowledge-based ML platforms; as well as profound anthropological efforts to understand the end customer and design products and interactions that create delight.
We are deeply committed to developing a comprehensive understanding of our client's problems and developing platforms to address them.
This position is a key lead in the analysis, definition and development of a long-term data plan that will meet the analytical needs of the organization.
This position involves making large amounts of data digestible by our researchers and traders.
You will lead or assist in all aspects of our data warehouse, including: ELT/ETL, data quality evaluation and management, data modeling, database architecture, warehousing principles, and other activities.
Be a thought leader and driving force behind all big data initiatives Design, build and support both real-time and batch data flows Learn our client's users' needs both from a historical/warehouse perspective and an operational/transactional perspective Support the logical and physical integration of all applications that are developed or licensed, including how data are used for multiple purposes Create and manage architecture documentation and project artifacts such as data models, data dictionaries, ETL data maps, performance requirements, etc.
Create standards and conventions for data warehouse, analytics, and ETL systems. Lead governance and enforcement of standards Communicate frequently and effectively with all internal associates, including research, management, development, and other operations personnel.
Demonstrate a disciplined approach to testing both software and data; show diligence in identifying and pursuing data anomalies, always striving not only to correct the data but also to identify the source of the corruption

Required Skill

Teradata *data warehouse development
Enhancement with good to have cloud (Azure, Snowflake, AWS)","{""role_summary"":""Lead the development of a long-term data plan, making large amounts of data digestible for researchers and traders, and drive big data initiatives as a thought leader."",""key_terms"":[{""term"":""ELT/ETL"",""explanation"":""Extract, Load, Transform/Extract, Transform, Load - processes of extracting data from sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Data Modeling"",""explanation"":""The process of creating a conceptual representation of data structures to organize and standardize data.""},{""term"":""Database Architecture"",""explanation"":""The design and organization of a database's components to meet performance, scalability, and security requirements.""},{""term"":""Data Warehousing"",""explanation"":""A system designed to store and manage large amounts of data to support business intelligence and analytics.""},{""term"":""Teradata"",""explanation"":""A relational database management system used for data warehousing and analytics.""},{""term"":""Cloud (Azure, Snowflake, AWS)"",""explanation"":""Cloud computing platforms providing on-demand access to a shared pool of computing resources, including storage, processing power, and databases.""}],""skill_priorities"":{""must_have"":[""Teradata data warehouse development""],""nice_to_have"":[""Cloud experience (Azure, Snowflake, AWS)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach data modeling for a large-scale data warehouse?"",""example_answer"":""I follow a top-down approach, starting with business requirements and then breaking them down into logical and physical data models. I ensure data quality and integrity by implementing data validation rules and data governance policies.""},{""question"":""Can you explain the difference between ELT and ETL, and when to use each?"",""example_answer"":""ELT (Extract, Load, Transform) is used for big data and cloud-based data warehousing, where data is loaded into a target system and then transformed. ETL (Extract, Transform, Load) is used for traditional data warehousing, where data is transformed before loading into a target system. I choose the approach based on the specific project requirements and data volumes.""}],""red_flags"":[""Lack of experience with Teradata data warehouse development"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Junior Front End Software Engineer,"DataVisor is the world's leading AI-powered Fraud and Risk Platform that delivers the best overall detection coverage in industry. With an open SaaS platform that supports easy consolidation and enrichment of any data, DataVisor's solution scales infinitely and enables organizations to act on fast-evolving fraud and money laundering activities in real time. Its patented unsupervised machine learning technology, advanced device intelligence, powerful decision engine and investigation tools work together to provide guaranteed performance lift from day one. DataVisor's platform is architected to support multiple use cases across different business units flexibly, dramatically lowering total cost of ownership, compared to legacy point solutions. DataVisor is recognized as an industry leader and has been adopted by many Fortune 500 companies across the globe. Our award-winning software platform is powered by a team of world-class experts in big data, machine learning, security, and scalable infrastructure. Our culture is open, positive, collaborative, and results driven.

We are looking for excellent web front-end engineers who can constantly challenge theirselves and surpass themselves. We hope that candidates have a solid development foundation and broad front-end or full-stack development experience. Mature experience in front-end framework and early start-up technology company experience is preferred, we look forward to furthering communication with you!

Responsibility:

Develop DataVisor user analysis interface, including data visualization and database interface functionality, and complete the development efficiently tasks;
Constantly participate in the development of the Web front-end, back-end development, API interface, etc. of the DataVisor big data analysis platform;
Focus on business, and business goals, and exert self-creativity and productivity to achieve business needs


Requirements

Basic Qualifications:

BS degree in Computer Science or relevant field of study
2+ years of web development experience, proficient in HTML, CSS, Javascript, Typescript and other related knowledge
2+ years of front-end frameworks (such as Angular, React), etc., experience in data visualization is preferred
Familiar with web testing framework, Java Selenium, experienced in writing E2E test cases/test suites and Unit Tests for frontend code, and also to be able to extend existing applications and have certain experience in performance tuning
Experienced in Java/Spring programming, familiar with Web back-end development and big data analysis experience is preferred
NodeJS server-side development, database interface development experience and SQL proficiency are preferred
Proficiency in using git, jenkins and other tools
Good communication skill including reading and writing skills


Benefits

Health Insurance, PTO and retirement plan","{""role_summary"":""Develop and maintain the user analysis interface of DataVisor's big data analysis platform, focusing on data visualization and database interface functionality, and contributing to the development of the web front-end and back-end."",""key_terms"":[{""term"":""Unsupervised machine learning"",""explanation"":""A type of machine learning that doesn't require labeled data to train models, often used in fraud detection and risk assessment.""},{""term"":""Front-end framework"",""explanation"":""A library or tool that helps build the user interface and user experience of a web application, such as Angular or React.""},{""term"":""Data visualization"",""explanation"":""The process of creating graphical representations of data to help understand and communicate insights and trends.""},{""term"":""Big data analysis"",""explanation"":""The process of examining large and complex data sets to uncover patterns, trends, and insights.""}],""skill_priorities"":{""must_have"":[""HTML"",""CSS"",""Javascript"",""Typescript"",""Front-end framework experience"",""Web testing framework"",""Java Selenium"",""Git"",""Jenkins""],""nice_to_have"":[""Data visualization experience"",""Java/Spring programming"",""NodeJS server-side development"",""Database interface development"",""SQL proficiency"",""Big data analysis experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach data visualization in a web application, and what tools do you typically use?"",""example_answer"":""I use D3.js or Chart.js to create interactive and dynamic visualizations. I consider the type of data, the audience, and the story I want to tell when choosing a visualization approach.""},{""question"":""Can you explain the concept of unsupervised machine learning and how it applies to fraud detection?"",""example_answer"":""Unsupervised machine learning is a type of machine learning that doesn't require labeled data to train models. In fraud detection, it can be used to identify patterns and anomalies in large datasets, helping to detect and prevent fraudulent activities.""}],""red_flags"":[""Lack of experience with front-end frameworks"",""Limited understanding of data visualization concepts"",""Inability to write efficient and scalable code""],""confidence_score"":85.0}"
Data Engineer III,"System1 is one of the largest customer acquisition companies in the world whose growth depends heavily on a very talented data engineering team. 
The Data Operations team at System1 is an engineering team that is focused on building processes, procedures and automation to ensure smooth running data infrastructure. We process billions of records per day, providing a core component of many organizational functions. The data that flows through these systems supports business intelligence, data science and machine learning, traffic quality and analytics.
You would be working in a fast-paced environment where enhancements to system scalability, reliability, usability, efficiency and performance are the goal. Come join us!

The Role You Will Have:
Designing, development and productizing of new well-orchestrated data pipelines, with data ingestion from various sources, delivering data assets at specific destinations.
Gather requirements, understand the big picture, create detailed proposals in technical specification documents.
Provide mentorship to colleagues within the team, and across the organization. Proof of concept evaluations of new technologies, new features, patterns, frameworks, API.
Influence the adoption of new or better practices, and outreach across the organization.
Continuously improve monitoring and alerting coverage.
Communicate effectively with upstream / downstream stake-holders, with clear understanding of data contracts or dependencies.
Conduct SQL data investigations, data quality analysis and optimizations.
Work in a transparent, and agile team environment, supporting the peers.
Perform maintenance of existing infrastructure, improving efficiency and costs.
Contribute in peer code reviews, and help the team produce high quality code.
Consolidate and modernize the codebase.

What You Will Bring:
Bachelor's or Master's degree in Computer Science/Engineering.
Programming expertise in Python is required. JVM lang like Scala, Kotlin are preferred.
Experience working within cloud ecosystems such as AWS, Azure or GCP
Strong knowledge of data mechanics, flow, distribution and latency
A good understanding of distributed systems and the associated engineering components and nuances of them(E.g. message queues)
Experience with modern orchestration platforms such as Airflow
Experience with various datastores, both relational and non-relational
Solid Linux skills, Containerization strategies and Demonstrable Python ability

What We Have to Offer:
Competitive salary + bonus + equity
Generous PTO + 11 company holidays
Open sick time
Medical, Dental & Vision 
RRSP w/matching
Paid professional development
Leadership & growth opportunities
Virtual company and team building events 
#BI-Remote
#BI-Hybrid


The base salary range in Canada for this full-time position is $115,000 - 144,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all U.S. and Canada locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.
Canada - System1’s headquarters is located in Marina del Rey, CA with additional offices in Bellevue, WA and Guelph, ON, Canada. Employees near office locations are returning to the office. Location-specific policies and available accommodations will be discussed during the interview process.","{""role_summary"":""Design and develop data pipelines, ensure data infrastructure scalability and reliability, and provide mentorship to colleagues in a fast-paced data engineering team."",""key_terms"":[{""term"":""Data pipelines"",""explanation"":""A series of processes that extract, transform, and load data from various sources to a target system.""},{""term"":""Data ingestion"",""explanation"":""The process of collecting and transporting data from various sources to a target system.""},{""term"":""Data assets"",""explanation"":""Valuable data that supports business intelligence, data science, and machine learning.""},{""term"":""Cloud ecosystems"",""explanation"":""Cloud computing environments such as AWS, Azure, or GCP that provide scalable infrastructure and services.""},{""term"":""Distributed systems"",""explanation"":""Systems that consist of multiple components that work together to achieve a common goal, often involving message queues and other engineering components.""},{""term"":""Orchestration platforms"",""explanation"":""Tools like Airflow that manage and coordinate complex workflows and data pipelines.""},{""term"":""Containerization"",""explanation"":""A technology that allows packaging applications and their dependencies into a single container, making deployment and management easier.""}],""skill_priorities"":{""must_have"":[""Python programming"",""Cloud ecosystem experience (AWS, Azure, or GCP)"",""Data mechanics knowledge"",""Distributed systems understanding"",""Linux skills"",""Containerization strategies""],""nice_to_have"":[""Scala or Kotlin programming"",""Experience with Airflow"",""Knowledge of relational and non-relational datastores""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a scalable data pipeline to handle high volumes of data?"",""example_answer"":""I would use a distributed architecture with message queues to handle high volumes of data, and implement data partitioning and parallel processing to ensure scalability.""},{""question"":""What are some best practices for ensuring data quality in a data pipeline?"",""example_answer"":""I would implement data validation and data cleansing processes, and use data profiling to identify data quality issues early on.""}],""red_flags"":[""Lack of experience with cloud ecosystems"",""Inability to work in a fast-paced environment"",""Limited knowledge of distributed systems""],""confidence_score"":90.0}"
New Graduate Software Engineer (Toronto),"We'd love to hear from you if you like:

Making a big impact on Day One with a Forbes Top Startup Employer
Working at a startup that has traction ($240M in funding, 40X revenue growth in 4 years)
Working with a newer tech stack and building products that have a real impact (Jerry saves the average person $1K a year)
Mentorship from talented engineering leaders and peers who have built and scaled companies like Nvidia, Kuaishou, Cepton, and Tiktok
Meritocracy: we promote based on performance, not tenure

About the opportunity:

Jerry is building the first AI-powered AllCar™ app to redefine car ownership. The average American spends over 20% of their annual income on their vehicle, yet every part of owning and managing a car is painful – lack of transparency, poor service, high costs, etc. We are simplifying and automating every step of car ownership, all streamlined on our mobile app. We started with insurance shopping in 2019, since then we’ve launched loan refinancing, real-time driving insights, car diagnostics, a repair marketplace, and a GPT-4 chatbot. Our engineering team isn’t just focused on making something that works, we want to make something that works exceptionally well. If you want to contribute to something that matters and is actively making car ownership easier, simpler, and more accessible for 5M+ people, join us!

We are looking for new graduates in the Toronto area to join our engineering team! We are in growth mode and have aggressive goals to scale our technology and our business in the next few years as we go from 5M to 50M users. We don't require any specific work experience but we are looking for the following characteristics: passion for learning, hustle, and ownership. The pace of learning at a startup like Jerry is unbeatable. You can expect your scope of responsibilities to grow quickly if you excel in your role and demonstrate a willingness to keep learning and growing. If you’re looking for an opportunity to accelerate your career, we are hiring across multiple engineering teams!

Our tech stack:

Hosting infra: AWS
React for web frontend
NodeJS + Typescript for backend development
React (mobile app is written in React Native)
Redis, Postgres, DynamoDB for backend storage
Python for data pipeline and ML
Clickhouse for data warehouse
Python + Go for infrastructure as code and continuous integration

What we are looking for:

Bachelor's degree in computer science or engineering
Any internship, co-op, or summer work experience is an asset

Jerry is proud to be an Equal Employment Opportunity employer. We prohibit discrimination based on race, religion, color, national origin, sex, pregnancy, reproductive health decisions or related medical conditions, sexual orientation, gender identity, gender expression, age, veteran status, disability, genetic information, or other characteristics protected by applicable local, state or federal laws.

Jerry is committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, please contact us at recruiting@getjerry.com

About Jerry:

Jerry is America’s first and only AllCar™ app. We are redefining and radically improving how people manage owning a car, one of their most expensive and time-consuming assets.

Backed by artificial intelligence and machine learning, Jerry simplifies and automates owning and maintaining a car while providing personalized services for all car owners' needs. We spend every day innovating and improving our AI-powered app to provide the best possible experience for our customers. From car insurance and financing to maintenance and safety, Jerry does it all.

We are the #1 rated and most downloaded app in our category with a 4.7 star rating in the App Store. We have more than 6 million customers — and we’re just getting started.

Jerry was founded in 2017 by serial entrepreneurs and has raised more than $242 million in financing.

Join our team and work with passionate, curious and egoless people who love solving real-world problems. Help us build a revolutionary product that’s disrupting a massive market.","{""role_summary"":""Join Jerry's engineering team as a new graduate in Toronto, contributing to the development of an AI-powered AllCar app that simplifies and automates car ownership. Work with a talented team to build products that have a real impact, with opportunities for rapid growth and learning."",""key_terms"":[{""term"":""AI-powered"",""explanation"":""Using artificial intelligence to drive the functionality of the AllCar app.""},{""term"":""AllCar app"",""explanation"":""A mobile app that streamlines and automates various aspects of car ownership, including insurance, financing, maintenance, and safety.""},{""term"":""GPT-4 chatbot"",""explanation"":""A type of artificial intelligence language model used in the AllCar app to provide conversational support to users.""},{""term"":""React Native"",""explanation"":""A framework used for building cross-platform mobile apps, in this case, the Jerry mobile app.""},{""term"":""Typescript"",""explanation"":""A programming language used for backend development, providing type safety and other features to improve code maintainability.""},{""term"":""Clickhouse"",""explanation"":""A column-oriented database management system used for data warehousing and analytics.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in computer science or engineering""],""nice_to_have"":[""Internship, co-op, or summer work experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach learning and adapting to new technologies in a fast-paced startup environment?"",""example_answer"":""I prioritize self-learning, staying up-to-date with industry trends and best practices. In my previous internship, I quickly picked up new skills and applied them to contribute to the project's success.""},{""question"":""Can you describe a project where you had to work with a team to solve a complex technical problem?"",""example_answer"":""In my university project, our team built a web application using React and NodeJS. We encountered issues with scalability, and I worked with my team to implement a load balancing solution using AWS, resulting in improved performance and reliability.""}],""red_flags"":[""Lack of passion for learning and growth"",""Inability to work in a fast-paced startup environment""],""confidence_score"":90.0}"
Senior Data Engineer- Snowflake,"Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best analytics global consulting team in the world.

We are seeking an experienced Sr. Data Engineer with expertise in Snowflake to join our data team. As a Data Engineer, you will be responsible for designing, building, and maintaining data pipelines, data integration processes, and data infrastructure using Cloud Snowflake DBT. You will collaborate closely with data scientists, analysts, and other stakeholders to ensure efficient data flow and support data-driven decision making across the organization.

Requirements

9+ years of overall industry experience specifically in data engineering
5+ years of experience building and deploying large-scale data processing pipelines in a production environment
Understanding of Datawarehouse (DWH) systems, and migration from DWH to data lakes/Snowflake
Solid experience with Snowflake Cloud Data Platform (SnowPro Core Certification is a bonus) or other cloud data warehouses (AWS Services)
Experience with dbt (core and/or Cloud) and Fivetran
Experience with Informatica Cloud is a bonus
Strong problem-solving skills and the ability to handle complex data challenges
Build processes supporting data transformation, data structures, metadata, dependency and workload management


Benefits

Significant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.","{""role_summary"":""Design, build, and maintain data pipelines, data integration processes, and data infrastructure to support data-driven decision making across the organization."",""key_terms"":[{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform used for storing and processing large amounts of data.""},{""term"":""DBT"",""explanation"":""An open-source tool used for data transformation and data pipeline management.""},{""term"":""Fivetran"",""explanation"":""A cloud-based data integration platform used for extracting and loading data from various sources.""},{""term"":""Datawarehouse (DWH)"",""explanation"":""A centralized repository that stores data from various sources in a single location, used for reporting and analysis.""},{""term"":""Data lakes"",""explanation"":""A storage repository that holds raw, unprocessed data in its native format, used for big data analytics.""}],""skill_priorities"":{""must_have"":[""9+ years of overall industry experience in data engineering"",""5+ years of experience building and deploying large-scale data processing pipelines"",""Understanding of Datawarehouse (DWH) systems and migration to data lakes/Snowflake"",""Solid experience with Snowflake Cloud Data Platform"",""Experience with dbt"",""Strong problem-solving skills""],""nice_to_have"":[""SnowPro Core Certification"",""Experience with AWS Services"",""Experience with Informatica Cloud""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the differences between a data warehouse and a data lake?"",""example_answer"":""A data warehouse is a structured repository that stores processed data for reporting and analysis, whereas a data lake is a storage repository that holds raw, unprocessed data in its native format, used for big data analytics.""},{""question"":""How would you optimize data pipeline performance in Snowflake?"",""example_answer"":""I would use Snowflake's built-in optimization features, such as columnar storage and data clustering, and also implement data partitioning and caching to improve query performance.""}],""red_flags"":[""Lack of experience with Snowflake or other cloud data warehouses"",""Inability to handle complex data challenges""],""confidence_score"":90.0}"
Software Engineer (Data/Airflow) - Elite FinTech Firm - Up to $180k CAD + Bonus,"Job Title: Software Engineer (Data/Airflow)
Client: Elite FinTech Firm
Salary: Up to $180k CAD + Bonus
Location: Montreal (Hybrid)
Sells: Cutting-edge tech, ownership of multiple greenfield projects, no red tape, a friendly/collaborative environment, beautiful offices, personal projects on Fridays!

An Elite FinTech Firm is looking for the best Software Engineers around to join a top-tier team.

The team is made up of some of the smartest individuals around (degree-educated McGill/MIT/Oxford/Imperial) who have worked at some elite firms (Google/Ubisoft/Jane St)

This team have an unlimited tech budget and promote a great culture!

Role
Building scalable and performant software
Being involved in code implementation, testing, software architecture best practices
Working on large-scale greenfield projects

Skills
They are fully open to experience level and will find good fits for the best people
Strong experience with Python or Rust
Experience with Airflow
Exposure to building ETL pipelines is a huge plus
A desire to learn Rust
Solid SQL knowledge
Fantastic education
Experience working in mission critical environments where speed, reliability and scalability are the most important attributes","{""role_summary"":""Design and develop scalable and performant software solutions, focusing on code implementation, testing, and architecture best practices, with a strong emphasis on greenfield projects."",""key_terms"":[{""term"":""ETL pipelines"",""explanation"":""Extract, Transform, Load pipelines, used to integrate data from multiple sources into a single, unified view.""},{""term"":""Greenfield projects"",""explanation"":""New projects that start from scratch, without any legacy technology or constraints, allowing for complete freedom in design and implementation.""},{""term"":""Mission critical environments"",""explanation"":""Systems or applications that are critical to the operation of an organization, requiring high speed, reliability, and scalability.""}],""skill_priorities"":{""must_have"":[""Strong experience with Python or Rust"",""Solid SQL knowledge""],""nice_to_have"":[""Experience with Airflow"",""Exposure to building ETL pipelines"",""A desire to learn Rust""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing scalable and performant software architectures?"",""example_answer"":""I focus on modular design, using microservices and load balancing to ensure horizontal scalability, and implement caching and content delivery networks to improve performance.""},{""question"":""Can you explain your experience with ETL pipelines and how you've optimized them for performance?"",""example_answer"":""I've worked on several ETL pipeline projects, using tools like Apache Beam and Apache NiFi to extract data from various sources, transform it using Python and SQL, and load it into a data warehouse for analysis.""}],""red_flags"":[""Lack of experience with Python or Rust"",""Inability to work in mission critical environments""],""confidence_score"":90.0}"
"Data Engineer, Finance Data","Why join us?

Are you looking to join a dynamic pension plan that embodies the strong values of its 500,000 members and is an industry leading global investor? If so, we would love to tell you our story.

At OMERS we put our people first and are proud to embrace the diversity of thought and leadership that comes from having locations in Toronto, London, New York, Singapore, Sydney and other major cities across North America and Europe. Our culture is truly one of a kind. We get stuff done, and have fun doing it! We take great pride in contributing to the communities where we live with an ever-constant eye to the global investment markets.

We’d be thrilled to have you join our team as we set up our Capital Markets Finance Data team for new and continued success! We’ll focus equally on expertise and excellence, paired with culture and community. We will serve OMERS teams primarily in Capital Markets, Total Portfolio Management, and the Corporate function through understanding their needs, delivering against their expectations, and contributing our proficiencies – to achieve collective wins. This role joins a team on a journey, with much future potential in a global, sophisticated, complex enterprise.

Scope of Position Support investment teams by enabling robust and reliable investment data, analytics, and reporting through investment technology and change management at one of Canada’s largest pension funds having assets exceeding $120 Billion.

Responsibilities

Design, develop, and help maintain data assets to extract, transform, and load data from various data files, APIs, and databases, and to make them accessible to various client-facing applications as well as investment data warehouse and internal tools
Implement data strategies that prepare, transform, combine and manage structured and unstructured data (e.g. internal investment accounting systems as well as external third-party investment feeds) to integrate the data into an investment data warehouse and BI solutions
Develop and operate highly scalable data pipelines and infrastructure that enable investment analytics, and investment reporting use cases
Automate manual processes and optimize data delivery
Utilize modern technologies for designing and building data solutions to meet business needs
Partner with business analysts and reporting analysts to develop reports and PowerBI dashboards
Support and troubleshoot existing investment data applications and BI reporting solutions as needed
Work as part of a cross-functional agile team responsible for end-to-end delivery of business needs
Collaborate and work effectively with business analysts and reporting analysts team members, and other investment professionals and leaders in solutioning and support

Qualifications

Track of record working in a fast-paced environment and multi-faceted role that intersects with business and technical analysts to support existing solutions, solution delivery, and contributions as a project resource for investment system implementations and upgrades
Strong experience with data management, investment systems, business intelligence, and other reporting technologies
Experience with Microsoft based BI/ETL tools (e.g. SQL Server, SSRS, SSIS, data factory or similar
Experience with Cloud based data and analytics platforms (e.g. Snowflake, DataBricks, Azure Synapse)
Deep proficiency in SQL, Python, and similar languages
Good understanding of investment products
Demonstrated ability to handle multiple projects and tasks at the same time to support daily production issues
Critical thinking skills with the ability to independently solve problems with data and/or reference documents
Investment data modeling experience using the Kimball method is an asset
Experience with BNY Eagle PACE, Calypso, and Charles River is an asset
Data governance experience is an asset
Bachelor’s or master’s degree in Computer Science, Engineering, Finance, or a related field

And you demonstrate

A people-first focus with a desire to develop meaningful, positive relationships across all levels of the organization
A teammate mentality coupled with servant leadership
A sense of urgency, optimism, and a desire to deliver excellence
A desire to drive debate, to speak candidly, and to listen empathetically
Strong orientation towards strategy, change, and results
A continuous improvement mindset

Our story

Founded in 1962, OMERS is one of Canada’s largest defined benefit pension plans, with $128.6 CAD billion in net assets as of December 31, 2023. OMERS is a jointly-sponsored pension plan, with more than 1,000 participating employers ranging from large cities to local agencies, and over half a million active, deferred and retired members. OMERS members include union and non-union employees of municipalities, school boards, local boards, transit systems, electrical utilities, emergency services and children’s aid societies across Ontario. Contributions to the Plan are funded equally by members and employers. OMERS teams work in Toronto, London, New York, Amsterdam, Luxembourg, Singapore, Sydney and other major cities across North America and Europe – serving members and employers and originating and managing a diversified portfolio of high-quality investments in public markets, private equity, infrastructure and real estate.

OMERS is committed to having a workforce that reflects the communities in which we live and work. We are an equal opportunity employer committed to a barrier-free recruitment and selection process. At OMERS inclusion and diversity means belonging. How we create a sense of belonging is through our employees and our vast network of Employee Resource Groups. Whether you are passionate about gender, pride, or visible minorities, we have groups that are focused on making a difference in all of our lives.","{""role_summary"":""Support investment teams by enabling robust and reliable investment data, analytics, and reporting through investment technology and change management at a large pension fund."",""key_terms"":[{""term"":""Data assets"",""explanation"":""Data assets refer to the data files, APIs, and databases used to extract, transform, and load data for investment analytics and reporting.""},{""term"":""Investment data warehouse"",""explanation"":""An investment data warehouse is a centralized repository that stores and manages investment data for reporting and analytics purposes.""},{""term"":""BI solutions"",""explanation"":""BI solutions refer to business intelligence tools and technologies used for data analysis, reporting, and visualization.""},{""term"":""Cloud-based data and analytics platforms"",""explanation"":""Cloud-based data and analytics platforms refer to cloud-hosted technologies used for data management, analytics, and reporting, such as Snowflake, DataBricks, and Azure Synapse.""},{""term"":""Data governance"",""explanation"":""Data governance refers to the policies, procedures, and standards used to manage and ensure the quality, security, and integrity of an organization's data.""}],""skill_priorities"":{""must_have"":[""Experience with data management"",""Strong experience with Microsoft-based BI/ETL tools"",""Experience with Cloud-based data and analytics platforms"",""Deep proficiency in SQL, Python, and similar languages"",""Critical thinking skills""],""nice_to_have"":[""Investment data modeling experience using the Kimball method"",""Experience with BNY Eagle PACE, Calypso, and Charles River"",""Data governance experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a data pipeline to integrate structured and unstructured data from various sources?"",""example_answer"":""I would use a combination of ETL tools and cloud-based data platforms to design a scalable and efficient data pipeline. I would first identify the data sources and requirements, then design a data model to integrate the data. Next, I would implement data quality checks and transformations to ensure data consistency and accuracy. Finally, I would deploy the pipeline and monitor its performance to ensure it meets the business needs.""},{""question"":""How do you stay up-to-date with the latest developments in data management and analytics technologies?"",""example_answer"":""I regularly follow industry blogs and attend webinars to stay current with the latest trends and technologies in data management and analytics. I also participate in online forums and communities to network with peers and learn from their experiences.""}],""red_flags"":[""Lack of experience with cloud-based data and analytics platforms"",""Inability to work in a fast-paced environment with multiple projects and tasks""],""confidence_score"":90.0}"
"Data Engineer, Data Application","Responsibilities

TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.
Join us.

TikTok's immersive experience, global presence, and high engagement makes it the ideal marketing destination for business, big and small, to showcase their unique brand identity, connect with their consumers, and build strong lasting relationships over time. The Ads Data Team builds and manages the petabyte scale data infrastructure, batch/realtime pipelines and services to support Tiktok's global Ads business. We are committed to building a robust data foundation and scalable data applications, unblocking the full potential of advertising data to optimize advertiser experience, boost business growth, empower strategy execution.

We are looking for passionate Data Engineers that have strong problem solving skills to join forces with talented cross functional partners (business operation, data science, engineering and product management) to solve some of the most interesting data challenges with efficiency and quality. In this role, you will contribute to the company's core business across innovative advertising products, campaign management and measurement solutions. You will see a direct impact from your day-to-day work to customer satisfaction and company growth.

Responsibilities:
1. Work closely with Product Managers, Data Scientists/Analysts, and Software/Machine Learning Engineers and other stakeholders to understand data requirements and deliver data solutions that meet business needs.
2. Evaluate, implement and maintain data infrastructure tools and technologies to support efficient data processing, storage and query.
3. Design, build and optimize scalable data pipelines to ingest, process and transform large volumes of data.
4. Design and implement robust data models and visualization to support complex analytical queries and reporting requirements.
5. Ensure the data integrity, accuracy and consistency of data by implementing data quality checks, validation processes and monitoring mechanisms.
6. Continously optimize data pipelines, queries and processes to improve performance, reduce latency and enhance scalability.
7. Provide rapid response to SLA oncall support to business critical data pipelines.
8. Create and maintain good documentation for data assets and promote best practices for data governance within the data user community.

Qualifications

Qualifications:
1. Bachelor's degree in Computer Science, Engineering, or a related field.
2. Proven 1~3 years' experience as a Data Engineer or similar role in supporting data-centric business.
3. Strong knowledge of SQL and experience working with relational and non-relational databases.
4. Proficiency in programming languages such as Python, Java, Go etc.
5. Solid understanding of data modeling and data warehousing concepts, data integration and ETL/ELT techniques.
6. Effective communication skills and ability to collaborate effectively with cross-functional teams.
7. Excellent problem-solving skills, attention to detail, and ability to thrive in a fast-paced environment.

Preferred Qualifications:
1. Experience with big data technologies(e.g. Apache Hadoop, Spark, Kafka, Flink) and working with terabyte to petabyte scale data.
2. Experience with cloud data warehouses(eg. Snowflake, Databricks, BigQuery) and modern business intelligence/data stack.
3. Experience with data governance, data privacy and compliance.
4. Experience in the advertising, e-commerce or gaming industry.

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2

Job Information:

【For Pay Transparency】Compensation Description (annually)
The base salary range for this position in the selected city is CAD$ 136800- CAD$ 205000 annually.
Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.
The compensation for this position is based on a monthly compensation structure. The range specified is the expected annual compensation for a person in this position.
Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:
We cover 100% premium coverage for employee and dependent's extended health care insurance. As well as Short/Long term Disability, Basic Life, Survivor Benefit and AD&D insurance plans.
Our time off and leave plans are: 11 paid holidays per year plus 19 days of vacation (prorated upon hire and increased by tenure) and 7 paid sick days per year as well as 13 weeks of supplemental paid maternity leave top-up and 10 weeks of Supplemental Paid Parental Leave top-up.
We also provide generous benefits such as RRSP company match, EAP, gym and cell phone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","{""role_summary"":""As a Data Engineer at TikTok, you will work closely with cross-functional teams to design, build, and optimize scalable data pipelines, ensuring data integrity and accuracy to support the company's core business across innovative advertising products."",""key_terms"":[{""term"":""Petabyte scale data infrastructure"",""explanation"":""A large-scale data infrastructure capable of handling massive amounts of data, typically measured in petabytes (1 petabyte = 1,000 terabytes).""},{""term"":""Batch/realtime pipelines"",""explanation"":""Data processing pipelines that handle large volumes of data in batches or in real-time, enabling efficient data processing and analysis.""},{""term"":""Data modeling and data warehousing"",""explanation"":""The process of designing and implementing data models and data warehouses to store and manage large datasets, enabling efficient data analysis and reporting.""},{""term"":""ETL/ELT techniques"",""explanation"":""Extract, Transform, Load (ETL) or Extract, Load, Transform (ELT) techniques used to extract data from various sources, transform it into a standardized format, and load it into a target system for analysis.""},{""term"":""Cloud data warehouses"",""explanation"":""Cloud-based data warehouses, such as Snowflake, Databricks, or BigQuery, that provide scalable and secure data storage and analysis capabilities.""}],""skill_priorities"":{""must_have"":[""Strong problem-solving skills"",""Experience with SQL and relational/non-relational databases"",""Proficiency in programming languages (Python, Java, Go)"",""Solid understanding of data modeling and data warehousing concepts"",""Effective communication skills""],""nice_to_have"":[""Experience with big data technologies (Apache Hadoop, Spark, Kafka, Flink)"",""Experience with cloud data warehouses (Snowflake, Databricks, BigQuery)"",""Experience with data governance, data privacy, and compliance"",""Experience in the advertising, e-commerce, or gaming industry""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize a slow-performing data pipeline?"",""example_answer"":""I would identify the bottleneck in the pipeline, consider parallel processing, and implement data caching or indexing to improve performance.""},{""question"":""Can you explain the difference between ETL and ELT?"",""example_answer"":""ETL involves transforming data before loading it into a target system, whereas ELT loads data first and then transforms it, allowing for more flexibility and scalability.""}],""red_flags"":[""Lack of experience with big data technologies"",""Inability to communicate technical concepts effectively""],""confidence_score"":90.0}"
Data Developer [Scotiabank],"Requisition ID: 199915

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

The Team

Automotive Finance IT support team is responsible for supporting the technology solutions implementations to drive the bank's automotive business. By joining us, you will be emersed in multiple ecosystems and you will be entraining on a journey of professional and personal development!

The Role

As a member of Automotive team, the Data Developer is responsible for operational data support and development for Automotive Finance System applications. The incumbent is responsible for providing specialized development and support work in data integration to and from Enterprise Data Lake and Data Warehouse and development work within our agile lab based on business requirements.

Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems, and knowledge.
Serves as a liaison between the business community and the IT organization in order to provide technical solutions to meet user needs.
Demonstrates an informed knowledge of business functions to resolve problems and capitalize on improvement opportunities.
Exercise good judgment in selecting methods and techniques for obtaining solutions.
Understand how the Bank's risk appetite and risk culture should be considered in day-to-day activities and decisions.

Is this role right for you? In this role you will:

Developing SQL queries / ETL packages using T-SQL and SSIS to ingest data from source systems to integrate with SQL Server data warehouse.
Design and develop physical data model structures in SQL Server
Design and development of high-quality dashboards / reports using tools like Power BI, SSRS, Crystal Report, Excel/PowerPivot, and Tableau. Develop custom reports, analytics and KPI's for the Business
Builds and maintain proper documentation, data lineage and extract-transform-load (ETL) processes.
Collecting business requirements / user stories while working in a lab with a product owner, Business Analyst, Scrum Master, and application developers.
Developing SQL views to enable data consumers to read data from data warehouse.
Documenting databases, data process flows and maintain data dictionaries, support and onboarding procedures.
Troubleshoot and resolve database and application defects in a timely manner with consultation with internal and external groups as needed.
Train and assist users at all levels.
Analyze root causes of operational malfunctions including but not limited to batch jobs and provide resolutions.
Analyze highly complex business requirements; generate technical specifications to design or redesign complex software components and applications.
Act as an expert technical resource in Data Warehouse/DBs and ETL
Leverage industry best practices to design, test, implement and support a solution.
Assure quality, security and compliance requirements are met for supported area.
Be flexible and thrive in an evolving environment.
Adapt to change quickly and adjust work accordingly in a positive manner.
On-call responsibilities to operate as the L2 point of contact for monitoring TIDAL/EDL jobs requests may be required for weekends rotation.

Skills

Do you have the skills that will enable you to succeed in this role? We'd love to work with you if you have:

3-5 years previous experience working within a technically focused environment as a database analyst / data developer.
Experience with databases such as Microsoft BI stack SQL Server, T-SQL, SSRS, MS SQL Enterprise Manager, MySQL, Crystal Report, Tidal jobs etc.
Experience working in an agile development team engaged in the SDLC process and SDLC methodologies (agile / waterfall).
Experience with EDL / Hadoop / Hive / Tableau a plus. Hands-on programming experience and advanced knowledge of SQL.
Expertise with data visualization / BI tools like e.g., Power BI.
Clear communication and interpersonal skills required.
Familiarity with JIRA/SharePoint
Attention to detail and feedback from clients on dashboards and reports must be completed rapidly.
Experience developing code to consume REST API services and integrating systems with sftp a plus.
Experience with MS Azure / SQL Server MI / Machine Learning services a plus.
Experience with databases, dimensional data modeling design.
Experience with data warehouse, ETL, SSIS, SSAS/cubes a must.
Experience with implementing DevOps / CIAD a plus.
Experience with web development (in ASP.NET MVC / C#) a plus.

Technical Environment

Database: SQL Server / MS SQL Enterprise Manager / Oracle
Platform: Microsoft.NET, IIS, SharePoint Online / Azure
Development Environment: Visual Studio / SSMS
Languages: T-SQL, C#, .NET, Python
Source Control: MS Team Foundation Server / Git / Bitbucket / TFS
Reporting: MS SQL Server Reporting Services, Crystal Reports, SSRS
Data Visualizations: MS PowerBI / Tableau / Excel

What's in it for you?

Diversity, Equity, Inclusion & Allyship - We strive to create an inclusive culture where every employee is empowered to reach their fullest potential, respected for who they are, and are embraced through bias-free practices and inclusive values across Scotiabank. We embrace diversity and provide opportunities for all employee to learn, grow & participate through our various Employee Resource Groups (ERGs) that span across diverse gender identities, ethnicity, race, age, ability & veterans.
Accessibility and Workplace Accommodations - We value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. Scotiabank continues to locate, remove and prevent barriers so that we can build a diverse and inclusive environment while meeting accessibility requirements.
Upskilling through online courses, cross-functional development opportunities, and tuition assistance.
Competitive Rewards program including bonus, flexible vacation, personal, sick days and benefits will start on day one.
Community Engagement - no matter where you choose to work from; we offer opportunities for community engagement & belonging with our various programs such as hackathons, contests, cooking with friends, Humans of Digital and much more!

Work arrangements: Hybrid

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here . Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","{""role_summary"":""The Data Developer is responsible for operational data support and development for Automotive Finance System applications, providing technical solutions to meet user needs, and championing a customer-focused culture."",""key_terms"":[{""term"":""Enterprise Data Lake"",""explanation"":""A centralized repository that stores all of an organization's data in its raw, unprocessed form.""},{""term"":""Data Warehouse"",""explanation"":""A central repository that stores data in a structured and transformed way to support business intelligence activities.""},{""term"":""ETL (Extract, Transform, Load)"",""explanation"":""A process used to extract data from multiple sources, transform it into a standardized format, and load it into a target system.""},{""term"":""Agile Development"",""explanation"":""An iterative approach to software development that emphasizes collaboration, flexibility, and rapid delivery.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development (Dev) and IT operations (Ops) to improve collaboration and speed up the release of software applications.""}],""skill_priorities"":{""must_have"":[""3-5 years of experience as a database analyst/data developer"",""Experience with databases such as Microsoft BI stack SQL Server, T-SQL, SSRS, MS SQL Enterprise Manager, MySQL"",""Experience with data visualization/BI tools like Power BI"",""Experience with data warehouse, ETL, SSIS, SSAS/cubes""],""nice_to_have"":[""Experience with EDL/Hadoop/Hive/Tableau"",""Hands-on programming experience and advanced knowledge of SQL"",""Experience with MS Azure/SQL Server MI/Machine Learning services"",""Experience with web development (in ASP.NET MVC/C#)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the difference between a data lake and a data warehouse?"",""example_answer"":""A data lake is a centralized repository that stores all of an organization's data in its raw, unprocessed form, whereas a data warehouse is a central repository that stores data in a structured and transformed way to support business intelligence activities.""},{""question"":""How do you approach data modeling for a complex business requirement?"",""example_answer"":""I would start by understanding the business requirement, then design a physical data model structure in SQL Server, and finally, develop custom reports, analytics, and KPIs for the business using tools like Power BI.""}],""red_flags"":[""Lack of experience with data visualization/BI tools"",""Inability to work in an agile development environment"",""Limited knowledge of data warehouse, ETL, SSIS, SSAS/cubes""],""confidence_score"":90.0}"
Data Analyst with Python and ETL [Scotiabank],"Requisition ID: 200666

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

The Team

This position belongs to a highly skilled development team that develops and supports various applications in growing Global Regulatory & Controls Technology team. The team is responsible for providing specialized analysis, design, development, and support of cost effective, mission critical, on-line, risk management and decision support systems for business users within Scotiabank IT group.

The Role

The incumbent will be responsible for supporting and building end-to-end technical solutions to support regulatory reporting of Scotia Capital Markets transactions. From root cause and business requirements analysis, aided by strong data and technical system analysis, to solutioning, development, testing, and release to production, the incumbent will ensure timely resolution of high priority Production Support tickets.
The incumbent will work closely with the broader project team, developers, scrum masters, regulatory stakeholders, trading systems, and downstream consumers to ensure high priority support tickets are resolved within SLAs with high quality. The incumbent will also be expected to develop application and business process subject matter expertise over the duration of the assignment.

Is this role right for you?

Work within a cross functional Agile team to analyse and troubleshoot technical issues and production support tickets and deliver solutions for the same.
Change request delivery – requirements gathering, design, implementation, and testing as part of new regulatory initiatives.
Support of advanced issue triage and ad-hoc data analysis and reporting
Work closely with business users and IT teams from multiple key trading systems in Canada, US, and Asia, in the design and prototyping of business solutions
Ad hoc inquiries from business stakeholders on G20 Regulatory Reporting logic (CFTC, SEC, CSA, MAS, HKMA, EMIR, UK, etc.), behaviour, and data requests
Keep current on rapidly changing technological trends, self-leaner on new technologies and maintain an understanding of the business and technology strategies.
Ability to look at a problem from both a business and technical angle.
Other projects and initiatives as required.

Do you have the skills that will enable you to succeed in this role?

Strong hands-on experience with data analysis and ETL (SQL, Python, Kafka, Jupyter, Java, XML, and JSON)
High levels of analytical, conceptual, problem solving and organizational skills
Excellent verbal and written communication skills
Attitude and willingness to learn fast, go above and beyond consistently and work independently without supervision.
Experience with Apache Kafka , Postman, ElasticSearch, Kubernetes, Airflow, and/or Linux
Ability to perform Java coding is a strong asset.
Knowledge of Capital Market products, front office trading, and back-office booking process globally.
Provide timely IT support to the enquiries from regulators in Canada and US and internal business stakeholders to meet critical timelines.
Excellent team building skills, working with diverse groups to resolve issues and identify efficiencies.
Ability to work in a project environment as required, with key deliverables and ensuring requirements of department are represented.
Strong ability to establish relationships with internal customers, as well as senior management.
A recognized degree in engineering, computer science, math, related discipline or experience

What's in it for you?

We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!
We provide you with the tools and technology needed to create beautiful customer experiences
You'll get to work with and learn from diverse industry leaders, who have hailed from top technology companies around the world
We offer a competitive total rewards package that includes a base salary, a performance bonus, company matching programs (on pension & profit sharing), generous vacation, personal & sick days, personal development funding, maternity leave top-up, parental leave and much more.

#Python

#ETL

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here . Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","{""role_summary"":""Support and build end-to-end technical solutions for regulatory reporting of Scotia Capital Markets transactions, ensuring timely resolution of high-priority production support tickets and developing application and business process subject matter expertise."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Agile"",""explanation"":""An iterative approach to project management that focuses on flexibility, collaboration, and continuous improvement.""},{""term"":""Kafka"",""explanation"":""A distributed streaming platform that enables high-throughput and provides low-latency, fault-tolerant data processing.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""Regulatory Reporting"",""explanation"":""The process of submitting required reports to regulatory bodies, such as the CFTC, SEC, CSA, MAS, HKMA, EMIR, and UK, to ensure compliance with financial regulations.""}],""skill_priorities"":{""must_have"":[""Strong hands-on experience with data analysis and ETL"",""High levels of analytical, conceptual, problem-solving, and organizational skills"",""Excellent verbal and written communication skills"",""Experience with Apache Kafka, Postman, ElasticSearch, Kubernetes, Airflow, and/or Linux""],""nice_to_have"":[""Ability to perform Java coding"",""Knowledge of Capital Market products, front office trading, and back-office booking process globally""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach troubleshooting a complex technical issue in a production environment?"",""example_answer"":""I would start by gathering information about the issue, then use data analysis and technical system analysis to identify the root cause. Next, I would collaborate with the project team and stakeholders to develop a solution, ensuring timely resolution within SLAs.""},{""question"":""Can you explain how you would design and prototype a business solution for regulatory reporting?"",""example_answer"":""I would work closely with business users and IT teams to understand the requirements, then use my knowledge of ETL, Kafka, and other technologies to design an efficient solution. I would also ensure that the solution meets the regulatory requirements and is scalable.""}],""red_flags"":[""Lack of experience with data analysis and ETL"",""Inability to work independently without supervision"",""Limited knowledge of regulatory reporting requirements""],""confidence_score"":90.0}"
GCP Data Engineer,"Role: GCP Data Engineer

Location: Ontario/Remote

Duration: 6-12+ Months

Job Description

As a Data Engineer, you'll focus on solving problems and creating value for business by
building solutions that are reliable and scalable to work with the size and scope of the
company. You will be tasked with creating a custom-built pipeline on GCP stack, and you
will be part of teams that implement vendor sourced enterprise software, configuring that
software, customizing it, and integrating with other internal systems.

Required Skills

5+ years of industry experience in software development, data engineering, business intelligence, or related field with experience in manipulating, processing, and extracting value from datasets.
Design, build and deploy internal applications to support our technology life cycle, collaboration and spaces, service delivery management, data and business intelligence among others.
Building Modular code for multi usable pipeline or any kind of complex Ingestion Framework used to ease the job to load the data into Datalake or Data Warehouse from multiple sources.
Work closely with analysts and business process owners to translate business requirements into technical solutions.
Coding experience in scripting and languages (YAML, Python, SQL).
Expertise in Google Cloud Platform (GCP) technologies in the data warehousing space (BigQuery, Cloud SQL, Dataflow, Data Catalog, Cloud Composer, Cloud SDK, Cloud PubSub, Google Cloud Storage, IAM, Compute Engine, Cloud Data Fusion, Dataproc, BigTable).
Maintain highest levels of development practices including: technical design, solution development, systems configuration, test documentation/execution, issue identification and resolution, writing clean, modular and self-sustaining code, with repeatable quality and predictability.
Understanding CI/CD Processes using Github, Cloud Build, Google Cloud SDK
Willing to work in ET Shift.

Qualifications

Bachelor's degree in Computer Science or related technical field, or equivalent practical experience.
GCP Certified Data Engineer (preferred)
Excellent verbal and written communication skills","{""role_summary"":""Design, build, and deploy scalable data solutions on Google Cloud Platform (GCP) to support business requirements, working closely with analysts and business process owners."",""key_terms"":[{""term"":""GCP"",""explanation"":""Google Cloud Platform, a suite of cloud computing services offered by Google.""},{""term"":""Data Engineering"",""explanation"":""The process of designing, building, and maintaining large-scale data systems to support business operations.""},{""term"":""BigQuery"",""explanation"":""A fully-managed enterprise data warehouse service on GCP, used for large-scale data analysis.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a set of practices to automate and streamline software development and deployment.""}],""skill_priorities"":{""must_have"":[""5+ years of industry experience in software development, data engineering, or related field"",""Experience with GCP technologies (BigQuery, Cloud SQL, Dataflow, etc.)"",""Coding experience in scripting and languages (YAML, Python, SQL)"",""Understanding of CI/CD processes using Github, Cloud Build, Google Cloud SDK""],""nice_to_have"":[""GCP Certified Data Engineer"",""Experience with vendor sourced enterprise software""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a scalable data pipeline on GCP?"",""example_answer"":""I would use a combination of Cloud Data Fusion, Cloud Composer, and Cloud PubSub to create a modular and scalable pipeline that can handle large volumes of data from multiple sources.""},{""question"":""How do you ensure data quality and integrity in your data engineering projects?"",""example_answer"":""I use a combination of data validation, data profiling, and data testing to ensure data quality and integrity. I also implement data governance policies and procedures to ensure data consistency and accuracy.""}],""red_flags"":[""Lack of experience with GCP technologies"",""Inability to work in ET Shift""],""confidence_score"":90.0}"
Data Engineer I,"Work Location:

Toronto, Ontario, Canada

Hours:

37.5

Line Of Business:

Technology Solutions

Pay Details:

$65,600 - $98,400 CAD

TD is committed to providing fair and equitable compensation opportunities to all colleagues. Growth opportunities and skill development are defining features of the colleague experience at TD. Our compensation policies and practices have been designed to allow colleagues to progress through the salary range over time as they progress in their role. The base pay actually offered may vary based upon the candidate's skills and experience, job-related knowledge, geographic location, and other specific business and organizational needs.

As a candidate, you are encouraged to ask compensation related questions and have an open dialogue with your recruiter who can provide you more specific details for this role.

Job Description:

About the Team

Data as a Service (DaaS) is an enterprise-wide data management improvement initiative that brings business data and technology resources together to maximize customer and colleague benefit.

The DaaS Practice is comprised of a group of highly skilled Subject Matter Experts (SME) who are focused on the delivery of specialized work including building data pipelines, supporting data science needs, driving data automation, creating and implementing data & analytics platforms.

Job Description

We are seeking highly motivated and capable technologists to join our Data as a Services team to work on the forefront of enabling TD's big data strategy with a special focus on ETL/data curation on on-cloud Azure Platform.

Across multiple large-scale transformation programs and in a data management context, reporting to the engineering manager, the data engineer will lead team members to develop ETL processes, design and build data stores and transformations on Azure platform, coordinate team member's work into an integrated high quality product.

As a Data Engineer, You Will:

Design and develop ETL processes based on functional and non-functional requirements in python / pyspark within Azure platform.
Recommend and execute improvements.
Execute and provide support during testing cycles and post-production deployment, engage in peer code reviews.
Apply automation and innovation on new and on-going data platforms that aligned to business strategies.
Understand the full end to end development activities from design to go live for ETL development in Azure platform.
Document component design for developers and for broader communication.
Understand and adopt an Agile (SCRUM like) software development mindset
Follow established processes/standards, business technology architecture for development, release management and deployment process.
Design, develop and implement reporting platforms and complex ETL frameworks that meet business requirements.
Provide data analysis and requirements within enterprise platform.
Develop, maintain knowledge of data available from upstream sources and data within various platforms.

Job Requirements

Undergraduate Degree or Technical Certificate.
2-3 years relevant design and development experience.
Working experience for the following:
Azure platform and tools like Azure Data Factory, Azure Databricks, Synapse
Python, Pyspark, Spark
Data Flow Processes
SQL Development
ETL
Working experience with data modeling, relational modeling and dimensional modeling.
Working knowledge of source code control tool such as GIT
Implementation experience in managing and working in multiple environments, release and change management and knowledge of firewall, network work protocols, file transfer – TIBCO
Familiar with Agile development methodologies
Readiness and motivation (as an experienced developer and subject matter expert) to address and resolve complex issues, guide/advise/support clients, partners and project teams, often working on multiple medium-to-large sized projects.
Commitment to and belief in the quality of your deliverables.
Capacity and eagerness to work independently as a senior/lead role on multiple tasks and also coach/educate/guide/direct others.
Ability to assume assignments that are moderate- to highly- complex and multi-faceted, to be performed under management guidance.
Innovative, problem-solving and critical thinking - asking the right questions, taking calculated risks.
Teamwork and collaboration strengths - ability to network, get involved and learn the organization culture and values.
Communication skills - ability to articulate impactfully and through the correct means.
Who We Are:

TD is one of the world's leading global financial institutions and is the fifth largest bank in North America by branches/stores. Every day, we deliver legendary customer experiences to over 27 million households and businesses in Canada, the United States and around the world. More than 95,000 TD colleagues bring their skills, talent, and creativity to the Bank, those we serve, and the economies we support. We are guided by our vision to Be the Better Bank and our purpose to enrich the lives of our customers, communities and colleagues.

TD is deeply committed to being a leader in customer experience, that is why we believe that all colleagues, no matter where they work, are customer facing. As we build our business and deliver on our strategy, we are innovating to enhance the customer experience and build capabilities to shape the future of banking. Whether you’ve got years of banking experience or are just starting your career in financial services, we can help you realize your potential. Through regular leadership and development conversations to mentorship and training programs, we’re here to support you towards your goals. As an organization, we keep growing – and so will you.

Our Total Rewards Package

Our Total Rewards package reflects the investments we make in our colleagues to help them and their families achieve their financial, physical, and mental well-being goals. Total Rewards at TD includes a base salary, variable compensation, and several other key plans such as health and well-being benefits, savings and retirement programs, paid time off, banking benefits and discounts, career development, and reward and recognition programs. Learn more

Additional Information:

We’re delighted that you’re considering building a career with TD. Through regular development conversations, training programs, and a competitive benefits plan, we’re committed to providing the support our colleagues need to thrive both at work and at home.

Please be advised that this job opportunity is subject to provincial regulation for employment purposes. It is imperative to acknowledge that each province or territory within the jurisdiction of Canada may have its own set of regulations, requirements.

Colleague Development

If you’re interested in a specific career path or are looking to build certain skills, we want to help you succeed. You’ll have regular career, development, and performance conversations with your manager, as well as access to an online learning platform and a variety of mentoring programs to help you unlock future opportunities. Whether you have a passion for helping customers and want to expand your experience, or you want to coach and inspire your colleagues, there are many different career paths within our organization at TD – and we’re committed to helping you identify opportunities that support your goals.

Training & Onboarding

We will provide training and onboarding sessions to ensure that you’ve got everything you need to succeed in your new role.

Interview Process

We’ll reach out to candidates of interest to schedule an interview. We do our best to communicate outcomes to all applicants by email or phone call.

Accommodation

Your accessibility is important to us. Please let us know if you’d like accommodations (including accessible meeting rooms, captioning for virtual interviews, etc.) to help us remove barriers so that you can participate throughout the interview process.

We look forward to hearing from you!

Language Requirement (Quebec Only):

Sans Objet","{""role_summary"":""Design and develop ETL processes, lead team members, and coordinate work on the Azure platform as a Data Engineer in the Data as a Service team, enabling TD's big data strategy."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service that allows users to create, schedule, and manage data pipelines.""},{""term"":""Pyspark"",""explanation"":""A Python library for Apache Spark, a unified analytics engine for large-scale data processing.""},{""term"":""Agile (SCRUM like) software development"",""explanation"":""An iterative and incremental approach to software development that emphasizes flexibility, collaboration, and continuous improvement.""}],""skill_priorities"":{""must_have"":[""Azure platform and tools like Azure Data Factory, Azure Databricks, Synapse"",""Python, Pyspark, Spark"",""Data Flow Processes"",""SQL Development"",""ETL"",""Data modeling, relational modeling and dimensional modeling"",""Working knowledge of source code control tool such as GIT""],""nice_to_have"":[""Implementation experience in managing and working in multiple environments, release and change management and knowledge of firewall, network work protocols, file transfer – TIBCO""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of ETL and how you would design an ETL process using Azure Data Factory?"",""example_answer"":""ETL stands for Extract, Transform, Load, which involves extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system. To design an ETL process using Azure Data Factory, I would first identify the data sources and targets, then create a data flow diagram to visualize the process. Next, I would create datasets and linked services in Azure Data Factory, followed by creating and scheduling pipelines to execute the ETL process.""},{""question"":""How do you optimize data pipelines for performance and scalability in a cloud-based environment?"",""example_answer"":""To optimize data pipelines for performance and scalability in a cloud-based environment, I would focus on parallel processing, data partitioning, and caching. I would also use cloud-based services like Azure Databricks and Synapse to leverage their scalability features. Additionally, I would monitor pipeline performance using metrics and logs, and apply optimization techniques such as data compression and columnar storage.""}],""red_flags"":[""Lack of experience with Azure platform and tools"",""Inability to design and develop ETL processes"",""Limited knowledge of data modeling and data flow processes""],""confidence_score"":90.0}"
DATA ENGINEER,"Eviden, part of the Atos Group, with an annual revenue of circa € 5 billion is a global leader in data-driven, trusted and sustainable digital transformation. As a next generation digital business with worldwide leading positions in digital, cloud, data, advanced computing and security, it brings deep expertise for all industries in more than 47 countries. By uniting unique high-end technologies across the full digital continuum with 47,000 world-class talents, Eviden expands the possibilities of data and technology, now and for generations to come.

Role Azure Data Engineer

Location Toronto, ON

Fulltime with Eviden

Job Description

Must Have – Azure Data Bricks, Azure Data Factory, Spark SQL with analytical knowledge.

4-5 Years Of Development Experience In Data Engineering Skills.

Strong experience in Spark.

Understand complex data system by working closely with engineering and product teams.

Develop scalable and maintainable applications to extract, transform, and load data in various formats to SQL Server, Hadoop Data Lake or other data storage locations.



Let’s grow together.","{""role_summary"":""Design and develop scalable data engineering solutions using Azure technologies, working closely with engineering and product teams to extract, transform, and load data."",""key_terms"":[{""term"":""Azure Data Bricks"",""explanation"":""A cloud-based analytics platform that allows for large-scale data processing and analysis.""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service that allows for the creation, scheduling, and management of data pipelines.""},{""term"":""Spark SQL"",""explanation"":""A high-level library for processing large-scale data sets, providing a SQL-like interface for querying and analyzing data.""},{""term"":""Hadoop Data Lake"",""explanation"":""A centralized repository that stores all types of data in its native format, allowing for flexible and scalable data processing and analysis.""}],""skill_priorities"":{""must_have"":[""Azure Data Bricks"",""Azure Data Factory"",""Spark SQL"",""Data Engineering Skills"",""Development Experience""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize data processing pipelines in Azure Data Factory for improved performance?"",""example_answer"":""I would use Azure Data Factory's built-in optimization features, such as parallel processing and caching, to improve pipeline performance. Additionally, I would monitor pipeline execution and adjust as needed to ensure optimal performance.""},{""question"":""Can you explain how you would handle complex data systems in a cloud-based environment?"",""example_answer"":""I would work closely with engineering and product teams to understand the data system requirements and design scalable and maintainable applications using Azure technologies such as Azure Data Bricks and Azure Data Factory.""}],""red_flags"":[""Lack of experience with Azure Data Bricks or Azure Data Factory"",""Inability to work with complex data systems""],""confidence_score"":90.0}"
Python Data Engineer,"Position Overview:
As a Python Data Engineer at High 5 Casino, you will be responsible for designing, implementing, and maintaining data pipelines, databases and our in-house real-time player interaction software. You will collaborate with cross-functional teams to ensure seamless data integration, support data-driven decision-making, and contribute to the overall success of our gaming platforms.



Key Responsibilitie
s:Data Pipeline Development: Design, build, and maintain robust and scalable data pipelines for extracting, transforming, and loading (ETL) data from various source
s.Database Management: Manage and optimize databases, ensuring data integrity, security, and performance. Implement best practices for database design, indexing, and maintenanc
e.Data Integration: Collaborate with game providers, analysts and other stakeholders to integrate data sources, ensuring a unified and accurate view of data across the organizatio
n.Performance Monitoring: Monitor and optimize the performance of data systems, identifying and addressing bottlenecks, ensuring scalability and minimizing cost
s.Collaboration: Work closely with cross-functional teams, including data analysts and business intelligence teams, to understand data requirements and deliver solution
s.Streaming Systems: Design and implement real-time data processing systems to handle streaming data, ensuring low-latency and high-throughput data processing for real-time player interaction
s.AI Integration: Collaborate with data scientists to deploy AI/ML models into production systems, ensuring proper integration, scalability, and performance. Enhance tools with AI-driven insights, predictive capabilities, and automated decision-making processe
s.AI-Powered Solutions: Develop AI-powered features for liveops, customer support, and fraud detection tools, such as automated ticket responses, player behavior analysis, and anomaly detectio
n.AI Model Maintenance: Partner with data scientists to maintain, retrain, and fine-tune AI models based on new data and business requirements, ensuring continuous improvement and relevanc

e
.
Qualificati
ons:Bachelor’s degree in Computer Science, Information Technology, or a related fi
eld.Proven experience as a Python Data Engineer or a similar r
ole.Strong proficiency in Python and experience with relevant frameworks and librar
ies.Deep familiarity with SQL and query management practi
ces.Solid understanding of data modeling, database design, and data warehousing conce
pts.Experience with ETL processes and to
ols.Knowledge of cloud platforms (e.g., GCP, AWS, Azure) and their data servi
ces.Familiarity with big data technologies (e.g., Hadoop, Spark) is a p
lus.Understanding of AI tools like Gemini and ChatGPT is also a p
lus.Excellent problem-solving and communication ski
lls.Ability to work independently and collaboratively in a fast-paced environm

en
t.","{""role_summary"":""Design, implement, and maintain data pipelines, databases, and real-time player interaction software as a Python Data Engineer, ensuring seamless data integration and contributing to the success of gaming platforms."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from sources, transforming it into a usable format, and loading it into a target system.""},{""term"":""Data Pipeline"",""explanation"":""A series of processes that extract, transform, and load data from various sources to a target system, ensuring data integration and scalability.""},{""term"":""AI/ML Models"",""explanation"":""Artificial Intelligence and Machine Learning models used for predictive analytics, automated decision-making, and enhancing tools with AI-driven insights.""},{""term"":""Cloud Platforms"",""explanation"":""Cloud-based infrastructure services like GCP, AWS, and Azure, providing scalable and on-demand access to computing resources and data services.""},{""term"":""Big Data Technologies"",""explanation"":""Tools and frameworks like Hadoop and Spark, designed to handle large volumes of data, enabling efficient processing and analysis.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Data Modeling"",""Database Design"",""ETL Processes"",""Cloud Platforms""],""nice_to_have"":[""Big Data Technologies"",""AI Tools like Gemini and ChatGPT""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize the performance of a data pipeline, and what metrics would you use to measure its efficiency?"",""example_answer"":""I would analyze the pipeline's architecture, identify bottlenecks, and implement parallel processing, caching, and data partitioning. I'd measure performance using metrics like data throughput, latency, and CPU utilization.""},{""question"":""Can you explain how you would integrate an AI/ML model into a production system, ensuring scalability and performance?"",""example_answer"":""I would containerize the model using Docker, deploy it on a cloud platform, and implement load balancing and auto-scaling to ensure scalability. I'd also monitor performance using metrics like model latency, throughput, and accuracy.""}],""red_flags"":[""Lack of experience with cloud platforms and their data services"",""Inability to explain data modeling and database design concepts"",""Limited understanding of AI/ML models and their integration into production systems""],""confidence_score"":90.0}"
Data Engineer/ Ingénieur de données,"Job Location

North York

Job Description

Would you like to develop your skills as the next generation of leaders in the world of technology at one of Canada’s Top 100 Employers (2025)?

We are currently hiring for a full-time Data Engineer starting April 2025 in our Toronto headquarters to assist in building tools and processes to bring data together to drive business decisions and efficiencies. If you wish to join a team of professionals motivated by advanced technologies, serving as a catalyst for change, and identifying and aligning solutions to help support business opportunities then a career at P&G is right for you.

What Can You Expect

You can expect meaningful work from Day 1 that creates real value for the company and our consumers. Information Technology (IT) at Procter & Gamble is where business, innovation and technology integrate to create a competitive advantage for P&G. Our mission is clear -- we deliver IT to help P&G win with the over 5 billion consumers we serve worldwide.

Key Responsibilities

Designs, develops and implements data and analytics cloud-based analytics platforms (DAP) and pipelines which acquire, cleanse, transform and publish data. Assemble large, complex data sets which meets functional and non-functional business requirements. Partners with data asset managers and architects to ensure technical solution provides data which is fit for use and in line with architecture blueprints. Leverages coding standards and best practices to ensure efficient and re-usable services and components.

Data Pipeline Development

Design, build, and maintain ETL/ELT processes to ingest, process, and integrate data from various sources into Azure data services.
Utilize Azure Data Factory, Azure Databricks, and Azure Synapse Analytics to orchestrate data workflows.

Big Data Management

Implement big data solutions using Azure Data Lake Storage, Azure HDInsight, and other big data technologies.
Optimize data storage and retrieval techniques to ensure high performance and scalability.

Data Modeling

Develop and maintain data models, schemas, and metadata to support analytical and reporting needs.
Collaborate with data architects and analysts to understand data requirements and implement solutions accordingly.

Data Quality And Governance

Establish data quality metrics and monitoring frameworks to ensure data accuracy and integrity.
Implement data governance practices to manage data access, security, and compliance.

Collaboration And Communication

Work closely with cross-functional teams including data scientists, analysts, and business stakeholders to understand data needs and deliver actionable insights.
Document data engineering processes, architecture designs, and best practices.

Performance Tuning

Monitor and optimize data processing workflows for performance and cost-efficiency.
Troubleshoot and resolve data-related issues in a timely manner.

Technology Evaluation

Stay updated on emerging technologies and trends in data engineering, big data, and cloud computing.
Evaluate and recommend new tools and technologies that align with business needs.

Front End Development

Exposure to Front end BI Development
Experience with tools like Power BI, Java Script for BI/Web app Development

Tech Stack

Microsoft Azure Cloud Services w.r.to Data Engineers
Python (primary PySpark)
Object Oriented Programming.
Version Control (GitHub, DevOps)
Power BI & other Visualization Tools aligned with Microsoft Azure
Good Sense of writing DAX, Incremantal Data Processing, Semantic Models, Star Schemas, SKID's etc.

Qualifications

Job Qualifications

A minimum of a bachelor’s degree from an accredited university, any major
You can conduct business in English (written & verbal). French is an asset.
You have 0-3 years of experience after graduation from a post-secondary institution
You can start the role April 2025 from Toronto (domestic relocation benefits may apply)
Strong leadership skills
Demonstrated ability of critical thinking and problem solving
Strong written and verbal communication skills
Expertise in Azure Cloud and Big Data technologies to design, develop, and maintain scalable data pipelines and architectures. The ideal candidate will leverage Azure services and big data frameworks to transform raw data into meaningful insights, ensuring data quality, security, and accessibility.
Exposure to BI Development is an important aspect as this role requires 10 -15% of work with Tools like Power BI so to support the business requirements.

What’s In It For YOU?

Access to P&G’s flexible work arrangements including our hybrid work approach and Work-from-Home Allowance
Robust Total Rewards Program including flexible benefits, competitive compensation, pension plan after 1 year of service, stock options, vacation allotment, and mobile phone plan where applicable
A comprehensive Corporate and Functional onboarding to accelerate your training and development
Integration into our New Hire Network for connections with peers, support and mentorship
Access to employee wellness programs including Employee & Family Assistance Program, employee support system, and psychology benefits
Domestic Relocation Benefits (if more than 60km from the work location where applicable)

How To Apply

Apply on www.pgcareers.com with resume only and complete both your application AND assessments as soon as possible as we will be reviewing applications on a rolling basis. We encourage you to review the information here for details on what to expect and our hiring process.

Assessment Overview: If your skills match our requirements, you will be asked to complete an online assessment(s). Please review our Assessment Overview for more information on how to prepare. Assessment scores are valid for 12 months; to apply previous scores please click on the assessment link(s). If your score has expired, you will be prompted to re-write the assessments.

Additional Information

We are an equal opportunity employer and value diversity at our company. Underrepresented candidates including, but not limited to, People with disabilities, female, 2SLGBTQIA+ and/or Black, Indigenous, Asian, Latin, or two or more races are strongly encouraged to apply.

P&G is committed to accommodating any applicant with a disability, as required by law, during the recruitment, assessment, and selection process. If you require a disability related accommodation in order to participate in the recruitment process, please click here to submit your request.

If you require an accommodation for the assessment process: 1) submit your request, 2) complete the Peak Performance Assessment (not timed), 3) do not complete the Interactive Assessment until you have been contacted by Canada Talent Acquisition for documentation verification. Thank you in advance for your patience.

Sponsorship for work authorization is not available for this role. It is the applicant’s responsibility to ensure they are authorized to work in the location to which they apply.

Ingénieur de données

Souhaitez-vous développer vos compétences en tant que la prochaine génération de leaders dans le monde de la technologie au sein de l'un des 100 meilleurs employeurs du Canada (2025) ?

Nous recrutons actuellement un ingénieur de données à temps plein à partir d'avril 2025 à notre siège social de Toronto pour aider à créer des outils et des processus permettant de rassembler les données afin de favoriser la prise de décisions et l'efficacité de l'entreprise. Si vous souhaitez rejoindre une équipe de professionnels motivés par les technologies de pointe, servir de catalyseur du changement, et identifier et aligner des solutions pour aider à soutenir les opportunités commerciales, alors une carrière chez P&G est faite pour vous.

Ce que vous pouvez attendre?

Dès le premier jour, vous pouvez vous attendre à un travail intéressant qui crée une valeur réelle pour l'entreprise et nos consommateurs. Chez Procter & Gamble, les technologies de l'information (TI) sont le lieu où l'entreprise, l'innovation et la technologie s'intègrent pour créer un avantage concurrentiel pour P&G. Notre mission est claire : nous fournissons des technologies de l'information pour aider P&G à gagner auprès des plus de 5 milliards de consommateurs que nous servons dans le monde entier.

Principales Responsabilités

Concevoir, développer et mettre en œuvre des plateformes analytiques basées sur le cloud (DAP) et des pipelines qui acquièrent, nettoient, transforment et publient des données. Assembler des ensembles de données complexes et de grande taille qui répondent aux exigences fonctionnelles et non fonctionnelles de l'entreprise. Il collabore avec les gestionnaires de données et les architectes pour veiller à ce que la solution technique fournisse des données adaptées à l'utilisation et conformes aux plans d'architecture. Utiliser les normes de codage et les meilleures pratiques pour garantir l'efficacité et la réutilisation des services et des composants.

Développement D'un Pipeline De Données

Concevoir, construire et maintenir des processus ETL/ELT pour ingérer, traiter et intégrer des données provenant de diverses sources dans les services de données Azure.
Utiliser Azure Data Factory, Azure Databricks et Azure Synapse Analytics pour orchestrer les flux de données.

Gestion Des Big Data

Mettre en œuvre des solutions big data en utilisant Azure Data Lake Storage, Azure HDInsight et d'autres technologies big data.
Optimiser les techniques de stockage et d'extraction des données pour garantir des performances et une évolutivité élevées.

Modélisation Des Données

Développer et maintenir des modèles de données, des schémas et des métadonnées pour prendre en charge les besoins d'analyse et de reporting.
Collaborer avec les architectes de données et les analystes pour comprendre les exigences en matière de données et mettre en œuvre des solutions en conséquence.

Qualité Des Données Et Gouvernance

Établir des mesures de la qualité des données et des cadres de contrôle pour garantir l'exactitude et l'intégrité des données.
Mettre en œuvre des pratiques de gouvernance des données pour gérer l'accès aux données, la sécurité et la conformité.

Collaboration Et Communication

Travailler en étroite collaboration avec des équipes interfonctionnelles, notamment des scientifiques des données, des analystes et des parties prenantes de l'entreprise, afin de comprendre les besoins en matière de données et de fournir des informations exploitables.
Documenter les processus d'ingénierie des données, les conceptions d'architecture et les meilleures pratiques.

Optimisation Des Performances

Contrôler et optimiser les flux de traitement des données en termes de performance et de rentabilité.
Dépanner et résoudre les problèmes liés aux données en temps opportun.

Évaluation Des Technologies

Se tenir au courant des technologies émergentes et des tendances en matière d'ingénierie des données, de big data et de cloud computing.
Évaluer et recommander de nouveaux outils et technologies qui s'alignent sur les besoins de l'entreprise.

Développement frontal

Exposition au développement BI frontal
Expérience d'outils tels que Power BI, Java Script pour le développement d'applications BI/Web.

Pile Technologique

Microsoft Azure Cloud Services avec les ingénieurs de données
Python (principalement PySpark)
Programmation orientée objet.
Contrôle de version (GitHub, DevOps)
Power BI et autres outils de visualisation alignés sur Microsoft Azure
Bonne connaissance de l'écriture DAX, du traitement des données incrémentielles, des modèles sémantiques, des schémas en étoile, des SKID, etc.

Qualifications

Au moins une licence d'une université accréditée, toutes disciplines confondues.
Vous pouvez travailler en anglais (écrit et oral). Le français est un atout.
Vous avez 0 à 3 ans d'expérience après l'obtention d'un diplôme d'un établissement postsecondaire
Vous pouvez commencer ce poste en avril 2025 à partir de Toronto (des avantages en matière de réinstallation nationale peuvent s'appliquer).
Solides compétences en matière de leadership
Aptitude avérée à la pensée critique et à la résolution de problèmes
Excellente communication écrite et orale
Expertise dans les technologies Azure Cloud et Big Data pour concevoir, développer et maintenir des architectures et des pipelines de données évolutifs. Le candidat idéal s'appuiera sur les services Azure et les frameworks Big Data pour transformer les données brutes en informations pertinentes, en garantissant la qualité, la sécurité et l'accessibilité des données.
L'exposition au développement BI est un aspect important car ce poste nécessite 10 à 15 % de travail avec des outils tels que Power BI afin de soutenir les exigences de l'entreprise.

Qu’y a-t-il pour VOUS?

Accès aux modalités de travail flexibles de P&G, y compris notre approche de travail hybride et l'allocation de travail à domicile.
Un solide programme de rémunération totale comprenant des avantages flexibles, une rémunération compétitive, un régime de retraite après un an de service, des options d'achat d'actions, des vacances et un plan de téléphonie mobile le cas échéant.
Une intégration complète au sein de l'entreprise et au niveau fonctionnel afin d'accélérer votre formation et votre développement
Intégration dans notre réseau de nouveaux embauchés pour établir des liens avec des pairs, bénéficier d'un soutien et d'un mentorat
Accès aux programmes de bien-être des employés, y compris le programme d'aide aux employés et à la famille, le système d'aide aux employés et les prestations psychologiques.
Indemnités de déménagement (à plus de 60 km du lieu de travail, le cas échéant)

Comment s'inscrire

Postulez sur www.pgcareers.com avec votre CV uniquement et complétez votre candidature ET vos évaluations le plus tôt possible, car nous examinons les candidats sur une base continue. Nous vous encourageons de consulter l’information suivant pour plus de détails sur ce à quoi vous attendre et sur notre processus d'embauche.

Aperçu de l'évaluation : si vos compétences correspondent à nos exigences, il vous sera demandé de remplir une ou plusieurs évaluations en ligne. Veuillez consulter Évaluations en ligne sur la façon de vous préparer. Les scores d'évaluation sont valables 12 mois ; pour appliquer les scores précédents, veuillez cliquer sur le(s) lien(s) d'évaluation. Si votre score a expiré, vous serez invité à reprendre les évaluations.

Informations Complémentaires

Nous sommes un employeur garantissant l'égalité des chances et valorisons la diversité dans notre entreprise. Les candidats sous-représentés, y compris, mais sans s'y limiter, les personnes handicapées, les femmes, les 2SLGBTQIA+ et/ou les Noirs, les Autochtones, les Asiatiques, les Latins ou les candidats d’origines mixed sont fortement encouragés à postuler.

P&G s'engage à prendre des mesures d'adaptation pour tout candidat handicapé, conformément à la loi, au cours du processus de recrutement, d'évaluation et de sélection.

Si vous avez besoin d'un aménagement lié à votre handicap pour participer au processus de recrutement, veuillez cliquer ici pour soumettre votre demande. Si vous avez besoin d'un aménagement pour le processus d'évaluation : 1) soumettez votre demande, 2) ne procédez à aucune évaluation tant que vous n'avez pas été contacté(e) pour la vérification des documents. Nous vous remercions par avance de votre patience.

Le parrainage pour l'obtention d'un permis de travail n'est pas disponible pour ce poste. Il incombe au candidat de s'assurer qu'il est autorisé à travailler dans le pays où il postule.

Job Schedule

Full time

Job Number

R000123701

Job Segmentation

Recent Grads/Entry Level (Job Segmentation)

Starting Pay / Salary Range","{""role_summary"":""Design, develop, and maintain data and analytics cloud-based analytics platforms, pipelines, and architectures to drive business decisions and efficiencies."",""key_terms"":[{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service that allows users to create, schedule, and manage data pipelines.""},{""term"":""Azure Databricks"",""explanation"":""A fast, easy, and collaborative Apache Spark-based analytics platform that provides a one-click setup, streamlined workflows, and an interactive workspace.""},{""term"":""Azure Synapse Analytics"",""explanation"":""A fully managed, cloud-native analytics service that integrates data warehousing, big data analytics, and data integration to provide a unified analytics platform.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""PySpark"",""explanation"":""A Python library for Apache Spark that allows users to write Spark applications using Python.""}],""skill_priorities"":{""must_have"":[""Azure Cloud and Big Data technologies"",""Python (primary PySpark)"",""Object-Oriented Programming"",""Version Control (GitHub, DevOps)"",""Power BI and other visualization tools aligned with Microsoft Azure""],""nice_to_have"":[""Front-end BI development experience"",""Knowledge of DAX, incremental data processing, semantic models, star schemas, SKID's, etc.""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a data pipeline to ingest, process, and integrate data from various sources into Azure data services?"",""example_answer"":""I would use Azure Data Factory to create a data pipeline that ingests data from various sources, processes it using Azure Databricks, and integrates it into Azure Synapse Analytics for analysis and reporting.""},{""question"":""How do you ensure data quality and governance in a big data environment?"",""example_answer"":""I would establish data quality metrics and monitoring frameworks to ensure data accuracy and integrity, and implement data governance practices to manage data access, security, and compliance.""}],""red_flags"":[""Lack of experience with Azure Cloud and Big Data technologies"",""Inability to write efficient and scalable data pipelines"",""Poor understanding of data governance and security best practices""],""confidence_score"":90.0}"
Data Engineer (Finance),"About KOHO

KOHO’s purpose is to empower Canadians to build a great financial foundation with products that are radically transparent and easy to manage. We first launched in 2017, and we have since built a community of over 1.5 million users. Leading investors around the globe believe in our vision, and we’ve successfully raised over $320M to make our vision a reality.

Discover our culture here and get the inside scoop from our team here!

Ready to Shape the Future of FinTech? 🚀

We’re seeking a Senior Analytics Engineer to help lead the future of financial analytics at KOHO. This is your opportunity to make a significant impact at the intersection of finance, technology, and analytics!

As a key player in our high-performing analytics engineering team, you’ll act as the direct intermediate between the data and finance teams to collect requirements, prioritize requests, build data products, communicate insights, and influence decisions. You'll have the unique opportunity to influence strategic decisions across the entire organization while working specifically with our finance domain. Your work will directly impact how KOHO operates, grows, and innovates in the FinTech space.

Impact & Influence 💫

Inform data-driven decision-making across multiple business units
Shape the future of financial analytics at a rapidly growing FinTech leader
Be the bridge between technical excellence and business success
Influence company strategy through powerful data insights

Your Mission 🎯

You'll revolutionize how KOHO leverages data to make strategic decisions. You'll be the driving force behind:

Building strong relationships with stakeholders (the finance team), scope and prioritize their analytics requests.
Understanding business needs and translating them to requirements.
Using dbt (Core for development and Cloud for orchestration) to transform, test, deploy, and document financial data while applying software engineering best practices.
Troubleshooting variances in reports, and striving to eliminate them at the source.
Building game-changing data products that empower the finance team
Architecting solutions that transform complex financial data into actionable insights
Monitoring, optimizing and troubleshooting warehouse performance (AWS Redshift).
Creating scalable, self-service analytics solutions that democratize data access
Occasionally building dashboards and reports in Sigma and Drivetrain.
Defining processes, building tools, and offering training to empower all data users in the organization.

Technical Excellence You'll Bring 💡

5+ years of mastery in data manipulation and analytics architecture
Advanced expertise in dbt (incremental modeling, materializations, snapshots, variables, macros, jinja)
Strong knowledge of SQL and how to write efficient SQL queries
Strong command of SQL, query optimization, and data warehouse design
Finance/accounting background is a plus!

What Sets You Apart 🌟

You're a natural problem-solver who thrives in complex environments
You have exceptional communication skills and can translate technical concepts for any audience
You're passionate about automation and continuous improvement
You have a track record of building strong stakeholder relationships

The KOHO Analytics Engineering Vision 🔮

We're Building The Future Of Data Accessibility And Reliability. Our Mission Is To Deliver a Unified Source Of Truth That Empowers Every Team Member To Make Data-driven Decisions. We Value

Enablement over control
Scalability over quick fixes
Agility over perfection

Ready to Transform Financial Analytics?

Join us in revolutionizing how financial data drives business success. Your expertise will directly impact millions of users while working with cutting-edge technologies in a dynamic, fast-paced environment.

What's In It For You?

We Invest Time And Resources Into Making Sure KOHO Is As Good As The People We Hire. Here Are Some Of The Reasons We Attract The Best People

🧘‍♂️ Balance Your Life - Company-wide summer wellness days, winter holiday closure, personal days, a wellness spending account, and maternity & parental leave top-up

💻 Remote First - Work from anywhere in Canada with a budget to set up your home office

🆙 Level Up - Access to an in-house certified performance coach and an annual training budget

🙌 The KOHO Culture - We have won 7 ""Great Place to Work ®"" awards since 2019

🤝 Be an Owner - Every KOHO employee gets a generous amount of equity with a 10 year exercise window

The KOHO culture is one of collaboration, creativity, and diverse perspectives. We are committed to building and fostering an inclusive, accessible environment for everyone. If you have any questions, concerns, or requests regarding accessibility needs, please contact peopleaccessibility@koho.ca and the People and Culture team will be happy to help.","{""role_summary"":""Lead the future of financial analytics at KOHO as a Senior Analytics Engineer, bridging the gap between data and finance teams to drive strategic decisions and business growth."",""key_terms"":[{""term"":""dbt"",""explanation"":""A data transformation tool used for building, testing, deploying, and documenting financial data.""},{""term"":""AWS Redshift"",""explanation"":""A cloud-based data warehousing and analytics platform used for monitoring, optimizing, and troubleshooting warehouse performance.""},{""term"":""Sigma and Drivetrain"",""explanation"":""Data visualization tools used for building dashboards and reports.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in data manipulation and analytics architecture"",""Advanced expertise in dbt"",""Strong knowledge of SQL and query optimization"",""Strong command of SQL, query optimization, and data warehouse design""],""nice_to_have"":[""Finance/accounting background""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach building strong relationships with stakeholders in a high-performing analytics engineering team?"",""example_answer"":""I prioritize open communication, active listening, and empathy to understand stakeholders' needs and requirements. I also ensure that I'm transparent about my work, providing regular updates and insights to stakeholders.""},{""question"":""Can you explain how you would troubleshoot variances in reports and eliminate them at the source?"",""example_answer"":""I would first identify the root cause of the variance by analyzing the data and the reporting process. Then, I would work with the stakeholders to understand their requirements and expectations. Finally, I would implement a solution that addresses the variance, and document the process to prevent similar issues in the future.""}],""red_flags"":[""Lack of experience with dbt or similar data transformation tools"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
"Data Analyst, Mapping","At Lyft, our purpose is to serve and connect. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

As a Data Analyst on the Mapping team, you will collaborate with our world class team of engineers, product managers, and designers to grow and improve the quality of recommended routes and accuracy of our travel time estimations. We're looking for a passionate, driven Data Analyst who is excited to dive into our spatial data and build a best-in-class mapping product that provides safe, efficient, and seamless navigation for our rideshare drivers.

Our team is heavily cross-functional, and our work often involves collaboration between Product, Engineering, Operations and Data Science. You will leverage data and rigorous, analytical thinking to shape our mapping products and make business decisions that put our customers first. This will involve identifying and scoping opportunities, shaping priorities, and measuring the impact of new features. You will help us solve some of the most impactful problems in mapping, including:

What defines a high quality route?
How do we improve the quality of our map data in order to improve our recommendations?
Are we meeting our travel estimation promises to our customers?
How do we benchmark and measure the success of our services?

As a key team member on the Mapping Science team, you’ll own various work streams, analyses, modeling, strategy, and business metrics that drive the growth of the Lyft ecosystem at scale. You’ll be a leader working cross-functionally by synthesizing input and perspectives from various key stakeholders. We are looking for analytical talent to provide insights and actionable recommendations that will drive impact and produce quality business and product decisions for our users.

Responsibilities

Leverage data and analytic frameworks to identify opportunities for growth and efficiency
Establish metrics that measure the health of our products, as well as rider and driver experience
Build dashboards and models to provide teams with actionable insights
Monitor product and service health to drive decision-making and prioritization
Utilize data and analyses to influence business strategy and product roadmaps
Regularly partner with Product, Engineering, Operations, Marketing, and Data Science
Present findings, recommendations, and results to senior leadership and cross-functional stakeholders

Experiences

2+ years experience in management consulting, operations, strategic data science/analytics roles in a technology company, or an equivalent analytical role in a high growth startup
Degree in a quantitative field such as statistics, economics, applied math, operations research or engineering (advanced degrees also an asset)
Proficiency in SQL - ability to independently break down large datasets and synthesize inputs from multiple sources
Experience in programming, especially with data science and analytics libraries in Python or R
Ability to craft a compelling story and concisely present recommendations across teams and levels including both technical and non-technical audiences
Ability to use data visualization tools to provide actionable insights and reusable frameworks
Strong product and user experience sense
Proven ability to influence, negotiate, and inspire others in a fast-moving environment
Excellent organization, planning skills, and attention to detail
Balance between intellectual curiosity and the desire to roll up your sleeves and execute
Experience working with ETL pipelines a plus
Experience in online experimentation a plus

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Child care and pet benefits
Access to a Lyft funded Health Care Savings Account
RRSP plan to help save for your future
In addition to provincial observed holidays, salaried team members are covered under Lyft's flexible paid time off policy. The policy allows team members to take off as much time as they need (with manager approval). Hourly team members get 15 days paid time off, with an additional day for each year of service
Lyft is proud to support new parents with 18 weeks of paid time off, designed as a top-up plan to complement provincial programs. Biological, adoptive, and foster parents are all eligible.
Subsidized commuter benefits

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Wednesdays, and Thursdays. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid

The expected base pay range for this position in the Toronto area is CAD $70,000 - CAD $87,500. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.","{""role_summary"":""Collaborate with cross-functional teams to improve the quality of recommended routes and accuracy of travel time estimations as a Data Analyst on the Mapping team at Lyft."",""key_terms"":[{""term"":""Spatial data"",""explanation"":""Data related to geographic locations and their relationships, used to improve mapping products.""},{""term"":""ETL pipelines"",""explanation"":""Extract, Transform, Load pipelines used to manage data flow and processing.""},{""term"":""Online experimentation"",""explanation"":""Testing and analysis of online products or services to measure their effectiveness.""}],""skill_priorities"":{""must_have"":[""2+ years experience in management consulting, operations, strategic data science/analytics roles"",""Degree in a quantitative field"",""Proficiency in SQL"",""Experience in programming (Python or R)"",""Ability to craft a compelling story and concisely present recommendations""],""nice_to_have"":[""Experience working with ETL pipelines"",""Experience in online experimentation""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach improving the quality of our map data to enhance route recommendations?"",""example_answer"":""I would analyze the current data sources, identify gaps, and propose a plan to integrate new data sources or improve data processing. I would also collaborate with the engineering team to implement changes and measure the impact on route quality.""},{""question"":""Can you walk me through your process for building dashboards to provide actionable insights?"",""example_answer"":""I would start by understanding the business problem and identifying key metrics. Then, I would design a dashboard that effectively communicates insights, using data visualization tools to make the data actionable. Finally, I would iterate on the dashboard based on stakeholder feedback.""}],""red_flags"":[""Lack of experience working with spatial data"",""Inability to effectively communicate technical insights to non-technical stakeholders""],""confidence_score"":90.0}"
Data Developer,"Job Offer: Data Developer
Location: Toronto
Contract Duration: 7 months
Work Mode: Hybrid
Start Date: March 10th

Why Join Us?

Astek is a global leader in technology consulting. With 9,600 experts worldwide, we guide our clients through digital transformation by developing innovative solutions.

In Canada, we excel in IT and engineering. We collaborate with leading companies to tackle major technological challenges, putting innovation, collaboration, and excellence at the heart of our actions.

Join a passionate and committed team ready to bring your ideas to life.

About the Role

On behalf of our client in the Banking industry, Astek Canada is seeking a motivated Data Developer ready to take on new challenges.

Your Responsibilities

As a Data Developer , you will be responsible for:
Support existing production tools used in operations and delivery, while working with business partners and our delivery teams on the creation of new process improvement tools.
Support the ideation, development, deployment and governance of new tools, processes and workflows that support our production teams.
Adopt Agile methodologies, enabling us to rapidly and efficiently deploy new tools that exceed our business partners' expectations.

Your Qualifications

Education/Experience:
Computer Science Degree.
2 - 4 Years' experience.

Key Skills:
Experience working as a Developer with Html/CSS and JavaScript coding with the ability to code with good quality (Need to be able to Code/update code/code from scratch).
Advanced knowledge of Visual Basic, MS Access, and MS Excel.
Knowledgeable in using built-in browser dev tools to understand web site API methods.
Advanced knowledge of SQL and experience working with SQL Databases.
Strong communication and stakeholder management skills are an asset.
Experience working in an Agile operating model using JIRA/Confluence would be beneficial.

Personal Qualities:
Analytical and solution-oriented mindset.
Team collaboration and teamwork skills.
Autonomy and rigor in managing priorities.

The Astek Advantages
Personalized CARE plan for our employees.
Diversity & Inclusion Charter.

Ready to Take on the Challenge?
Apply now by sending your CV and discover a rewarding career at Astek Canada.","{""role_summary"":""Support and develop production tools, collaborate with business partners, and adopt Agile methodologies to improve processes and workflows."",""key_terms"":[{""term"":""Agile methodologies"",""explanation"":""An iterative approach to project management that emphasizes flexibility, collaboration, and rapid delivery.""},{""term"":""Html/CSS"",""explanation"":""Programming languages used for building web applications, Html for structure and CSS for styling.""},{""term"":""Visual Basic"",""explanation"":""A programming language used for developing applications, especially those that interact with Microsoft products.""},{""term"":""MS Access"",""explanation"":""A database management system used for creating and managing databases.""},{""term"":""JIRA/Confluence"",""explanation"":""Tools used for project management, issue tracking, and collaboration.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational databases.""}],""skill_priorities"":{""must_have"":[""Html/CSS"",""JavaScript"",""Visual Basic"",""MS Access"",""MS Excel"",""SQL""],""nice_to_have"":[""Experience working in an Agile operating model using JIRA/Confluence""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach improving the performance of a slow database query?"",""example_answer"":""I would use SQL optimization techniques such as indexing, caching, and query rewriting to improve the performance. I would also analyze the database schema and identify opportunities for normalization and denormalization.""},{""question"":""How do you stay organized and manage priorities in a fast-paced Agile environment?"",""example_answer"":""I use tools like JIRA and Confluence to track tasks and prioritize my work. I also communicate regularly with my team and stakeholders to ensure everyone is aligned on priorities and deadlines.""}],""red_flags"":[""Lack of experience with Agile methodologies"",""Inability to write clean, efficient code""],""confidence_score"":85.0}"
Intern - Data Engineer,"(Leamington, ON)

Summer 2025 Internship

On-Site: 5 days/week

Full-time. Paid Internship

Duration: June - August 2025

About Tilray Brands, Inc.

Tilray Brands, Inc. (“Tilray”) (Nasdaq: TLRY; TSX: TLRY), is a leading global lifestyle and consumer packaged goods company with operations in Canada, the United States, Europe, Australia, and Latin America that is leading as a transformative force at the nexus of cannabis, beverage, wellness, and entertainment, elevating lives through moments of connection. Tilray’s mission is to be a leading premium lifestyle company with a house of brands and innovative products that inspire joy, wellness and create memorable experiences. Tilray’s unprecedented platform supports over 40 brands in over 20 countries, including comprehensive cannabis offerings, hemp-based foods, and craft beverages.

Looking to develop your career at the forefront of a rapidly expanding industry?

JOB SUMMARY:

The Intern - Data Engineer is responsible for preparing and cleansing data for analytics and machine learning operations around the company, while maintaining standards for accuracy and scalability required for a global enterprise.

This is a great 3-month paid internship opportunity for third or fourth-year students, as well as new graduates looking for real-world experience. As a candidate for this role, you are passionate about learning new technologies and implementing systems that unlock data for various stakeholders across the business. You are a self-starter who enjoys collaborating within a communicative and enthusiastic technical team. You are also personable and able to engage non-technical stakeholders with exciting technical solutions.

Work Schedule: Monday - Friday / 8:30am - 5:00pm

ROLE AND RESPONSIBILITIES:

Assist in the deployment of ETL and ELT data pipelines in an Azure environment
Build and design Data Warehouse tables which fit stakeholder needs in a computationally efficient manner
Quickly troubleshoot and remediate errors due to source data changes
Engage with stakeholders to gather requirements, and translate their needs into concrete, technically sound solutions
Properly document and outline changes for an enterprise IT environment
Coding complex transformations using programming languages like Python
Maintaining and improving scripts and libraries used for data processing and delivery


QUALIFICATIONS AND EDUCATION REQUIREMENTS:

Ability to write and troubleshoot SQL queries
Moderate knowledge of Python, and some familiarity with the major data processing libraries like pandas, polars, and pyspark
Familiarity with software engineering techniques and practices such as unit testing, CI/CD pipelines, containerized environments, and version control
Knowledge of cloud environments like Azure and AWS an asset
Excellent problem-solving skills.
Ability to help solve problems and develop solutions while working with stakeholders around the business


Accommodations are available for applicants with disabilities throughout the recruitment process. If you require accommodations for interviews or other meetings, please advise when submitting your application.

Please note that Tilray does not authorize, engage, or sponsor any consultants, agencies or organizations that seek certain personal or financial information from you (e.g. passwords, login ids, credit card information). Tilray does not charge any application, processing or onboarding fee at any stage of the recruitment or hiring process.

When replying to emails, please ensure the sender name and email address match exactly. Please also ensure the Reply-To address matches the sending address exactly.

If you are concerned about the authenticity of an email, letter, or call purportedly from, for, or on behalf of Tilray, please send an email inquiry to infosec@tilray.com","{""role_summary"":""Assist in preparing and cleansing data for analytics and machine learning operations, maintaining standards for accuracy and scalability in a global enterprise."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""ELT"",""explanation"":""Extract, Load, Transform - a process of extracting data from multiple sources, loading it into a target system, and transforming it into a standardized format.""},{""term"":""Azure"",""explanation"":""A cloud computing platform and set of services offered by Microsoft that allows users to build, deploy, and manage applications and services.""},{""term"":""Data Warehouse"",""explanation"":""A central repository that stores data from various sources in a single location, making it easier to analyze and report on.""},{""term"":""pandas"",""explanation"":""A popular Python library used for data manipulation and analysis.""},{""term"":""pyspark"",""explanation"":""A Python library that provides high-level APIs in Python for using Apache Spark, a unified analytics engine for large-scale data processing.""},{""term"":""CI/CD pipelines"",""explanation"":""Continuous Integration and Continuous Deployment pipelines - a set of practices that automate the build, test, and deployment of software applications.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Data processing"",""Problem-solving skills""],""nice_to_have"":[""Azure"",""AWS"",""pandas"",""pyspark"",""CI/CD pipelines""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you troubleshoot and remediate errors due to source data changes in a data pipeline?"",""example_answer"":""I would first identify the source of the error, then use debugging tools to isolate the issue. Next, I would collaborate with stakeholders to understand the requirements and develop a solution that meets their needs.""},{""question"":""Can you explain how you would design a Data Warehouse table to fit stakeholder needs in a computationally efficient manner?"",""example_answer"":""I would start by understanding the stakeholder requirements and identifying the key performance indicators. Then, I would design a table structure that minimizes data redundancy and optimizes query performance.""}],""red_flags"":[""Lack of experience with data processing and delivery"",""Inability to troubleshoot and remediate errors in data pipelines""],""confidence_score"":90.0}"
AI Software Engineer Graduate,"About Us

TrustFlight is an innovative aviation software company that specializes in developing cutting-edge digital workflow and analytics applications for the aviation industry. Our software empowers airlines, airports, and aviation service providers to optimize their operations, enhance safety, and improve overall efficiency. As we continue to expand our global presence, we are looking for an AI Process Graduate to join our dynamic team and contribute to the growing AI efforts within the organization.

Why Choose TrustFlight?

Our Mission: To revolutionize aviation by delivering digital workflow solutions that enhance safety, streamline operations, and inspire confidence across the industry.
Impact: Over 200,000 users rely on our systems daily, making aviation safer and more efficient.
Core Values: Guided by integrity, responsibility, innovation, and excellence, we are committed to empowering our partners to operate with confidence.


Join us in shaping the future of aviation and making an impact through technology.✈️

Locations: Jersey | Leamington Spa | Luton | Vancouver

Role Overview

As an AI Software Engineer Graduate at TrustFlight you will play a pivotal role in transforming our internal processes and automations. Your work will involve implementing, developing, and optimizing AI solutions to augment our digital workflows, and collaborating closely across our Sales Ops and Finance teams to ensure seamless integration of AI technologies into our existing systems. We value each member's input and believe in harnessing the power of collective intelligence, with each team members contribution playing a crucial role in our success. Working with us means working at the forefront of technology. With AI being central to our innovation strategy, we're invested in staying ahead of the curve. Here, you won't be maintaining the status quo; you'll be pushing it forward. Your work will directly contribute to our AI-driven solutions, which are set to revolutionize the way the aviation industry operates. The scale of the impact we strive to make offers an unparalleled opportunity to apply your skills in a context that matters, making your work rewarding and purposeful. Come join us, and let's shape the future of aviation together.

Key Responsibilities:

Integrating AI to transform and scale our internal business processes
Implementing and contributing to the ongoing development of AI solutions.
Optimizing and maximizing AI tools to increase workflow efficiency.
Collaborate with cross-functional teams to embed AI-driven solutions across the organization.
Leveraging weekly advancements in AI to increase the scope of integration.


Qualifications:

Bachelor’s degree in Computer Science, Software Engineering, or a related field.
Proficiency in JavaScript/TypeScript and familiarity with Python.
Hands-on experience with OpenAI and Anthropic APIs, specifically GPT-4 and Claude 3.
Experience with GPT-4/Claude 3 function-calling and integration in large scale applications.
Track record of developing and deploying applications leveraging OpenAI/Anthropic APIs.
Experience working with embeddings, vector databases and similarity search.
Experience working with, fine-tuning and deploying the infrastructure to integrate open source LLMs.
Strong communication and interpersonal skills.
Ability to work independently and as part of a team.
Ability to work seamlessly across teams.
Familiarity with React and NextJS.
Experience with CRM or ERP systems is a bonus


Why Join Us:

Opportunity to shape the revenue processes within a leading SaaS company.
Hands-on experience with cutting-edge technology and automation.
Collaborative and innovative work environment.
Health & Wellness: Comprehensive benefits package including health and dental benefits. Generous vacation days, plus an extra day off to celebrate your birthday.
Invest in your future: Take advantage of our RRSP matching program to grow your savings while you work.
Professional Growth: As a fast-growing company, we offer incredible opportunities for career advancement and skill development.
We place huge importance on the contribution and experience you bring to the team. The salary will be based on the value you will bring to the role with a range spanning from $63000 to $65000 CAD per year. The actual base pay offered will be based on a wide range of factors, including skills, qualifications, relevant experience, and work location.


How To Apply

Send us your resume, including a cover letter. Let us know how you can contribute to creating best-in-class tools and services throughout the aviation industry.

While we sincerely appreciate all applications, only those candidates selected for an interview will be contacted.

TrustFlight is an equal-opportunity employer. We work together to create the most talented team that celebrates inclusivity, diversity and equality in a serious way. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. All candidates will receive consideration for this role without regard for race, nationality, colour, religion, gender, gender identity and expression, sexual orientation, disability, or age. Our inclusive culture empowers all of us to inspire, enlighten and thrive.","{""role_summary"":""Transform internal processes and automations by implementing, developing, and optimizing AI solutions to augment digital workflows, collaborating with cross-functional teams to ensure seamless integration."",""key_terms"":[{""term"":""AI Process Graduate"",""explanation"":""An entry-level role focused on developing and implementing AI solutions to improve internal processes and operations.""},{""term"":""Digital workflow solutions"",""explanation"":""Software applications that automate and streamline business processes, enhancing safety, efficiency, and overall performance.""},{""term"":""OpenAI and Anthropic APIs"",""explanation"":""Application Programming Interfaces (APIs) provided by OpenAI and Anthropic, used for developing and integrating AI-powered applications.""},{""term"":""GPT-4 and Claude 3"",""explanation"":""Specific AI models developed by OpenAI and Anthropic, used for natural language processing and generation tasks.""},{""term"":""Embeddings, vector databases, and similarity search"",""explanation"":""Techniques used in AI and machine learning for data representation, storage, and retrieval, enabling efficient search and analysis.""},{""term"":""Open source LLMs"",""explanation"":""Large Language Models (LLMs) that are open-sourced, allowing developers to access, modify, and integrate them into their applications.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in Computer Science, Software Engineering, or a related field"",""Proficiency in JavaScript/TypeScript"",""Familiarity with Python"",""Hands-on experience with OpenAI and Anthropic APIs"",""Experience with GPT-4/Claude 3 function-calling and integration"",""Strong communication and interpersonal skills""],""nice_to_have"":[""Experience with React and NextJS"",""Experience with CRM or ERP systems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would integrate AI solutions to transform internal business processes?"",""example_answer"":""I would start by identifying areas where AI can augment our workflows, then develop and implement AI models using OpenAI and Anthropic APIs, ensuring seamless integration with our existing systems.""},{""question"":""How do you stay updated with the latest advancements in AI and its applications?"",""example_answer"":""I regularly follow industry blogs, research papers, and attend conferences to stay informed about the latest developments in AI, and I'm excited to apply this knowledge to drive innovation at TrustFlight.""}],""red_flags"":[""Lack of experience with OpenAI and Anthropic APIs"",""Inability to work independently and as part of a team"",""Limited understanding of AI concepts and their applications""],""confidence_score"":90.0}"
Sr. Data Engineer - Data & AI Platform,"Rivian and Volkswagen Group Technologies is seeking a Data Engineer to join our Data & AI team. This role is pivotal in enabling our big data platform to operate seamlessly at a petabyte scale. The successful candidate will be an architect and custodian of scalable, high-volume vehicle data processing pipelines written in Pyspark and executed on our Databricks platform.
 PySpark Pipeline Development: Design, develop, deploy, and enhance petabyte-scale Spark structured streaming pipelines using Pyspark on Databricks. 
Databricks Platform Ownership: Understand the intricacies of the Databricks Platform, manage our Databricks deployment using Terraform infrastructure as code, and possess a firm grasp of data governance concepts. 
CI/CD & Infrastructure Management: Take ownership of the pipeline deployment lifecycle. Implement and manage robust CI/CD pipelines using Terraform to ensure smooth, automated, and reliable deployments.
Performance Optimization: Monitor pipeline performance, identify bottlenecks, and implement optimizations to ensure they operate at peak efficiency even as data volumes grow.
Troubleshooting & Issue Resolution: Proactively identify and resolve issues that may arise. The ability to diagnose problems quickly and implement effective solutions will be critical to maintaining system uptime.
Collaborative Development: Collaborate with data producers, data consumers, and data stewards to deliver dependable and scalable solutions.
Staying Ahead of the Curve: Keep abreast of the latest advancements in big data technologies, data engineering practices, and cloud computing. Explore new tools and techniques to improve our data infrastructure.
 Education: Bachelor's or Master's degree in Computer Science, Data Science, or a related field.
Experience: 5+ years of hands-on experience in data engineering or a similar role, with a proven track record of building and maintaining large-scale data processing systems.
Spark Expertise: Deep proficiency in the Apache Spark data engineering engine, with a strong understanding of best practices for building high-performance applications. Proficiency with structured streaming preferred. 
Big Data Technologies: Solid understanding of big data ecosystems such as Databricks. Experience with data warehousing and data lake concepts is a plus.
Problem-Solving Skills: Exceptional analytical and problem-solving skills, with the ability to break down complex problems into manageable components and develop effective solutions.
Communication & Collaboration: Excellent communication and interpersonal skills, with the ability to collaborate effectively with cross-functional teams
Delta Lake: Familiarity interacting with open source or Databricks proprietary Delta tables.","{""role_summary"":""Design, develop, and maintain large-scale data processing systems, ensuring seamless operation of petabyte-scale vehicle data processing pipelines."",""key_terms"":[{""term"":""Pyspark"",""explanation"":""A Python library for Apache Spark, used for building scalable data processing pipelines.""},{""term"":""Databricks"",""explanation"":""A cloud-based platform for working with big data, providing a managed Apache Spark environment.""},{""term"":""Terraform"",""explanation"":""An infrastructure as code tool, used for managing and deploying cloud infrastructure.""},{""term"":""Structured Streaming"",""explanation"":""A scalable and fault-tolerant stream processing engine built on Apache Spark, used for real-time data processing.""},{""term"":""Delta Lake"",""explanation"":""An open-source storage layer that provides ACID transactions, scalable metadata handling, and unifies streaming and batch data processing.""}],""skill_priorities"":{""must_have"":[""Pyspark"",""Databricks"",""Apache Spark"",""Data engineering"",""Problem-solving skills"",""Communication and collaboration skills""],""nice_to_have"":[""Terraform"",""Data warehousing"",""Data lake concepts"",""Delta Lake""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize the performance of a PySpark pipeline on Databricks?"",""example_answer"":""I would start by monitoring the pipeline's performance using Databricks' built-in metrics, then identify bottlenecks using Spark's UI. Next, I would implement optimizations such as caching, repartitioning, and broadcast joins to improve performance.""},{""question"":""Can you explain how you would manage a Databricks deployment using Terraform?"",""example_answer"":""I would use Terraform to define the infrastructure as code, creating a Databricks cluster and configuring the necessary resources. I would then use Terraform to manage the deployment lifecycle, ensuring smooth and reliable deployments.""}],""red_flags"":[""Lack of hands-on experience with PySpark and Databricks"",""Inability to communicate technical concepts effectively""],""confidence_score"":95.0}"
Data Engineer - Contract,"Our client is a leading data and cloud services provider that works with enterprise companies to build systems and infrastructures for them.

As a Data Engineer, you'd be responsible for designing, building, and optimizing data pipelines, ensuring seamless data flow and analytics capabilities.

This is a 6-month contract, with a possibility of extension.

Responsibilities:

Develop and maintain scalable data pipelines using Python and SQL.
Design and implement ETL processes for efficient data ingestion, transformation, and storage.
Work extensively with AWS SageMaker to develop, train, and deploy machine learning models.
Optimize data storage, retrieval, and performance in AWS Redshift.
Collaborate with data scientists, analysts, and software engineers to provide data solutions.
Ensure data integrity, quality, and governance across various platforms.
Automate data workflows and deployment processes.
Troubleshoot and resolve data issues efficiently.

Requirements:

3+ years of experience in data engineering.
Strong proficiency in Python and SQL.
Hands-on experience with AWS SageMaker (model training, deployment, and management).
Expertise in AWS Redshift (performance tuning, data modeling, and query optimization).
Experience working with ETL processes, data lakes, and data warehousing solutions.
Knowledge of cloud infrastructure (AWS Lambda, S3, Glue, Step Functions, etc.).
Familiarity with CI/CD pipelines and infrastructure as code (Terraform, CloudFormation) is a plus.
Strong problem-solving skills and the ability to work independently in a contract-based role.","{""role_summary"":""Design, build, and optimize data pipelines to ensure seamless data flow and analytics capabilities for enterprise companies."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from sources, transforming it into a usable format, and loading it into a target system.""},{""term"":""AWS SageMaker"",""explanation"":""A cloud-based platform for building, training, and deploying machine learning models.""},{""term"":""AWS Redshift"",""explanation"":""A data warehousing and analytics service that allows for efficient data storage, retrieval, and performance.""},{""term"":""CI/CD pipelines"",""explanation"":""Continuous Integration and Continuous Deployment pipelines - a process of automating code testing, building, and deployment.""},{""term"":""Infrastructure as Code"",""explanation"":""A practice of managing and provisioning cloud infrastructure using code and configuration files (e.g., Terraform, CloudFormation).""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""AWS SageMaker"",""AWS Redshift"",""ETL processes"",""Cloud infrastructure (AWS)""],""nice_to_have"":[""CI/CD pipelines"",""Infrastructure as Code (Terraform, CloudFormation)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data storage and retrieval in AWS Redshift?"",""example_answer"":""I use columnar storage, data compression, and distribution styles to optimize storage. For retrieval, I implement efficient query optimization techniques, such as using materialized views and caching.""},{""question"":""Can you explain how you would troubleshoot a data pipeline issue in AWS SageMaker?"",""example_answer"":""I would start by checking the pipeline logs for errors, then verify data input and output formats, and finally, test individual components of the pipeline to isolate the issue.""}],""red_flags"":[""Lack of hands-on experience with AWS SageMaker and AWS Redshift"",""Inability to work independently in a contract-based role""],""confidence_score"":90.0}"
Data engineer,"Functie­omschrijving

Wil jij ons helpen bij de verdere doorontwikkeling van ons eigen datawarehouse bij ODC Noord? En wil jij werken in een gedreven, gezellig en warm team? Lees dan snel verder en reageer!

De ontwikkeling van een datawarehouse is een teamsport. Als data engineer werk je samen met data-analisten, data scientists en businessanalisten aan het standaardiseren en optimaliseren van data exchange processen. Dit doe je binnen (een nog in ontwikkeling zijnde) analyse omgeving. Je realiseert data pipelines, gebruik makend van DBT (Data Build Tool) binnen onze PostgreSQL omgeving, waarbij je ook data transformeert en code structureert in repositories (GitLab). We werken veel met open source software, daarom zien we graag dat je niet bang bent om met de command line aan de slag te gaan.

Bij transformaties maak je verder gebruik van PostgreSQL (via DBT) en Python. Je zorgt dat data beschikbaar komen via de centrale databases of via API’s. Veel voorkomende transformaties en scripts beheer je gestructureerd. Je monitort periodieke scripts en zorgt dat deze up to date blijven zodat de benodigde data continu en stabiel beschikbaar is voor producten, analyses en dashboards.

Als data engineer binnen de afdeling Beleidsinformatie houd jij je daarnaast bezig met het functioneel ontwerp van ons eigen datawarehouse. Je kunt op conceptueel niveau denken en ontwerpen en bent in staat om de performance van onze databases te optimaliseren. Daarnaast weet je hoe je SQL query’s kan maken en beoordelen.

Functie-eisen

Wij bieden een dynamische, uitdagende werkomgeving waarin ruimte is voor vernieuwing, innovatie en verdere professionele ontwikkeling!

We zijn op zoek naar een ervaren data engineer (datawarehouse ontwikkelaar). Je hebt:

Afgeronde HBO of WO-studie in een relevante richting.
Aantoonbaar relevante werkervaring als data(-base) engineer, datawarehouse ontwikkelaar of vergelijkbare functie.
Kennis van databasetechnologieën, waarbij ervaring met PostgreSQL een pré is.
Vaardigheid in Python (bij voorkeur met relevante Python libraries zoals Pandas/Polars).
Een groot analytisch vermogen.
Een proactieve en positieve instelling.
Ervaring met Git en goede version-control gewoonten.
Goede beheersing van de Nederlandse taal.
Affiniteit of ervaring in het werken in een beleidsomgeving.
Verder zijn kennis van dataformaten (JSON, CSV, Parquet), data storage (S3) en FTP; als ook affiniteit met Netwerk & Systeem beheer en ervaring met DBT (data build tool) en Apache Airflow een pré.

Arbeids­voorwaarden

Salaris­niveau

schaal 11



Maand­salaris: Min €4024 - Max €6110","{""role_summary"":""As a data engineer, you will contribute to the development of our data warehouse, working closely with data analysts, scientists, and business analysts to standardize and optimize data exchange processes."",""key_terms"":[{""term"":""Datawarehouse"",""explanation"":""A central repository that stores data from various sources in a single location, making it easily accessible for analysis and reporting.""},{""term"":""DBT (Data Build Tool)"",""explanation"":""An open-source tool used to transform and structure data in a data warehouse, making it easier to manage and analyze.""},{""term"":""PostgreSQL"",""explanation"":""A popular open-source relational database management system used to store and manage data.""},{""term"":""Python"",""explanation"":""A high-level programming language used for data analysis, machine learning, and automation.""},{""term"":""GitLab"",""explanation"":""A web-based platform used for version control and collaboration on software development projects.""}],""skill_priorities"":{""must_have"":[""Experience as a data engineer or datawarehouse developer"",""Knowledge of database technologies, including PostgreSQL"",""Python skills, preferably with relevant libraries like Pandas/Polars"",""Analytical skills"",""Proactive and positive attitude"",""Experience with Git and good version control habits"",""Good command of the Dutch language""],""nice_to_have"":[""Knowledge of data formats (JSON, CSV, Parquet)"",""Experience with data storage (S3) and FTP"",""Affinity or experience with Network & System administration"",""Experience with DBT (Data Build Tool) and Apache Airflow""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize the performance of our PostgreSQL database?"",""example_answer"":""I would analyze the database schema, identify bottlenecks, and implement indexing and caching to improve query performance. Additionally, I would consider partitioning and parallel processing to further optimize the database.""},{""question"":""How do you ensure data quality and integrity in your data pipelines?"",""example_answer"":""I use a combination of data validation, data normalization, and data transformation to ensure data quality and integrity. I also implement data testing and monitoring to detect any issues and ensure data consistency.""}],""red_flags"":[""Lack of experience with PostgreSQL or similar database technologies"",""Inability to work with command-line interfaces"",""Limited analytical skills or problem-solving abilities""],""confidence_score"":90.0}"
"Sr. Data Engineer, Analytics (Remote)","About Us

Luxury Presence is the leading digital platform revolutionizing the real estate industry for agents, teams, and brokerages. Our award-winning websites, cutting-edge marketing solutions, and AI-powered mobile platform empower real estate professionals to grow their business, operate more efficiently, and deliver exceptional service to their clients. Trusted by over 60,000 real estate professionals, including 31 of the nation’s 100 top-performing agents as published in the Wall Street Journal, Luxury Presence continues to set the standard for innovation and excellence in real estate technology.

Why Now?

We’ve enjoyed tremendous growth over the last 5 years. With that growth comes a treasure trove of data that is valuable to us, and our customers. We need experienced and passionate data professionals to help us realize that value and unlock the insights that exist at the intersection of our operational, financial, and product data. This is a unique opportunity to join a fast growing startup and build our data team, culture, and processes from the ground up.

What You’ll Do

Design, develop, and maintain scalable data pipelines and ELT processes for our data lake/data warehouse
Implement data orchestration tools to automate and streamline data workflows.
Work with our AI Solutions team to implement AI enhanced processes throughout the organization
Build and integrate machine learning models and data pipelines into end-to-end analytics solutions
Build and manage reverse ETL workflows to business systems such as the CRM
Support development of predictive models to support strategic and operational initiatives
Develop and maintain comprehensive documentation for data processes and systems.
Build production-ready data models and schemas using DBT to support downstream analytics
Collaborate with cross-functional teams to define and implement data governance policies and best practices.
Manage our modern analytics tech stack to support the democratization of data and analytics through dashboards, reports, and predictive models
Support analysts in developing dashboards, data products, and ad hoc report studies to analyze and present data associated with GTM analytics, product performance, business operations, and strategic decision-making

Must Haves

Proficiency in SQL
Proficiency in any statistical programming language (i.e, Python or R)
Hands-on experience building and managing ETL and rETL workflows
Strong understanding of data engineering principles, including ETL/ELT processes, data modeling, and data warehousing
Experience with workflow orchestration tools, such as Airflow
Experience with ETL/ELT tools, such as Fivetran
Experience with cloud data warehouse and transformation tools (e.g.,, snowflake, DBT etc)

Nice to Haves

Experience working with AI workflow orchestration tools such as AirOps or Vectorshift
Experience working with entitlements and connecting the CRM to the Platform to gatekeep product features
Experience setting up large scale integrations to pull data from various Google products
Experience working with BI tools (Tableau, SiSense, Sigma, or Looker etc)
Ability to communicate technical concepts to both technical and non-technical audiences through visualizations and presentations
Ability to partner with leadership and stakeholders across the company to understand business needs and how these can be addressed through analytics
Experience in a B2B or SaaS environment, supporting functions such as sales, marketing, product development, and/or customer success.

Join us in shaping the future of real estate

The real estate industry is in the midst of a seismic shift, and the future belongs to those who break new ground. As one of the fastest-growing companies in the proptech and marketing sectors, Luxury Presence challenges the status quo of what technology can do for real estate agents, leaders, and brokerages.

We’re a team of agile and tenacious innovators working collaboratively to drive the industry forward. Together, we build game-changing products that empower modern real estate entrepreneurs to dominate their markets. From award-winning web design to agile SEO solutions to cutting-edge AI tools, we deliver tech that anticipates market shifts and keeps our clients ahead of their competition.

Founded in 2016 by Stanford Business School alum Malte Kramer, Luxury Presence has grown to a global team ranked on the Inc. 5000 fastest-growing companies list three years in a row. We’re backed by world-class investors, including Bessemer Venture Partners, Toba Capital, and Switch Ventures, and have raised $52.6 million to date.

More than 13,000 real estate businesses rely on our platform, including 31 of the RealTrends top 100 agents featured in The Wall Street Journal. Additionally, many of the industry’s most powerful brokerages — including Compass, Coldwell Banker, and Sotheby’s International Realty — rely on Luxury Presence as a trusted business partner.

Every year since 2020, Luxury Presence has ranked on BuiltIn’s Best Place to Work lists. HousingWire named our founder and CEO a 2024 Tech Trendsetter, we’ve received several Tech100 Awards, and our lead nurturing tool just scored an Inman Innovation Award for Best AI-Powered Platform.

Luxury Presence is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin.","{""role_summary"":""Design, develop, and maintain scalable data pipelines and ELT processes for a data lake/data warehouse, implement data orchestration tools, and build machine learning models to support business initiatives."",""key_terms"":[{""term"":""ELT processes"",""explanation"":""Extract, Load, and Transform processes that move data from a source to a target system, such as a data warehouse.""},{""term"":""Data orchestration tools"",""explanation"":""Tools that automate and streamline data workflows, such as Airflow.""},{""term"":""Reverse ETL workflows"",""explanation"":""Workflows that move data from a target system, such as a data warehouse, back to a source system, such as a CRM.""},{""term"":""DBT"",""explanation"":""A tool used to build production-ready data models and schemas to support downstream analytics.""}],""skill_priorities"":{""must_have"":[""Proficiency in SQL"",""Proficiency in a statistical programming language (e.g., Python or R)"",""Hands-on experience building and managing ETL and rETL workflows"",""Strong understanding of data engineering principles"",""Experience with workflow orchestration tools (e.g., Airflow)"",""Experience with ETL/ELT tools (e.g., Fivetran)"",""Experience with cloud data warehouse and transformation tools (e.g., Snowflake, DBT)""],""nice_to_have"":[""Experience working with AI workflow orchestration tools (e.g., AirOps or Vectorshift)"",""Experience working with entitlements and connecting the CRM to the Platform"",""Experience setting up large scale integrations to pull data from various Google products"",""Experience working with BI tools (e.g., Tableau, SiSense, Sigma, or Looker)"",""Ability to communicate technical concepts to both technical and non-technical audiences"",""Ability to partner with leadership and stakeholders across the company"",""Experience in a B2B or SaaS environment""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the difference between ETL and ELT processes?"",""example_answer"":""ETL (Extract, Transform, Load) processes transform data before loading it into a target system, whereas ELT (Extract, Load, Transform) processes load data into a target system and then transform it.""},{""question"":""How would you optimize data pipelines for scalability?"",""example_answer"":""I would use distributed computing, parallel processing, and caching to optimize data pipelines for scalability.""}],""red_flags"":[""Lack of experience with cloud data warehouse and transformation tools"",""Inability to communicate technical concepts to non-technical audiences""],""confidence_score"":90.0}"
Software Engineer,"At Lyft, our purpose is to serve and connect. To do this, we start with our own community by creating an open, inclusive, and diverse organization

We are seeking a Software Engineer to join the Localization team, responsible for processing all GPS signals of our users to better understand their location. The team owns the services and infrastructure that map-matches in real-time to connect drivers and riders and to provide a location aware guidance experience for our users. Additionally the team processes location data at the end of the ride to produce the distance and time that a driver spent on the ride. The team is also responsible for the toll traversals of our drivers and ensuring accurate toll payments for them. Overall the team is very technical and goes deep into problems to ensure we deliver high quality experiences to our customers. Localization is a critical function for Lyft, and in this role you will be helping to ensure the reliable operations of services that are crucial for Lyft.

We are looking for an engineer with proven expertise in system architecture, microservices, and big-data processing and experience in building scalable solutions in the cloud environments. Additionally we are looking for someone with experience and interest in mapping, map-matching, HMMs, and Kalman filters.

Our technology stack runs on AWS, Kubernetes, Python, Go, C++. In this role, you will work with incredibly passionate and talented colleagues from software engineering, machine learning and data science on building rideshare experiences that delight millions of riders and drivers.

Responsibilities:

Lead large features from idea to positive execution and launch
Write well-crafted, well-tested, readable, maintainable code
Participate in code reviews to ensure code quality and distribute knowledge, as well as on call rotations
Share your knowledge by giving brown bags, tech talks, and promoting appropriate tech and engineering best practices
Unblock, support and communicate with internal partners to achieve results
Utilize your expertise in Python, Golang, AWS, C++ and SQL to deliver robust and scalable solutions.

Experience:

BS/MS or equivalent in Computer Engineering, Computer Science, or related field or relevant work experience
3+ years of software engineering/production infrastructure industry experience
Experience designing, debugging and running fault-tolerant, highly available, large-scale distributed systems
Experience working with public cloud platforms (e.g., AWS, GCP, Microsoft Azure, etc.)
Experience working with databases, relational or NoSQL
Led a set of components from design to launch
Interest and experience with Map matching, Kalman filters and HMMs.
Interest in Mapping technologies

If you are a seasoned engineer with a passion for innovation, microservices, and possess the skills to ensure the ongoing maintenance and improvement of services, we invite you to join our dynamic team. Apply now to be part of an exciting journey in the world of mapping technology.

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Child care and pet benefits
Access to a Lyft funded Health Care Savings Account
RRSP plan to help save for your future
In addition to provincial observed holidays, salaried team members are covered under Lyft's flexible paid time off policy. The policy allows team members to take off as much time as they need (with manager approval). Hourly team members get 15 days paid time off, with an additional day for each year of service
Lyft is proud to support new parents with 18 weeks of paid time off, designed as a top-up plan to complement provincial programs. Biological, adoptive, and foster parents are all eligible.
Subsidized commuter benefits

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Wednesdays, and Thursdays. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid

The expected base pay range for this position in the Toronto area is CAD $108,000 - CAD $148,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.","{""role_summary"":""Software Engineer responsible for processing GPS signals to better understand user location, ensuring reliable operations of services crucial for Lyft."",""key_terms"":[{""term"":""Microservices"",""explanation"":""An architectural approach to building software systems as a collection of small, independent services.""},{""term"":""Big-data processing"",""explanation"":""The process of handling and analyzing large and complex data sets to extract insights and patterns.""},{""term"":""Map-matching"",""explanation"":""The process of aligning GPS data with a digital map to determine the user's location.""},{""term"":""HMMs"",""explanation"":""Hidden Markov Models, a statistical model used for analyzing and predicting system behavior.""},{""term"":""Kalman filters"",""explanation"":""A mathematical algorithm used to estimate the state of a system from noisy data.""}],""skill_priorities"":{""must_have"":[""System architecture"",""Microservices"",""Big-data processing"",""Cloud environments"",""Python"",""Go"",""C++"",""AWS"",""Kubernetes""],""nice_to_have"":[""Map-matching"",""HMMs"",""Kalman filters"",""SQL""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a scalable solution for processing large amounts of GPS data in a cloud environment?"",""example_answer"":""I would use a microservices architecture with load balancing and auto-scaling to handle high volumes of data. I would also utilize big-data processing tools like Apache Spark to process the data in parallel.""},{""question"":""Can you explain how you would implement map-matching using HMMs and Kalman filters?"",""example_answer"":""I would use HMMs to model the probability of a user's location given the GPS data, and then use Kalman filters to estimate the user's location based on the model. I would also consider using other techniques like particle filters to improve the accuracy of the location estimation.""}],""red_flags"":[""Lack of experience with cloud environments"",""Inability to design scalable solutions"",""Limited knowledge of map-matching and location-based technologies""],""confidence_score"":90.0}"
Data Engineer - Snowflake,"Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best analytics global consulting team in the world.

The Data Engineer will be responsible for architecting, designing, and implementing advanced analytics capabilities. The right candidate will have broad skills in database design, be comfortable dealing with large and complex data sets, have experience building self-service dashboards, be comfortable using visualization tools, and be able to apply your skills to generate insights that help solve business challenges.We are looking for someone who can bring their vision to the table and implement positive change in taking the company's data analytics to the next level.

Requirements

8+ years of overall industry experience specifically in data engineering

5+ years of experience building and deploying large-scale data processing pipelines in a production environment.

Strong experience in Python, SQL, and PySpark

Creating and optimizing complex data processing and data transformation pipelines using python

Experience with ""Snowflake Cloud Datawarehouse"" and DBT tool

Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases

Understanding of Datawarehouse (DWH) systems, and migration from DWH to data lakes/Snowflake

Understanding of ELT and ETL patterns and when to use each. Understanding of data models and transforming data into the models

Strong analytic skills related to working with unstructured datasets

Build processes supporting data transformation, data structures, metadata, dependency and workload management

Experience supporting and working with cross-functional teams in a dynamic environment

Benefits

Significant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.","{""role_summary"":""Design and implement advanced analytics capabilities, architecting and building large-scale data processing pipelines, and generating insights to solve business challenges."",""key_terms"":[{""term"":""Data Engineering"",""explanation"":""The process of designing, building, and maintaining large-scale data systems and pipelines.""},{""term"":""Snowflake Cloud Datawarehouse"",""explanation"":""A cloud-based data warehousing platform for storing and processing large datasets.""},{""term"":""DBT tool"",""explanation"":""A software tool for transforming and loading data into a data warehouse.""},{""term"":""ELT and ETL patterns"",""explanation"":""Methods for extracting, transforming, and loading data into a target system, with ELT focusing on loading and then transforming, and ETL focusing on extracting, transforming, and then loading.""},{""term"":""Datawarehouse (DWH) systems"",""explanation"":""A type of database designed to store and manage large amounts of data for reporting and analysis.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""PySpark"",""Data engineering"",""Data processing pipelines"",""Data transformation"",""Data modeling"",""Relational databases"",""Data warehousing"",""ELT and ETL patterns""],""nice_to_have"":[""Snowflake Cloud Datawarehouse"",""DBT tool"",""Unstructured datasets"",""Cross-functional team experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the differences between ELT and ETL patterns and when to use each?"",""example_answer"":""ELT focuses on loading data into a target system and then transforming it, whereas ETL focuses on extracting data, transforming it, and then loading it. I would use ELT when the target system has the necessary processing power and ETL when the source system has limitations.""},{""question"":""How would you optimize a complex data processing pipeline?"",""example_answer"":""I would identify performance bottlenecks, apply parallel processing, and optimize database queries to reduce processing time and improve efficiency.""}],""red_flags"":[""Lack of experience with large-scale data processing pipelines"",""Inability to work with complex data sets"",""Limited experience with data modeling and transformation""],""confidence_score"":90.0}"
Sr. Data/Backend Engineer - Canada,"About KnotchKnotch is a Content Intelligence Platform that enables brands to drive business growth through content. We build products for people who use content to drive performance. We also offer Strategic Consulting services which enable brands to achieve new levels of efficiency and effectiveness through ongoing and ad hoc support. Knotch gives marketers a holistic view of content’s performance and provides insights and actions that drive performance and increase efficiency.
About the Role
As a Sr Data Engineer at Knotch you will design, build, and maintain data infrastructure that powers business intelligence and analytics. In this role, you'll bridge the gap between raw data and actionable insights by creating robust data pipelines and models. This role is ideal for someone who combines technical excellence with business acumen and thrives in a collaborative environment where data drives decision-making.
How you will add value at Knotch
Collaborate cross-functionally to gather requirements and design data models that deliver successful analytics outcomes
Design and implement production-grade ETL/ELT processes to transform raw data into valuable business assets
Maintain and enhance existing data applications to ensure optimal performance and reliability
Build strong relationships with various teams to understand data needs and deliver appropriate solutions
Own data quality and serve as the subject matter expert for assigned business domains
You will successful if you bring:
5+ years of Data Engineering experience with demonstrated expertise in pipeline development and data modeling
Strong application development skills with advanced proficiency in SQL and Python
Hands-on experience with AWS services and Snowflake
Sharp analytical skills to identify data gaps, inconsistencies, and deliverable opportunities
Excellent communication abilities to translate complex technical concepts for both technical and business audiences
Prior experience as a backend engineer (application development) is a plus!
Our Benefits and Perks:
Salary - The expected salary range for this role is $150,000 - $165,000 CADdepending on experience.
Knotch is a fully remote company. Candidates can work from anywhere in Canada for this position.
Knotch is a US based equal opportunity employer. We strive to provide equal opportunities in all of our processes, including our hiring and employee experience.mWe pride ourselves on our three values: transparency, relentlessness, and inclusiveness.
We commit to daily work towards leading with empathy, reducing bias through periodic training, and engaging with and uplifting communities of marginalized groups. We condemn all forms of racism and discrimination on the basis of race, religion, ethnicity, nationality, gender identity, sexual orientation, age, marital status, pregnancy or parenthood status, veteran status, disability status or any other identifier. We encourage all employees, clients, investors, candidates, vendors, and friends of Knotch to deliver honest feedback directly or anonymously so that we may always seek to improve as an organization that is dedicated to diversity, equity, inclusion, and belonging.
Powered by JazzHR
lK7M04uXEn","{""role_summary"":""Design, build, and maintain data infrastructure to power business intelligence and analytics, bridging the gap between raw data and actionable insights."",""key_terms"":[{""term"":""ETL/ELT"",""explanation"":""Extract, Transform, Load/Extract, Load, Transform processes that transform raw data into valuable business assets.""},{""term"":""Data Modeling"",""explanation"":""The process of creating a conceptual representation of data structures to deliver successful analytics outcomes.""},{""term"":""AWS Services"",""explanation"":""Cloud computing services provided by Amazon Web Services, used for building and maintaining data infrastructure.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform used for storing and processing large amounts of data.""}],""skill_priorities"":{""must_have"":[""Data Engineering experience"",""SQL"",""Python"",""AWS services"",""Snowflake"",""Data modeling"",""ETL/ELT""],""nice_to_have"":[""Backend engineer experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a data pipeline to handle large volumes of data?"",""example_answer"":""I would use a scalable architecture, leveraging AWS services such as S3 and Lambda, and Snowflake for data warehousing. I would also implement data quality checks and monitoring to ensure data integrity.""},{""question"":""How do you stay up-to-date with new technologies and trends in data engineering?"",""example_answer"":""I regularly read industry blogs and attend conferences to stay current with the latest developments in data engineering. I also participate in online forums and communities to learn from others and share my own experiences.""}],""red_flags"":[""Lack of experience with cloud-based data warehousing platforms"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Staff Data Engineer,"Afresh is on a mission to eliminate food waste and make fresh food accessible to all. Our first A.I.-powered solution optimizes ordering, forecasting, and store operations for fresh food departments in brick-and-mortar grocers. With our Fresh Operating System, regional and national grocery retailers have placed $1.6 billion in produce orders across the US and we've helped our partners prevent 34 million pounds of food from going to waste. Working at Afresh represents a one-of-a-kind opportunity to have massive social impact at scale by leveraging uncommonly impactful software – we hope you'll join us!

About The Role

As a Staff Data Engineer, you’ll play a key role in scaling and improving how we integrate and process customer data. You will design and implement ETLs that reliably process large volumes of customer-provided data and build tools to make customer integrations faster, more accurate, and more scalable. You’ll also contribute to the development of new features that support our expanding product lines. Your work will have a direct and visible impact on our ability to onboard customers easier and quicker and power our machine learning grocery solution.

What To Expect


Build tools and frameworks that streamline customer integrations, enabling faster onboarding and better handling of customer data.
Create robust ETLs in PySpark and DBT to process billions of records from customer datasets, ensuring data is accurate, reliable, and ready for downstream use.
Collaborate with product, engineering, and go-to-market teams to design and deliver data solutions for new products and features.
Identify and implement optimizations to improve ETL runtime and data processing scalability, reducing the time and effort required for integrations.
Solve real-world data quality challenges by working directly with messy, incomplete, or inconsistent customer data to extract the signal we need.
Investigate and implement new technologies into the data platform, focusing on practical solutions that address current pain points and anticipate future needs.
Support team members by mentoring engineers, leading technical discussions, and providing clear, actionable feedback.


Skills And Experience

We encourage all highly-qualified candidates to apply, even if they don’t meet every listed qualification.


Significant experience designing and maintaining ETLs that process large-scale datasets.
Proficiency with Python, PySpark, SQL, and experience working on platforms/tools like Databricks, Snowflake, or DBT.
Strong problem-solving skills and the ability to work with ambiguous or incomplete requirements to deliver concrete, impactful solutions.
A focus on practical outcomes—you're skilled at balancing technical rigor with the need to get things done.
Experience working directly with complex, unclean datasets and finding innovative ways to process and analyze them.
A knack for identifying areas where tooling or automation can simplify workflows and reduce manual effort.
Excellent communication skills—you’re able to explain your ideas clearly to both technical and non-technical audiences.
Proven leadership in technical projects, with a willingness to mentor and help others grow.


Why Work Here


Join a mission-driven company reducing millions of pounds of food waste in grocery stores per year.
Work on challenging, real-world problems that have a direct impact on our customers.
Be part of a collaborative, supportive team where your ideas are valued and acted on.
Use cutting-edge tools and platforms to solve meaningful data challenges.


We’re looking for someone who thrives on tackling complex data problems and takes pride in building systems that work seamlessly at scale. If that sounds like you, we’d love to hear from you!

Salary Range in CAD:

About Afresh

Founded in 2017, Afresh is working on the #1 solution to curb climate change: reducing food waste. By combining human insight and transformative technology, we're helping grocers provide fresher food to customers at more affordable prices.

Afresh sits at an incredible intersection of positive social impact, rocket ship financial growth, and cutting-edge technology. Our best-in-class AI research has been published in top journals including ICML, and we've raised over $148 million in funding from investors including former co-CEO of Whole Foods Market Walter Robb and Eric Schmidt's Innovation Endeavors.

Fresh is the past, present, and future of our food system – the waste we create today will impact our planet for years to come. Join us as we continue to build a vibrant, diverse, and inclusive team that embodies our company’s values of proactivity, kindness, candor, and humility.

Afresh provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity/expression, marital status, pregnancy or related condition, or any other basis protected by law.

Here at Afresh, many of our employees work remotely provided that they reside in one of the following states: AR, CA, CO, FL, GA, IL, KY, MA, MI, MT, MO, NV, NJ, NY, NC, OR, PA, TX, WA, WI. However, there may be key roles that will require a candidate/employee to be local to our San Francisco, CA office. In which case this requirement will be included in the job posting details under ""Skills and experience"" for reference.","{""role_summary"":""As a Staff Data Engineer, you will design and implement ETLs, build tools for customer integrations, and contribute to the development of new features, having a direct impact on customer onboarding and machine learning grocery solutions."",""key_terms"":[{""term"":""ETLs"",""explanation"":""Extract, Transform, Load processes that reliably process large volumes of customer-provided data.""},{""term"":""PySpark"",""explanation"":""A Python library for large-scale data processing that provides high-level APIs in Python and Java.""},{""term"":""DBT"",""explanation"":""A data transformation tool that enables the creation of reliable and scalable data pipelines.""}],""skill_priorities"":{""must_have"":[""Significant experience designing and maintaining ETLs that process large-scale datasets"",""Proficiency with Python, PySpark, SQL"",""Strong problem-solving skills"",""Experience working directly with complex, unclean datasets""],""nice_to_have"":[""Experience working on platforms/tools like Databricks, Snowflake, or DBT"",""Proven leadership in technical projects"",""Willingness to mentor and help others grow""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach optimizing ETL runtime and data processing scalability?"",""example_answer"":""I would investigate and implement new technologies into the data platform, focusing on practical solutions that address current pain points and anticipate future needs. I would also collaborate with the team to design and deliver data solutions for new products and features.""},{""question"":""Can you give an example of a time when you had to work with ambiguous or incomplete requirements to deliver concrete, impactful solutions?"",""example_answer"":""In my previous role, I had to work with a customer dataset that was incomplete and inconsistent. I used my problem-solving skills to identify the key issues and developed a solution that extracted the required signal from the data, resulting in a successful customer integration.""}],""red_flags"":[""Lack of experience with large-scale data processing"",""Inability to work with ambiguous or incomplete requirements"",""Poor communication skills""],""confidence_score"":90.0}"
"Software Engineer, Data Pipelines","At Lyft, our purpose is to serve and connect. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

Our Infrastructure team is passionate about building software to solve problems at massive scale. We do this often, and when we believe our solution is worth sharing with the community, such as Envoy Proxy, we open source our ideas for the benefit of others.

As a Infrastructure Engineer at Lyft, you will run our Production Infrastructure by monitoring system availability and take a holistic view of our platform health. You will build software and platforms to automate infrastructure platform operations and management. By measuring and monitoring our operations you will seek opportunities to optimize our systems in order to push our platform forward, anticipating our customers' needs in order to continually improve the platform. You will provide Lyft partner teams with operational support to help them build robust large scale distributed systems.

About The Team

Data Pipelines is at the heart of all critical data flowing through Lyft supporting hundreds of services that impact millions of drivers and passengers every day. We support Kafka as our primary data streaming platform and offer a number of services to manage data and make it available to our internal customers.

Responsibilities:

Maintain and analyze metrics from; operating systems; control planes; and applications to assist in fault detection and performance enhancement
Design, develop and deploy tooling and systems that continually improve the reliability, scalability and efficiency of our platform
Balance feature development speed and reliability with service-level objectives
Operate and improve our Infrastructure using industry best practices and tools
Participate in design and production readiness reviews, platform management and capacity planning ceremonies with cross-functional teams
Document Infrastructure operations process and insights, identify repeatable actions and ruthlessly automate repetitive tasks
Participate in our teams on-call rotations, respond to incidents and support other teams mitigate customer impacting events

Experience:

2+ years experience working on teams responsible for software development, automation and systems engineering
Ability to create production ready code in one or more high level languages, such as Go Lang, Python
Experience operating large scale infrastructure in public cloud environments, such as AWS
Prior infra experience with infra tooling (Terraform, Cloud Formation, Docker, Kubernetes, Ansible, Chef, Puppet etc preferably in an AWS context)
Experience identifying nascent problems, performance bottlenecks and areas for improvement and developing and executing plans to mitigate them

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Child care and pet benefits
Access to a Lyft funded Health Care Savings Account
RRSP plan to help save for your future
In addition to provincial observed holidays, salaried team members are covered under Lyft's flexible paid time off policy. The policy allows team members to take off as much time as they need (with manager approval). Hourly team members get 15 days paid time off, with an additional day for each year of service
Lyft is proud to support new parents with 18 weeks of paid time off, designed as a top-up plan to complement provincial programs. Biological, adoptive, and foster parents are all eligible.
Subsidized commuter benefits

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Wednesdays, and Thursdays. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid

The expected base pay range for this position in the Toronto area is CAD $108,000 - CAD $149,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.","{""role_summary"":""As an Infrastructure Engineer at Lyft, you will run and maintain Lyft's Production Infrastructure, ensuring system availability and platform health. You will build software and platforms to automate infrastructure operations and management, and provide operational support to partner teams."",""key_terms"":[{""term"":""Envoy Proxy"",""explanation"":""An open-source software proxy that helps manage network traffic and is used by Lyft to solve problems at massive scale.""},{""term"":""Kafka"",""explanation"":""A distributed streaming platform used by Lyft to support hundreds of services that impact millions of drivers and passengers every day.""},{""term"":""Terraform"",""explanation"":""An infrastructure as code tool used to manage and provision infrastructure resources, such as AWS.""},{""term"":""Ansible"",""explanation"":""An automation tool used to configure and manage infrastructure resources, such as servers and networks.""}],""skill_priorities"":{""must_have"":[""2+ years experience working on teams responsible for software development, automation and systems engineering"",""Ability to create production ready code in one or more high level languages, such as Go Lang, Python"",""Experience operating large scale infrastructure in public cloud environments, such as AWS""],""nice_to_have"":[""Prior infra experience with infra tooling (Terraform, Cloud Formation, Docker, Kubernetes, Ansible, Chef, Puppet etc preferably in an AWS context)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach fault detection and performance enhancement in a large-scale infrastructure?"",""example_answer"":""I use metrics from operating systems, control planes, and applications to identify areas for improvement. I then design and develop tooling and systems to continually improve the reliability, scalability, and efficiency of the platform.""},{""question"":""Can you give an example of a time when you had to balance feature development speed and reliability with service-level objectives?"",""example_answer"":""In my previous role, I had to balance the need to deploy new features quickly with the need to ensure the reliability of our platform. I worked with cross-functional teams to prioritize features and develop a deployment strategy that met our service-level objectives.""}],""red_flags"":[""Lack of experience with large-scale infrastructure in public cloud environments"",""Inability to create production-ready code in high-level languages""],""confidence_score"":90.0}"
Database Engineer,"We are currently seeking a full-time permanent Database Engineer to join our Technology team.

As a Database Engineer, you will be responsible for ensuring the performance, availability, and security of databases within the organization. You will also play a crucial role in designing, implementing, and maintaining large-scale data processing systems that handle sizable amounts of structured and unstructured data. Your role involves managing, maintaining, and optimizing databases to meet the needs of the business and its users, architecting data pipelines, optimizing data workflows, and ensuring the scalability, reliability, and performance of data solutions. You will work closely with other members of the IT team to ensure seamless integration and efficient operation of database systems.

The duties and responsibilities of the Database Engineer include but are not limited to:

Design and Architecture: Develops database schemas, tables, and relationships. Designs scalable and fault-tolerant data architectures that leverage modern design principles to process and analyze large datasets.
Database Configuration: Ensures proper settings and configurations are in place for optimal performance and security of all Relational Database Management Systems.
Data Ingestion and Integration: Develops robust data ingestion pipelines to collect, extract, transform, and load (ETL) data from various sources, including databases, streaming platforms, and APIs. Implements data processing workflows to cleanse, enrich, and transform raw data into usable formats for analytics, reporting, and machine learning applications.
Performance Tuning: Monitors database performance and identifies opportunities for optimization. Tunes database queries, indexes, and other performance-critical elements to enhance efficiency and response times.
Backup and Disaster Recovery: Implements and manages backup and disaster recovery procedures to safeguard data against loss or corruption. Tests procedures regularly to ensure reliability.
Application Performance Optimization: Optimizes data processing algorithms, data structures, and resource utilization to maximize performance, reduce latency, and improve throughput in big data systems.
Security Management: Enforces security best practices to protect sensitive data from unauthorized access, breaches, or cyberattacks. Manages user access privileges, roles, and permissions, and data lineage throughout various data processing system.
Troubleshooting and Issue Resolution: Investigates and resolves database-related issues, such as performance bottlenecks, and system errors. Provides timely support to stakeholders. Collaborates with cross-functional teams to resolve system issues.
Automation and Scripting: Develops scripts and automation workflows to streamline repetitive tasks, such as data imports, exports, and maintenance activities. Embraces automation tools to improve operational efficiency.
Research and Innovation: Stays abreast of emerging trends, technologies, and best practices in big data, machine learning, and artificial intelligence. Experiments with new tools and techniques to drive innovation and enhance data engineering capabilities.
Documentation and Reporting: Maintains comprehensive documentation of database configurations, data processing procedures, and security policies.

Critical Competencies
Technical Knowledge – Profound knowledge in data architecture, real-time analytics, and cloud computing platforms, especially within financial services. Expert knowledge of data modeling, ETL processes, and data warehousing concepts.
Attention to Detail – Meticulous attention to precision in data handling and system design to ensure the integrity and reliability of our data platforms.
Problem Solving – Exceptional analytical skills with the ability to tackle complex technical challenges and innovate solutions.
Communication – Excellent communication skills, capable of articulating complex data concepts to non-technical stakeholders.
Teamwork – Strong aptitude to work well with others and support a thriving, team-first culture.
Requirements
Bachelor's or Master’s degree in Computer Science, Data Engineering, or a related field
Minimum of 5 years of experience as a DBA, Data Engineer, or similar role, with a focus on designing and implementing large-scale data processing systems
Experience with cloud platforms and services, such as AWS (EMR, S3, Glue), Azure (HDInsight, Data Lake, Data Factory), or Google Cloud (Dataproc, BigQuery)
Experience with SQL Server and MySQL
Strong knowledge of and experience with real-time analytics, persistent data stores, data modeling techniques, and adept data pipeline management
Proficient in various programming languages (Python/C#/Java) and adept with tools required for developing complex APIs and executing streaming or real-time data processes
Experience with cloud platforms and services, such as AWS (EMR, S3, Glue), Azure (HDInsight, Data Lake, Data Factory), or Google Cloud (Dataproc, BigQuery)
Familiarity with containerization technologies (e.g., Docker, Kubernetes) and orchestration tools (e.g., Apache Airflow) is considered an asset

Additional Information
Position Type: Full-Time Permanent
Work Location: Toronto To learn more about life at RPIA, visit https://rpia.ca/
Read our firm’s magazine, Voices of RPIA: https://online.flippingbook.com/view/859829658/24/

RPIA is proud to be Great Place to Work Certified™. What sets us apart?
Exceptional single and family benefits package that includes health, dental, and vision insurance plus additional Health Care Spending and Wellness credits.
Employee and Family Assistance Program to support mental well-being and extends to all family members in your household.
Opportunities for professional and personal growth through: Cross-functional Mentorship Program, Internally-curated Leadership Skills training program, Community outreach opportunities and monthly team socials.

RPIA is an Equal Opportunity Employer
We believe in the power of diversity of thought, and we aspire to have an inclusive workplace that mirrors the fabric of our community. We strongly encourage applications regardless of race, religion, colour, national origin, gender, sexual orientation, age, marital status, or disability status. We are committed to providing an accessible and equitable application and hiring process and will make accommodations should you require it at any point. We encourage you to connect with us at hr@rpia.ca if you require accommodation during the recruitment process.
Our culture is defined by our five core values: excellence, partnership, transparency, integrity, and community. Our clients often say the outstanding service we deliver is as important to them as the returns we achieve for them. With over 100 employees and $14 billion under management for a broad investor base of institutions and private clients, we proudly remain privately owned by employees who invest alongside our clients.","{""role_summary"":""The Database Engineer is responsible for ensuring the performance, availability, and security of databases within the organization, designing and implementing large-scale data processing systems, and managing and optimizing databases to meet business needs."",""key_terms"":[{""term"":""Data Architecture"",""explanation"":""The design and structure of databases and data processing systems to handle large datasets.""},{""term"":""ETL (Extract, Transform, Load)"",""explanation"":""A process of collecting, processing, and loading data from various sources into a target system.""},{""term"":""Cloud Computing Platforms"",""explanation"":""On-demand access to a shared pool of computing resources over the internet, such as AWS, Azure, or Google Cloud.""},{""term"":""Real-time Analytics"",""explanation"":""The ability to analyze and process data in real-time, enabling immediate insights and decision-making.""},{""term"":""Containerization Technologies"",""explanation"":""Tools like Docker and Kubernetes that allow for efficient and scalable deployment of applications.""}],""skill_priorities"":{""must_have"":[""Data architecture"",""Real-time analytics"",""Cloud computing platforms"",""SQL Server"",""MySQL"",""Python/C#/Java programming languages""],""nice_to_have"":[""Containerization technologies (e.g., Docker, Kubernetes)"",""Orchestration tools (e.g., Apache Airflow)""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a scalable data architecture to handle large datasets?"",""example_answer"":""I would use a distributed database system with a scalable storage solution, such as HDFS or S3, and implement data partitioning and indexing to optimize query performance.""},{""question"":""What is your experience with ETL processes, and how would you optimize data workflows?"",""example_answer"":""I have experience with ETL tools like Informatica and Talend, and I would optimize data workflows by implementing parallel processing, data caching, and efficient data transformation techniques.""}],""red_flags"":[""Lack of experience with cloud computing platforms"",""Inadequate knowledge of data modeling and ETL processes""],""confidence_score"":90.0}"
Sr. Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:


Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
Write code to ensure the performance and reliability of data extraction and processing
Support continuous process automation for data ingest
Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
Work with program management and engineers to implement and document complex and evolving requirements
Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists




Qualifications:


Must be a US Citizen
Must be able to obtain a Public Trust Clearance
7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
Proficiency in developing ETL processes, and performing test and validation steps
Proficiency to manipulate data (Python, R, SQL, SAS)
Strong knowledge of big data analysis and storage tools and technologies
Strong understanding of the agile principles and ability to apply them
Strong understanding of the CI/CD pipelines and ability to apply them
Experience with relational database, such as, PostgreSQL
Work comfortably in version control systems, such as, Git Repositories




Ideally, you will also have:


Experience creating and consuming APIs
Experience with DHS and knowledge of DHS standards a plus
Candidates will be given special consideration for extensive experience with Python
Ability to develop visualizations utilizing Tableau or PowerBI
Experience in developing Shell scripts on Linux
Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences




Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:


Health, Dental, and Vision
Life Insurance
401k
Flexible Spending Account (Health, Dependent Care, and Commuter)
Paid Time Off and Observance of State/Federal Holidays




Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com","{""role_summary"":""Support a rapidly growing Data Analytics and Business Intelligence platform by developing and maintaining data pipelines, ensuring data quality, and collaborating with cross-functional teams to deliver actionable insights to federal customers."",""key_terms"":[{""term"":""Agile/Scrum"",""explanation"":""A project management methodology that emphasizes collaboration, continuous improvement, and flexibility.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""API-first design"",""explanation"":""A software development approach that prioritizes the design of application programming interfaces (APIs) as the primary interface for interacting with a system.""},{""term"":""CI/CD pipelines"",""explanation"":""Continuous Integration and Continuous Deployment - a set of practices that automate the build, test, and deployment of software applications.""},{""term"":""Big data analysis and storage tools"",""explanation"":""Technologies used to process, store, and analyze large datasets, such as Hadoop, Spark, and NoSQL databases.""}],""skill_priorities"":{""must_have"":[""7+ years of IT experience"",""Experience with designing, managing, and solutioning large, complex data sets and models"",""Proficiency in developing ETL processes and performing test and validation steps"",""Strong knowledge of big data analysis and storage tools and technologies"",""Strong understanding of agile principles and ability to apply them"",""Strong understanding of CI/CD pipelines and ability to apply them"",""Experience with relational databases, such as PostgreSQL"",""Proficiency in manipulating data using Python, R, SQL, or SAS""],""nice_to_have"":[""Experience creating and consuming APIs"",""Experience with DHS and knowledge of DHS standards"",""Extensive experience with Python"",""Ability to develop visualizations using Tableau or PowerBI"",""Experience in developing Shell scripts on Linux"",""Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a data pipeline to handle large, complex datasets?"",""example_answer"":""I would use an ETL tool like Informatica or Talend to extract data from multiple sources, transform it into a standardized format, and load it into a target system like a data warehouse. I would also ensure data quality by implementing data validation and data cleansing processes.""},{""question"":""How do you stay current with new technologies and trends in data engineering?"",""example_answer"":""I regularly read industry blogs and attend conferences to stay up-to-date on the latest developments in data engineering. I also participate in online forums and communities to learn from others and share my own experiences.""}],""red_flags"":[""Lack of experience with agile methodologies and CI/CD pipelines"",""Inability to communicate technical terms to non-technical audiences"",""Limited experience with big data analysis and storage tools and technologies""],""confidence_score"":90.0}"
Azure DWH Data Engineer,"Proficient in deriving solutions from loosely defined business challenges, demonstrating adaptability and problem-solving acumen.
Exceptional team leadership and mentoring abilities, fostering collaboration and professional growth within teams.
Skilled in architecting and implementing medium to large scale BI solutions on Azure, utilizing a comprehensive suite of Azure Data Platform services.
Capable of assessing the current production state of applications and evaluating the impact of new implementations on existing business processes.
Proficient in developing cost-effective architectures in Azure, providing recommendations to optimize data infrastructure.
Experienced in designing, setting up, and maintaining Azure services, ensuring smooth operations of critical components.
Expertise in executing Extract, Transform, and Load (ETL) processes from diverse source systems to Azure Data Storage services, employing a variety of tools and languages.
Competent in developing and managing pipelines in Azure Data Factory, facilitating seamless data extraction, transformation, and loading from multiple sources.
Possesses a strong understanding of Spark Architecture and effectively develops Spark applications for data extraction, transformation, and aggregation.
Assumes responsibility for estimating cluster sizes, monitoring, and troubleshooting Spark Databricks clusters, optimizing performance parameters for efficiency.
Demonstrates exceptional communication skills, conveying complex data insights to non-technical stakeholders with clarity and precision.
Proven ability to drive organizational buy-in for data-driven initiatives, influencing stakeholders to embrace data-driven decision-making.
Expertise in data analysis, data mining, and statistical techniques, leveraging statistical packages and programming languages like SAS, R, or Python.
Familiarity with statistical packages, quantitative analytics, forecasting, and optimization algorithms, enabling informed decision-making and strategic planning.
Possesses solid industry knowledge and extensive experience leading teams, guiding them to deliver impactful results in alignment with organizational goals.","{""role_summary"":""Lead and architect medium to large scale BI solutions on Azure, driving data-driven initiatives and ensuring smooth operations of critical components."",""key_terms"":[{""term"":""Azure Data Platform services"",""explanation"":""A comprehensive suite of services offered by Microsoft Azure for building, deploying, and managing business intelligence solutions.""},{""term"":""ETL"",""explanation"":""Extract, Transform, and Load, a process of extracting data from diverse sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Spark Architecture"",""explanation"":""An open-source data processing engine for large-scale data processing, providing high-level APIs in Java, Python, and Scala.""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service for creating, scheduling, and managing data pipelines across different sources and destinations.""},{""term"":""Spark Databricks"",""explanation"":""A fast, easy, and collaborative Apache Spark-based analytics platform for data engineering, data science, and data analytics.""}],""skill_priorities"":{""must_have"":[""Azure"",""BI solutions"",""ETL"",""Spark Architecture"",""Azure Data Factory"",""Data analysis"",""Statistical techniques""],""nice_to_have"":[""SAS"",""R"",""Python"",""Statistical packages"",""Quantitative analytics"",""Forecasting"",""Optimization algorithms""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach architecting a medium to large scale BI solution on Azure?"",""example_answer"":""I would start by assessing the business requirements and identifying the necessary Azure Data Platform services. Then, I would design a scalable and cost-effective architecture, ensuring seamless data integration and smooth operations.""},{""question"":""Can you explain how you would optimize the performance of a Spark Databricks cluster?"",""example_answer"":""I would monitor the cluster's performance, identify bottlenecks, and adjust the configuration accordingly. I would also ensure efficient resource allocation and optimize the Spark application code for better performance.""}],""red_flags"":[""Lack of experience with Azure Data Platform services"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
"Software Engineer, Python","TRADER Corporation is a trusted Canadian leader in online media, dealer and lender services. The company is comprised of AutoTrader.ca, AutoSync and Dealertrack Canada. AutoTrader.ca (AutoHebdo.net in Quebec) offers the largest inventory of new cars and used cars in Canada, receiving over 25 million monthly visits to its marketplace. With over 3,500 subscribers and counting, AutoSync is the largest and fastest growing dealer and OEM software provider in Canada. The platform's suite of connected automotive software solutions brings advertising, conversion and operational support together, synchronizing the entire retail process. AutoSync's diverse range of offerings includes: vAuto, EasyDeal, xtime, Motoinsight, Activix, TAdvantage and TRFFK. Dealertrack is Canada’s largest automotive financing portal, enhancing efficiency and profitability for all major segments of the automotive, marine, recreational vehicle, motorcycle and powersport retail industries. Over 6.5 million credit applications are submitted via the Dealertrack Canada portal each year. Collateral Management is a national, end-to-end, managed technology solution that offers industry insight and multi-channel collection strategies to maximize funds recovered. Collateral Management helps you remain compliant in all jurisdictions, alleviating your exposure to reputational and financial risks. Visit tradercorporation.com to learn more. .

TRADER Corporation's parent company AutoScout24 is the largest pan-European online car market with over 2 million listings and more than 43,000 dealer customers. With AutoScout24, users can find, finance, buy, subscribe for and sell used and new cars. The marketplace provides inspiration on cars and other vehicles and makes hard decisions easy.

Since 1998 AutoScout24 has been offering private users, car dealers and other cooperation partners from the automotive, financial and insurance services sector a comprehensive digital platform for car trading. The online marketplace includes used and new cars, motorcycles as well as commercial vehicles. AutoScout24 has over 30 million users per month, more than 43,000 dealers and around 500 employees. In addition to Germany, AutoScout24 is also represented in the European core markets of Belgium, Luxembourg, the Netherlands, Italy, France and Austria.

More information on www.autoscout24.de

Experience leveraging AI, Generative AI (GenAI) to enhance engineering productivity, automate repetitive tasks, and optimize workflows. Candidates should demonstrate the ability to integrate AI-driven solutions into their daily work — such as code generation, debugging, reviews, documentation, and decision support—to improve efficiency for themselves and their teams. A proactive approach to exploring and implementing AI tools that drive innovation and streamline development processes is highly valued

Key areas of responsibility
- Design, develop and oversee the successful end-to-end delivery of full-stack web solutions, from technical analysis to architecture and implementation, through to unit testing, development, integration testing and documentation.
- Providing appropriate testing information and environments to QA engineers and Product Owners, to validate the deliverables meet the desired expectations.
- Maintain and improve our engineering standards by participating in thorough code reviews, proposing process changes, and having a proactive attitude towards improvement in all areas of our software delivery lifecycle.
- Participate in the on-call rotation to ensure a timely response during production incidents.
- Performing root-cause analysis on software defects, to help identify weak spots in processes and tools, with the aim of preventing defects from happening again.
- Being an active participant in your team's meetings and processes, providing useful information through efficient communication with Product and Project stakeholders.
- Working closely with Product stakeholders in understanding project needs and providing technical advice in the feasibility of solutions as well as alternative options that could be considered.

Required skills
- Experience working as a full-stack web developer with Python and Vue.js or React.
- Hands-on knowledge of SQL and RDBMs fundamentals, particularly Postgres.
- Experience writing detailed unit, component and integration tests.
- Experience designing and implementing RESTful APIs.
- Working knowledge of git or similar VCS, docker, and cloud-based platforms.
- Working experience profiling and optimizing software in all levels of the stack, from time-consuming API endpoints to expensive queries, through to inefficient algorithms.
- Ability to work in a fully-remote environment, with a distributed team.
- Ability to dig into issues and errors and figure out their causes and potential solutions.
- Great self-organization and time management skills.
- Exceptional written and spoken English.

Required experience
- University degree in Computer Science, or equivalent experience.
- 5+ years of experience building online software. Strong knowledge of website usability and web application architectures.
- Knowledge of relational and non-relational storage foundations and their tradeoffs.
- Working knowledge of modern security fundamentals and best practices.
- Great understanding of agile methodologies in a Kanban delivery environment.
- Experience working with a remote, distributed team.

What’s in it for you…
-We understand that there is life at work and life outside of work. Here are a few benefits we all benefit from that support us to be our creative best.
Fitness and wellness
-We provide discounts to nation-wide gyms, onsite gyms (when we’re in the office), an Employee and Family Assistance Program, as well as a virtual wellness program.
Benefits from Day 1
-Gym discounts
-Local in-office free gyms
-Employee and Family Assistance program
-Weekly virtual wellness events
-Conferences & training budget
-Regular internal training programs
Financial planning
-Let us help you invest in your future with 3% matching towards your pension and multiple forms of income protection.
Competitive salary
-Annual bonus structure
-3% CPP matching","{""role_summary"":""A full-stack web developer responsible for designing, developing, and delivering web solutions, ensuring efficient engineering productivity, and leveraging AI-driven solutions to optimize workflows."",""key_terms"":[{""term"":""Generative AI (GenAI)"",""explanation"":""A type of artificial intelligence that enables machines to generate new, original content, such as code, images, or text, to automate repetitive tasks and improve productivity.""},{""term"":""Full-stack web development"",""explanation"":""The development of complete web applications, including front-end (client-side), back-end (server-side), and database integration, to deliver a seamless user experience.""},{""term"":""RESTful APIs"",""explanation"":""A type of web service that follows the Representational State of Resource (REST) architectural style, allowing different systems to communicate with each other over the internet.""},{""term"":""Kanban delivery environment"",""explanation"":""A visual system for managing work, emphasizing continuous flow and limiting work in progress, to improve team efficiency and delivery speed.""}],""skill_priorities"":{""must_have"":[""Python"",""Vue.js or React"",""SQL and RDBMs fundamentals"",""Experience with unit, component, and integration testing"",""Knowledge of git or similar VCS, docker, and cloud-based platforms"",""Ability to work in a fully-remote environment""],""nice_to_have"":[""Experience with profiling and optimizing software"",""Knowledge of modern security fundamentals and best practices"",""Understanding of agile methodologies""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach optimizing software performance in a full-stack web development environment?"",""example_answer"":""I use profiling tools to identify performance bottlenecks, then apply optimization techniques such as caching, query optimization, and code refactoring to improve the overall efficiency of the application.""},{""question"":""Can you explain how you would design and implement a RESTful API for a web application?"",""example_answer"":""I would follow the REST architectural style, defining API endpoints, request and response formats, and implementing authentication and authorization mechanisms to ensure secure data exchange.""}],""red_flags"":[""Lack of experience with AI-driven solutions for engineering productivity"",""Inability to work effectively in a fully-remote environment"",""Limited knowledge of modern security fundamentals and best practices""],""confidence_score"":90.0}"
Senior Software Data Engineer - (Remote - Canada),"Jobgether has ALL remote jobs globally. We match you to roles where you're most likely to succeed and provide feedback on every application to help you learn. No more guesswork, application black holes, or recruiter ghosting in your job search.

For one of our clients, we are looking for a Senior Software Data Engineer, remotely from Canada.

As a Senior Software Data Engineer, you will play a key role in designing, developing, and optimizing data solutions that drive strategic decision-making. You will be responsible for building scalable data pipelines, ensuring data integrity, and collaborating with cross-functional teams to create efficient data architectures. This position requires a deep technical background, a problem-solving mindset, and a passion for transforming raw data into valuable insights.

Accountabilities:

Develop and maintain robust data pipelines to process and analyze large datasets efficiently
Design scalable data architectures, ensuring optimal performance and reliability
Collaborate with stakeholders across different teams to evaluate business needs and translate them into technical solutions
Implement and refine data integrity tests to maintain high-quality data standards
Stay current with emerging technologies, continuously improving data infrastructure and methodologies
Own and operate data products, ensuring seamless functionality and usability


Requirements

Extensive experience with distributed query engines and SQL-based data processing
Proficiency in SQL composition frameworks such as dbt or SQLMesh
Strong Python programming skills for data engineering tasks
Experience designing and building data pipelines with a focus on scalability and reliability
Excellent communication skills, with the ability to collaborate across remote teams and time zones
Proven ability to stay ahead of industry trends and implement innovative solutions
A track record of continuous learning and professional growth


Preferred Qualifications:

Experience with data governance and regulatory compliance
Familiarity with workflow orchestration tools
Previous contributions to production-level code
Experience developing fully managed cloud services
Knowledge of integrating Business Intelligence tools


Benefits

💰 Competitive compensation package, including Restricted Stock Units (RSUs)
🌴 Generous paid vacation, sick time, and 16 company holidays (including 2 floating holidays)
🏡 Flexible, fully remote work environment with no mandatory office presence
👶 Up to 26 weeks of paid parental leave
❤️ Paid volunteer and mental health days
🏦 RRSP plan with company match
🏥 Employer-provided supplemental medical, dental, disability, and life insurance coverage","{""role_summary"":""Design, develop, and optimize data solutions to drive strategic decision-making as a Senior Software Data Engineer, working remotely from Canada."",""key_terms"":[{""term"":""Distributed query engines"",""explanation"":""Systems that allow for efficient querying of large datasets across multiple machines.""},{""term"":""SQL composition frameworks"",""explanation"":""Tools that help build and manage complex SQL queries, such as dbt or SQLMesh.""},{""term"":""Data governance"",""explanation"":""Policies and procedures to ensure data quality, security, and compliance with regulations.""},{""term"":""Workflow orchestration tools"",""explanation"":""Software that helps manage and automate complex workflows and tasks.""},{""term"":""Cloud services"",""explanation"":""On-demand computing resources and services provided over the internet.""},{""term"":""Business Intelligence tools"",""explanation"":""Software that helps analyze and visualize data to inform business decisions.""}],""skill_priorities"":{""must_have"":[""Distributed query engines"",""SQL composition frameworks"",""Python programming"",""Data pipeline design and development"",""Communication and collaboration skills""],""nice_to_have"":[""Data governance and regulatory compliance"",""Workflow orchestration tools"",""Cloud services development"",""Business Intelligence tools integration""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing scalable data architectures?"",""example_answer"":""I consider factors like data volume, query patterns, and performance requirements to design architectures that can handle large datasets and high traffic. I also ensure that the architecture is modular, flexible, and easy to maintain.""},{""question"":""Can you give an example of a complex data pipeline you've built and how you optimized its performance?"",""example_answer"":""In my previous role, I built a data pipeline that processed millions of records daily. I optimized its performance by implementing parallel processing, data partitioning, and caching, which reduced the processing time by 50%.""}],""red_flags"":[""Lack of experience with distributed query engines"",""Inability to communicate technical solutions to non-technical stakeholders""],""confidence_score"":90.0}"
Backend Engineer - Data Platform,"At Spotify, our data platform powers the insights behind 600+ million Monthly Active Users and supports over 8,000 employees worldwide. Processing over 2 petabytes of data daily, it’s the backbone of our mission to bring audio to the world. Without it, the music doesn’t play.

Imagine starting your day with Spotify, eager to dive into your refreshed Daylist, only to find it’s stuck in yesterday. That’s the kind of experience we strive to prevent, and you’ll help make sure we deliver on that promise.

We’re looking for a Backend Engineer to join our Data Quality and Observability team. You’ll work on innovative tools and scalable systems that empower data practitioners and developers to collaborate effectively, ensuring reliability and accuracy across Spotify’s data platform. Whether it’s building backend services, optimizing pipelines, or supporting teams in delivering insights, your contributions will directly impact the way the world experiences audio.

What You'll Do

Build and maintain backend services and data pipelines used by thousands of engineers and data practitioners.
Participate in scaling systems while collaborating with teammates, stakeholders, and leaders.
Gain hands-on experience in understanding user workflows to create tools that improve data quality, observability and reliability.
Engage in hack days, hack weeks, and community events to learn, share, and grow.
Contribute to a team culture that values respect, collaboration, and playfulness.
Join a company that values innovation, iteration, and inclusivity, providing reasonable accommodations for those who need them.

Who You Are

You enjoy breaking down complex technical problems and iterating quickly, taking ownership from ideation to production.
Your skills include Java, and a strong understanding of systems design, data structures, and algorithms.
Bonus: Experience with Scala or collaborating with data engineers to build impactful tools and pipelines.
You are curious and customer-focused, excited to work closely with internal teams and open-source communities to build reliable solutions.
You thrive in an environment where engineers are empowered to solve meaningful problems with autonomy.

Where You'll Be

This role is based in Toronto, CA.
We offer you the flexibility to work where you work best! There will be some in person meetings, but still allows for flexibility to work from home.

Today, we are the world’s most popular audio streaming subscription service.","{""role_summary"":""As a Backend Engineer at Spotify, you'll work on innovative tools and scalable systems to ensure reliability and accuracy across Spotify's data platform, directly impacting the way the world experiences audio."",""key_terms"":[{""term"":""Data Quality"",""explanation"":""Ensuring the accuracy and reliability of data across Spotify's data platform.""},{""term"":""Observability"",""explanation"":""The ability to monitor and understand the performance and behavior of complex systems.""},{""term"":""Scalable Systems"",""explanation"":""Designing and building systems that can handle large amounts of data and traffic.""},{""term"":""Backend Services"",""explanation"":""Server-side applications and APIs that power the user interface and provide data to clients.""}],""skill_priorities"":{""must_have"":[""Java"",""Systems design"",""Data structures"",""Algorithms""],""nice_to_have"":[""Scala"",""Collaboration with data engineers""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach optimizing a data pipeline for better performance?"",""example_answer"":""I would start by analyzing the pipeline's current performance metrics, identifying bottlenecks, and then applying optimization techniques such as caching, parallel processing, or data compression. I would also consider refactoring the pipeline's architecture to improve scalability and reliability.""},{""question"":""Can you describe a time when you had to troubleshoot a complex technical issue in a backend service?"",""example_answer"":""In my previous role, I encountered an issue with a backend service that was causing errors for users. I used logging and monitoring tools to identify the root cause, then worked with the team to implement a fix and deploy it to production. The solution involved refactoring the service's architecture to improve fault tolerance and scalability.""}],""red_flags"":[""Lack of experience with Java or systems design"",""Inability to work collaboratively with cross-functional teams""],""confidence_score"":90.0}"
Data Engineer IV,"Financial or Banking experience

Must have
• In-depth proven experience with complex SQL data manipulation
• Proven Java experience
• Working knowledge of data warehouse
• XML, XLSX, JSON, CSV and other data source experience
Nice to have
• - Powershell experience
• - Sailpoint experience with bean shell knowledge

Responsibilities:

• Develop automated data pipelines and data stores from multiple systems including designing, implementing, testing, debugging, and deploying.
• Develop complex SQL queries, stored procedures, and scripts for data manipulation and retrieval.
• Build metadata-driven solutions that are reusable and highly configurable.
• Optimize data warehouse performance through effective data modeling, partitioning, and indexing strategies.
• Spearhead the design and implementation of ETL processes.
• Collaborate with various system owner to understand data requirements and deliver precise reporting and analytical solutions.
• Ensure data integrity and security within the data environment, complying with industry regulations and standards.
• Work on an agile team to quickly iterate and release solutions.
• Research and put forward new recommendations to create, automate and improve processes
• Provide technical expertise and support for warehouse to internal teams, including troubleshooting and resolving issues.
• Stay up to date with data features and updates, continuously improving and expanding our data warehouse capabilities.
• Develop and maintain documentation for processes, systems, and procedures.
• Design, develop, and support a data lake environment, ensuring efficient data storage, retrieval, and processing.
• Implement data governance and data quality frameworks to ensure the accuracy and reliability of data within the environment.
• Integrate warehouse with other data sources and platforms, including both cloud-based and on-premises systems.","{""role_summary"":""Design, develop, and maintain complex data pipelines, warehouses, and lakes, ensuring data integrity and security, and providing technical expertise to internal teams."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Data Lake"",""explanation"":""A centralized repository that stores raw, unprocessed data in its native format, allowing for flexible and scalable data processing and analysis.""},{""term"":""Data Governance"",""explanation"":""A set of policies, procedures, and standards that ensure the accuracy, completeness, and security of an organization's data.""},{""term"":""Data Quality"",""explanation"":""The process of ensuring that data is accurate, complete, and consistent, and meets the requirements of its intended use.""},{""term"":""Agile Team"",""explanation"":""A collaborative team that follows agile principles and methodologies to deliver solutions quickly and iteratively.""}],""skill_priorities"":{""must_have"":[""Complex SQL data manipulation"",""Java experience"",""Data warehouse knowledge"",""XML, XLSX, JSON, CSV data source experience""],""nice_to_have"":[""Powershell experience"",""Sailpoint experience with bean shell knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize the performance of a data warehouse?"",""example_answer"":""I would use effective data modeling, partitioning, and indexing strategies to improve query performance and reduce data latency.""},{""question"":""Can you explain the concept of ETL and its importance in data integration?"",""example_answer"":""ETL stands for Extract, Transform, Load, and it's a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system. It's essential for data integration as it allows for the consolidation of data from various sources into a single, unified view.""}],""red_flags"":[""Lack of experience with complex SQL data manipulation"",""Inability to work in an agile team environment""],""confidence_score"":90.0}"
"Data Engineer – Senior (Python, SQL, Pyspark)","The Data Engineer is a senior level position responsible for establishing and implementing new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to lead applications systems analysis and programming activities.Responsibilities:

Partner with multiple management teams to ensure appropriate integration of functions to meet goals as well as identify and define necessary system enhancements to deploy new products and process improvements
Resolve variety of high impact problems/projects through in-depth evaluation of complex business processes, system processes, and industry standards
Provide expertise in area and advanced knowledge of applications programming and ensure application design adheres to the overall architecture blueprint
Utilize advanced knowledge of system flow and develop standards for coding, testing, debugging, and implementation
Develop comprehensive knowledge of how areas of business, such as architecture and infrastructure, integrate to accomplish business goals
Provide in-depth analysis with interpretive thinking to define issues and develop innovative solutions
Serve as advisor or coach to mid-level developers and analysts, allocating work as necessary
Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.

Qualifications:

6-10 years of relevant experience in Apps Development or systems analysis role. Pyspark, SQL, and Python
Extensive experience system analysis and in programming of software applications
Experience in managing and implementing successful projects
Subject Matter Expert (SME) in at least one area of Applications Development
Ability to adjust priorities quickly as circumstances dictate
Demonstrated leadership and project management skills
Consistently demonstrates clear and concise written and verbal communication

Education:

Bachelor’s degree/University degree or equivalent experience
See All Jobs","{""role_summary"":""The Data Engineer leads application systems analysis and programming activities, ensuring integration of functions to meet business goals and identifying necessary system enhancements."",""key_terms"":[{""term"":""Pyspark"",""explanation"":""An open-source data processing engine used for large-scale data processing.""},{""term"":""SQL"",""explanation"":""A standard language for managing relational databases.""},{""term"":""Python"",""explanation"":""A high-level programming language used for various applications, including data analysis and machine learning.""},{""term"":""Applications Development"",""explanation"":""The process of designing, building, testing, and maintaining software applications.""}],""skill_priorities"":{""must_have"":[""Pyspark"",""SQL"",""Python"",""Applications Development""],""nice_to_have"":[""Project management skills"",""Leadership skills""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach integrating multiple functions to meet business goals in a complex system?"",""example_answer"":""I would first identify the key stakeholders and their requirements, then analyze the system's current architecture and identify areas for improvement. Next, I would develop a plan to integrate the functions, ensuring that it aligns with the overall business objectives.""},{""question"":""Can you explain how you would optimize the performance of a slow database query?"",""example_answer"":""I would first analyze the query to identify the bottleneck, then consider indexing, caching, or rewriting the query to improve performance. I would also ensure that the solution aligns with the overall system architecture and does not introduce new issues.""}],""red_flags"":[""Lack of experience with Pyspark, SQL, or Python"",""Inability to adjust priorities quickly"",""Poor communication skills""],""confidence_score"":90.0}"
Senior Data Engineer & AI Specialist,"Pharma Medica Research (PMRI) Inc. is a Contract Research Organization that strives for innovation and original solutions in a highly regulated and competitive industry. If your career goals align with innovation and original thinking you will be the perfect candidate to be part of an inclusive, adaptable, and forward-thinking organization. Our reputation for delivering high quality research is outstanding. At PMRI we are committed to making a difference in healthcare and people’s lives. Come join our team!

About the Role
We are looking for an experienced Senior Data Engineer & AI Specialist to join our dynamic team. In this role, you will design, implement, and maintain scalable data solutions leveraging Azure cloud services, Databricks, Snowflake, and BI tools. Your expertise in ETL/ELT pipelines, AI-driven automation, and data visualization will be essential in driving innovation and delivering actionable insights for the business.
This is an exciting opportunity for a data expert who thrives in complex data environments, has a passion for AI & machine learning integration, and enjoys optimizing data architectures for performance and efficiency.

🔹 Key Responsibilities

Data Pipeline Development & Management
Develop scalable ETL/ELT pipelines using Azure Data Factory to process diverse data sources.
Optimize data ingestion, transformation, and orchestration workflows.
Implement error handling, monitoring, and logging mechanisms for data reliability.
Develop custom Azure Functions for specialized data processing.

Azure Data Lake Storage (ADLS) Gen2 Management
Design data lake architecture following best practices (bronze, silver, gold layers).
Implement data partitioning strategies and lifecycle management.
Optimize storage performance and cost, ensuring secure access control.

Data Transformation & Processing
Develop and optimize data transformations using Databricks (PySpark, Scala, SQL) & Snowflake.
Implement Delta Lake for efficient data storage and reliability.
Create dbt models, reusable macros, and automated dbt tests to ensure data quality.
Optimize SQL & Spark queries for performance.

Process Automation & CI/CD
Design automated workflows using Azure Logic Apps & Power Automate.
Implement CI/CD pipelines using Azure DevOps for automated testing and deployment.
Manage schema changes, infrastructure as code (IaC), and automated data quality checks.

Data Visualization & Reporting
Build interactive Power BI dashboards and advanced Tableau visualizations.
Implement row-level security (RLS) & optimized data models for reporting.
Enhance report performance and semantic layer configurations.

🔹 What We’re Looking For

💡 Required Technical Skills
Azure Technologies: Azure Data Factory, Azure Data Lake (ADLS Gen2), Azure DevOps.
Data Engineering & Development: ETL/ELT pipelines, big data processing, cloud architectures.
Programming: Python (PySpark, Pandas, NumPy), SQL (T-SQL, Spark SQL, Snowflake SQL), and Scala.
Databricks & Snowflake Expertise: Performance optimization, security, and data management.
Visualization & Reporting: Power BI (DAX, Power Query, Dataflows) & Tableau (dashboarding, modeling).
DevOps & Automation: Azure DevOps, Git, YAML pipelines, PowerShell, CLI automation.

🎓 Required Experience & Qualifications
7+ years of experience in data engineering, analytics, or related fields.
Bachelor’s degree in Computer Science, Engineering, or a related discipline.
Preferred Azure certifications:
Azure Data Engineer Associate
Azure Solutions Architect
Power BI Data Analyst

🔍 Preferred Skills (Nice to Have)
Experience in AI/ML integration, including NLP, Generative AI, or predictive analytics.
Familiarity with data governance frameworks and privacy regulations (GDPR, HIPAA, etc.).
Understanding of modern data architectures (Data Mesh, ELT vs. ETL, Snowflake best practices).
Strong agile project management and leadership skills.

We offer:
Competitive compensation plan
A benefit plan that is fully paid for by PMRI, including healthcare, dentalcare, vision care, LTD, Life Insurance, AD&D, along with a Health Spending and Wellness Spending Accounts and a voluntary RRSP Contribution Plan
Opportunities for advancement and career progression
A generous Employee Milestones Awards Program
Corporate Discounts Program
Learning Support Programs
Friendly atmosphere, culture of learning

Please note all applications must be eligible to work within Canada.
PMRI is an Equal Opportunity Employer; promoting accessibility and inclusivity at work and offering accommodation for applicants as required and requested.
We thank all applicants for their interest; however, only those selected to proceed in the interview process will be contacted.","{""role_summary"":""Design, implement, and maintain scalable data solutions leveraging Azure cloud services, Databricks, Snowflake, and BI tools as a Senior Data Engineer & AI Specialist."",""key_terms"":[{""term"":""ETL/ELT pipelines"",""explanation"":""Extract, Transform, Load/Extract, Load, Transform pipelines for data processing and integration.""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service for creating, scheduling, and managing data pipelines.""},{""term"":""Databricks"",""explanation"":""A unified analytics platform for data engineering, data science, and data analytics.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and processing large datasets.""},{""term"":""Azure Data Lake Storage (ADLS) Gen2"",""explanation"":""A highly scalable and secure data lake storage solution for storing and processing large datasets.""},{""term"":""Delta Lake"",""explanation"":""An open-source storage layer that brings reliability and performance to data lakes.""},{""term"":""dbt"",""explanation"":""A data transformation tool for data modeling, testing, and documentation.""},{""term"":""Azure Logic Apps"",""explanation"":""A cloud-based workflow automation platform for integrating applications and services.""},{""term"":""Power Automate"",""explanation"":""A cloud-based workflow automation platform for automating repetitive tasks and processes.""},{""term"":""Azure DevOps"",""explanation"":""A set of cloud-based services for collaborative software development, delivery, and deployment.""},{""term"":""Power BI"",""explanation"":""A business analytics service for data visualization, business intelligence, and reporting.""},{""term"":""Tableau"",""explanation"":""A data visualization tool for business intelligence, analytics, and reporting.""}],""skill_priorities"":{""must_have"":[""Azure Technologies"",""Data Engineering & Development"",""Programming (Python, SQL, Scala)"",""Databricks & Snowflake Expertise"",""Visualization & Reporting (Power BI & Tableau)"",""DevOps & Automation (Azure DevOps, Git, YAML pipelines)""],""nice_to_have"":[""AI/ML integration"",""Data governance frameworks and privacy regulations"",""Modern data architectures (Data Mesh, ELT vs. ETL, Snowflake best practices)"",""Agile project management and leadership skills""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize data ingestion, transformation, and orchestration workflows in Azure Data Factory?"",""example_answer"":""I would use Azure Data Factory's built-in optimization features, such as data partitioning, parallel processing, and caching, to improve data ingestion, transformation, and orchestration workflows.""},{""question"":""Can you explain how you would implement error handling, monitoring, and logging mechanisms for data reliability in Azure Data Factory?"",""example_answer"":""I would use Azure Data Factory's built-in error handling mechanisms, such as retry policies and error outputs, and implement custom logging and monitoring solutions using Azure Monitor and Azure Log Analytics.""},{""question"":""How would you design automated workflows using Azure Logic Apps and Power Automate?"",""example_answer"":""I would use Azure Logic Apps' visual interface to design workflows, and Power Automate's automation capabilities to integrate with other Azure services, such as Azure Data Factory and Azure DevOps.""}],""red_flags"":[""Lack of experience with Azure cloud services and Databricks"",""Inability to optimize data architectures for performance and efficiency"",""Limited knowledge of data governance frameworks and privacy regulations""],""confidence_score"":95.0}"
Big Data Developer,"Inclusion without Exception
Tata Consultancy Services (TCS) is an equal opportunity employer, and embraces diversity in race, nationality, ethnicity, gender, age, physical ability, neurodiversity, and sexual orientation, to create a workforce that reflects the societies we operate in. Our continued commitment to Culture and Diversity is reflected in our people’s stories across our workforce and implemented through equitable workplace policies and processes.

About TCS
TCS is an IT services, consulting, and business solutions organization that has been partnering with many of the world’s largest businesses in their transformation journeys for over 55 years. Its consulting-led, cognitive-powered portfolio of business, technology, and engineering services and solutions is delivered through its unique Location Independent Agile™ delivery model, recognized as a benchmark of excellence in software development. A part of the Tata group, India's largest multinational business group, TCS employs over 612,000 of the world’s best-trained consultants in 55 countries. The company generated consolidated revenues of US $29 billion in the fiscal year ended March 31, 2024, [BS1] and is listed on the BSE and the NSE in India. TCS' proactive stance on climate change and award-winning work with communities across the world have earned it a place in leading sustainability indices such as the MSCI Global Sustainability Index and the FTSE4Good Emerging Index.

Job Description:
Role Description:
Design high quality deliverables adhering to business requirements with defined standards and design principles and patterns.
Develop and maintain highly scalable, high performance Data transformation applications using Apache Spark framework.
Develop/Integrate the code adhering to CI/CD, using Spark Framework in Scala/Java. Provide solutions to big data problems dealing with huge volumes of data using Spark based data transformation solutions, Hive, MPP processes like IMPALA.
Create Junit tests and ensure code coverage is met as per the agreed standards.
Should be able to work with a team who might be geographically distributed.
Review the code modules developed by other juniors.

Required Skill Sets
Hands-on development experience in programming languages such as JAVA, SCALA using Maven, Apache Spark Frameworks and Unix Shell scripting.
Should be comfortable with Unix File system as well as HDFS commands.
Should have worked on query languages such as Oracle SQL, Hive SQL, Spark SQL, Impala, HBase DB.
Should be flexible and should have good communication and customer management skills.

Desired Skill Set
Should have knowledge on Big data Data Ingestion tools such as SQOOP and KAFKA.
Should be aware of the components in Big Data ecosystem.
Should have worked on building projects using Eclipse IDE, Tectia Client, Oracle SQL Developer.

Tata Consultancy Services Canada Inc. is committed to meeting the accessibility needs of all individuals in accordance with the Accessibility for Ontarians with Disabilities Act (AODA) and the Ontario Human Rights Code (OHRC). Should you require accommodation during the recruitment and selection process, please inform Human Resources.

Thank you for your interest in TCS. Candidates that meet the qualifications for this position will be contacted within a 2-week period. We invite you to continue to apply for other opportunities that match your profile.","{""role_summary"":""Design and develop high-quality data transformation applications using Apache Spark, ensuring scalability and performance, and collaborating with a geographically distributed team."",""key_terms"":[{""term"":""Apache Spark"",""explanation"":""An open-source data processing engine for large-scale data processing.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a software development practice that automates testing, building, and deployment of code changes.""},{""term"":""HDFS"",""explanation"":""Hadoop Distributed File System, a distributed file system for storing and managing large amounts of data.""},{""term"":""Impala"",""explanation"":""A high-performance, distributed SQL engine for querying large datasets.""},{""term"":""Maven"",""explanation"":""A software project management and build tool for Java-based projects.""},{""term"":""Scala"",""explanation"":""A programming language that runs on the Java Virtual Machine, used for building scalable and concurrent systems.""}],""skill_priorities"":{""must_have"":[""JAVA"",""SCALA"",""Apache Spark"",""Unix Shell scripting"",""Oracle SQL"",""Hive SQL"",""Spark SQL"",""Impala"",""HBase DB""],""nice_to_have"":[""Big data Data Ingestion tools (SQOOP, KAFKA)"",""Big Data ecosystem components"",""Eclipse IDE"",""Tectia Client"",""Oracle SQL Developer""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data transformation applications for scalability and performance using Apache Spark?"",""example_answer"":""I would use Spark's built-in optimization techniques, such as caching and parallel processing, and ensure that the data is properly partitioned and distributed across the cluster.""},{""question"":""Can you explain the importance of CI/CD in a distributed development environment?"",""example_answer"":""CI/CD ensures that code changes are automatically tested, built, and deployed, reducing the risk of errors and improving collaboration among team members, especially in a geographically distributed team.""}],""red_flags"":[""Lack of experience with Apache Spark or Scala"",""Inability to work with a geographically distributed team""],""confidence_score"":90.0}"
Software Engineer (New Grad),"The Software Engineer applies the principles of software engineering to design, develop, test, and maintain our OSI software products. The Software Engineer has the primary responsibility to provide a successful implementation of the assigned software modules. The Software Engineer will collaborate with a team of multidisciplinary engineers and stakeholders to ensure the successful delivery of our software products to our end users and customers. Our Engineers have a focus on collaboration, and assist their team with devising innovative technical solutions and removing roadblocks. As a group, the engineers work together to complete software development activities through the full software lifecycle. To do this the Software Engineer must demonstrate strong communication skills and interpersonal skills. The OSI Software Engineer exhibits professionalism, integrity, and ownership.

RESPONSIBILITIES
Follows the SDLC, Software Development Lifecycle using Software Engineering best practices as described in the OSI documented processes and training. Follows the coding standards and best practices to write high quality source code in C and C++. Participates in peer reviews of the source code and ensures all development is maintained in the version control repository.
Prepares software specifications and manages requirements for new software features.
Produces software detailed designs and makes regular updates to the design documents when changes are made.
Maintains the code by correcting defects (bugs) and troubleshooting system problem reports and customer tickets.
Demonstrates full ownership for their work, resolving road blocks, and communicates deadlines and technical challenges to their Technical Lead or Manager.
Produces software estimates and participates in technical work breakdown and defining scope.
Identifies, analyses, and resolves diverse software technical challenges.
Commits to project objectives and meeting the project schedule and budgets.
Provides technical expertise and reviews of documentation including the publications developed by the Technical Publication group.
Produces software technical documentation which supports the project or department needs.
May participate in the concept phase including the creation of prototypes or use cases.
May support the Test Team activities including running test procedures and supporting lab setup or deployment may assistance is required.
Provides technical guidance and mentoring to new staff including participation in onboarding and the buddy program.
May interface and provide support and assistance to customers while visiting sites or ships.
Demonstrates professionalism when interfacing with customer and prioritizes customer requests.
Commits to prioritizing and correcting Usability, Safety and Security concerns.
Complies with OSI’s established ISO-9001-compliant development guidelines and standards
Follows and ensures workplace operating and environmental, health and safety procedures and guideline

KNOWLEDGE & QUALIFICATIONS
Education: Degree in Computer Science, Software, Electrical or Computer Engineering, Engineering Physics or Mathematics.
Experience: 0-3 years’ experience in a software environment; experience in developing real-time interfaces to external systems; experience working in an ISO 9001 compliant software engineering environment would be an asset; experience in the defense or aerospace domains is an asset
Technical Skills: Experience in C/C++ development under Windows; Experience in areas such as 2D/3D graphics,
Open GL, TCP/IP, GPS, UDP Multicast, and real-time systems are highly desirable; ability to understand and work with complex software requirement specifications; strong theoretical and algorithmic background with experience in mathematical and/or geospatial applications; ability to assist with analysis and design of solutions for algorithmically complex requirements; Ability to learn quickly
Soft Skills: Excellent verbal and written communication skills
Uses strong communication skills to ask questions, provide technical solutions and help build a strong team environment
Ability to work well under pressure in a high paced, challenging environment; strong team work skills; takes full ownership of any mistakes that are made and corrects the situation.
Other: Required to obtain security clearance; occasional travel; knowledge of marine navigation concepts and systems is an asset","{""role_summary"":""Design, develop, test, and maintain OSI software products, collaborating with a multidisciplinary team to ensure successful delivery to end users and customers."",""key_terms"":[{""term"":""SDLC"",""explanation"":""Software Development Lifecycle, a process used to design, develop, and test software products.""},{""term"":""OSI documented processes"",""explanation"":""The company's established guidelines and standards for software development.""},{""term"":""ISO-9001-compliant development guidelines"",""explanation"":""International Organization for Standardization guidelines for quality management systems in software development.""},{""term"":""Real-time interfaces"",""explanation"":""Software interfaces that process and respond to data in real-time, often used in systems that require immediate feedback.""},{""term"":""2D/3D graphics"",""explanation"":""Computer-generated images and graphics used to visualize and interact with data in two or three dimensions.""},{""term"":""Open GL"",""explanation"":""A cross-language, cross-platform application programming interface for rendering 2D and 3D vector graphics.""},{""term"":""TCP/IP"",""explanation"":""A set of communication protocols used to interconnect devices on the internet.""},{""term"":""GPS"",""explanation"":""Global Positioning System, a network of satellites that provide location information to GPS receivers.""},{""term"":""UDP Multicast"",""explanation"":""A method of sending data packets to multiple recipients on a network using the User Datagram Protocol.""}],""skill_priorities"":{""must_have"":[""C/C++ development under Windows"",""Strong communication skills"",""Ability to work in an ISO 9001 compliant software engineering environment""],""nice_to_have"":[""Experience in 2D/3D graphics, Open GL, TCP/IP, GPS, UDP Multicast, and real-time systems"",""Experience in the defense or aerospace domains"",""Knowledge of marine navigation concepts and systems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of following SDLC in software development?"",""example_answer"":""Following SDLC ensures that software is developed in a structured and phased approach, reducing errors and improving overall quality.""},{""question"":""How would you approach debugging a complex issue in a real-time system?"",""example_answer"":""I would use a systematic approach to identify the root cause, isolate the issue, and then develop and test a solution, ensuring minimal impact on the system.""},{""question"":""How do you prioritize and manage multiple tasks with competing deadlines?"",""example_answer"":""I would use project management tools and techniques to prioritize tasks, allocate resources, and communicate with stakeholders to ensure timely delivery.""}],""red_flags"":[""Lack of experience in C/C++ development under Windows"",""Inability to work in an ISO 9001 compliant software engineering environment"",""Poor communication skills""],""confidence_score"":90.0}"
Azure Data Engineer (Databricks Expert),"Role : Azure Data Engineer (Databricks Expert)
Location : Toronto, ON
Hire Type : Full-Time with Eviden

Job Description:
About the Role:
We are seeking a highly skilled and experienced Senior Azure Data Engineer to join team and tackle critical performance challenges within Azure data platform. You will play a pivotal role in optimizing and re-architecting key components of data infrastructure, directly impacting the performance and scalability of core data marts. This is not a maintenance role; this is a chance to make a significant impact by redesigning and implementing solutions for a high-visibility project.
Responsibilities:
Performance Optimization: Lead the performance tuning and optimization of Azure-based data pipelines, specifically addressing the current bottleneck where processing 1000 records takes 40 minutes. This requires a deep understanding of Azure Data Factory (ADF), Databricks (Spark), and data processing best practices.
Architecture Review and Redesign: Evaluate the existing Azure data platform architecture, identify bottlenecks and design flaws, and propose and implement solutions for a more efficient and scalable system. This will involve working with Delta tables and optimizing data storage and retrieval.
Databricks Expertise: Utilize your advanced PySpark skills, particularly with structured streaming, to re-engineer data transformation and processing logic within Databricks. The ideal candidate will have a proven track record of optimizing Spark jobs for performance.
Data Integration: Work with Azure Data Lake Storage (ADLS), Azure Data Factory (ADF), Azure Database (DB), and file exchange processes (batch mode) to ensure seamless data flow and integration.
MDM Integration (Desirable): Contribute to the ongoing development and optimization of Master Data Management (MDM) system, which follows a hub-and-spoke architecture. Experience with large-scale MDM implementations is highly desirable.
Collaboration: Work closely with other engineers, business stakeholders, and vendors to understand requirements, communicate progress, and ensure successful project delivery. You will be expected to mentor and guide other team members.
Qualifications:
Minimum experience of implementing 2 projects on Azure data platform
Minimum experience of around 8-12 years
""Ninja"" Level Expertise: A proven track record of success in optimizing and scaling Azure data platforms, particularly with Databricks and Spark. We are looking for an expert who can quickly diagnose and resolve complex performance issues.
Deep Azure Knowledge: Extensive experience with Azure Data Factory (ADF), Azure Data Lake Storage (ADLS), Azure Synapse, Event hub, and other relevant Azure services. Experience with Azure SaaS offerings is a plus.
Databricks Mastery: Advanced proficiency in PySpark and structured streaming. Demonstrated ability to write and optimize complex Spark queries for performance.
Data Warehousing and MDM: Solid understanding of data warehousing principles and experience with Master Data Management (MDM) implementations, preferably with a hub-and-spoke architecture.
Problem-Solving Skills: Exceptional analytical and problem-solving skills, with the ability to identify root causes of performance bottlenecks and design effective solutions.
Communication Skills: Excellent communication and collaboration skills, with the ability to work effectively 1 with both technical and non-technical 2 stakeholders.
Desirable:
Experience with AI Search and Cosmos DB.
Experience with Informatica MDM in an Azure environment.","{""role_summary"":""Lead the optimization and re-architecture of Azure data infrastructure, ensuring high performance and scalability of core data marts."",""key_terms"":[{""term"":""Databricks"",""explanation"":""A unified analytics platform that provides data engineering, data science, and data analytics capabilities.""},{""term"":""Spark"",""explanation"":""An open-source data processing engine for large-scale data processing.""},{""term"":""PySpark"",""explanation"":""A Python library for Spark that allows users to write Spark applications using Python.""},{""term"":""Azure Data Factory (ADF)"",""explanation"":""A cloud-based data integration service that allows users to create, schedule, and manage data pipelines.""},{""term"":""Delta tables"",""explanation"":""An open-source storage layer that provides ACID transactions, scalable metadata handling, and unified streaming and batch data processing.""},{""term"":""Master Data Management (MDM)"",""explanation"":""A method of managing an organization's critical data entities in a unified and consistent manner.""}],""skill_priorities"":{""must_have"":[""Azure Data Factory (ADF)"",""Databricks"",""Spark"",""PySpark"",""Azure Data Lake Storage (ADLS)"",""Data warehousing principles"",""Problem-solving skills"",""Communication skills""],""nice_to_have"":[""AI Search"",""Cosmos DB"",""Informatica MDM"",""Azure SaaS offerings""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize the performance of an Azure-based data pipeline that takes 40 minutes to process 1000 records?"",""example_answer"":""I would analyze the pipeline's architecture, identify bottlenecks, and apply optimization techniques such as parallel processing, data partitioning, and caching. I would also leverage Databricks' capabilities, such as structured streaming, to improve performance.""},{""question"":""Can you explain how you would redesign an existing Azure data platform architecture to improve scalability and efficiency?"",""example_answer"":""I would evaluate the current architecture, identify design flaws, and propose a new design that incorporates best practices for data processing, storage, and retrieval. I would also consider using Delta tables and optimizing data storage and retrieval.""}],""red_flags"":[""Lack of experience with Databricks and Spark"",""Inability to optimize complex Spark queries for performance"",""Limited understanding of data warehousing principles and MDM implementations""],""confidence_score"":95.0}"
"Data Enginner- Databricks, ADF, Snowflake, Pyspark, SQL -Canada/Hybrid","Montreal/Toronto, Canada/Hybrid

Databricks, ADF, Snowflake, Pyspark, SQL

7-10 years

Collaborate with stakeholders to understand requirements, data solutions, data models and mapping documents.
Lead the design, development, and implementation of data solutions using Azure Data Lake Storage (ADLS), Azure Data Factory, Event Hub, Databricks, and Snowflake.
Oversee the end-to-end data pipeline, ensuring data quality, integrity, and security.
Lead the deployment activities including the Dev test approval, PR approval, Collaboration with DevOps team, Release mgmt. for deployment into all environments including production and provide knowledge sharing to Data operations team
Assist data analysts with technical input.
Provide data engineering inputs to the data solution architect.
Lead the effort estimates/story point estimates for the sprint.
Mentor and guide a team of data engineers.
Foster a collaborative environment to encourage knowledge sharing and continuous improvement.

Conduct code reviews and ensure adherence to coding standards and best practices.","{""role_summary"":""Lead the design, development, and implementation of data solutions, ensuring data quality, integrity, and security, while collaborating with stakeholders and mentoring a team of data engineers."",""key_terms"":[{""term"":""Azure Data Lake Storage (ADLS)"",""explanation"":""A cloud-based storage solution for storing and processing large amounts of data.""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service for creating, scheduling, and managing data pipelines.""},{""term"":""Event Hub"",""explanation"":""A fully managed, real-time data ingestion service that can handle large volumes of data.""},{""term"":""Databricks"",""explanation"":""A unified analytics platform that provides data engineering, data science, and data analytics capabilities.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and processing large amounts of data.""},{""term"":""Pyspark"",""explanation"":""A Python library for big data processing that provides high-level APIs for Spark programming.""},{""term"":""SQL"",""explanation"":""A standard language for managing and manipulating data in relational database management systems.""}],""skill_priorities"":{""must_have"":[""Databricks"",""Azure Data Factory"",""Snowflake"",""Pyspark"",""SQL""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data quality and integrity in a data pipeline?"",""example_answer"":""I use data validation and data quality checks at each stage of the pipeline to ensure data accuracy and completeness. I also implement data lineage and data provenance to track data origin and movement.""},{""question"":""Can you explain the difference between Azure Data Lake Storage and Azure Blob Storage?"",""example_answer"":""Azure Data Lake Storage is optimized for big data analytics and provides features like data cataloging, data governance, and data security, whereas Azure Blob Storage is a general-purpose object store for storing and serving large amounts of unstructured data.""}],""red_flags"":[""Lack of experience with cloud-based data engineering technologies"",""Inability to lead and mentor a team of data engineers""],""confidence_score"":90.0}"
ETL Developer/Specialist,"Requirements
Experience and Skillset Requirements
Mandatory Requirements

5+ years working experience of Microsoft (MS) Azure Cloud technology especially MS Dynamics 365 Customer Relationship Management (CRM) and Enterprise Resource Planning (ERP) applications such as Customer Engagement and Finance & Operations, PowerApps, Power Automate and Power BI, Data Factory and Data Pipelines.
5+ years of proven working experience in integrating various data sources and systems, both on-premises and in the cloud, using Azure ETL services or other ETL tools.
5+ years of experience working on, preferably leading, testing teams and efforts.
In-depth knowledge of integration technologies commonly used with Dynamics, such as DataVerse, Data Entities, and APIs.
Understanding of data pipeline architectures, Azure workflow orchestration tools, and concepts related to data ingestion, transformation, and movement.
Proficiency in Azure Data Factory, Azure Synapse workspaces
Strong SQL skills and experience working with Azure SQL Databases and Dataverse; good understanding of Azure storage concepts and technologies.
Proficiency in Azure-specific scripting using PowerShell or Azure CLI, .NET, C#, Power Platform, Logic Apps
Expert proficiency with data manipulation languages (T-SQL, PL/SQL), data definition languages, physical database design, data modeling, query performance analysis & tuning

Nice-to-Have Skills and Experience

Azure cloud certifications (e.g., Azure Administrator, Azure Developer, Azure Data Engineer, Azure Database Administrator)
Knowledge of integration technologies commonly used with Dynamics, such as DataVerse, Data Entities, and APIs.
Experience with continuous integration/continuous deployment (CI/CD) processes around DevOps, data workflows, Synapse workspaces.
CV to be shared at sweta@maarutinc.com","{""role_summary"":""Lead the integration of various data sources and systems, both on-premises and in the cloud, using Azure ETL services or other ETL tools, and work on testing teams and efforts."",""key_terms"":[{""term"":""MS Dynamics 365 Customer Relationship Management (CRM)"",""explanation"":""A customer relationship management application that provides sales, marketing, and customer service capabilities.""},{""term"":""Enterprise Resource Planning (ERP)"",""explanation"":""A type of software that helps organizations manage their business operations and automate back-office functions.""},{""term"":""PowerApps"",""explanation"":""A low-code development platform that enables users to create custom business applications.""},{""term"":""Power Automate"",""explanation"":""A cloud-based workflow automation and integration platform that helps automate repetitive tasks and processes.""},{""term"":""Power BI"",""explanation"":""A business analytics service that provides interactive visualizations and business intelligence capabilities.""},{""term"":""Data Factory"",""explanation"":""A cloud-based data integration service that helps create, schedule, and manage data pipelines.""},{""term"":""Data Pipelines"",""explanation"":""A series of processes that extract, transform, and load data from various sources to a target system.""},{""term"":""Azure ETL services"",""explanation"":""A set of cloud-based services that enable the extraction, transformation, and loading of data from various sources.""},{""term"":""DataVerse"",""explanation"":""A cloud-based data storage and management platform that provides a unified view of data across an organization.""},{""term"":""Azure Synapse workspaces"",""explanation"":""A cloud-based analytics platform that integrates data warehousing, big data analytics, and data integration.""},{""term"":""Azure SQL Databases"",""explanation"":""A cloud-based relational database service that provides a managed database platform.""},{""term"":""Azure storage concepts"",""explanation"":""A set of cloud-based storage services that provide secure, durable, and scalable storage for data.""},{""term"":""PowerShell"",""explanation"":""A task automation and configuration management framework from Microsoft.""},{""term"":""Azure CLI"",""explanation"":""A command-line tool that provides a set of commands for managing Azure resources.""},{""term"":""T-SQL"",""explanation"":""A set of extensions to SQL that provide additional functionality for managing and manipulating data in relational databases.""},{""term"":""PL/SQL"",""explanation"":""A procedural language that provides a set of features for managing and manipulating data in relational databases.""}],""skill_priorities"":{""must_have"":[""MS Azure Cloud technology"",""MS Dynamics 365 Customer Relationship Management (CRM)"",""Enterprise Resource Planning (ERP)"",""PowerApps"",""Power Automate"",""Power BI"",""Data Factory"",""Data Pipelines"",""Azure ETL services"",""DataVerse"",""Azure Synapse workspaces"",""Azure SQL Databases"",""Azure storage concepts"",""PowerShell"",""Azure CLI"",""T-SQL"",""PL/SQL""],""nice_to_have"":[""Azure cloud certifications"",""CI/CD processes around DevOps"",""Data workflows"",""Synapse workspaces""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would integrate various data sources and systems using Azure ETL services or other ETL tools?"",""example_answer"":""I would use Azure Data Factory to create a data pipeline that extracts data from various sources, transforms the data using Azure Synapse workspaces, and loads it into a target system such as Azure SQL Databases.""},{""question"":""How do you optimize the performance of a data pipeline in Azure?"",""example_answer"":""I would use Azure Data Factory's built-in optimization features, such as data caching and parallel processing, to improve the performance of the data pipeline. I would also monitor the pipeline's performance using Azure Monitor and make adjustments as needed.""}],""red_flags"":[""Lack of experience with MS Dynamics 365 Customer Relationship Management (CRM) and Enterprise Resource Planning (ERP) applications"",""Inability to integrate various data sources and systems using Azure ETL services or other ETL tools""],""confidence_score"":90.0}"
Data Engineering Analyst,"Requisition ID: 187935

Career Group: Corporate Office Careers

Job Category: Data Science - Merchandising

Travel Requirements: 0 - 10%

Job Type: Full-Time

Country: Canada (CA)

Province: Ontario

City: Toronto

Location: Sobeys Innovation Hub

Embark on a rewarding career with Sobeys Inc., celebrated among Canada’s Top 100 employers, where your talents contribute to our commitment to excellence and community impact.

Our family of 128,000 employees and franchise affiliates share a collective passion for delivering exceptional shopping experiences and amazing food to all our customers. Our mission is to nurture the things that make life better – great experiences, families, communities, and our employees. We are a family nurturing families.

A proudly Canadian company, we started in a small town in Nova Scotia but we are now in communities of all sizes across this great country. With over 1,600 stores in all 10 provinces, you may know us as Sobeys, Safeway, IGA, Foodland, FreshCo, Thrifty Foods, Lawtons Drug Stores or another of our great banners but we are all one extended family.

Ready to Make an impact?

Job title - Data Engineering Analyst

Location: Sobeys COLAB Office (Toronto Downtown)

Team: Advanced Analytics

The Advanced Analytics team at Sobeys operates on the frontlines of retail innovation. We are a multi-disciplinary team of data scientists, engineers, developers, and analysts who design, develop, and deploy high-impact, scalable ML/AI solutions that are fundamentally transforming how Sobeys and its family of banners interact with customers and plan and operate their businesses. We leverage the latest cloud tech and advanced analytical techniques to connect the dots between customer behaviour and business operations and unearth the true drivers of customer engagement, sales growth, and profitability. Our work directly impacts the daily lives of millions of Canadian consumers and is a key pillar in our mission to deliver a best-in-class shopping experience for our customers.

In this role, you’ll have the chance to roll up your sleeves and apply data engineering methods and analytics to real-world business situations in one of the biggest retailers in Canada. The Data Engineer will play a key role in enhancing our advanced analytics and machine learning capabilities within the organization

Responsibilities

Here’s where you’ll be focusing:

Maintaining, streamlining and hardening existing data pipelines, from ingestion, through ETL and batch processing in order to reliably process billions of records per day.
Build data support for our personalization and experimentation efforts, solving problems from statistical test automation to building real-time M/L applications.
Working with Analytics and Product Management to ensure optimal data design and efficiency.
Assisting Data Analysts and Data Scientists with pipeline and model deployment
Use an analytical, data-driven approach to drive a deep understanding of our fast-changing business.
Building data models to deliver insightful analytics while ensuring the highest standard in data integrity.

Qualifications

What you have to offer:

Bachelor’s or higher degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance or related quantitative field, or equivalent practical experience.
Experience on back-end data infrastructure in cloud, preferably like Databricks, Azure, Airflow, Snowflake
Ability to build, debug, optimize, monitor of large and complex spark data pipelines comprising of complex UDF.
Experience with SQL and SQL-like languages (2 year+)
Experience on cloud-based CI/CD infrastructure e.g. Azure DevOps, Jenkins, MLOps exposure. (2 year +)
Proficiency with at least one of the following languages: Java, Python, Scala. (Python is preferred) (2 year+)
Proficiency with Spark and Hadoop/YARN environment and comfortable with Linux operating system
Ability to creatively solve problems in a fast paced, rapidly changing environment
Ability to navigate ambiguity, drive solutions forward and bring stakeholders along.
Strong problem solving, analytical skills and capability of managing multiple projects and reporting simultaneously across different stakeholders.
Strong structured thinking and the ability to easily break down complex ambiguous problems and propose impactful data modeling designs.

At Sobeys we require our teammates to have the ability to adhere to a hybrid work model that requires your presence at one of our office locations at least three days per week. This requirement is integral to our commitment to team collaboration and the overall success of our office culture.

We offer a comprehensive Total Rewards package, which varies by role and designed to help our teammates to live better – physically, financially and emotionally.

Some websites share our job opportunities and may provide salary estimates without our knowledge. These estimates are based on similar jobs and postings for general comparison, but these numbers are not provided by our organization nor monitored for accuracy.

We will consider factors such as your working location, work experience and skills as well as internal equity, and market conditions to ensure the selected candidate is paid fairly and competitively. We look forward to discussing the specific compensation details relevant to this role with candidates who are selected to move forward in the recruitment process.

Our Total Rewards programs, for full-time teammates, goes well beyond your paycheque:

Competitive Benefits Package, tailored to meet your needs, including health and dental coverage, life, short- and long-term disability insurance.
Access to Virtual Health Care Platform and Employee and Family Assistance Program.
A Retirement and Savings Plan that provides you with the opportunity to build and add value to your savings.
A 10% in-store discount at our participating banners and access to a wide range of other discount programs, making your purchases more affordable.
Learning and Development Resources to fuel your professional growth.
Parental leave top-up
Paid Vacation and Days-off

We are committed to accommodating applicants with disabilities throughout the hiring process and will work with applicants requesting accommodation at any stage of this process.","{""role_summary"":""The Data Engineering Analyst will apply data engineering methods and analytics to real-world business situations, enhancing advanced analytics and machine learning capabilities within the organization."",""key_terms"":[{""term"":""ML/AI solutions"",""explanation"":""Machine Learning and Artificial Intelligence solutions that are used to transform how Sobeys interacts with customers and operates its business.""},{""term"":""Cloud tech"",""explanation"":""Cloud technology used for data processing and analytics, such as Databricks, Azure, and Snowflake.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load process used for data pipeline management.""},{""term"":""Spark data pipelines"",""explanation"":""Data pipelines built using Apache Spark for large-scale data processing.""},{""term"":""CI/CD infrastructure"",""explanation"":""Continuous Integration and Continuous Deployment infrastructure used for automated testing and deployment of code changes.""}],""skill_priorities"":{""must_have"":[""Experience with back-end data infrastructure in cloud"",""Ability to build, debug, optimize, monitor large and complex spark data pipelines"",""Experience with SQL and SQL-like languages"",""Proficiency with at least one of the following languages: Java, Python, Scala"",""Proficiency with Spark and Hadoop/YARN environment and comfortable with Linux operating system""],""nice_to_have"":[""Experience with Databricks, Azure, Airflow, Snowflake"",""Experience with cloud-based CI/CD infrastructure e.g. Azure DevOps, Jenkins, MLOps""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize a complex Spark data pipeline for better performance?"",""example_answer"":""I would use Spark's built-in optimization techniques such as caching, broadcasting, and predicate pushdown. I would also consider re-partitioning the data, using more efficient data structures, and optimizing the Spark configuration.""},{""question"":""Can you explain how you would design a data model to deliver insightful analytics while ensuring data integrity?"",""example_answer"":""I would follow a structured approach to data modeling, starting with understanding the business requirements and identifying the key performance indicators. I would then design a data model that ensures data integrity through data validation, data normalization, and data quality checks.""}],""red_flags"":[""Lack of experience with cloud-based data infrastructure"",""Inability to work with complex Spark data pipelines"",""Limited proficiency with SQL and SQL-like languages""],""confidence_score"":90.0}"
Software Engineer (Intern),"Software Engineer (Intern) | naptha.ai

About This Role

We are seeking exceptional Software Engineering interns to join Naptha AI and contribute to building the future of AI agent infrastructure. This internship offers hands-on experience working with frontier AI technology, backed by industry veterans and technical leaders through NVIDIA Inception, Google for Startups, and Microsoft for Startups.

We're building the foundational infrastructure for the next wave of AI companies, enabling frontier AI developers to build products powered by enormous networks of highly capable next-generation AI agents. As an Engineering Intern, you'll work directly with our technical team on real projects that impact our core platform.

What You'll Do

Build and improve components of our agent infrastructure
Work on real features that ship to production
Collaborate with experienced engineers and researchers
Learn about large-scale AI systems and infrastructure
Contribute to our agent development platform
Gain experience with cutting-edge AI tools and frameworks

Technical Areas

Backend development with Python and modern frameworks
Agent system implementation and testing
API development and integration
Performance optimization and monitoring
Infrastructure and tooling development
Testing and deployment automation

Requirements

Currently pursuing BS/MS in Computer Science or related field
Strong programming skills, particularly in Python
Basic understanding of AI/ML concepts
Experience with software development practices
Ability to work independently and learn quickly
Strong problem-solving abilities

Nice to Have

Experience with AI frameworks or tools
Familiarity with distributed systems
Open source contributions
Experience with developer tools
Interest in AI infrastructure

About The Internship

Duration: 12-16 weeks
Location: Remote
Competitive compensation
Real-world project ownership
Mentorship from experienced engineers
Opportunity for return offers

This internship offers a unique opportunity to work on cutting-edge AI infrastructure while learning from experienced technical leaders. You'll gain practical experience building systems that power the next generation of AI applications.","{""role_summary"":""Contribute to building AI agent infrastructure as a software engineering intern, working on real projects that impact the core platform, and gaining experience with cutting-edge AI tools and frameworks."",""key_terms"":[{""term"":""AI agent infrastructure"",""explanation"":""The underlying systems and tools that enable the development and deployment of AI applications.""},{""term"":""Frontier AI technology"",""explanation"":""Advanced AI technology that is at the forefront of innovation and development.""},{""term"":""API development and integration"",""explanation"":""The process of building and connecting application programming interfaces (APIs) to enable data exchange between systems.""},{""term"":""Distributed systems"",""explanation"":""Systems that consist of multiple components or nodes that work together to achieve a common goal, often distributed across different locations.""}],""skill_priorities"":{""must_have"":[""Python programming skills"",""Basic understanding of AI/ML concepts"",""Experience with software development practices"",""Ability to work independently and learn quickly"",""Strong problem-solving abilities""],""nice_to_have"":[""Experience with AI frameworks or tools"",""Familiarity with distributed systems"",""Open source contributions"",""Experience with developer tools"",""Interest in AI infrastructure""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach optimizing the performance of a large-scale AI system?"",""example_answer"":""I would start by identifying performance bottlenecks using profiling tools, then apply optimization techniques such as caching, parallel processing, or model pruning to improve efficiency.""},{""question"":""Can you explain the concept of distributed systems and how they are used in AI applications?"",""example_answer"":""Distributed systems are networks of nodes that work together to achieve a common goal. In AI, they are used to scale machine learning models, enable real-time processing, and improve overall system resilience.""}],""red_flags"":[""Lack of experience with Python or AI/ML concepts"",""Inability to work independently or learn quickly""],""confidence_score"":90.0}"
"Senior Software Engineer, Admin Area","The Product team builds features end-to-end. From designing our data models to implementing the subtle interaction behaviors that differentiate good software from great software. We work closely with UI designers and are supported by our infrastructure team. We aim to delight users with both large new features and smaller, daily product enhancements—thanks to our continuous deployment architecture. We want to create a superlative user experience, down to the smallest details.

We are looking for a Senior Software Engineer to join the Data Management team in our Vancouver Office. The team plays a vital role in understanding the Asana data graph and ensuring the integrity and compliant use of data across the product. You’ll work on essential features touching the entire customer data lifecycle, such as data exports, object archiving, trashing & recovery, and audit logs. All of these are fundamental for Enterprise customers and involve handling and managing large-scale datasets to ensure smooth and secure operations.

Being part of this team will provide you with the opportunity to dive deep into Asana’s data graph, gaining a deep understanding of how data is managed at scale. While compliance is a key focus, our work goes beyond and empowers customers to efficiently manage their data across large, complex environments. You will implement efficient algorithms for handling vast datasets and work closely with cross-functional teams, including core infrastructure, product, and legal, to deliver scalable, secure solutions.

This role is based in our Vancouver office with an office-centric hybrid schedule. The standard in-office days are Monday, Tuesday, and Thursday. Most Asanas have the option to work from home on Wednesdays. Working from home on Fridays depends on the type of work you do and the teams with which you partner. If you're interviewing for this role, your recruiter will share more about the in-office requirements.

What You’ll Achieve
Work in a high-performance, dynamic team with a strong focus on velocity and software quality
Contribute to building a complex SaaS application that is a market leader in its segment
Be exposed to Asana’s core infrastructure, particularly how data is represented, stored and deleted in the storage layer.
Work with asynchronous jobs and efficiently and implement algorithms that efficiently traverse the Asana Work Graph
Work with legal to implement data ownership rules, requiring simple and effective technical solutions to make this process easy and clear to customers.
Drive large, impactful projects, delivering features that will be rolled out and used in large organizations
Support other teams and stakeholders that work in the team’s space

About You
Experience working in ambiguous and complex technical spaces and creating clarity and alignment with partners and stakeholders
Comfortable and autonomously diving deep into the weeds of complex technical contexts, to make sense of them, and then share their knowledge in a clear way with people in different roles and with different technical backgrounds
Have a strong understanding of software concepts and design patterns that make solutions scalable and robust.
Care deeply about the User Experience and comfortable working with frontend frameworks such as React.
Excited about mentoring and coaching teammates and stakeholders and contributing to leveling the team
Have experience driving projects of medium to large complexity.
You have a continuous improvement mindset and are never satisfied with the status quo, whether it's about the architecture, the code or the team's processes

At Asana, we're committed to building teams that include a variety of backgrounds, perspectives, and skills, as this is critical to helping us achieve our mission. If you're interested in this role and don't meet every listed requirement, we still encourage you to apply.

What We’ll Offer
Our comprehensive compensation package plays a big part in how we recognize you for the impact you have on our path to achieving our mission. We believe that compensation should be reflective of the value you create relative to the market value of your role. To ensure pay is fair and not impacted by biases, we're committed to looking at market value which is why we check ourselves and conduct a yearly pay equity audit.

For this role, the estimated base salary range is between $176,000 CAD - $224,000 CAD. The actual base salary will vary based on various factors, including market and individual qualifications objectively assessed during the interview process. The listed range above is a guideline, and the base salary range for this role may be modified.

In addition to base salary, your compensation package may include additional components such as equity, sales incentive pay (for most sales roles), and benefits. If you're interviewing for this role, speak with your Talent Acquisition Partner to learn more about the total compensation and benefits for this role.

We strive to provide equitable and competitive benefits packages that support our employees worldwide and include:
Mental health, wellness & fitness benefits
Career coaching & support
Inclusive family building benefits
Long-term savings or retirement plans
In-office culinary options to cater to your dietary preferences

These are just some of the benefits we offer, and benefits may vary based on role, country, and local regulations. If you're interviewing for this role, speak with your Talent Acquisition Partner to learn more about the total compensation and benefits for this role.

About Us
Asana helps teams orchestrate their work, from small projects to strategic initiatives. Millions of teams around the world rely on Asana to achieve their most important goals, faster. Asana has been named a Top 10 Best Workplace for 5 years in a row, is Fortune's #1 Best Workplace in the Bay Area, and one of Glassdoor’s and Inc.’s Best Places to Work. After spending more than a year physically distanced, Team Asana is safely and mindfully returning to in-person collaboration, incorporating flexibility that adds hybrid elements to our office-centric culture . With 11+ offices all over the world, we are always looking for individuals who care about building technology that drives positive change in the world and a culture where everyone feels that they belong.

We believe in supporting people to do their best work and thrive, and building a diverse, equitable, and inclusive company is core to our mission. Our goal is to ensure that Asana upholds an inclusive environment where all people feel that they are equally respected and valued, whether they are applying for an open position or working at the company. We provide equal employment opportunities to all applicants without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by law. We also comply with the San Francisco Fair Chance Ordinance and similar laws in other locations.","{""role_summary"":""A Senior Software Engineer to join the Data Management team, working on essential features touching the entire customer data lifecycle, ensuring data integrity and compliance, and implementing scalable and secure solutions."",""key_terms"":[{""term"":""Data graph"",""explanation"":""A complex network of data relationships and interactions within the Asana product.""},{""term"":""Asynchronous jobs"",""explanation"":""Background tasks that run independently of the main application, used for efficient data processing and management.""},{""term"":""Data ownership rules"",""explanation"":""Policies and regulations governing data access, management, and deletion, ensuring compliance and security.""},{""term"":""React"",""explanation"":""A popular frontend framework used for building user interfaces and improving user experience.""}],""skill_priorities"":{""must_have"":[""Experience working in complex technical spaces"",""Strong understanding of software concepts and design patterns"",""Comfortable working with frontend frameworks such as React"",""Experience driving projects of medium to large complexity""],""nice_to_have"":[""Mentoring and coaching teammates and stakeholders"",""Continuous improvement mindset""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach optimizing data processing and management for large-scale datasets?"",""example_answer"":""I would implement efficient algorithms, leverage asynchronous jobs, and ensure data ownership rules are in place to ensure smooth and secure operations.""},{""question"":""Can you describe a project you led that involved complex technical contexts and stakeholder alignment?"",""example_answer"":""In my previous role, I led a project that required integrating multiple systems, working closely with cross-functional teams, and implementing scalable solutions. I successfully delivered the project, and it resulted in significant improvements to our product.""}],""red_flags"":[""Lack of experience working with complex data graphs"",""Inability to effectively communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Sr. Data Analyst - CANADA (Remote),"About Us
Luxury Presence is the leading digital platform revolutionizing the real estate industry for agents, teams, and brokerages. Our award-winning websites, cutting-edge marketing solutions, and AI-powered mobile platform empower real estate professionals to grow their business, operate more efficiently, and deliver exceptional service to their clients. Trusted by over 60,000 real estate professionals, including 31 of the nation’s 100 top-performing agents as published in the Wall Street Journal, Luxury Presence continues to set the standard for innovation and excellence in real estate technology.

Position

Title: Sr. Data Analyst

Location: Canada, Remote

Compensation: Stock Options, Flex PTO, Health/Vision/Dental, Retreats

Why Now?

We’ve enjoyed tremendous growth over the last 5 years. With that growth comes a treasure trove of data that is valuable to us, and our customers. We need experienced and passionate data analysts to help us realize that value and unlock the insights that exist at the intersection of our operational, financial, and product data. This is a unique opportunity to join a fast growing startup and build our data team, culture, and processes from the ground up.

What You’ll Do

Deliver recommendations and actionable insights to key stakeholders to help drive revenue
Use strong technical and business intuition to optimize GTM motions, ensuring data-driven approaches drive efficiency, revenue growth, and customer acquisition
Solve difficult open ended up problems through novel data solutions and analytics
Support development of predictive models to support strategic and operational initiatives
Build dashboards, data products, and ad hoc report studies to analyze and present data associated with GTM analytics, product performance, business operations, and strategic decision making
Work with key stakeholders and the leadership team to define and monitor KPIs across the company
Build production-ready data models and schemas using DBT to support downstream analytics




Must Haves

Proficiency in SQL
Proficiency in any statistical programming language (i.e, Python or R)
5+ years in doing analytics with a robust understanding of statistical concepts
Experience working with BI tools (Sigma, Tableau, SiSense, Hex, or Looker etc)
Experience building predictive/forecasting models
Ability to work independently, and lead projects from start to finish
Ability to handle multiple stakeholders, and prioritize competing requests
Ability to identify and push for process improvements for the teams we support
Ability to communicate technical concepts to both technical and non-technical audiences through visualizations and presentations
Ability to partner with leadership and stakeholders across the company to understand business needs and how these can be addressed through analytics
Experience supporting any GTM teams including Sales, Marketing, or Customer Success




Nice to Haves

M.S. in Math, Statistics, or closely related quantitative field
Experience with Snowflake and dbt
Experience building supervised and unsupervised learning models
Experience working in a B2B or SaaS company




Join us in shaping the future of real estate
The real estate industry is in the midst of a seismic shift, and the future belongs to those who break new ground. As one of the fastest-growing companies in the proptech and marketing sectors, Luxury Presence challenges the status quo of what technology can do for real estate agents, leaders, and brokerages.

We’re a team of agile and tenacious innovators working collaboratively to drive the industry forward. Together, we build game-changing products that empower modern real estate entrepreneurs to dominate their markets. From award-winning web design to agile SEO solutions to cutting-edge AI tools, we deliver tech that anticipates market shifts and keeps our clients ahead of their competition.

Founded in 2016 by Stanford Business School alum Malte Kramer, Luxury Presence has grown to a global team ranked on the Inc. 5000 fastest-growing companies list three years in a row. We’re backed by world-class investors, including Bessemer Venture Partners, Toba Capital, and Switch Ventures, and have raised $52.6 million to date.

More than 13,000 real estate businesses rely on our platform, including 31 of the RealTrends top 100 agents featured in The Wall Street Journal. Additionally, many of the industry’s most powerful brokerages — including Compass, Coldwell Banker, and Sotheby’s International Realty — rely on Luxury Presence as a trusted business partner.

Every year since 2020, Luxury Presence has ranked on BuiltIn’s Best Place to Work lists. HousingWire named our founder and CEO a 2024 Tech Trendsetter, we’ve received several Tech100 Awards, and our lead nurturing tool just scored an Inman Innovation Award for Best AI-Powered Platform.

Luxury Presence is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin.","{""role_summary"":""As a Sr. Data Analyst, you will deliver actionable insights to drive revenue, optimize business processes, and support strategic initiatives through data analysis and predictive modeling."",""key_terms"":[{""term"":""GTM motions"",""explanation"":""GTM stands for 'go-to-market', referring to the process of launching a product or service to the market. GTM motions involve optimizing this process to drive revenue and customer acquisition.""},{""term"":""DBT"",""explanation"":""DBT (Data Build Tool) is a software tool used for building, testing, and deploying data models and analytics.""},{""term"":""BI tools"",""explanation"":""BI (Business Intelligence) tools are software applications used for data analysis, reporting, and visualization, such as Sigma, Tableau, and Looker.""}],""skill_priorities"":{""must_have"":[""Proficiency in SQL"",""Proficiency in a statistical programming language (e.g., Python or R)"",""5+ years of analytics experience with a robust understanding of statistical concepts"",""Experience working with BI tools"",""Experience building predictive/forecasting models"",""Ability to work independently and lead projects"",""Ability to handle multiple stakeholders and prioritize competing requests"",""Ability to identify and push for process improvements"",""Ability to communicate technical concepts to both technical and non-technical audiences""],""nice_to_have"":[""M.S. in Math, Statistics, or a closely related quantitative field"",""Experience with Snowflake and dbt"",""Experience building supervised and unsupervised learning models"",""Experience working in a B2B or SaaS company""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a predictive model to support strategic initiatives?"",""example_answer"":""I would start by identifying the key business problem and defining the objectives of the model. Then, I would collect and preprocess the relevant data, feature engineer, and select the most suitable algorithm. Finally, I would validate the model using metrics such as accuracy and F1 score, and iterate on the model to improve its performance.""},{""question"":""How do you stay up-to-date with new developments in data analytics and machine learning?"",""example_answer"":""I regularly read industry blogs and research papers, attend conferences and webinars, and participate in online forums and communities to stay current with the latest trends and advancements in data analytics and machine learning.""}],""red_flags"":[""Lack of experience working with BI tools"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
"Software Engineer, Backend","At Lyft, our purpose is to serve and connect. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

Our mission depends on having a digital representation of the physical world - a map with all routing related (real-time) information. This is what makes Lyft different from many products: our products don’t just facilitate online interactions, they facilitate dynamic, real-world ones. Without mapping services, none of these real world interactions between people and transport can happen.

The Mapping organization at Lyft has spent the last few years building up Lyft’s mapping assets and capabilities by combining many internal and external data sources and services into an increasingly powerful and mission-critical technology stack. In doing so, we’ve also enabled new user experiences and features across all of Lyft’s products, including rideshare industry leading firsts like CarPlay, Android Auto, and real-time driver feedback!

We are hiring a Software Engineer to join our Mapping experiences team that builds end user features to enhance drivers and riders experience on Lyft’s platform by using our in house navigation system. We are looking for an engineer with expertise in system architecture, cross team collaboration, and experience in building scalable solutions in the cloud environments.

In this role, you'll collaborate with engineering, product, data science, analytics, and operations on programs that empower us to iterate quickly, delighting our passengers and drivers with rideshare focused mapping experiences.

Responsibilities:

Drive high-impact projects and innovate new solutions to provide the best user experience.
Lead large features from idea to positive execution and launch
Write well-crafted, well-tested, readable, maintainable code
Participate in code reviews to ensure code quality and distribute knowledge, as well as on call rotations
Share your knowledge by giving brown bags, tech talks, and promoting appropriate tech and engineering best practices
Unblock, support and communicate with internal partners to achieve results

Experience:

BS/MS or equivalent in Computer Engineering, Computer Science, or related field or relevant work experience
4+ years of software engineering/production infrastructure industry experience
Experience designing, debugging and running fault-tolerant, highly available, large-scale distributed systems
Experience working with public cloud platforms (e.g., AWS, GCP, Microsoft Azure, etc.)
Experience working with databases, relational or NoSQL
Led a set of components from design to launch

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Child care and pet benefits
Access to a Lyft funded Health Care Savings Account
RRSP plan to help save for your future
In addition to provincial observed holidays, salaried team members are covered under Lyft's flexible paid time off policy. The policy allows team members to take off as much time as they need (with manager approval). Hourly team members get 15 days paid time off, with an additional day for each year of service
Lyft is proud to support new parents with 18 weeks of paid time off, designed as a top-up plan to complement provincial programs. Biological, adoptive, and foster parents are all eligible.
Subsidized commuter benefits

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Wednesdays, and Thursdays. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid

The expected base pay range for this position in the Toronto area is CAD $108,000 - CAD $135,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.","{""role_summary"":""As a Software Engineer on the Mapping experiences team at Lyft, you will build end-user features to enhance drivers and riders' experience on Lyft's platform using their in-house navigation system, collaborating with cross-functional teams to deliver high-impact projects and innovate new solutions."",""key_terms"":[{""term"":""Cloud environments"",""explanation"":""Refers to the use of cloud-based infrastructure and services, such as AWS, GCP, or Microsoft Azure, to build and deploy scalable solutions.""},{""term"":""Fault-tolerant, highly available, large-scale distributed systems"",""explanation"":""Describes systems that can continue to operate even when some components fail, are highly available, and can handle a large volume of users and data.""},{""term"":""Public cloud platforms"",""explanation"":""Refers to cloud computing services offered by third-party providers, such as AWS, GCP, or Microsoft Azure, that can be accessed over the internet.""}],""skill_priorities"":{""must_have"":[""Experience designing, debugging and running fault-tolerant, highly available, large-scale distributed systems"",""Experience working with public cloud platforms"",""Experience working with databases, relational or NoSQL"",""4+ years of software engineering/production infrastructure industry experience""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to design and implement a scalable solution in a cloud environment?"",""example_answer"":""In my previous role, I designed and implemented a cloud-based architecture for a real-time analytics platform, which involved selecting the right cloud services, configuring auto-scaling, and ensuring high availability.""},{""question"":""How do you approach debugging and troubleshooting issues in a large-scale distributed system?"",""example_answer"":""I use a combination of logging, monitoring, and tracing tools to identify issues, and then work backwards to isolate the root cause, using techniques like fault injection and canary releases to validate fixes.""}],""red_flags"":[""Lack of experience with cloud-based infrastructure and services"",""Inability to design and implement scalable solutions""],""confidence_score"":90.0}"
Data Engineer II,"Who we are

Founded in 2002, Zafin offers a SaaS product and pricing platform that simplifies core modernization for top banks worldwide. Our platform enables business users to work collaboratively to design and manage pricing, products, and packages, while technologists streamline core banking systems.

With Zafin, banks accelerate time to market for new products and offers while lowering the cost of change and achieving tangible business and risk outcomes. The Zafin platform increases business agility while enabling personalized pricing and dynamic responses to evolving customer and market needs.

Zafin is headquartered in Vancouver, Canada, with offices and customers around the globe including ING, CIBC, HSBC, Wells Fargo, PNC, and ANZ. Zafin is proud to be recognized as a top employer and certified Great Place to Work® in Canada, India and the UK.

What You Will Do

We're looking for a product-focused Senior Data Engineer. In this role, you build and maintain the cloud-based data stack that powers Zafin Analytics. You will think deeply about the undercurrents of data engineering, such as security, DataOps, data modelling and data integration – to help design the data architecture that delivers on the product roadmap, while maintaining a high standard for scalability, data integrity and reliability.

If you are passionate about building hi-tech products, comfortable with ambiguity, have the lateral skills to go from roadmap to architecture to code, and most importantly, if you want to apply your engineering chops to make an impact, talk to us.



Location: Toronto



As a Data Engineer, you will:

Build the pipeline to ingest data from source systems to a cloud-based data warehouse and perform required data transformations.
Develop the analytics product from prototyping to production-quality code.
Implement processes to monitor data quality and the health of the data pipeline.
Implement test cases for the data pipelines and the data-intensive application.
Define and extend the data model required to power the analytics use-cases.
Contribute to the analytics strategy and help set up the data infrastructure stack.
Apply software engineering best practices to analytics code (e.g., version control, testing, CI/CD).

To be successful in this position, you must have:

Bachelor of Computer Science or a related technical field.
4+ years of experience as a Data Engineer.
Experience with Java or Python.
Demonstrated expertise in engineering data-intensive applications.
Ability to work with large datasets, including the skills to establish scalable data pipelines.
Schema design for data warehouses, preferably with cloud-native data warehouses.
Experience with Infrastructure as Code.
Although not required, please highlight your Lambda or Kappa architecture experience.

What's in it for you

Joining our team means being part of a culture that values diversity, teamwork, and high-quality work. We offer competitive salaries, annual bonus potential, generous paid time off, paid volunteering days, wellness benefits, and robust opportunities for professional growth and career advancement. Want to learn more about what you can look forward to during your career with us? Visit our careers site and our openings: zafin.com/careers

Zafin welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.

Zafin is committed to protecting the privacy and security of the personal information collected from all applicants throughout the recruitment process. The methods by which Zafin contains uses, stores, handles, retains, or discloses applicant information can be accessed by reviewing Zafin's privacy policy at https://zafin.com/privacy-notice/. By submitting a job application, you confirm that you agree to the processing of your personal data by Zafin described in the candidate privacy notice.","{""role_summary"":""Design and maintain a cloud-based data stack for Zafin Analytics as a Senior Data Engineer, focusing on data engineering, security, DataOps, data modeling, and data integration to deliver on the product roadmap."",""key_terms"":[{""term"":""DataOps"",""explanation"":""Data Operations, a set of practices that combines DevOps and data engineering to improve data quality, security, and reliability.""},{""term"":""Data modelling"",""explanation"":""The process of creating a conceptual representation of data structures and relationships to organize and standardize data.""},{""term"":""Lambda or Kappa architecture"",""explanation"":""Cloud-native architecture patterns for building scalable and fault-tolerant data pipelines.""},{""term"":""Infrastructure as Code"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files, rather than manual processes.""}],""skill_priorities"":{""must_have"":[""4+ years of experience as a Data Engineer"",""Experience with Java or Python"",""Demonstrated expertise in engineering data-intensive applications"",""Ability to work with large datasets and establish scalable data pipelines"",""Schema design for data warehouses, preferably with cloud-native data warehouses""],""nice_to_have"":[""Experience with Lambda or Kappa architecture""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing a scalable data pipeline for a cloud-based data warehouse?"",""example_answer"":""I would start by understanding the data sources and requirements, then design a pipeline that leverages cloud-native services and follows best practices for data processing and storage. I would also ensure data quality and integrity through monitoring and testing.""},{""question"":""Can you explain the importance of DataOps in a data engineering role?"",""example_answer"":""DataOps is crucial in data engineering as it enables collaboration, automation, and monitoring of data pipelines, ensuring data quality, security, and reliability. It also helps to reduce errors and improve the overall efficiency of the data engineering process.""}],""red_flags"":[""Lack of experience with cloud-native data warehouses"",""Inability to work with large datasets and establish scalable data pipelines""],""confidence_score"":90.0}"
AWS Data Engineer-Developer,"Role Description: AWS Redshift, AWS GLUE, Python, Pyspark, Cloud Data Engineering

Competencies: Digital : Python, Digital : NoSQL Key-Value DB

Experience (Years): 10 & Above

Essential Skills: AWS Redshift, AWS GLUE, Python, Pyspark, Cloud Data Engineering","{""role_summary"":""Design and implement data engineering solutions on cloud-based platforms, focusing on data warehousing and ETL processes."",""key_terms"":[{""term"":""AWS Redshift"",""explanation"":""A fully managed data warehouse service in the cloud that makes it simple to analyze data across data warehouses and data lakes.""},{""term"":""AWS GLUE"",""explanation"":""A fully managed extract, transform, and load (ETL) service that makes it easy to prepare and load data for analysis.""},{""term"":""Pyspark"",""explanation"":""A Python library for large-scale data processing that provides high-level APIs in Python and Java.""},{""term"":""Cloud Data Engineering"",""explanation"":""The process of designing, building, and managing the infrastructure for storing, processing, and retrieving large datasets in cloud-based environments.""}],""skill_priorities"":{""must_have"":[""AWS Redshift"",""AWS GLUE"",""Python"",""Pyspark"",""Cloud Data Engineering""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize data processing in a cloud-based data warehouse using AWS Redshift?"",""example_answer"":""I would use columnar storage, distribute data across nodes, and leverage query optimization techniques to improve performance.""},{""question"":""Can you explain how you would integrate AWS GLUE with Pyspark for ETL processes?"",""example_answer"":""I would use AWS GLUE to extract data from various sources, transform it using Pyspark, and load it into a target data warehouse or lake.""}],""red_flags"":[""Avoid candidates without hands-on experience with AWS Redshift and AWS GLUE.""],""confidence_score"":90.0}"
Software Engineer Intern (Summer 2025),"Block is one company built from many blocks, all united by the same purpose of economic empowerment. The blocks that form our foundational teams — People, Finance, Counsel, Hardware, Information Security, Platform Infrastructure Engineering, and more — provide support and guidance at the corporate level. They work across business groups and around the globe, spanning time zones and disciplines to develop inclusive People policies, forecast finances, give legal counsel, safeguard systems, nurture new initiatives, and more. Every challenge creates possibilities, and we need different perspectives to see them all. Bring yours to Block.

The Role

Our Software Engineers keep Block simple and make our users faster and smarter. We're looking for engineers of all skillsets, who are excited about building outstanding software and solving hard problems. Our challenges span many technologies, from web and mobile applications (iOS, Android) to server-side development (Java, Ruby). As an engineer at Block, you will work on a small team with people across engineering, product, and creative, building reliable, fast, responsive, and beautiful software.

You Will

Reliability: Ensure our products work right, every time, by using testing, continuous integration, and in-depth code reviews
Security: Create interactions and APIs that promote trust, increase security, and make it harder to do the wrong thing
Analytics: Collect all the data around every transaction and turn it into tools that help our users
Products: Envision entire new products, features, and flows that are inspired, considered, and magical
Fraud Prevention: Make quick decisions on millions of dollars which requires diligence and passion for detecting bad actors and preventing loss

You Have

Pursuing degree in Computer Science, Electrical Engineering, Math or related technical field, graduating between May 2026 and May 2027. Recent bootcamp graduates and engineering training participants are also considered within three months of completing program/training requirements
Programming experience in one or more object-oriented languages, including: Java, Python, Ruby, Go, Kotlin, Swift, C, and C++
Internships are 12-weeks
Co-op placements are 16 weeks

Technologies We Use And Teach

Java, Python, Ruby, Go, Kotlin, Swift, C, and C++

We’re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is an equal opportunity employer evaluating all employees and job applicants without regard to identity or any legally protected class. We also consider qualified applicants with criminal histories for employment on our team, and always assess candidates on an individualized basis.

We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations throughout the recruitment process. If you require an accommodation, let your recruiter know.

Want to learn more about what we’re doing to build an inclusive workplace? Check out our Inclusion & Diversity page.

Every benefit we offer is designed with one goal: empowering you to do the best work of your career while building the life you want. Remote work, medical insurance, flexible time off, retirement savings plans, and modern family planning are just some of our offering. Check out our other benefits at Block.

Block, Inc. (NYSE: XYZ) builds technology to increase access to the global economy. Each of our brands unlocks different aspects of the economy for more people. Square makes commerce and financial services accessible to sellers. Cash App is the easy way to spend, send, and store money. Afterpay is transforming the way customers manage their spending over time. TIDAL is a music platform that empowers artists to thrive as entrepreneurs. Bitkey is a simple self-custody wallet built for bitcoin. Proto is a suite of bitcoin mining products and services. Together, we’re helping build a financial system that is open to everyone.

Privacy Policy","{""role_summary"":""As a Software Engineer at Block, you will work on a small team to build reliable, fast, responsive, and beautiful software, solving hard problems and making users faster and smarter."",""key_terms"":[{""term"":""Continuous Integration"",""explanation"":""A development practice that involves integrating code changes into a central repository frequently, usually through automated processes.""},{""term"":""Object-Oriented Languages"",""explanation"":""Programming languages that organize software design around objects and the interactions between them, such as Java, Python, and Ruby.""},{""term"":""APIs"",""explanation"":""Application Programming Interfaces, which are sets of defined rules that enable different applications to communicate with each other.""}],""skill_priorities"":{""must_have"":[""Programming experience in one or more object-oriented languages"",""Pursuing degree in Computer Science, Electrical Engineering, Math or related technical field""],""nice_to_have"":[""Internship or co-op experience"",""Experience with Java, Python, Ruby, Go, Kotlin, Swift, C, and C++""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach ensuring reliability in your code, and can you give an example of a time when you caught a critical bug?"",""example_answer"":""I use a combination of testing, continuous integration, and in-depth code reviews to ensure reliability. In my previous project, I caught a bug that would have caused a significant delay in our product launch. I worked with my team to identify the root cause and implemented a fix, which was then reviewed and tested thoroughly.""},{""question"":""Can you describe a situation where you had to make a difficult decision about security in your code, and how you approached it?"",""example_answer"":""In my previous role, I had to decide whether to implement a specific security feature that would have added complexity to our codebase. I weighed the pros and cons, consulted with my team, and ultimately decided to implement the feature, which significantly improved our product's security.""}],""red_flags"":[""Lack of experience with object-oriented languages"",""No demonstrated understanding of security principles""],""confidence_score"":90.0}"
Senior Software Engineer - Integrations,"Who We’re Looking For
The Senior Software Engineer will act as both a hands-on software engineer and a liaison between our customers and integration developers. You will be responsible for performing integrations which typically involve coding, developing requirements, estimating tasks, and providing technical leadership to our offshore development team. Your expertise in software development, cloud platforms, and integration processes will be essential in executing integration projects and guiding the development team. Additionally, you will analyse integration processes to identify commonalities and implement improvements for greater efficiency and reuse. We are a 100% remote company, but have regional concentrations of team members in Canada, the United States and Sri Lanka. In this role you will be coordinating with team members in every location.
Job Responsibilities:
Hands-On Integration: Perform coding tasks required for integrations in order to become an expert in our integration processes and technologies.
Technical Leadership: Provide technical guidance and mentorship to the offshore development team.
Liaison Role: Serve as the primary technical point of contact between U.S. customers and the development team in Sri Lanka.
Requirement Development: Gather, analyze, and document customer requirements for integration projects.
Task Estimation: Evaluate and estimate the time and resources needed for development tasks.
Team Coordination: Manage and coordinate the activities of the offshore development team to ensure project milestones are met.
Process Improvement: Identify commonalities across different integrations and enhance our systems to improve efficiency and promote code reuse.
Project Execution: Oversee the integration process from initiation to completion, ensuring alignment with customer expectations.
Quality Assurance: Monitor project outcomes to ensure they meet quality standards and customer requirements.
Stakeholder Communication: Regularly update internal and external stakeholders on project status, challenges, and solutions.
Qualifications:
Education: Bachelor's degree in Computer Science, Information Technology, or a related field.
Experience: Minimum of 5 years of experience in software integration, development, or a related technical role.
Technical Skills:
Strong proficiency in software development and coding practices.
Experience with programming languages such as PHP, Python, or JavaScript.
Familiarity with cloud platforms like AWS, Azure, or Google Cloud Platform.
Knowledge of databases such as SQL or NoSQL databases.
Experience with API integrations and file-based data exchange.
Understanding of web technologies and frameworks.
Leadership Skills: Proven experience in leading and mentoring development teams.
Process Improvement: Demonstrated ability to analyze processes and implement improvements for efficiency.
Communication Skills:
Exceptional verbal and written communication abilities, especially with non-technical stakeholders.
Must be fluent in English, with excellent spoken and written skills, to effectively communicate with U.S customers.
Analytical Skills: Strong problem-solving skills with a focus on attention to detail.
Preferred Qualifications:
Experience with PHP, AWS services (especially S3), React, and SQL.
Familiarity with cloud-based integration tools.
Relevant technical certifications.
Food service experience.
Who We AreCut+Dry is a fast-growing FoodTech startup searching for flexible go-getters who welcome the challenge of meeting the needs of a rapidly expanding business. Our company is revolutionizing the $300B US food supply industry by directly connecting the people who produce and distribute food with those who purchase and prepare it in a commercial setting. Our platform provides wholesale suppliers, manufacturers, and their customers (restaurants, caterers, hotels, lodging, etc.) with an all-in-one order management, shopping, payment, marketing, and tracking solution. Our solution drives revenue and saves valuable time, allowing users to do more with their existing staff, and ultimately, build a more profitable business.
The Cut+Dry founders and executive team have a background uniquely suited to attack this complicated problem. Consisting of lifelong Silicon Valley entrepreneurs, the leaders have built and exited multiple startups and possess deep domain expertise in the restaurant and food supply chain business. The founders have sold prior startups to the world’s largest food distributor, Sysco, and were directly responsible for building Sysco’s industry leading digital customer experiences.
Why Work at Cut+Dry?
Results-driven company culture that encourages a balanced lifestyle
Base salary + stock options package
Paid Medical, Dental, and Vision
401k Plan
Unlimited PTO
Flexible remote (work-from-anywhere) environment
Workspace equipment provided (computer, external monitor, and VoIP headset)
Powered by JazzHR
0s2fjRE24a","{""role_summary"":""The Senior Software Engineer will act as a liaison between customers and integration developers, performing integrations, providing technical leadership, and identifying process improvements for greater efficiency and reuse."",""key_terms"":[{""term"":""Cloud platforms"",""explanation"":""Cloud-based infrastructure for deploying and managing applications, such as AWS, Azure, or Google Cloud Platform.""},{""term"":""Integration processes"",""explanation"":""The steps involved in connecting different systems, applications, or services to enable data exchange and workflow automation.""},{""term"":""API integrations"",""explanation"":""The process of connecting applications or services using APIs (Application Programming Interfaces) to enable data exchange and functionality.""},{""term"":""File-based data exchange"",""explanation"":""The process of exchanging data between systems or applications using files, such as CSV, JSON, or XML.""}],""skill_priorities"":{""must_have"":[""Software development and coding practices"",""Experience with programming languages (PHP, Python, or JavaScript)"",""Familiarity with cloud platforms (AWS, Azure, or Google Cloud Platform)"",""Knowledge of databases (SQL or NoSQL)"",""Experience with API integrations and file-based data exchange"",""Leadership and mentoring skills"",""Process improvement skills"",""Exceptional verbal and written communication abilities""],""nice_to_have"":[""Experience with PHP, AWS services (especially S3), React, and SQL"",""Familiarity with cloud-based integration tools"",""Relevant technical certifications"",""Food service experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with cloud-based integration tools and how you've used them to improve integration processes?"",""example_answer"":""I've worked with AWS Lambda and API Gateway to integrate multiple services, reducing latency and improving data consistency. I've also used cloud-based integration tools like Zapier to automate workflows and increase efficiency.""},{""question"":""How do you approach process improvement, and can you give an example of a process you've improved in a previous role?"",""example_answer"":""I identify inefficiencies by analyzing workflows and gathering feedback from team members. In my previous role, I improved our deployment process by automating testing and deployment scripts, reducing deployment time by 50%.""}],""red_flags"":[""Lack of experience with cloud platforms and integration tools"",""Inability to communicate technical information to non-technical stakeholders"",""No experience leading or mentoring development teams""],""confidence_score"":90.0}"
"Machine Learning Software Engineer, Mapping","At Lyft, our purpose is to serve and connect. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

With over half a billion rides and counting, Lyft is solving hard problems in a rapidly growing domain with a lot of data and creative solutions in Mapping to better serve our customers. The mapping organization is seeking a machine learning engineer to help turn our telemetry and feedback pipelines into improved traffic predictions for more accurate ETAs. Accurate ETAs are important for providing the best service for both our drivers and riders. Our highly motivated Machine Learning Engineers work on these challenging problems and define solutions to directly impact various aspects of our core business.

If you are a critical thinker with experience in machine learning workflows, passionate about solving business problems using data and working in a dynamic, creative, and collaborative environment, we are searching for you.

As a machine learning engineer, you will be developing and launching the algorithms that power Mapping systems to create better experiences for our customers. Compared to similarly-sized technology companies, the set of problems that we tackle is incredibly diverse. We are hiring motivated experts in each of these fields. We’re looking for someone who is passionate about solving problems with data, building reliable ML systems, and is excited about working in a fast-paced, innovative, and collegial environment.

Responsibilities:

Partner with Engineers, Data Scientists, Product Managers, and Business Partners to apply machine learning for business and user impact
Perform data analysis and build proof-of-concept to explore and propose ML solutions to both new and existing problems
Develop statistical, machine learning, or optimization models
Write production quality code to launch machine learning models at scale
Evaluate machine learning systems against business goal

Experience:

B.S., M.S., or Ph.D. in Computer Science or other quantitative fields or related work experience
3+ years of Machine Learning experience
Passion for building impactful machine learning models leveraging expertise in one or multiple fields.
Proficiency in Python, Golang, or other programming language
Excellent communication skills and fluency in English
Strong understanding of Machine Learning methodologies, including supervised learning, forecasting, reinforcement learning, and neural networks.
Interest and experience in the Mapping domain.

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Child care and pet benefits
Access to a Lyft funded Health Care Savings Account
RRSP plan to help save for your future
In addition to provincial observed holidays, salaried team members are covered under Lyft's flexible paid time off policy. The policy allows team members to take off as much time as they need (with manager approval). Hourly team members get 15 days paid time off, with an additional day for each year of service
Lyft is proud to support new parents with 18 weeks of paid time off, designed as a top-up plan to complement provincial programs. Biological, adoptive, and foster parents are all eligible.
Subsidized commuter benefits

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Wednesdays, and Thursdays. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid

The expected base pay range for this position in the Toronto area is CAD $118,000 - CAD $163,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.","{""role_summary"":""Develop and launch machine learning algorithms to improve traffic predictions and provide accurate ETAs for Lyft customers, working collaboratively with cross-functional teams to drive business and user impact."",""key_terms"":[{""term"":""Machine Learning"",""explanation"":""The use of algorithms and statistical models to enable machines to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Telemetry"",""explanation"":""The process of collecting and transmitting data from remote sources, such as sensors or devices, to a central location for analysis and processing.""},{""term"":""ETAs"",""explanation"":""Estimated Time of Arrivals, which are predictions of when a ride will arrive at a specific location.""}],""skill_priorities"":{""must_have"":[""Machine Learning experience"",""Proficiency in Python, Golang, or other programming language"",""Strong understanding of Machine Learning methodologies""],""nice_to_have"":[""Experience in the Mapping domain"",""Knowledge of supervised learning, forecasting, reinforcement learning, and neural networks""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a machine learning model to improve traffic predictions?"",""example_answer"":""I would start by analyzing the available data, including telemetry and feedback pipelines, to identify patterns and correlations. Then, I would develop and train a machine learning model using techniques such as supervised learning or reinforcement learning, and evaluate its performance using metrics such as mean absolute error or mean squared error.""},{""question"":""How do you ensure that your machine learning models are scalable and reliable in production?"",""example_answer"":""I would focus on building modular and flexible models that can handle large volumes of data and traffic. I would also implement robust testing and validation procedures to ensure that the models perform well in different scenarios and edge cases.""}],""red_flags"":[""Lack of experience with machine learning workflows"",""Inability to communicate complex technical concepts effectively""],""confidence_score"":90.0}"
AI Engineer,"AI Engineer
BluWave-ai is dedicated to revolutionizing the renewable energy sector through the implementation of cutting-edge AI solutions. Our mission is to accelerate the adoption of clean energy in smart grids and facilitate the transition towards electrification of transportation.
We are seeking individuals who are passionate about driving change and making a positive environmental impact. Join us at the forefront of this exciting journey, where entrepreneurial spirits are encouraged, career growth is nurtured, and opportunities to shape a sustainable future abound.
Who you are
A seasoned AI Engineer strongly motivated by building impactful and dependable products based on pragmatic and rigorous application of ML techniques.
You have the drive to learn, evaluate, and apply a range of data science and ML techniques. The applications are real-time smart grid control and optimization solutions in the context of best scalability, availability, and security principles.
You are a pragmatic innovator who thrives in a fast-paced, disciplined, and team-oriented environment where we strive individually while supporting, learning from, and building on each other's ideas and efforts to succeed as a team.
Responsibilities:
Time Series Forecasting: Develop and implement advanced time series forecasting models to predict future trends, demand, and other relevant variables. Apply techniques such as ARIMA, SARIMA, exponential smoothing, or machine learning algorithms tailored to time series data.
Data Preprocessing and Cleaning: Clean, transform, and preprocess time series data to ensure data integrity and quality. Handle missing data, outliers, and other data anomalies appropriately.
Feature Engineering: Identify and engineer relevant features to improve the accuracy and performance of forecasting models. Incorporate domain knowledge to enhance feature selection and extraction.
Model Development and Evaluation: Build, train, and evaluate forecasting models using appropriate evaluation metrics. Select and fine-tune models to achieve optimal performance.
Performance Monitoring: Continuously monitor and validate the accuracy and performance of forecasting models over time. Identify and address issues related to model drift or degradation.
Collaboration and Communication: Collaborate with cross-functional teams, including stakeholders from different departments, to understand business requirements and provide actionable insights based on time series analysis and optimization.
Visualization and Reporting: Create clear and compelling visualizations, reports, and dashboards to effectively communicate forecasting results, optimization recommendations, and key insights to both technical and non-technical stakeholders.
Research and Innovation: Stay updated with the latest advancements in time series forecasting, optimization techniques, and related domains. Explore and propose innovative approaches to improve forecasting accuracy and optimization outcomes.
Requirements
Education: Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, or a related field (Ph.D. is a plus).
3 years of experience in data science or a related field, with a focus on time series forecasting and optimization.
Time Series Forecasting: Strong knowledge and hands-on experience in developing time series forecasting models using statistical and machine learning approaches.
Programming Skills: Proficiency in Python for data manipulation, analysis, and model development.
Analytical Skills: Ability to apply mathematical concepts and statistical techniques to analyze complex time-dependent data and derive actionable insights.
Data Visualization: Proficiency in data visualization and dashboarding tools likeGrafana, Plotly, or similar.
Communication: Excellent verbal and written communication skills for presenting complex concepts and findings.
Teamwork: Proven ability to collaborate effectively in cross-functional teams.
Continuous Learning: Strong desire to stay updated with advancements in data science, time series forecasting, and optimization.
Considered an asset:
Familiarity with control and optimization of modern power and energy systems.
Experience with optimization techniques such as linear programming, integer programming, and related tools (e.g. Pyomo, Gurobi, CPLEX).
Deployment and Monitoring: Understanding of machine learning model deployment strategies and monitoring techniques.
MLOps Tools: Familiarity with Kubeflow, MLflow, or similar for managing and deploying machine learning models.
Cloud Platforms: Experience with Azure, AWS, or Google Cloud Platform and their machine learning services.
Big Data Technologies: Knowledge of Apache Hadoop, Spark, or Hive and experience with large-scale time series datasets.
Time Series Databases: Familiarity with InfluxDB, Prometheus, or TimescaleDB for efficient time series data storage.
Version Control Systems: Experience with Git or similar tools for collaborative development.
General Information
Level: All experience ranges are encouraged to applyPosition Type: Full-timeLocation: Ottawa, ON / Summerside, PE / Calgary, AB (hybrid, no remote)Position Reports to: Software Engineering Manager
Diversity makes us stronger. BluWave-ai provides equal employment opportunities to all employees and applicants without regard to race, color, religion, sex, gender, national origin, disability, or any other characteristic protected by applicable laws, regulations, or ordinances. Authorization to work in Canada is required for this position.
Powered by JazzHR
pGDli6DlYX","{""role_summary"":""Develop and implement advanced time series forecasting models to predict future trends, demand, and other relevant variables in the context of smart grid control and optimization solutions."",""key_terms"":[{""term"":""Time Series Forecasting"",""explanation"":""Predicting future trends, demand, and other relevant variables using statistical and machine learning approaches.""},{""term"":""ARIMA"",""explanation"":""A statistical model used for time series forecasting, which stands for AutoRegressive Integrated Moving Average.""},{""term"":""SARIMA"",""explanation"":""A statistical model used for time series forecasting, which stands for Seasonal AutoRegressive Integrated Moving Average.""},{""term"":""Exponential Smoothing"",""explanation"":""A family of statistical models used for time series forecasting, which gives more weight to recent data.""},{""term"":""Machine Learning Algorithms"",""explanation"":""A set of algorithms used for time series forecasting, which enable machines to learn from data and make predictions.""},{""term"":""MLOps"",""explanation"":""A set of practices that combines machine learning and DevOps to streamline the machine learning lifecycle.""},{""term"":""Kubeflow"",""explanation"":""An open-source MLOps platform used for managing and deploying machine learning models.""},{""term"":""MLflow"",""explanation"":""An open-source MLOps platform used for managing and deploying machine learning models.""},{""term"":""Pyomo"",""explanation"":""An open-source optimization tool used for linear and nonlinear programming.""},{""term"":""Gurobi"",""explanation"":""A commercial optimization tool used for linear and nonlinear programming.""},{""term"":""CPLEX"",""explanation"":""A commercial optimization tool used for linear and nonlinear programming.""}],""skill_priorities"":{""must_have"":[""Time Series Forecasting"",""Python"",""Data Visualization"",""Analytical Skills"",""Communication"",""Teamwork""],""nice_to_have"":[""Control and Optimization of Modern Power and Energy Systems"",""Optimization Techniques"",""Deployment and Monitoring"",""MLOps Tools"",""Cloud Platforms"",""Big Data Technologies"",""Time Series Databases"",""Version Control Systems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the difference between ARIMA and SARIMA models in time series forecasting?"",""example_answer"":""ARIMA is a non-seasonal model, whereas SARIMA is a seasonal model that takes into account periodic patterns in the data.""},{""question"":""How do you handle missing data in time series forecasting?"",""example_answer"":""I use techniques such as imputation, interpolation, or padding to handle missing data, depending on the nature of the data and the problem at hand.""},{""question"":""What is your experience with MLOps tools, and how do you use them to manage and deploy machine learning models?"",""example_answer"":""I have experience with Kubeflow and MLflow, and I use them to manage the machine learning lifecycle, from data preparation to model deployment and monitoring.""}],""red_flags"":[""Lack of experience with time series forecasting and optimization"",""Inability to communicate complex concepts and findings to non-technical stakeholders"",""No experience with MLOps tools and practices""],""confidence_score"":95.0}"
Senior Software Engineer-Performance/Data/Java,"PointClickCare is a leading North American healthcare technology platform enabling meaningful care collaboration and real‐time patient insights. For over 20 years, the company has been focused on realizing its vision: to help create a world in which providers and plans can confidently deliver frictionless care. Since its inception, PointClickCare has grown exponentially, with over 2,200 employees working to impact millions across North America. Recognized by Forbes as one of the top 100 private cloud companies and acknowledged by Waterstone Human Capital as Canada’s Most Admired Corporate Cultures, PointClickCare leads the way in creating cloud-based healthcare software.

At PointClickCare, we offer a wealth of opportunities and a vibrant culture that empowers our employees. Our dynamic environment is the perfect place to advance your career while engaging in meaningful work alongside incredible colleagues. Here, you’ll discover a space where your talents can thrive, your career can grow, and your work will have a lasting impact on healthcare across North America. We believe that work becomes profoundly fulfilling when driven by a higher purpose.

Join us and be part of a team that is making a real impact.

To learn more about us, check out Life at PointClickCare and connect with us on Glassdoor and LinkedIn.

Position Summary

As a Senior Software Engineer at PointClickCare, you will be part of a focused team with the ability to have a significant impact on the performance, scalability, and reliability of our Data Platform.

You’ll collaborate closely with cross-functional teams to identify bottlenecks, analyze system behavior, and propose performance enhancements. In addition, your contribution to a performance engineering culture, ensuring engineers are building in performance during the design phase is key to success. This role provides an opportunity to work with cutting edge cloud technologies as PointClickCare continues to expand its use of public cloud. If you thrive in a fast-paced environment and have a passion for optimizing software systems, we’d love to hear from you!

Key Responsibilities

Contribute to quality products: The engineer will work on performance, stability, scalability, and reliability of the Data Platform.
Drive performance initiatives: The engineer will design, develop, and implement performance enhancements for the Data Platform.
Develop performance test suite: The engineer will plan, scope, schedule, and execute performance testing initiatives for the Data Platform.
Consult with development SMEs: The engineer will collaborate with development subject matter experts to define performance metrics and goals.
Advise on scalability and performance strategies: The engineer will provide guidance and recommendations to engineering teams on how to optimize system performance and scalability.
Communicate performance insights: The engineer will present and explain performance findings, solutions, and best practices to peers and cross-functional groups.
Develop performance tools and infrastructure: The engineer will assist in maintaining and provisioning performance test environments and creating automated performance solutions.

What Qualifications We’re Looking For

Experience with distributed computing tools like Apache Hudi, Trino, Map Reduce and other big data technologies.
Experience with distributed storage systems like HDFS, S3, etc.
Familiarity with Hadoop, Spark, or other distributed computing systems.
Understanding of data partitioning and sharding techniques.
Knowledge of distributed computing principles and how they apply to large-scale data processing.
Experience writing clean code that performs well at scale using languages such as Java/Kotlin/C#/Go.
Experience in scripting languages such as Python.
Knowledge of relational databases (e.g. Microsoft SQL Server, MySQL).
Solid experience writing RESTful API endpoints.
Absolutely love TDD and have working knowledge of it.
Proficient in GIT.
Experience using system and performance monitoring tools (e.g. New Relic, DataDog).
Excellent organization, critical-thinking and personal leadership skills
Self-starter with the ability to deliver with minimal supervision.
Being okay with the uncomfortable feeling that comes from learning new things.
Team player.
Analytical mind with problem-solving aptitude.
Proven experience as a great Engineer.
Degree in Mathematics or Computer science or related experience
Recent hands-on experience in Performance Engineering and/or Software Engineering.
Experience tackling performance problems related to data.

Bonus Points For

Exposure to data lakehouse technologies like Azure Data Lake, Hive, Trino etc…
Experience with Spring Boot, Cloud infrastructure development.
Experience with Jenkins CI/CD pipeline.
Experience working on a SaaS product.
Knowledge of scripting languages such as Python, Bash or Groovy.
Experience in JMeter, LoadRunner.
Understand systems environments like shared resources, components and services, CPU, memory, storage, network, etc.
Has mentored others in a professional setting.

PointClickCare Benefits & Perks

Benefits starting from Day 1!

Retirement Plan Matching

Flexible Paid Time Off

Wellness Support Programs and Resources

Parental & Caregiver Leaves

Fertility & Adoption Support

Continuous Development Support Program

Employee Assistance Program

Allyship and Inclusion Communities

Employee Recognition … and more!

It is the policy of PointClickCare to ensure equal employment opportunity without discrimination or harassment on the basis of race, religion, national origin, status, age, sex, sexual orientation, gender identity or expression, marital or domestic/civil partnership status, disability, veteran status, genetic information, or any other basis protected by law. PointClickCare welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process. Please contact recruitment@pointclickcare.com should you require any accommodations.

When you apply for a position, your information is processed and stored with Lever, in accordance with Lever’s Privacy Policy. We use this information to evaluate your candidacy for the posted position. We also store this information, and may use it in relation to future positions to which you apply, or which we believe may be relevant to you given your background. When we have no ongoing legitimate business need to process your information, we will either delete or anonymize it. If you have any questions about how PointClickCare uses or processes your information, or if you would like to ask to access, correct, or delete your information, please contact PointClickCare’s human resources team: recruitment@pointclickcare.com

PointClickCare is committed to Information Security. By applying to this position, if hired, you commit to following our information security policies and procedures and making every effort to secure confidential and/or sensitive information.","{""role_summary"":""As a Senior Software Engineer at PointClickCare, you will contribute to the performance, scalability, and reliability of the Data Platform, collaborating with cross-functional teams to identify bottlenecks and propose performance enhancements."",""key_terms"":[{""term"":""Distributed computing"",""explanation"":""A method of processing large amounts of data by breaking it down into smaller tasks that can be executed simultaneously across multiple machines.""},{""term"":""Big data technologies"",""explanation"":""Tools and systems designed to handle and process large amounts of structured and unstructured data, such as Apache Hudi and Trino.""},{""term"":""Performance engineering"",""explanation"":""The practice of ensuring software systems are designed and built to meet performance, scalability, and reliability requirements.""},{""term"":""Cloud technologies"",""explanation"":""Platforms and tools that enable on-demand access to a shared pool of computing resources over the internet, such as public cloud infrastructure.""}],""skill_priorities"":{""must_have"":[""Experience with distributed computing tools"",""Familiarity with distributed storage systems"",""Knowledge of data partitioning and sharding techniques"",""Experience writing clean code that performs well at scale"",""Knowledge of relational databases"",""Solid experience writing RESTful API endpoints"",""Proficient in GIT"",""Experience using system and performance monitoring tools""],""nice_to_have"":[""Exposure to data lakehouse technologies"",""Experience with Spring Boot, Cloud infrastructure development"",""Experience with Jenkins CI/CD pipeline"",""Experience working on a SaaS product"",""Knowledge of scripting languages such as Python, Bash or Groovy"",""Experience in JMeter, LoadRunner"",""Has mentored others in a professional setting""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach optimizing the performance of a distributed computing system?"",""example_answer"":""I would start by identifying bottlenecks in the system, then apply principles of distributed computing to design and implement performance enhancements. This might involve data partitioning, sharding, and parallel processing to improve scalability and reliability.""},{""question"":""Can you explain the importance of performance engineering in software development?"",""example_answer"":""Performance engineering is crucial because it ensures software systems meet performance, scalability, and reliability requirements. This involves designing and building systems that can handle large amounts of data and user traffic, while also providing a good user experience.""}],""red_flags"":[""Lack of experience with distributed computing tools and technologies"",""Inability to write clean, scalable code"",""Limited knowledge of relational databases and data partitioning techniques""],""confidence_score"":90.0}"
Data Analyst - GCP,"Inclusion without Exception

Tata Consultancy Services (TCS) is an equal opportunity employer, and embraces diversity in race, nationality, ethnicity, gender, age, physical ability, neurodiversity, and sexual orientation, to create a workforce that reflects the societies we operate in. Our continued commitment to Culture and Diversity is reflected in our people stories across our workforce and implemented through equitable workplace policies and processes.

About TCS

TCS is an IT services, consulting, and business solutions organization that has been partnering with many of the world’s largest businesses in their transformation journeys for over 55 years. Its consulting-led, cognitive-powered portfolio of business, technology, and engineering services and solutions is delivered through its unique Location Independent Agile™ delivery model, recognized as a benchmark of excellence in software development. A part of the Tata group, India's largest multinational business group, TCS employs over 612,000 of the world’s best-trained consultants in 55 countries. The company generated consolidated revenues of US $29 billion in the fiscal year ended March 31, 2024, and is listed on the BSE and the NSE in India. TCS' proactive stance on climate change and award-winning work with communities across the world have earned it a place in leading sustainability indices such as the MSCI Global Sustainability Index and the FTSE4Good Emerging Index.

Required Skills:
· Data Collection & Cleaning: Gathering data from various sources and ensuring its accuracy and consistency through cleaning and preprocessing.
· Data Analysis: Using statistical methods and analytical tools to identify patterns, trends, and insights within the data.
· Data Visualization: Creating clear and compelling visual representations of data, such as charts and dashboards, to facilitate decision-making.
· Reporting: Generating detailed reports and summaries that communicate findings effectively to stakeholders.
· Collaboration: Working closely with cross-functional teams to understand business requirements and tailor data analysis to support strategic initiatives.
· Continuous Improvement: Regularly evaluating data processes and methodologies to enhance data quality and analysis efficiency.
Roles & Responsibilities:
· combination of technical expertise, hands-on experience with data science tools and methodologies, familiarity with cloud technologies, and the ability to drive impactful insights from data.

Tata Consultancy Services Canada Inc. is committed to meeting the accessibility needs of all individuals in accordance with the Accessibility for Ontarians with Disabilities Act (AODA) and the Ontario Human Rights Code (OHRC). Should you require accommodations during the recruitment and selection process, please inform Human Resources.
Thank you for your interest in TCS. Candidates that meet the qualifications for this position will be contacted within a 2-week period. We invite you to continue to apply for other opportunities that match your profile.","{""role_summary"":""This role involves collecting, analyzing, and visualizing data to drive business insights and support strategic initiatives, while collaborating with cross-functional teams and continuously improving data processes."",""key_terms"":[{""term"":""Data Collection & Cleaning"",""explanation"":""Gathering data from various sources and ensuring its accuracy and consistency through cleaning and preprocessing.""},{""term"":""Data Analysis"",""explanation"":""Using statistical methods and analytical tools to identify patterns, trends, and insights within the data.""},{""term"":""Data Visualization"",""explanation"":""Creating clear and compelling visual representations of data, such as charts and dashboards, to facilitate decision-making.""},{""term"":""Cloud Technologies"",""explanation"":""Familiarity with cloud-based platforms and tools used for data analysis and processing.""}],""skill_priorities"":{""must_have"":[""Data Collection & Cleaning"",""Data Analysis"",""Data Visualization"",""Collaboration"",""Continuous Improvement""],""nice_to_have"":[""Cloud Technologies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to collect and clean a large dataset? How did you ensure data accuracy and consistency?"",""example_answer"":""In my previous role, I worked on a project where I had to collect data from multiple sources and clean it to ensure accuracy. I used data profiling techniques to identify inconsistencies and developed a data quality dashboard to track progress. Through this process, I was able to improve data quality by 30%.""},{""question"":""How do you stay up-to-date with new data analysis tools and methodologies?"",""example_answer"":""I regularly attend industry conferences and webinars to stay current with the latest trends and tools in data analysis. I also participate in online forums and communities to learn from others and share my own experiences.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to work collaboratively with cross-functional teams""],""confidence_score"":85.0}"
"Data Engineer, Dash Finance","Dropbox is a Virtual First company. For this role, we are currently only authorized to hire candidates from the following provinces: Alberta, British Columbia, Ontario, and Saskatchewan.

Company Description

Dropbox isn’t just a workplace—it’s a living lab for more enlightened ways of working. We're a global community of more than 2,000 bold visionaries and resourceful doers who are shaping the future of Dropbox—and with it the future of work. Our Virtual First model combines the flexibility of a distributed workplace with the power of human connection, making space for both meaningful work and meaningful relationships. With our start-up mindset and enterprise-level opportunities, you can be who you are and grow into who you’re meant to be. Here, you can own your impact to make work more intuitive, joyful, and human—for you as a Dropboxer and for hundreds of millions of people worldwide. If you're ready to push boundaries—and yourself— Dropbox is ready for you.

Team Description

The Dropbox Engineering Team builds the technology that creates more enlightened ways of working for hundreds of millions of people. Every day, our platforms—including Dropbox Dash, Dropbox Sign, and our core sync engine—handle over a billion files for users worldwide, creating engineering challenges as great as the opportunity for impact. Our software engineering team uses a range of technologies to solve interesting problems, including Python, React, Node.js, JavaScript, MongoDB, PostgreSQL, and Android development. We think like a startup but build for an enterprise, exploring new possibilities that transform how people work. If you're excited about turning complex technical challenges into intuitive solutions at scale, join our Engineering team. Areas of work include Machine Learning Engineers, Infrastructure Engineer, Product SWE Frontend and Backend, Mobile Software Engineers (iOS and Android), Engineering Manager, Data Engineer, Software Development Engineer in Test, Security Engineering, Site Reliability Engineer, Technical Program Managers, Network Engineer, Datacenter Engineer, Technical Supply Chain Manager and more.

Role Description

Dropbox is seeking a highly skilled and motivated Data Engineer to join our dynamic Financial Data Engineering team. You will be responsible for building next-generation financial data pipelines that support crucial business decisions across the organization. The ideal candidate will have extensive experience migrating from other platforms to Databricks, a strong culture of innovation and accountability, and expertise in developing data health metrics that integrate with data governance, observability, and quality management tools.

If you enjoy thinking about how businesses can utilize data and figuring out how to build it, this role is perfect for you. With a solid foundation in test-driven development and experience in building scalable data pipelines, as well as familiarity with traditional data warehousing (DW) and ETL architectures, and significant experience with ecosystems like Databricks, Snowflake, EMR, and Airflow, you would be a great fit for our team. By collaborating with cross-functional teams, you will have the opportunity to drive substantial business impact, as high data quality and effective tooling are key to achieving significant growth at Dropbox.

Our Engineering Career Framework is viewable by anyone outside the company and describes what’s expected for our engineers at each of our career levels. Check out our blog post on this topic and more here.

Responsibilities

Participate in data migration from legacy platforms to Databricks and develop scalable, efficient, and cost-optimized data pipelines
Build and integrate data health metrics and quality management tools, ensuring robust data governance and consistent standards
Design and maintain tools for efficient data investigations, issue detection, and automated mitigation to uphold data quality and consistency
Replace outdated infrastructure with modern systems and provide operational support for critical data pipelines
Solve complex data integration challenges using optimal ETL patterns, frameworks, and techniques for structured and unstructured data
Collaborate with cross-functional teams to meet technical and business needs while fostering a culture of innovation and continuous improvement
Define and manage SLAs for high-priority datasets, including those driving critical (P0) business metrics
Apply Agile methodologies and industry best practices to ensure consistent delivery and alignment with business objectives

Many teams at Dropbox run Services with on-call rotations, which entails being available for calls during both core and non-core business hours. If a team has an on-call rotation, all engineers on the team are expected to participate in the rotation as part of their employment. Applicants are encouraged to ask for more details of the rotations to which the applicant is applying.

Requirements

5+ years of experience in data engineering or related roles
Bachelor’s degree or foreign equivalent in Computer Science or a closely related field
Proven experience with data migration projects, specifically to Databricks
Strong expertise in data health metrics, data governance, and quality management, with experience integrating tools like Monte Carlo and Atlan
Solid experience in building and maintaining data pipelines and infrastructure
Excellent problem-solving skills and the ability to troubleshoot complex data issues
Strong programming skills in Python, Scala, or Java
Demonstrated ability to innovate and drive accountability within a team
Experience with version control systems like Git and test automation and CICD

Preferred Qualifications

5+ years of Python or Java, Scala development experience
5+ years of SQL experience
5+ years of experience with schema design and dimensional data modeling

Compensation

Canada Pay Range

$125,000—$169,100 CAD

The range listed above is the expected annual salary/OTE for this role, subject to change.

Salary/OTE is just one component of Dropbox’s total rewards package. All regular employees are also eligible for the corporate bonus program or a sales incentive (target included in OTE) as well as stock in the form of Restricted Stock Units (RSUs).

Benefits

Dropbox is committed to investing in the holistic health and wellbeing of all Dropboxers and their families. Our benefits and perks programs include, but are not limited to:

Competitive medical, dental and vision coverage*
Retirement savings through a defined contribution pension or savings plan**
Flexible PTO/Paid Time Off policy in addition to statutory holidays, allowing you time to unplug, unwind, and refresh
Income Protection Plans: Life and disability insurance*
Business Travel Protection: Travel medical and accident insurance*
Perks Allowance to be used on what matters most to you, whether that’s wellness, learning and development, food & groceries, and much more
Parental benefits including: Parental Leave, Fertility Benefits, Adoptions and Surrogacy support, and Lactation support
Mental health and wellness benefits

Additional Benefits Details Are Available Upon Request.

Where group plans are not available, allowances may be provided
Benefit, amount, and type are dependent on geographical location, based upon applicable law or company policy

Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work.","{""role_summary"":""Design and maintain scalable data pipelines, develop data health metrics, and ensure data quality and governance as a Data Engineer at Dropbox."",""key_terms"":[{""term"":""Databricks"",""explanation"":""A cloud-based Apache Spark platform for data engineering, analytics, and machine learning.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process for extracting data from sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Data governance"",""explanation"":""The policies, procedures, and standards for managing data quality, security, and integrity within an organization.""},{""term"":""SLA"",""explanation"":""Service Level Agreement - a commitment between a service provider and its customers that specifies the quality, availability, and responsiveness of the service.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in data engineering or related roles"",""Proven experience with data migration projects, specifically to Databricks"",""Strong expertise in data health metrics, data governance, and quality management"",""Solid experience in building and maintaining data pipelines and infrastructure"",""Excellent problem-solving skills and the ability to troubleshoot complex data issues"",""Strong programming skills in Python, Scala, or Java""],""nice_to_have"":[""5+ years of Python or Java, Scala development experience"",""5+ years of SQL experience"",""5+ years of experience with schema design and dimensional data modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach migrating a large dataset from a legacy platform to Databricks?"",""example_answer"":""I would first assess the dataset's complexity and identify potential challenges, then design a scalable and efficient data pipeline using Databricks' features, such as data lakes and delta tables. I would also ensure data quality and integrity by implementing data validation and testing.""},{""question"":""How do you ensure data governance and quality in your data pipelines?"",""example_answer"":""I would implement data health metrics and quality management tools, such as Monte Carlo and Atlan, to monitor data quality and detect issues. I would also establish data governance policies and procedures to ensure data consistency and integrity.""}],""red_flags"":[""Lack of experience with Databricks or similar cloud-based data engineering platforms"",""Inability to troubleshoot complex data issues or demonstrate problem-solving skills""],""confidence_score"":90.0}"
Artificial Intelligence Engineer,"Alquemy's client is a leading organization in the higher education sector. They are seeking an AI Engineer for a One Year Term (contract) Salaried position.

The AI Engineer is responsible for designing, developing, deploying, and monitoring advanced AI and ML models to address business challenges. This role focuses on end-to-end machine learning solutions, including intelligent chatbot applications, MLOps best practices, and scalable AI model deployment on cloud platforms. The successful candidate will work with technologies like AWS SageMaker, Amazon Bedrock, MLflow, Apache Tika, and various MLOps frameworks to ensure robust model versioning, monitoring, and lifecycle management. They will leverage open-source frameworks (e.g., Hugging Face, LangChain, spaCy) and work closely with the Project Manager and AI Data Engineer to develop efficient AI-driven solutions.

Responsibilities:

Design, develop, and implement machine learning models to address specific business needs.
Optimize ML models through rigorous hyperparameter tuning and algorithmic enhancements.
Develop and maintain MLOps pipelines to automate model training, validation, and deployment.
Ensure proper model versioning and reproducibility using MLflow, SageMaker Pipelines, or Kubeflow.
Build and maintain intelligent chatbot solutions, employing techniques such as: Retrieval-Augmented Generation (RAG):
Improve response accuracy with relevant contextual data.
Utilize Apache Tika for extracting and processing unstructured data (PDFs, text, documents, images).
Clean, process, and transform raw datasets for efficient model training and inference.
Deploy ML models on AWS SageMaker, Amazon Bedrock, and other cloud environments.

Requirements:

Bachelor's or Master’s degree in Computer Science, Data Science, AI, Machine Learning, or a related field.
5–8 years of experience in AI/ML development, machine learning engineering, or software engineering roles.
Strong understanding of ML models, fine-tuning, supervised learning, and deep learning techniques.
Hands-on experience with generative AI (GenAI) and agentic AI.
Experience deploying chatbot solutions using RAG, prompt engineering, and knowledge graphs.
Proficiency in MLflow, SageMaker Pipelines, or Kubeflow for model versioning and tracking.
Experience with model monitoring using SageMaker Model Monitor, AWS CloudWatch, or Prometheus.
Strong experience in CI/CD for ML pipelines (GitHub Actions, Jenkins, or AWS CodePipeline). Cloud & Infrastructure:
Hands-on experience with AWS SageMaker, Amazon Bedrock, and Azure OpenAI.
Expertise in deploying AI models via Docker, Kubernetes, and AWS Lambda.

Our client works in a hybrid model with 3-4 days/week required on site. Apply today to learn more!","{""role_summary"":""Design, develop, and deploy advanced AI and ML models to address business challenges, focusing on end-to-end machine learning solutions and scalable AI model deployment on cloud platforms."",""key_terms"":[{""term"":""MLOps"",""explanation"":""Machine Learning Operations, a set of practices to manage and maintain machine learning models in production environments.""},{""term"":""RAG"",""explanation"":""Retrieval-Augmented Generation, a technique used in chatbot solutions to improve response accuracy with relevant contextual data.""},{""term"":""GenAI"",""explanation"":""Generative AI, a type of artificial intelligence that generates new, original content, such as images, text, or music.""},{""term"":""Agentic AI"",""explanation"":""A type of artificial intelligence that enables machines to make decisions and take actions autonomously.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a set of practices to automate and streamline the software development and deployment process.""}],""skill_priorities"":{""must_have"":[""Machine learning development"",""MLOps"",""Cloud platforms (AWS SageMaker, Amazon Bedrock)"",""CI/CD for ML pipelines"",""Generative AI (GenAI) and agentic AI""],""nice_to_have"":[""Experience with Azure OpenAI"",""Knowledge of Docker, Kubernetes, and AWS Lambda""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach model versioning and reproducibility in your machine learning projects?"",""example_answer"":""I use MLflow to track model versions and ensure reproducibility. I also implement automated testing and validation to ensure model consistency across different environments.""},{""question"":""Can you explain the concept of Retrieval-Augmented Generation (RAG) in chatbot development?"",""example_answer"":""RAG is a technique used to improve response accuracy in chatbots by incorporating relevant contextual data. It involves retrieving relevant information from a knowledge base and generating responses based on that information.""}],""red_flags"":[""Lack of experience with cloud platforms (AWS SageMaker, Amazon Bedrock)"",""Inability to explain MLOps concepts and best practices""],""confidence_score"":90.0}"
"Staff Engineer, Database Specialist, Platform","As a technical expert at Cardata you’ll take a hands-on approach to architecting and coding scalable front-end and back-end solutions, ensuring a world-class user experience.

As a Staff Engineer and key member of our Platform Team, you’ll play a critical role in designing, architecting and implementing our new, customizable platform. With your full-stack expertise—especially in relational databases (PostgreSQL preferred)—you’ll guide key decisions on database best practices and platform-to-platform migration strategies.

At Cardata, we foster a culture of continuous learning, collaboration, and innovation. Our Engineering Team thrives on shared knowledge and product ownership, engaging in pair programming, Lunch & Learn sessions, and architecture discussions. We are a highly engaged team dedicated to improving core processes, driving product evolution, and achieving goals collaboratively. 🚀

What You'll Be Doing

Help establish best practices and design patterns for our new platform
Lead the design of a migration strategy to move users from our legacy platform to our new one
Design, develop, test, and maintain new features of the platform
Help lead unit test initiatives by instilling high coverage amongst code bases
Write clean, efficient, and maintainable code that adheres to best practices and standards
Collaborate with other members of the development team, including product managers and other engineers, to define requirements, design solutions, and implement features
Help set high coding standards by reviewing RFC documents, defining standards, and through PR reviews🏆
Stay up-to-date with emerging trends and technologies in software development, and share knowledge with the team📚
Continuously improve our best practices, standards, tooling, and methodologies to ensure software quality, efficiency, and maintainability
Provide technical leadership and mentorship to other engineers, helping them to develop their skills and grow as professionals
Able to break down significant project goals into smaller achievable steps and hit milestones

What You'll Bring

8 to 12 years of software development experience building highly reliable, scalable software solutions
Experience with TypeScript, React, NextJS, and NestJS 💻
Experience with relational databases such as PostgreSQL or MySQL🗄️
Experience with TDD or unit testing, bonus using JEST
Familiarity with Agile/Scrum methodologies and CI/CD deployment processes ⚡
Ability to thrive in a dynamic, ambiguous environment, managing multiple priorities, tackling complex technical challenges, and delivering high-quality results
Strong time management, with an aptitude for scoping projects and developing accurate timelines⏳
Exceptional interpersonal and communication skills, with the ability to effectively collaborate with cross-functional teams, translate complex concepts into digestible formats and manage expectations
Demonstrated success managing development projects end-to-end with significant ownership over technical decision-making
Experience building applications with AWS, using services such as SNS/SQS, EC2, Lambda

Nice to Have

Bachelor's or Master's degree in Computer Science, Software Engineering, or an equivalent educational experience","{""role_summary"":""As a technical expert, you will architect and code scalable front-end and back-end solutions, ensuring a world-class user experience, and play a critical role in designing and implementing a new, customizable platform."",""key_terms"":[{""term"":""Full-stack expertise"",""explanation"":""The ability to work on both front-end and back-end development, including relational databases and platform-to-platform migration strategies.""},{""term"":""Relational databases"",""explanation"":""Databases that organize data into one or more tables, such as PostgreSQL or MySQL, used for storing and managing data.""},{""term"":""TypeScript"",""explanation"":""A programming language used for building scalable JavaScript applications, often used with React, NextJS, and NestJS.""},{""term"":""TDD (Test-Driven Development)"",""explanation"":""A software development process that relies on the repetitive cycle of writing automated tests before writing the actual code.""},{""term"":""Agile/Scrum methodologies"",""explanation"":""Iterative and incremental approaches to project management and software development, focusing on flexibility and team collaboration.""},{""term"":""CI/CD deployment processes"",""explanation"":""Automated processes for building, testing, and deploying software applications, ensuring continuous integration and delivery.""}],""skill_priorities"":{""must_have"":[""Full-stack expertise"",""Experience with relational databases (PostgreSQL preferred)"",""TypeScript, React, NextJS, and NestJS experience"",""TDD or unit testing experience"",""Agile/Scrum methodologies and CI/CD deployment processes experience""],""nice_to_have"":[""Bachelor's or Master's degree in Computer Science, Software Engineering, or an equivalent educational experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach designing a migration strategy to move users from a legacy platform to a new one?"",""example_answer"":""I would start by analyzing the current platform's architecture and identifying key pain points, then develop a phased approach to migration, ensuring minimal disruption to users and leveraging automated testing to ensure data integrity.""},{""question"":""Can you explain the benefits of using TypeScript in a full-stack development project?"",""example_answer"":""TypeScript provides type safety, which helps catch errors early, and improves code maintainability and scalability. It also enables better code completion and IntelliSense, making development more efficient.""}],""red_flags"":[""Lack of experience with relational databases"",""Inability to thrive in a dynamic, ambiguous environment""],""confidence_score"":95.0}"
"Software Engineer, Analytics","About Dialpad

Dialpad is the leading Ai-powered customer communications platform creating human-first, Ai-enhanced solutions that will drive the next wave of how businesses communicate with and serve their customers. Enterprise customers like Randstad, Remax, Mizuho, Cigna, T-Mobile, Johns Hopkins, Motorola, Warby Parker, Panera Bread, and Netflix, use Dialpad and its Ai capabilities to deliver amazing customer experiences. Supported by notable investors such as Andreessen Horowitz, Google Ventures, and ICONIQ Capital, Dialpad is a dynamic force in Ai technology with a rapidly expanding presence. Visit dialpad.com to learn more.

About The Team

Our Data Analysis and QA team works alongside the Data Annotation team to support the Ai teams, working on projects on cutting-edge Automatic Speech Recognition(ASR), Natural Language Processing(NLP) and Computer Vision(CV). We take care of the complex business and product logic as well as making sure the data follows our security and privacy standards letting our applied scientists focus on model development. We help the NLP team to launch and enhance DialpadGPT, our in-house LLM specifically designed for the domain of business communication.

We work closely with the Product team to help them understand how users interact with our Ai product using data analysis.

We also build data pipelines and infrastructure and adopt software engineering best practices.

We are a group of engineers who enjoy writing reports to tell the stories behind the data, which often spin up new data science ideas and help businesses make better decisions.

Your role

As a software engineer, you’ll be an integral part of our data analysis and QA team, supporting ASR and NLP teams for their data needs. You will own our internal package for dataset management and anonymization. You’ll work closely with our Ai Engineering team to build and maintain toolings for data science projects. You will help the team with various technical issues. You’ll be actively looking for opportunities to improve the team’s productivity and workflow through automation and process optimization. You will work with QA team to implement automated QA.

This position reports to the manager of the data analysis and QA team and has the opportunity to be based in our Vancouver Office.

What You’ll Do

You will own our internal library for dataset management and other data tooling packages
You will build and maintain data pipelines on Kubeflow
You will implement rigorous testing for our data pipelines and SQL queries
You will work closely with Ai Engineering team to build toolings for data science projects
You will implement automation and processes to improve our workflow
You will share the ownership of the DBT core infrastructure with AI Engineering
You will create and maintain dashboards (Tableau) and data pipelines (DBT) that help drive product and business decisions
You will contribute to our continuous efforts to enforce data privacy and compliance
You will collaborate with cross-functional teams, including Ai, engineering and product team

Skills You’ll Bring

Bachelor's or Master’s degree in Computer Science, Software Engineering or related fields.
2 - 4 years of working experience with software engineering or data engineering project
2 - 4 years of experience with Python, preferably building libraries or web applications
2 -4 years of experience with SQL, able to optimize complex SQL queries and build data pipelines
Experience working with GCP including storage, BigQuery, Compute, Kubernetes or similar.
Experience with version control systems such as Git.
Experience with CI/CD and familiarity with containerization using Docker or similar.
Familiarity with DBT Cloud (bonus: DBT Core)
Familiarity with BI tools such as Tableau
Strong attention to detail, with a focus on data accuracy, quality, and integrity.
Strong problem-solving and analytical abilities, with the capacity to handle complex technical and analytical problems.
Excellent communication and collaboration skills to effectively work in a multi-disciplinary team.
Familiarity with version control tools like Git for collaborative projects.

Dialpad Benefits And Perks

Benefits, time-off, and wellness

An apple a day keeps the doctor away—and it doesn’t hurt that we offer flexible time off and great options for medical, dental, and vision plans for all employees. Along with that, employees also receive a monthly stipend to help cover your cell phone bill, home internet bill, and we reimburse for gym membership costs, a variety of wellness events, and more!

Professional development

Dialpad offers reimbursement for expenses related to professional development, up to an annual limit per calendar year.

For exceptional talent based in British Columbia, Canada the target base salary range for this position is posted below. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the target range for new hire salaries for the position. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in British Columbia role postings reflect the base salary only, and do not include bonus, equity, or benefits.

British Columbia, Canada Salary Range

$119,550—$141,217 CAD

Culture

We’ve been named a Top Workplace seven times, and a big part of this is because of our collaborative culture that elevates our teammates, celebrates wins, and brings together passion and talent.

Compensation

Teamwork makes the dream work, and Dialpad offers competitive salaries because each and every Dialer participates in our success.

Diversity, Equity, and Inclusion (DEI) at Dialpad

At Dialpad, we are passionate about Doing the Right Thing. This means we are committed to building a values-driven culture that celebrates identity, inclusion and belonging. As a global company, it’s our responsibility to come together to create a culture where all Dialers can Work Beautifully, Delight Our Users, and Innovate Continuously to bring our world-class product to life.

Every Voice Matters at Dialpad. We build community through our Employee Resource Groups, company-wide celebrations, service days, and a robust internal learning & development program focused on the success of our Dialers.

Don’t meet every single requirement? Studies have shown that women and marginalized groups are less likely to apply to jobs unless they meet every single qualification. At Dialpad we are dedicated to building an inclusive and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.

Dialpad is an equal-opportunity employer. We are dedicated to creating a community of inclusion and an environment free from discrimination or harassment.","{""role_summary"":""As a software engineer, you will be part of the data analysis and QA team, supporting ASR and NLP teams for their data needs, building and maintaining toolings for data science projects, and improving the team's productivity and workflow through automation and process optimization."",""key_terms"":[{""term"":""Automatic Speech Recognition (ASR)"",""explanation"":""A technology that enables computers to recognize and transcribe spoken words into text.""},{""term"":""Natural Language Processing (NLP)"",""explanation"":""A subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""},{""term"":""Computer Vision (CV)"",""explanation"":""A field of study that focuses on enabling computers to interpret and understand visual information from the world.""},{""term"":""Kubeflow"",""explanation"":""An open-source platform for machine learning that provides a simple, portable, and scalable way to deploy machine learning models.""},{""term"":""DBT"",""explanation"":""A software tool that enables data engineers to transform, test, and deploy data pipelines.""},{""term"":""Tableau"",""explanation"":""A data visualization tool that helps people see and understand data.""}],""skill_priorities"":{""must_have"":[""Bachelor's or Master's degree in Computer Science, Software Engineering or related fields"",""2-4 years of working experience with software engineering or data engineering projects"",""2-4 years of experience with Python"",""2-4 years of experience with SQL"",""Experience working with GCP including storage, BigQuery, Compute, Kubernetes or similar"",""Experience with version control systems such as Git"",""Experience with CI/CD and familiarity with containerization using Docker or similar""],""nice_to_have"":[""Familiarity with DBT Cloud"",""Familiarity with BI tools such as Tableau""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize complex SQL queries for better performance?"",""example_answer"":""I would use indexing, caching, and query optimization techniques to improve the performance of complex SQL queries.""},{""question"":""Can you explain how you would implement automated testing for data pipelines?"",""example_answer"":""I would use a combination of unit testing, integration testing, and end-to-end testing to ensure the data pipelines are working correctly and efficiently.""}],""red_flags"":[""Lack of experience with GCP or similar cloud platforms"",""Inability to optimize complex SQL queries"",""Limited experience with data engineering or software engineering projects""],""confidence_score"":90.0}"
Data Scientist,"If you take pride in being compassionate, honest, professional and safe, consider an exciting and rewarding career at Shannex. Our communities offer more than a place to work – they welcome and celebrate Great People who inspire meaningful connections while Leading the Way to Better Living™.

We are searching for a Data Scientist to join our Insights Lab Team based in Halifax, Nova Scotia.

Meaningful Benefits

You will be surrounded by supportive and talented team members who make our communities great places to live, work and visit. As an established and respected organization in the healthcare sector, Shannex offers opportunities for growth, development and advancement. And at the end of every day, you will know you’ve made a measured difference in the lives of our residents. Additional benefits include:

Comprehensive health and dental benefits plan including an Employee and Family Assistance Program
Access to virtual healthcare 24/7 for FREE through the group health benefit plan
RRSP program (with employer matching)
Vacation accrual (begins immediately) and travel insurance
Free onsite parking
Access to thousands of vendors offering perks and discounts through our WorkPerks program
Access to continuing education and training through Shannex’s Centre of Excellence
Opportunities to be part of sector innovation and continuous improvement initiatives
Recognition and Rewards for service excellence and safety

About The Opportunity

Collect, analyze, and interpret large datasets to derive meaningful insights.
Develop predictive models to forecast patient outcomes and optimize resource allocation.
Design and implement data experiments to test hypotheses and validate models.
Stay up-to-date with the latest data science techniques and tools.
Work closely with clinical staff, administrators, and BIA to understand data needs and deliver actionable insights.
Present findings and recommendations to stakeholders in a clear and concise manner
Ensure data integrity, accuracy, and security in compliance with regulatory standards.
Develop and maintain databases and data collection systems
Identify opportunities for process improvement and operational efficiency through data analysis
Implement machine learning algorithms to enhance decision making processes

About You

In addition to placing high value on continuous improvement, collaboration and accountability, you bring:

Bachelor's degree in Data Science, Statistics, Computer Science, or a related field. Master's degree preferred.
Minimum of 3 years of experience in data science or a related role.
Proficiency in programming languages such as Python, and SQL.
Experience with data visualization tools like Tableau, Power BI, or similar.
Knowledge of machine learning techniques and frameworks.
Experience working with data from wearable devices and Electronic Health Records (EHR) systems is an asset.
Experience with cloud computing platforms
A passion for the healthcare sector and/or ensuring seniors have access to quality accommodations, services and care.

About Us

It all began in 1988 when our Founder, Joseph Shannon, purchased a single nursing home in his hometown of Sydney, Cape Breton. For 35 years, Shannex has grown as a trusted provider of senior accommodations, services and care in Nova Scotia, New Brunswick, and Ontario. Our industry-leading services are inspired by residents and delivered by Parkland Retirement Living and Lifestyle Residences, Shannex Enhanced Care, Faubourg du Mascaret, and a home care division of team members who create an exceptional resident experience and a positive, fulfilling work environment where every voice matters.

If you’re ready to join the Shannex team of Great People, apply today!

Great People is a core value at Shannex based on the belief that our team members are the spirit and foundation of the organization. Shannex believes equity, diversity, inclusion and belonging is about creating a culture that embraces the uniqueness of individuals, where every person is treated fairly and where racism and discrimination are not tolerated. At Shannex, every team member belongs.

All applications are kept in strict confidentiality.

Only those selected for an nterview will be contacted.","{""role_summary"":""As a Data Scientist at Shannex, you will collect, analyze, and interpret large datasets to derive meaningful insights, develop predictive models, and work closely with clinical staff to deliver actionable insights, ultimately contributing to better living for seniors."",""key_terms"":[{""term"":""Predictive models"",""explanation"":""Statistical models that forecast future events or behaviors, such as patient outcomes, to inform decision-making.""},{""term"":""Data experiments"",""explanation"":""Systematic tests of hypotheses using data to validate models and identify insights.""},{""term"":""Machine learning algorithms"",""explanation"":""Automated processes that enable machines to learn from data and make predictions or decisions without human intervention.""},{""term"":""Cloud computing platforms"",""explanation"":""On-demand access to a shared pool of computing resources, such as storage and processing power, over the internet.""},{""term"":""Electronic Health Records (EHR) systems"",""explanation"":""Digital versions of a patient's medical history, including diagnoses, medications, test results, and other health information.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in Data Science, Statistics, Computer Science, or a related field"",""Minimum of 3 years of experience in data science or a related role"",""Proficiency in programming languages such as Python, and SQL"",""Experience with data visualization tools like Tableau, Power BI, or similar"",""Knowledge of machine learning techniques and frameworks""],""nice_to_have"":[""Master's degree"",""Experience working with data from wearable devices and Electronic Health Records (EHR) systems"",""Experience with cloud computing platforms"",""Passion for the healthcare sector and/or ensuring seniors have access to quality accommodations, services and care""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a data experiment to test a hypothesis?"",""example_answer"":""I would first clearly define the hypothesis and identify the key variables to measure. Then, I would design an experiment with a control group and a treatment group, ensuring that the sample size is sufficient and the data is representative. Next, I would collect and analyze the data, using statistical methods to validate the results. Finally, I would interpret the findings and communicate the results to stakeholders.""},{""question"":""How do you stay up-to-date with the latest data science techniques and tools?"",""example_answer"":""I regularly read industry publications and blogs, attend conferences and webinars, and participate in online forums and communities to stay current with the latest developments in data science. I also experiment with new tools and techniques on personal projects to deepen my understanding and skills.""}],""red_flags"":[""Lack of experience working with healthcare data"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Junior Data Scientist,"This is a remote position.

Junior Data Scientist - Remote Job, 1+ Year Experience

Annual Income: $69K - $79K

A valid work permit is necessary in Canada

About us: Patterned Learning is a platform that aims to help developers code faster and more efficiently. It offers features such as collaborative coding, real-time multiplayer editing, and the ability to build, test, and deploy directly from the browser. The platform also provides tightly integrated code generation, editing, and output capabilities.

Responsibilities:

Partner with engineers, product managers, and business partners to identify algorithmic problems, brainstorm possible approaches, and recommend the best path forward.
Develop algorithms iteratively, building in the right level of complexity to solve the business problem at hand and support future improvements.
Define success criteria for your models so that you can measure impact and changes over time. You'll be expected to communicate findings and drive continuous improvements.
Collaborate with Software Engineers to implement algorithms in production that scale gracefully.
Collaborate with stakeholders to prioritize projects and define requirements.
Carry out analysis of data produced by our hardware systems and create insightful visualizations to share your findings.
Contribute to internal libraries to help other teams with their data science needs, including visualization, prediction, optimization, and inference.

Requirements & Experience:

Advanced proficiency with Python and libraries commonly used for data analysis, e.g., Pandas, NumPy, SciPy, and Diplomatist.
Strong understanding of data modeling and statistical analysis.
Knowledge of optimization and predictive modeling techniques and experience applying them to real-world problems.
Skilled at translating a general question or problem into a clearly defined algorithmic solution.
Ability to communicate clearly with both technical and non-technical audiences.
Ability to work independently and manage multiple projects simultaneously.

Nice to haves:

1-year Experience with Data Bricks or PySpark
1 year Experience with product ionizing data models

Why Patterned Learning LLC?

Patterned Learning can provide intelligent suggestions, automate repetitive tasks, and assist developers in writing code more effectively. This can help reduce coding errors, improve productivity, and accelerate the development process.

Pattern recognition is particularly relevant in the context of coding. Neural networks, especially deep learning models, are commonly employed for pattern detection and classification tasks. These models simulate human decision-making and can identify patterns in data, making them well-suited for tasks like code analysis and generation.","{""role_summary"":""Collaborate with cross-functional teams to identify and solve algorithmic problems, develop and implement data-driven solutions, and communicate insights to drive business improvements."",""key_terms"":[{""term"":""Algorithmic problems"",""explanation"":""Complex mathematical or computational problems that require data analysis and modeling to solve.""},{""term"":""Real-time multiplayer editing"",""explanation"":""A feature that allows multiple users to edit code simultaneously in real-time.""},{""term"":""Code generation"",""explanation"":""The process of automatically generating code using machine learning models or algorithms.""},{""term"":""Pattern recognition"",""explanation"":""A machine learning technique used to identify patterns in data, often employed in code analysis and generation.""},{""term"":""Deep learning models"",""explanation"":""A type of neural network that simulates human decision-making to identify patterns in data.""}],""skill_priorities"":{""must_have"":[""Python"",""Data modeling"",""Statistical analysis"",""Optimization and predictive modeling"",""Communication skills""],""nice_to_have"":[""Data Bricks"",""PySpark"",""Product ionizing data models""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach solving an algorithmic problem, and what metrics would you use to measure its success?"",""example_answer"":""I would start by understanding the problem requirements and identifying the key variables involved. Then, I would develop a hypothesis and create a prototype to test it. To measure success, I would use metrics such as accuracy, precision, and recall, and continuously iterate on the solution to improve its performance.""},{""question"":""How do you stay up-to-date with new developments in data science and machine learning, and how do you apply that knowledge to your work?"",""example_answer"":""I regularly read industry blogs and research papers, and participate in online forums to stay current. I apply that knowledge by experimenting with new techniques and tools, and collaborating with colleagues to implement them in our projects.""}],""red_flags"":[""Lack of experience with Python and data analysis libraries"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":85.0}"
Data Scientist I (Junior),"Data Scientist

Location: Calgary, Alberta

Duration: 12-Month Contract

Role Overview

We're in search of a skilled Data Scientist to join our Digital Manufacturing team. In this role, you'll leverage machine learning, statistical algorithms, and optimization techniques to support initiatives aimed at ensuring safe, reliable, and competitive operations of our manufacturing assets. Working closely with process, mechanical, and automation engineers, you'll solve complex problems and design predictive or prescriptive models.

Additionally, you'll collaborate with data architects and developers to build scalable data pipelines and deploy models in production environments, both on the edge and in the cloud. Ensuring timely analysis and testing for regular maintenance, you'll translate business requirements into technical prototypes and solutions and effectively communicate the design, functionality, and output of analytical models/solutions developed.

Why Join Us

Engage in impactful projects within a dynamic team environment.
Access professional growth opportunities and competitive compensation.
Contribute to a culture of innovation and excellence.

Key Responsibilities

Support initiatives to deliver safe, reliable, and competitive operations of manufacturing assets.
Collaborate with process, mechanical, and automation engineers to solve complex problems using data science methodologies.
Design and build explorative, predictive, or prescriptive models utilizing optimization, simulation, and machine learning techniques.
Collaborate with data architects and data developers to build scalable data pipelines and deploy models from development to production environments on edge or in the cloud.
Ensure timely analysis and testing for regular maintenance of solutions over time.
Translate business requirements into technical prototypes and solutions.
Communicate the design, functionality, and output of analytical models/solutions developed.

Qualifications

Bachelor’s or Graduate Degree in engineering, computer science, mathematics, physics, or a similar technical discipline.
0-5 years of experience in statistics and machine learning, including work with time series, images, and text data processing.
Proficiency in Python and related data science libraries (Pandas, Scikit-learn, Numpy, Matplotlib, etc.).
Experience in deploying models in a production environment, particularly using cloud platforms such as Azure Databricks.
Experience executing projects, both working independently and as part of a cross-functional team.
Excellent written and verbal communication skills.
Openness to learning and a commitment to safety, actively contributing to a safe working environment.

Apply now and join us in shaping the future of the industry.","{""role_summary"":""Work as a Data Scientist to support manufacturing operations by leveraging machine learning, statistical algorithms, and optimization techniques to solve complex problems and design predictive models."",""key_terms"":[{""term"":""Machine learning"",""explanation"":""A type of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Statistical algorithms"",""explanation"":""Mathematical procedures used to analyze and interpret data, often involving hypothesis testing and confidence intervals.""},{""term"":""Optimization techniques"",""explanation"":""Methods used to find the best solution among a set of possible solutions, often involving minimizing or maximizing a function.""},{""term"":""Data pipelines"",""explanation"":""A series of processes used to extract, transform, and load data from one system to another, often for analysis or reporting purposes.""},{""term"":""Cloud platforms"",""explanation"":""Remote computing environments that provide on-demand access to a shared pool of computing resources, such as Azure Databricks.""}],""skill_priorities"":{""must_have"":[""Python"",""Machine learning"",""Statistical algorithms"",""Data pipelines"",""Cloud platforms""],""nice_to_have"":[""Experience with time series, images, and text data processing"",""Experience executing projects independently and as part of a cross-functional team""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a predictive model to optimize manufacturing operations?"",""example_answer"":""I would start by collecting and preprocessing relevant data, then use techniques such as regression analysis or decision trees to build a model. I would also consider using techniques such as cross-validation to evaluate the model's performance and ensure it generalizes well to new data.""},{""question"":""How do you ensure that your data pipelines are scalable and efficient?"",""example_answer"":""I would design the pipeline to handle large volumes of data by using distributed computing frameworks such as Apache Spark, and ensure that the pipeline is modular and easy to maintain by using design patterns such as the Extract-Load-Transform (ELT) pattern.""}],""red_flags"":[""Lack of experience with cloud platforms"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Data Scientist - Machine Learning,"Company Description

You will join a world-class team of engineers and data scientists from Facebook, Uber, Amazon and Google. We are a fast growing consulting firm based in Toronto with clients ranging from leading startups building impactful technologies to Fortune 500 companies looking to scale their engineering and data capabilities.

Job Description

We are looking for Data Scientists who are passionate about solving real world problems. You enjoy working with both structured and/or unstructured data and are motivated to productize scalable machine learning models. Critical thinking and problem-solving skills are essential for this role.

Qualifications

BS (or higher, e.g., MS, or PhD) in Computer Science or related engineering field involving coding
Experienced implementing and scaling machine learning models in production environments
Strong understanding of machine learning theory
Hands on experience with Statistics
Capable of quickly implementing prototypes of cutting-edge research papers
Proficient in Python (i.e. Pandas, Numpy, scikit-learn, etc), R, TensorFlow, amongst other data science related tools and libraries
Analytical mind and strong business acumen

If you're passionate about data science and is hungry to learn, please apply!

Additional Information

We have competitive compensation.
Work on cool projects based on your interests and skills. We believe in accountability and NOT micro-management.","{""role_summary"":""Work as a Data Scientist to solve real-world problems by developing scalable machine learning models and working with structured and unstructured data."",""key_terms"":[{""term"":""Machine Learning"",""explanation"":""A type of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Scalable"",""explanation"":""Able to handle increased data volume, traffic, or user activity without compromising performance.""},{""term"":""Unstructured Data"",""explanation"":""Data that lacks a predefined format or organization, making it difficult for computers to search and analyze.""},{""term"":""Production Environment"",""explanation"":""A live system where software applications or models are deployed for real-world use.""}],""skill_priorities"":{""must_have"":[""Python"",""Machine Learning"",""Statistics"",""Data Science""],""nice_to_have"":[""R"",""TensorFlow""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach implementing a machine learning model in a production environment?"",""example_answer"":""I would start by ensuring the model is properly tested and validated, then deploy it using a containerization tool like Docker, and finally monitor its performance using metrics like accuracy and latency.""},{""question"":""How do you stay current with new developments in machine learning research?"",""example_answer"":""I regularly read research papers and articles, attend conferences or meetups, and participate in online forums to stay up-to-date with the latest advancements.""}],""red_flags"":[""Lack of experience with machine learning model implementation in production environments"",""Inability to explain machine learning concepts or theories""],""confidence_score"":90.0}"
HDO Data Scientist-Canada,"Role: HDO Data Scientist

Location: Remote/Canada

Duration: 6+ Months

Job Description

Key Responsibilities:

Collaborate with cross-functional teams to identify and prioritize quick win opportunities for data-driven insights and improvements.

Develop and implement ML models to analyze large datasets and extract valuable insights.

Apply advanced statistical techniques and algorithms to solve complex business problems.

Design and implement data transformation processes to ensure data quality and integrity.

Utilize genAI and LLM models to enhance data analysis and predictive capabilities.

Collaborate with Data Engineers to design and optimize data architecture for efficient data processing and storage.

Develop and deploy scalable and production-ready ML models.

Conduct exploratory data analysis to uncover patterns, trends, and correlations in the data.

Stay up-to-date with the latest advancements in ML, AI, and data science technologies.

Qualifications

What you bring

You are comfortable with high level of ambiguity and possess a continuous improvement mindset

Master's or Ph.D. degree in Computer Science, Data Science, or a related field.

Proven experience as a Data Scientist or similar role, working on data transformation and AI-related projects.

Strong programming skills in Python for data manipulation, analysis, and model development.

In-depth knowledge of ML algorithms, techniques, and frameworks.

Familiarity with genAI and LLM models and their implementation.

Experience in designing and optimizing data architecture for efficient data processing and storage.

Proficiency in SQL and database management systems.

Strong Problem-solving And Analytical Skills.

Excellent communication and collaboration skills to work effectively with cross-functional teams.

If you are passionate about leveraging data and AI to drive business outcomes and have the required skills and experience, we would love to hear from you. Join our team and contribute to the success of our data-driven initiatives","{""role_summary"":""Work with teams to identify opportunities for data-driven insights, develop and implement machine learning models, and analyze large datasets to extract valuable insights."",""key_terms"":[{""term"":""ML models"",""explanation"":""Machine learning models used to analyze large datasets and extract valuable insights.""},{""term"":""genAI and LLM models"",""explanation"":""Generative AI and Large Language Models used to enhance data analysis and predictive capabilities.""},{""term"":""Data transformation"",""explanation"":""The process of converting and preparing data for analysis and modeling.""},{""term"":""Data architecture"",""explanation"":""The design and organization of data storage and processing systems.""}],""skill_priorities"":{""must_have"":[""Python programming skills"",""Machine learning algorithms and techniques"",""Data manipulation and analysis skills"",""SQL and database management skills"",""Problem-solving and analytical skills"",""Communication and collaboration skills""],""nice_to_have"":[""Experience with genAI and LLM models"",""Experience with designing and optimizing data architecture""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach developing a machine learning model to analyze a large dataset?"",""example_answer"":""I would start by exploring the dataset to understand the features and patterns, then select a suitable algorithm and implement it using Python. I would also ensure the model is scalable and production-ready.""},{""question"":""How do you stay up-to-date with the latest advancements in machine learning and AI?"",""example_answer"":""I regularly read industry blogs and research papers, attend conferences and webinars, and participate in online forums to stay current with the latest developments.""}],""red_flags"":[""Lack of experience with machine learning algorithms and techniques"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Machine Learning Engineer (Canada),"Title : Machine Learning Engineer

Type : Contract to Hire

Location : 100% Remote (Canada)

Rate: $Open / Market

Requirements

BSc/MSc in computer science, mathematics or related technical discipline
1-4 years' experience in software engineering with exposure to statistical and/or data science role (5-10 years for Senior ML Engineer)
Deep knowledge and proven experience with optimizing machine learning model in a production context
Experience with Python or Scala is required. Background in programming in C, C++, Java is beneficial. Exposure to both streaming and non-streaming analytics Experience with SQL, Spark, Pandas, Numpy, SciPy, Statsmodels, Stan, pymc3, Caret, Scikit-learn, Keras, TensorFlow, Pytorch, Databricks is beneficial
Experience working with large data sets, simulation/optimisation and distributed computing tools (Map/Reduce, Hadoop, Hive, Spark, Gurobi, Arena, etc.)
Refactor prototypes of predictive models into highly performant, production ready solutions
Work closely with Data Engineers and Data Scientists to create analytical variables, metrics, and models
Work closely with data scientists to solve difficult engineering and machine learning problems and produce high-quality code
Choose and use the right analytical libraries, programming languages, and frameworks for each task
Contribute to building client capabilitiesby coaching team members on data science methodologies and approaches
Contribute to best coding and engineering practice across AI projects
Build/refactor/develop code into reusable libraries, APIs, and tools
Able to build a sense of trust and rapport that creates a comfortable & effective workplace; collaborative
Attitude to thrive in a fun, fast-paced, startup-like environment
Open minded to new approaches and learning


Benefits

Note: If interested please send your updated resume to ajith.anthoniraj@two95intl.com and include your rate requirement along with your contact details with a suitable time when we can reach you. If you know of anyone in your sphere of contacts, who would be a perfect match for this job then, we would appreciate if you can forward this posting to them with a copy to us.

We look forward hearing from you at the earliest!","{""role_summary"":""Design, develop, and deploy machine learning models in a production environment, collaborating with data engineers and scientists to create analytical solutions."",""key_terms"":[{""term"":""Machine Learning Model"",""explanation"":""A mathematical model that enables a system to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Production Context"",""explanation"":""A live environment where machine learning models are deployed to process real-world data and provide insights.""},{""term"":""Streaming Analytics"",""explanation"":""Real-time analysis of data as it is generated, often used for applications that require immediate insights.""},{""term"":""Distributed Computing"",""explanation"":""A method of processing large datasets by breaking them down into smaller tasks that can be executed simultaneously across multiple machines.""}],""skill_priorities"":{""must_have"":[""Python or Scala programming"",""Experience with machine learning model optimization"",""Familiarity with SQL and data analysis libraries (e.g., Pandas, NumPy)""],""nice_to_have"":[""Background in C, C++, Java programming"",""Experience with Spark, Hadoop, and other distributed computing tools"",""Knowledge of statistical modeling libraries (e.g., SciPy, Statsmodels)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach optimizing machine learning models for production deployment?"",""example_answer"":""I use techniques such as hyperparameter tuning, model pruning, and knowledge distillation to optimize models for production. I also consider factors like data quality, model interpretability, and scalability.""},{""question"":""Can you explain the trade-offs between using streaming analytics versus batch processing for large datasets?"",""example_answer"":""Streaming analytics provides real-time insights but can be computationally expensive, while batch processing is more cost-effective but may introduce latency. The choice depends on the specific use case and business requirements.""}],""red_flags"":[""Lack of experience with machine learning model optimization"",""Inability to work collaboratively with data engineers and scientists""],""confidence_score"":85.0}"
Machine Learning Engineer,"Machine Learning Engineer
Healthcare, AI

DeepRec.ai are hiring for a talented Machine Learning Engineer to join a fantastic organisation in Canada who are using AI to improve patient experiences and the clinical workflow. This is an innovative and inspiring organisation who have specific clinical tasks they need to perform, where they use AI to execute them.

As well as creating datasets, you'll also be building bleeding-edge AI applications, aimed to assist clinicians in practice management, cost reduction, issue prevention and improved health care experiences.

This role reports into the Head of AI.

If you are an ML Engineer, with some experience in the healthcare sector, and you have experience in some of the following skills: LLamaIndex, HuggingFace, SentenceTransformers, PyTorch, Python, Apache Spark, we would love to chat

This is a hybrid role in Toronto and the chance to join a growing company!

We look forward to hearing from you","{""role_summary"":""Design and develop AI applications to improve patient experiences and clinical workflow in a healthcare organization."",""key_terms"":[{""term"":""LLamaIndex"",""explanation"":""A machine learning library for efficient indexing and retrieval of large language models.""},{""term"":""HuggingFace"",""explanation"":""A popular open-source library for natural language processing and transformer models.""},{""term"":""SentenceTransformers"",""explanation"":""A library for sentence embeddings and semantic search.""},{""term"":""PyTorch"",""explanation"":""A popular open-source machine learning framework for building and training AI models.""},{""term"":""Apache Spark"",""explanation"":""A unified analytics engine for large-scale data processing and machine learning.""}],""skill_priorities"":{""must_have"":[""Machine Learning Engineer"",""Python"",""PyTorch""],""nice_to_have"":[""Healthcare sector experience"",""LLamaIndex"",""HuggingFace"",""SentenceTransformers"",""Apache Spark""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach building and deploying machine learning models in a healthcare setting?"",""example_answer"":""I would focus on understanding the clinical requirements, selecting the right algorithms and tools, and ensuring model explainability and interpretability. I would also consider data privacy and security regulations in the healthcare sector.""},{""question"":""Can you describe your experience with PyTorch and how you've used it in previous projects?"",""example_answer"":""I've used PyTorch for building and training deep learning models, including computer vision and natural language processing tasks. I've also used it for rapid prototyping and deployment of AI applications.""}],""red_flags"":[""Lack of experience in the healthcare sector"",""Limited knowledge of PyTorch and its ecosystem""],""confidence_score"":85.0}"
AI/ML Engineer,"🏢 Locations: Hybrid Remote (1-2 days onsite) in Toronto (Bloor-Yonge)

Impact-Driven Senior/Staff AI/ML Engineer for Productivity Automation

We're seeking a passionate and impact-driven Senior or Staff Artificial Intelligence and Machine Learning Engineer to join our experienced founding team from Mozilla, Spotify, LinkedIn, and Apple and revolutionize productivity through automation.

Your mission will be to design and develop AI/ML models and algorithms that automate mundane, soul-crushing tasks.

As part of our team, you'll play a crucial role in shaping our data graph used by over 500K people across 30K companies in 150 countries. This data graph standardizes the internet, and you'll have direct input in shaping our roadmap as we grow to 1 million users.

What you'll do:

In this role you will collaborate with frontend and full-stack teams across the organization as we implement the machine learning functionalities you develop into our React.js and Redux applications. You will also:

Collaborate in integrating AI/ML solutions with existing Node.js applications.
Conduct data preprocessing, feature engineering, and model evaluation.
Optimize database interactions using PostgreSQL to efficiently handle large datasets.
Manage and query large datasets with PostgreSQL.
Leverage AWS services for deploying, scaling, and maintaining AI/ML models and data pipelines.
Deploy applications and manage data with AWS (Eg. EC2, S3, Lambda, Elastic Beanstalk and others).
Manage workflows and data pipelines (Eg. Apache Airflow, Camunda or similar)
Perform OCR tasks with Tesseract and advanced image and video analysis with Google Cloud Vision or Amazon Rekognition.
Use Docker for containerizing applications.

About you:

You are proficient in Python, or JavaScript and TypeScript
You have experience with any cloud provider such as AWS (we use AWS), GCP, or Azure.
You have a passion for building innovative solutions that drive impact and automate mundane tasks.
You have expertise in AI/ML model design and development, frameworks, and libraries such as TensorFlow, PyTorch, scikit-learn, Pandas, NumPy, NLTK or spaCy, OpenCV or similar.
You have experience working with RPA technologies such as Apache Airflow, Camunda, Tesseract, Google Cloud Vision, or Amazon Rekognition and AWS services like EC2, S3, Lambda, and Elastic Beanstalk.
You have knowledge of CI/CD tools and Docker.
You work collaboratively in a fast-paced environment.
You are excited about leveraging OpenAI and Gemini technologies

Join us and pioneer the first AI model to catalog the internet and take high ownership in productionizing research.

Tech Stack

Previous experience with all of these technologies is not required

Python
Typescript
React
Redux
RxJS
Emotion
Node.js
Postgres

Benefits

Interesting and challenging work
Competitive salary and equity
Regular team events and off-sites (Iceland, Lisbon, Dominican Republic, Mexico)
Unlimited PTO
Annual wellness credit
Productivity stipend","{""role_summary"":""Design and develop AI/ML models and algorithms to automate mundane tasks, collaborating with cross-functional teams to implement solutions and shape the company's data graph."",""key_terms"":[{""term"":""AI/ML models"",""explanation"":""Artificial Intelligence and Machine Learning models used for automation and data analysis.""},{""term"":""Data graph"",""explanation"":""A standardized data structure used by the company to organize and connect data across multiple sources.""},{""term"":""RPA technologies"",""explanation"":""Robotic Process Automation technologies used for automating repetitive tasks, such as Apache Airflow, Camunda, and Tesseract.""},{""term"":""CI/CD tools"",""explanation"":""Continuous Integration and Continuous Deployment tools used for automating the software development and deployment process.""}],""skill_priorities"":{""must_have"":[""Python or JavaScript and TypeScript"",""Experience with cloud providers (AWS, GCP, or Azure)"",""AI/ML model design and development"",""Collaborative work in a fast-paced environment""],""nice_to_have"":[""Experience with RPA technologies"",""Knowledge of CI/CD tools and Docker"",""Familiarity with OpenAI and Gemini technologies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach designing and developing an AI/ML model to automate a mundane task?"",""example_answer"":""I would start by identifying the task and its requirements, then select the appropriate AI/ML framework and library based on the task's complexity. Next, I would preprocess the data, engineer features, and evaluate the model's performance. Finally, I would deploy and maintain the model using cloud services like AWS.""},{""question"":""How do you optimize database interactions for large datasets using PostgreSQL?"",""example_answer"":""I would use indexing, caching, and query optimization techniques to improve the performance of database interactions. Additionally, I would consider using data warehousing and ETL processes to manage large datasets.""}],""red_flags"":[""Lack of experience with AI/ML model design and development"",""Inability to work collaboratively in a fast-paced environment""],""confidence_score"":90.0}"
Junior Data Scientist Engineer,"This is a remote position.

Junior Data Scientist Engineer - Remote Job, 1+ Year Experience

Annual Income: $64K - $74K

A valid work permit is necessary in Canada

About us: Patterned Learning is a platform that aims to help developers code faster and more efficiently. It offers features such as collaborative coding, real-time multiplayer editing, and the ability to build, test, and deploy directly from the browser. The platform also provides tightly integrated code generation, editing, and output capabilities.

Skills and Abilities:

Strong knowledge of R or Python for data analysis and modeling.
Proficiency in statistical programs such as R, SAS, MATLAB, or Python.
Familiarity with spreadsheets (VBA) and database applications (Access, Oracle, SQL, or equivalent technology).
Basic understanding of SQL, Javascript, XML, JSON, and HTML.
Ability to learn new methods quickly and work under deadlines.
Excellent teamwork and communication skills.
Strong analytical and problem-solving abilities.
Basic understanding of SQL, Javascript, XML, JSON, and HTML.

Preferred:

Knowledge of actuarial concepts and life, health, and/or annuity products.
Experience with statistical modeling techniques such as GLM, Decision Trees, Time Series, Regression, etc.
Familiarity with Microsoft DeployR.
Exposure to insurance risk analysis.
Basic experience in computational finance, econometrics, statistics, and math.
Knowledge of SQL and VBA.
Familiarity with R or Python for predictive modeling

Why Patterned Learning LLC?

Patterned Learning can provide intelligent suggestions, automate repetitive tasks, and assist developers in writing code more effectively. This can help reduce coding errors, improve productivity, and accelerate the development process.

Pattern recognition is particularly relevant in the context of coding. Neural networks, especially deep learning models, are commonly employed for pattern detection and classification tasks. These models simulate human decision-making and can identify patterns in data, making them well-suited for tasks like code analysis and generation.","{""role_summary"":""Assist in developing and improving the Patterned Learning platform by applying data analysis and modeling skills to help developers code more efficiently."",""key_terms"":[{""term"":""R"",""explanation"":""A programming language used for statistical computing and graphics.""},{""term"":""Python"",""explanation"":""A high-level programming language used for data analysis, machine learning, and web development.""},{""term"":""SQL"",""explanation"":""A standard language for managing relational databases.""},{""term"":""GLM"",""explanation"":""Generalized Linear Models, a statistical technique used for modeling and analyzing data.""},{""term"":""Decision Trees"",""explanation"":""A machine learning technique used for classification and regression tasks.""},{""term"":""Time Series"",""explanation"":""A sequence of data points measured at regular time intervals, often used for forecasting and analysis.""},{""term"":""Regression"",""explanation"":""A statistical technique used for modeling the relationship between variables.""},{""term"":""DeployR"",""explanation"":""A platform for deploying and managing R-based applications.""},{""term"":""Insurance risk analysis"",""explanation"":""The process of identifying and assessing potential risks in the insurance industry.""},{""term"":""Computational finance"",""explanation"":""The use of computational methods and algorithms to analyze and model financial systems.""},{""term"":""Econometrics"",""explanation"":""The application of statistical methods to economic data.""},{""term"":""Pattern recognition"",""explanation"":""The process of identifying patterns in data, often using machine learning and deep learning techniques.""}],""skill_priorities"":{""must_have"":[""R or Python for data analysis and modeling"",""Statistical programs such as R, SAS, MATLAB, or Python"",""Familiarity with spreadsheets (VBA) and database applications (Access, Oracle, SQL, or equivalent technology)"",""Basic understanding of SQL, Javascript, XML, JSON, and HTML"",""Ability to learn new methods quickly and work under deadlines"",""Excellent teamwork and communication skills"",""Strong analytical and problem-solving abilities""],""nice_to_have"":[""Knowledge of actuarial concepts and life, health, and/or annuity products"",""Experience with statistical modeling techniques such as GLM, Decision Trees, Time Series, Regression, etc."",""Familiarity with Microsoft DeployR"",""Exposure to insurance risk analysis"",""Basic experience in computational finance, econometrics, statistics, and math"",""Knowledge of SQL and VBA"",""Familiarity with R or Python for predictive modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of overfitting in machine learning and how to prevent it?"",""example_answer"":""Overfitting occurs when a model is too complex and performs well on the training data but poorly on new, unseen data. To prevent overfitting, techniques such as regularization, early stopping, and cross-validation can be used.""},{""question"":""How would you approach data preprocessing for a predictive modeling task?"",""example_answer"":""I would start by exploring the data to identify missing values, outliers, and correlations. Then, I would perform necessary transformations, such as normalization and feature scaling, to prepare the data for modeling.""},{""question"":""Can you describe a project where you applied statistical modeling techniques to solve a business problem?"",""example_answer"":""In my previous role, I used regression analysis to identify factors contributing to customer churn. The insights from the model helped the company develop targeted retention strategies, resulting in a significant reduction in churn rate.""}],""red_flags"":[""Lack of experience with R or Python"",""Inability to work under deadlines"",""Poor communication and teamwork skills""],""confidence_score"":85.0}"
"Data Scientist, Decisions - Safety","At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

Data Science is at the heart of Lyft’s products and decision-making. As a member of the Rider & Safety Science team, you will work in a dynamic environment, where we embrace moving quickly to build the world’s best transportation. Data Scientists take on a variety of problems ranging from shaping critical business decisions to building algorithms that power our internal and external products. We’re looking for passionate, driven Data Scientists to take on some of the most interesting and impactful problems in ridesharing.

As a Data Scientist, Decisions in the Rider & Safety team, you will leverage data and rigorous, analytical thinking to shape our rider app and make business decisions that put our customers first. You will identify and scope opportunities, shape priorities, recommend technical solutions, design experiments, and measure impact. You will bring a quantitative mindset to decision-making in partnership with product, design, engineering, business, and operations stakeholders throughout the organization.

You will report to a Data Science Manager in the Rider & Safety Science team.

Responsibilities:

Leverage data and analytic frameworks to identify opportunities for growth and efficiency
Partner with product managers, engineers, marketers, designers, and operators to translate data insights into decisions and action
Design and analyze online experiments; communicate results and act on launch decisions
Develop analytical frameworks to monitor business and product performance
Establish metrics that measure the health of our products, as well as rider and driver experience

Experience:

Degree in a quantitative field such as statistics, economics, applied math, operations research or engineering (advanced degrees preferred), or relevant work experience
3+ years of industry experience in a data science or analytics role
Proficiency in SQL - able to write structured and efficient queries on large data sets
Experience in programming, especially with data science and visualization libraries in Python or R is helpful
Experience in online experimentation and statistical analysis
Strong oral and written communication skills, and ability to collaborate with and influence cross-functional partners

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Access to a Health Care Savings Account
In addition to provincial observed holidays, team members get 15 days paid time off, with an additional day for each year of service
4 Floating Holidays each calendar year prorated based off of date of hire
10 paid sick days per year regardless of province
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid","{""role_summary"":""As a Data Scientist in the Rider & Safety team, you will leverage data and analytical thinking to shape business decisions, identify opportunities, and measure impact, working closely with cross-functional stakeholders to put customers first."",""key_terms"":[{""term"":""Data Science"",""explanation"":""The practice of extracting insights and knowledge from data to inform business decisions.""},{""term"":""Online Experiments"",""explanation"":""A method of testing hypotheses by randomly assigning users to different groups and measuring the impact of a change on a specific outcome.""},{""term"":""Quantitative Field"",""explanation"":""A field of study that focuses on the use of mathematical and statistical techniques to analyze and interpret data, such as statistics, economics, or operations research.""}],""skill_priorities"":{""must_have"":[""Degree in a quantitative field"",""3+ years of industry experience in a data science or analytics role"",""Proficiency in SQL"",""Experience in online experimentation and statistical analysis"",""Strong oral and written communication skills""],""nice_to_have"":[""Experience with data science and visualization libraries in Python or R"",""Advanced degree""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to design and analyze an online experiment to inform a business decision?"",""example_answer"":""In my previous role, I designed an experiment to test the impact of a new feature on user engagement. I worked with cross-functional stakeholders to define the experiment's objectives, developed the experimental design, and analyzed the results using statistical methods. The insights from the experiment informed a key business decision, resulting in a 20% increase in user engagement.""},{""question"":""How do you stay up-to-date with new developments in data science and analytics?"",""example_answer"":""I regularly read industry blogs and publications, attend conferences and meetups, and participate in online forums to stay current with the latest trends and techniques in data science and analytics.""}],""red_flags"":[""Lack of experience with online experimentation and statistical analysis"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
ML Engineer / Toronto,"Intersog® is a Chicago-based provider of ROI-driven custom web and mobile development specializing in the delivery of full-service, end-to-end solutions, and project resources to Fortune 500 companies, SMEs, and startups. We help our clients attack their ambitious business goals, solve skills shortage issues, and become innovative by building Dedicated Software Development Teams in Mexico, Canada, the U.S.A., and Ukraine and/or providing on-demand IT project resources to complete required skills on their in-house teams.

About The Role

We seek an ML Engineer to join the AI Practice team dedicated to pioneering AI-driven solutions, encompassing hyper-personalization, AI-powered selling strategies, extensive unstructured data analysis through NLP, and innovative dynamic pricing approaches. Utilizing the latest in machine learning and deep learning technologies alongside comprehensive engineering platforms, they are committed to developing impactful products and client-centered solutions.

Requirements

Develop and manage ML model pipelines, focusing on feature engineering, model training, and inferencing
Scale ML algorithms for large data sets under strict service level agreements (SLAs)
Enhance ML Engineering platforms and ensure the implementation of MLOps practices for model monitoring and feedback loops
Write clean, production-quality code that adheres to best practices and design guidelines
Work collaboratively with global teams to deliver projects, utilizing development and project management tools to maintain organization and communication
Engage in continuous learning to stay abreast of new technologies and methodologies in ML architecture and design

Qualifications:

Bachelor's or Master's in Computer Science, MIS, IT, or related fields
2-4 years of experience in deploying production-level ML models
Proficiency in Python / PySpark and experience with ML platforms (e.g., Dataiku, Sagemaker, MLFlow)
Skilled in deploying models to cloud services (AWS, Azure, GCP) and optimizing ML models for performance and scalability
Solid understanding of machine learning, deep learning fundamentals, common data structures, algorithms, and design patterns
Excellent communication skills, both verbal and written","{""role_summary"":""Develop and manage machine learning model pipelines, scale algorithms for large data sets, and enhance ML engineering platforms to deliver impactful products and client-centered solutions."",""key_terms"":[{""term"":""MLOps"",""explanation"":""Machine Learning Operations, a set of practices that combines machine learning and DevOps to streamline the machine learning lifecycle.""},{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""},{""term"":""Hyper-personalization"",""explanation"":""The use of data and analytics to create highly targeted and relevant experiences for individuals.""},{""term"":""PySpark"",""explanation"":""A Python library for Apache Spark, a unified analytics engine for large-scale data processing.""}],""skill_priorities"":{""must_have"":[""Python"",""ML platforms (e.g., Dataiku, Sagemaker, MLFlow)"",""Cloud services (AWS, Azure, GCP)"",""Machine learning, deep learning fundamentals""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize ML models for performance and scalability?"",""example_answer"":""I use techniques such as model pruning, knowledge distillation, and batch normalization to optimize ML models for performance and scalability.""},{""question"":""Can you explain the concept of MLOps and its importance in machine learning development?"",""example_answer"":""MLOps is a set of practices that combines machine learning and DevOps to streamline the machine learning lifecycle. It's important because it enables efficient collaboration, automates repetitive tasks, and ensures reproducibility and reliability of ML models.""}],""red_flags"":[""Lack of experience with ML platforms and cloud services"",""Inability to communicate complex technical concepts effectively""],""confidence_score"":90.0}"
Engineer - AI/ML,"Our team has an immediate 12-month contract opening for an Engineer.

Responsibilities:

Development of next-gen PaaS platform, including PaaS Middleware, Application Platform and Application Integration Services.
Collaborate with PaaS Engineers for integrating advanced AI/ML models (e.g., LLMs) into existing solutions.
Analyze, investigate, and implement (Generative) AI solutions for Cloud Service features and technologies.
Conduct technical research, and assist in POCs development and deliveries.

Job requirements

What you’ll bring to the team:

2+ years of Data Science and Machine Learning development experience.
A strong foundation in algorithms, data structure, and object-oriented-programming along with proficiency in Python, R, Java and SQL.
Experience in using ML algorithms (i.e., supervised, unsupervised, and reinforcement learning) and exploratory data analysis (EDA) tools and libraries including Numpy, Pandas, Matplotlib, Seaborn, and Scikit-learn.
Solid knowledge of Artificial Neural Networks like CNN, RNN, LSTM, and GRU, along with expertise in Deep Learning frameworks such as PyTorch and TensorFlow.
Familiarity with NLP and Generative AI concepts and tools including Transformers, (Mutlimodal) Large Language Models, Vector databases.
Excellent organization skills, attention to detail, and ability to multi-task under considerable pressure and changing priorities.
Strong interpersonal and team communications skills.
BS degree in Computer Science or equivalent; advanced degree is an asset.","{""role_summary"":""Develop and integrate AI/ML models into a next-gen PaaS platform, conducting technical research and assisting in proof-of-concept developments."",""key_terms"":[{""term"":""PaaS"",""explanation"":""Platform as a Service, a cloud computing model that provides a complete platform for developing, running, and managing applications.""},{""term"":""LLMs"",""explanation"":""Large Language Models, a type of artificial intelligence model trained on large amounts of text data to generate language outputs.""},{""term"":""Generative AI"",""explanation"":""A type of artificial intelligence that involves generating new, original content, such as images, videos, or text, based on patterns and structures learned from data.""},{""term"":""CNN"",""explanation"":""Convolutional Neural Network, a type of artificial neural network used for image and signal processing.""},{""term"":""RNN"",""explanation"":""Recurrent Neural Network, a type of artificial neural network used for sequential data processing.""},{""term"":""LSTM"",""explanation"":""Long Short-Term Memory, a type of recurrent neural network used for sequential data processing.""},{""term"":""GRU"",""explanation"":""Gated Recurrent Unit, a type of recurrent neural network used for sequential data processing.""},{""term"":""PyTorch"",""explanation"":""An open-source machine learning framework used for building and training artificial neural networks.""},{""term"":""TensorFlow"",""explanation"":""An open-source machine learning framework used for building and training artificial neural networks.""},{""term"":""Transformers"",""explanation"":""A type of artificial neural network architecture used for natural language processing tasks.""},{""term"":""Vector databases"",""explanation"":""A type of database optimized for storing and querying large amounts of vector data, often used in machine learning and AI applications.""}],""skill_priorities"":{""must_have"":[""Python"",""R"",""Java"",""SQL"",""Machine Learning development experience"",""Data Science experience"",""Algorithms"",""Data structure"",""Object-oriented-programming"",""ML algorithms"",""Exploratory data analysis tools"",""Artificial Neural Networks"",""Deep Learning frameworks""],""nice_to_have"":[""Advanced degree in Computer Science""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of Generative AI and its applications in Cloud Service features?"",""example_answer"":""Generative AI involves generating new, original content based on patterns and structures learned from data. In Cloud Service features, it can be used for tasks such as image and video generation, text summarization, and chatbots.""},{""question"":""How do you approach integrating AI/ML models into existing solutions?"",""example_answer"":""I would first analyze the requirements of the existing solution and identify areas where AI/ML models can be integrated. Then, I would design and implement the integration, ensuring seamless interaction between the models and the existing solution.""}],""red_flags"":[""Lack of experience in integrating AI/ML models into cloud-based solutions"",""Inability to explain complex AI/ML concepts in simple terms""],""confidence_score"":90.0}"
Machine Learning Engineer (6 month contract),"About You

You're driven by the potential of machine vision in transforming the world. You thrive on crafting intricate algorithms that power seamless, user-centric experiences. Every pixel and every frame matter to you, and you're eager to pioneer solutions that will redefine how people redesign their spaces. Feel like you're on the edge of a breakthrough, but need the right platform? Join us. With our elite tech squad, you'll take our revolutionary digital décor tools beyond the horizon!

At Leap Tools, we are building the world's most advanced solutions for the interior décor industry. With customers in 80+ countries, our clientele includes Fortune 500 companies such as Home Depot, local retailers such as Alexanian's, and everything in between. We have been recognized as one of the fastest-growing tech companies by Deloitte for multiple years in a row, and we are looking for ambitious challenge-seekers to fuel our momentum and help us create an iconic global tech company.

About You

Your expertise in Machine Learning isn’t just about models and algorithms; it’s about driving tangible, user-centric solutions.
You are willing and able to tackle unsolved problems without supervision or much guidance after you collaborate with your team members on initial designs.
You are persistent, despite days, weeks, or even months of disappointing results, maintaining the same level of determination as on day one.
You have a strong foundation in computer science and are very comfortable coding in Python.
You have read papers on machine learning topics and implemented your own versions of the papers.
You're hands-on with data: from collection and cleaning to putting together evaluation sets.
Challenges? Bring them on. You thrive when you're pushing the boundaries of what Machine Learning can achieve.


About The Role

Innovative Vision: Spearhead machine vision initiatives to instantly generate and visualize a vast array of home décor items, transforming virtual browsers into personalized interior design studios.
Holistic Redecoration: Utilize advanced algorithms to offer users an all-encompassing redecoration experience, seamlessly integrating wallpapers, flooring, countertops, and a plethora of other home essentials.
User-Centric Design: Develop technology to effortlessly reimagine and redesign their spaces with a few simple clicks, bridging the gap between vision and reality.
Adaptive Product Rendering: Implement dynamic machine vision techniques to adapt and present décor products in real-time based on user preferences, room dimensions, and existing furnishings.
Collaborative Evolution: Work closely with interior design experts, UX/UI designers, and tech teams to constantly refine models, ensuring trending styles and timeless classics are just a click away.


About Our Stack

PyTorch, Tensorflow, as well as our own in-house systems
Python and Django
Kubernetes on AWS


About Our Culture

We work in tight-knit teams to maximize speed and cultivate an ownership mentality.
We cherish curiosity and an obsession for details because we know these details are invaluable over the long run.
We promote an environment where ideas are challenged. The best ideas win!
We're hyper-focused on our achievements and our ability to execute on our promises. We act with urgency.
It's not always about us. We give back to our community to ensure it can grow.
We love to compete and have fun. Our game nights are legendary.


About Our Products

Our technology lets you see products in your own room before you buy.

Imagine you want to redesign your home and have been searching for new tiles for your kitchen, or a new rug for your living room. You definitely want to make sure it will look good in your space. We enable that through cutting-edge computer vision technology, presented in an extraordinarily simple and accessible way. Try our rug demo now! Simply upload a picture of your room using your mobile phone, and slide the rug under your coffee table: https://www.roomvo.com/rugdemo4r

About Our Results

Our customers see a 5x increase in e-commerce conversion rates and a dramatic decrease in the time it takes for their customers to make a purchase decision. We are also reducing the world’s carbon footprint by eliminating trips to the store and avoiding product returns, while also saving marriages -- now you can be sure you’re buying the right product for your home.

About Our Office And Remote Work

We are located in downtown Toronto with nearby access to both of the main subway lines. Currently, we are all working from home; we encourage our teams to work from wherever they are most productive, and many of us will continue to work from home in the future, either full-time or partially. While we're all working remotely, we’ve come up with a few ways to keep everyone on the same page, including a quick company-wide check-in every Monday, remote coffee breaks on Fridays, and ad hoc topical sharing sessions. Another big upside is you get to be around your pets and plants (if you have them).

About Our Hiring Process

Now: You upload your resume and complete a brief questionnaire.

Week 1: We arrange a video call with you to assess your abilities.

Week 2 or 3: You attend the second video interview soon after.

Week 3 or 4: You meet one of the founders.

Week 4 or 5: You receive an offer.

Take the Leap. Apply now.

Our demo, in case you missed it: https://www.roomvo.com/rugdemo4r","{""role_summary"":""Develop innovative machine vision solutions to transform the interior décor industry, focusing on user-centric experiences and seamless design tools."",""key_terms"":[{""term"":""Machine Vision"",""explanation"":""The use of computer algorithms to enable devices to interpret and understand visual information from the world.""},{""term"":""PyTorch"",""explanation"":""An open-source machine learning library used for building and training neural networks.""},{""term"":""Tensorflow"",""explanation"":""An open-source software library for machine learning and artificial intelligence.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""}],""skill_priorities"":{""must_have"":[""Machine Learning expertise"",""Python coding skills"",""Strong foundation in computer science"",""Experience with PyTorch and/or Tensorflow""],""nice_to_have"":[""Experience with Kubernetes"",""Knowledge of Django""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach developing a machine vision solution for generating and visualizing home décor items?"",""example_answer"":""I would start by researching existing solutions and identifying key challenges. Then, I would design and implement a machine learning model using PyTorch or Tensorflow, leveraging computer vision techniques to generate and visualize décor items. I would also ensure the solution is scalable and efficient, using Kubernetes for deployment.""},{""question"":""How do you stay up-to-date with the latest developments in machine learning and computer vision?"",""example_answer"":""I regularly read research papers and articles on machine learning topics, and implement my own versions of the papers to deepen my understanding. I also participate in online forums and attend conferences to stay current with industry trends.""}],""red_flags"":[""Lack of experience with machine learning and computer vision"",""Inability to work independently with minimal supervision"",""Insufficient persistence in the face of disappointing results""],""confidence_score"":90.0}"
Software Engineer (Python) - Up to CAD$200k + Huge Bonus Montreal,"Job title: Software Engineer (Python)- Up to $200,000 + Bonus + Package
Client: Elite Fintech Client
Experience Level: 1+ years
Salary: Up to $200,000 + Bonus + Package
Location: Montreal (hybrid)

Sells: Cutting-edge tech, a collaborative environment fostering Python/ React knowledge growth and development, fantastic office space in the heart of Montreal
An elite Fintech client are searching for Python/ React Developers to join elite talent and expertise.
This team has an unlimited tech budget, promotes a great culture, and is made up of incredible like-minded individuals.

Role
· Working on highly scalable, low latency infrastructure
· Provides the chance not only to work in Python or React, but gain exposure to a lot more from some of the best developers worldwide

Skills/Experience
· Strong knowledge of Python, FAST APIs
· Strong Computer Science fundamentals
If you're interested in this role, you can contact me (hogundapo@hunterbond.com) to learn more and express your interest.","{""role_summary"":""Develop scalable and low-latency infrastructure using Python and React, and collaborate with elite talent in a cutting-edge fintech company."",""key_terms"":[{""term"":""FAST APIs"",""explanation"":""A high-performance API framework for building scalable and efficient web applications.""},{""term"":""Scalable infrastructure"",""explanation"":""Designing and building systems that can handle increased traffic, data, or user activity without compromising performance.""},{""term"":""Low latency infrastructure"",""explanation"":""Building systems that minimize delays or lag in data processing, transmission, or response times.""}],""skill_priorities"":{""must_have"":[""Strong knowledge of Python"",""Strong Computer Science fundamentals""],""nice_to_have"":[""Experience with React""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize the performance of a Python application?"",""example_answer"":""I would use profiling tools to identify bottlenecks, implement caching mechanisms, and leverage parallel processing to improve the application's performance.""},{""question"":""Can you explain the concept of latency in software development?"",""example_answer"":""Latency refers to the delay between the time data is sent and the time it is received. In software development, minimizing latency is crucial for ensuring a responsive user experience.""}],""red_flags"":[""Lack of experience with Python or React"",""Inability to work in a collaborative environment""],""confidence_score"":90.0}"
HDO ML Engineer- Canada,"Role: HDO ML Engineer

Location: Remote/Canada

Duration: 6+ Months

Job Description

Key Responsibilities:

Collaborate with cross-functional teams to identify and prioritize quick win opportunities for data-driven insights and improvements.
Design, develop, and maintain ETL processes to extract, transform, and load data from various sources into our data infrastructure.
Implement and optimize genAI LLM models to enhance data analysis and predictive capabilities.
Ensure data quality and integrity by implementing data validation and cleansing processes.
Develop and maintain data pipelines to support real-time and batch data processing.
Collaborate with Data Scientists and Machine Learning Engineers to deploy and operationalize AI models.
Monitor and troubleshoot data pipelines and resolve any issues or bottlenecks.
Stay up-to-date with the latest trends and advancements in data engineering, AI, and machine learning technologies

Qualifications

What you bring
You are comfortable with high level of ambiguity and possess a continuous improvement mindset
You are known for strong leadership, project and process management
You enjoy quantitative analysis and have a reputation for being a problem solver and creative thinker
You have the ability to maintain high workloads, including the management of competing priorities and multiple projects at once
University degree, preferably in business, commerce or a related field
You have experience in successfully launching new products
4+ years of progressive experience in product or project management, business strategy or product marketing
Please note that this role is not IT product or project management. Some knowledge of or experience with data and analytics technologies or offerings is preferred, but not necessary
English verbal and written is required for this opportunity.","{""role_summary"":""The HDO ML Engineer role involves designing, developing, and maintaining data pipelines, implementing AI models, and ensuring data quality to drive business insights and improvements."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from various sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""genAI LLM"",""explanation"":""General Artificial Intelligence Large Language Model - a type of AI model that can process and analyze large amounts of data to generate insights and predictions.""},{""term"":""Data Pipelines"",""explanation"":""A series of processes that extract, transform, and load data from various sources into a target system, enabling real-time and batch data processing.""}],""skill_priorities"":{""must_have"":[""ETL"",""Data Pipelines"",""AI/ML"",""Data Analysis"",""Project Management""],""nice_to_have"":[""Business Strategy"",""Product Marketing"",""Data and Analytics Technologies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a data pipeline to support real-time data processing?"",""example_answer"":""I would first identify the data sources and requirements, then design a pipeline using tools like Apache Beam or AWS Glue, and finally implement data validation and quality checks to ensure accurate and timely data processing.""},{""question"":""How do you stay up-to-date with the latest trends and advancements in data engineering and AI?"",""example_answer"":""I regularly read industry blogs and research papers, attend webinars and conferences, and participate in online forums to stay current with the latest developments and best practices in data engineering and AI.""}],""red_flags"":[""Lack of experience in data engineering or AI/ML"",""Inability to manage competing priorities and multiple projects""],""confidence_score"":85.0}"
"Data Science, Decisions - Airports","At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

Data Science is at the heart of Lyft’s products and decision-making. You will leverage data and rigorous, analytical thinking to shape our products and make business decisions. This will involve identifying and scoping opportunities, shaping team priorities, recommending and implementing technical solutions, designing experiments, and measuring the impact of new features.

Airports are one of the most important, impactful, and complex parts of Lyft’s Rideshare business, as they are a key part of both the rider and driver Lyft experiences and have unique marketplaces with special considerations and dynamics. As a Data Scientist on the Airports team, you will collaborate with engineering, product, design, and operations to think critically about the current airport experience and implement product enhancements to facilitate market growth. The ideal candidate can apply strong business acumen to propose product changes, develop end-to-end technical solutions, and is comfortable working with a highly cross functional team. In this role, you will help us tackle problems at airports such as:

How do we efficiently match drivers and riders at the airport to reduce wait times?
Are we able to forecast ride demand and implement driver guidance to ensure riders can rely on Lyft for an airport ride at all times of the day?
How can we develop a technical model to predict ride wait times and communicate this to drivers?
What is the most helpful way to display ride information to drivers so they can make informed decisions?

Responsibilities

Leverage data and analytic frameworks to identify opportunities for growth and efficiency
Partner with product managers, engineers, marketers, designers, and operators to translate data insights into decisions and action
Construct and fit statistical, machine learning, or optimization models
Design and analyze online experiments; communicate results and act on launch decisions
Develop analytical frameworks to monitor business and product performance
Establish metrics that measure the health of our products, the business, as well as the driver experience

Experience

Degree in a quantitative field such as statistics, economics, applied math, operations research or engineering (advanced degrees preferred), or relevant work experience
3+ years of industry experience in a data science, analytics, or management consulting role.
End-to-end experience with data, including querying, aggregation, analysis, and visualization
Ability to manage, influence, negotiate, and inspire others in a fast-moving environment
Proficiency in SQL and Python
Strong oral and written communication skills, and ability to collaborate with cross-functional partners

Benefits

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Access to a Health Care Savings Account
In addition to provincial observed holidays, team members get 15 days paid time off, with an additional day for each year of service
4 Floating Holidays each calendar year prorated based off of date of hire
10 paid sick days per year regardless of province
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule following the establishment of a Lyft office in Toronto — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid","{""role_summary"":""As a Data Scientist on the Airports team at Lyft, you will leverage data and analytical thinking to shape products and make business decisions, collaborating with cross-functional teams to improve the airport experience and drive market growth."",""key_terms"":[{""term"":""Rigorous analytical thinking"",""explanation"":""The ability to apply logical and systematic approaches to analyze complex data and make informed decisions.""},{""term"":""Technical solutions"",""explanation"":""The development and implementation of data-driven solutions to address business problems and improve product performance.""},{""term"":""Cross-functional team"",""explanation"":""A team comprising individuals from different departments, such as engineering, product, design, and operations, working together to achieve a common goal.""}],""skill_priorities"":{""must_have"":[""Degree in a quantitative field"",""3+ years of industry experience in data science, analytics, or management consulting"",""End-to-end experience with data, including querying, aggregation, analysis, and visualization"",""Proficiency in SQL and Python"",""Strong oral and written communication skills""],""nice_to_have"":[""Advanced degrees"",""Experience with machine learning, optimization models, or management consulting""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach forecasting ride demand and implementing driver guidance at airports?"",""example_answer"":""I would leverage historical data and machine learning algorithms to develop a predictive model, then collaborate with product managers and engineers to implement a driver guidance system that ensures riders can rely on Lyft for airport rides at all times of the day.""},{""question"":""Can you walk me through your process for designing and analyzing online experiments?"",""example_answer"":""I would start by defining the experiment's objectives and hypotheses, then design the experiment using a randomized controlled trial approach. Next, I would analyze the results using statistical methods and communicate the findings to stakeholders, recommending launch decisions based on the results.""}],""red_flags"":[""Lack of experience working with cross-functional teams"",""Inability to communicate complex data insights effectively""],""confidence_score"":95.0}"
Machine Learning Engineer - Biotechnology Company,"This is a leading company in artificial intelligence for drug discovery that has launched multiple software products, including target identification platform, and automated drug discovery platform. We are looking for a Senior Machine Learning Engineer to join the team. You will work with product teams as well as top AI scientists in this field. We focus on AI-assisted systems that can identify novel drug targets for untreated diseases, assist in the development of new treatments and eventually predict how well those treatments may perform in clinical trials. This company was ranked Top 5 AI companies in its potential for social impact according to NVIDIA and in 2018, the company was named one of the global top 100 AI companies by CB Insights. They are growing their team in Canada and are looking for people who want to be part of this journey.

More about role:
We are seeking a Senior Machine Learning Engineer for the product, a comprehensive small-molecule drug discovery platform.

The person will be researching and developing generative models for the platform product. The product designs druglike molecular structures for the necessary target, which will hopefully, in the broader context of Insilco platforms, pass clinical trials and cure patients.

Title: Machine Learning Research scientist
Address: 1215 Boulevard René-Lévesque, Montreal. Hybrid model. Coming in to office 2 days a week.
Type: Full time and permanent
Salary: Open to discuss + 8.33% bonus + Benefits + 4 weeks’ vacation

What you will do:
Conduct ideation, research, and development of state-of-the-art AI-driven systems for small molecule design.
Spearhead initiatives to advance and refine our suite of AI tools for small molecule generation, screening, simulation, and prediction.
Architect and engineer AI-powered feature prototypes for the Chemistry42 platform, enhancing product discovery and user growth.
Champion the optimization and support of critical AI components within the platform, ensuring scalability, efficiency, and effectiveness.
Do you have this experience?
At least five years of experience in ML engineering and Python
Extensive experience and a strong background in AI/ML/DL: transformers, GNNs, diffusion models, RNNs, CNNs, GANs, VAEs, flow-based generative models, reinforcement learning, evolutionary algorithms
Be experienced in Pytorch, Numpy, Pandas, Scikit-Learn, JupyterLab, Plotly, Git, AWS, W&B
An ability to quickly test hypotheses with prototypes for product R&D
Ability to work under pressure with tight deadlines
Motivation to learn new things fast and improve the product with AI solutio

Desirable Skills
Background in chemistry or chemoinformatics
Successful experience in ML competitions (Kaggle, etc.)
Proven track of publications in machine learning for drug discovery
Skills and mindset for feature/component/product ownership
Ph.D. or M.S. in Computer Science, Artificial Intelligence, Data Science, Computational Chemistry, Medicinal Chemistry, or closely related fields

More Information:
Voluntary health insurance program and language courses (English and Chinese) after the probation period
Reimbursement of training programs, participation in conferences and webinars, course certificates
Flexible working schedule
Friendly team and warm environment","{""role_summary"":""A Senior Machine Learning Engineer will work with product teams and top AI scientists to develop AI-assisted systems for identifying novel drug targets and predicting treatment performance. The role involves researching and developing generative models for a comprehensive small-molecule drug discovery platform."",""key_terms"":[{""term"":""Generative models"",""explanation"":""AI models that generate new, unique data, such as molecular structures, based on patterns learned from existing data.""},{""term"":""Transformers"",""explanation"":""A type of neural network architecture used for natural language processing and other sequence-based tasks.""},{""term"":""GNNs"",""explanation"":""Graph Neural Networks, a type of neural network designed to work with graph-structured data, such as molecular structures.""},{""term"":""Diffusion models"",""explanation"":""A type of generative model that learns to represent complex distributions by iteratively refining an initial noise signal.""},{""term"":""Reinforcement learning"",""explanation"":""A type of machine learning that involves training agents to make decisions based on rewards or penalties in a dynamic environment.""}],""skill_priorities"":{""must_have"":[""Python"",""ML engineering"",""AI/ML/DL"",""Pytorch"",""Numpy"",""Pandas"",""Scikit-Learn"",""JupyterLab"",""Plotly"",""Git"",""AWS"",""W&B""],""nice_to_have"":[""Background in chemistry or chemoinformatics"",""Successful experience in ML competitions"",""Proven track of publications in machine learning for drug discovery"",""Ph.D. or M.S. in Computer Science, Artificial Intelligence, Data Science, Computational Chemistry, Medicinal Chemistry, or closely related fields""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of generative models and how they can be applied to small-molecule drug discovery?"",""example_answer"":""Generative models are AI models that can generate new, unique data, such as molecular structures, based on patterns learned from existing data. In small-molecule drug discovery, generative models can be used to design new drug-like molecular structures that can interact with specific targets, potentially leading to new treatments for diseases.""},{""question"":""How do you approach optimizing and supporting critical AI components within a platform to ensure scalability, efficiency, and effectiveness?"",""example_answer"":""I would approach this by first identifying the critical AI components and their dependencies, then implementing monitoring and logging to track performance metrics. I would also develop and implement optimization strategies, such as hyperparameter tuning and model pruning, to improve efficiency and scalability.""}],""red_flags"":[""Lack of experience with Pytorch and other required ML frameworks"",""Inability to work under pressure with tight deadlines"",""Limited understanding of AI-driven systems for small molecule design""],""confidence_score"":95.0}"
Data Scientist with MI- Canada,"Role: Data Scientist with MI

Location: Canada/Remote

Duration: 6+ Months

Job Description

Research,identify,and analyze data to evaluate existing and potential trends
Good Exposure working with Business stakeholders on understanding Product Scope, Lifecycle and able to create Prototypes & Roadmap based on customer use cases
Create or use existing frameworks to test and validate new models
Apply statistical techniques to analyze data
Apply machine learning techniques to streamline data analysis

Skills/Experience Required

Strong background in data mining and statistical analysis
Experience developing Al/ML models using Python and open source frameworks like: sklearn, keras,pytorch, numpy,pandas
Ability to work with large amounts of data
Good Exposure to multiple SOL and NOSQL databases
Abilty to quickly learn and implement new data science algorithms
Experience with machine learning techniques and creat ng algorithms
Experience in any cloud environments (AWS, Azure, GCP)
Exposure to MLOps is added advantage.
Exposure to NLP concepts & implementation will be a good to have skill","{""role_summary"":""A Data Scientist with MI role involves researching, analyzing, and evaluating data trends, working with stakeholders to create prototypes and roadmaps, and applying statistical and machine learning techniques to streamline data analysis."",""key_terms"":[{""term"":""MI"",""explanation"":""Machine Intelligence, which involves using machine learning and other techniques to analyze and make decisions from data.""},{""term"":""Prototypes"",""explanation"":""Initial versions of a product or model, used to test and validate ideas.""},{""term"":""Roadmap"",""explanation"":""A visual representation of a product's development plan, outlining key milestones and timelines.""},{""term"":""MLOps"",""explanation"":""Machine Learning Operations, which involves the deployment, management, and monitoring of machine learning models in production environments.""},{""term"":""NLP"",""explanation"":""Natural Language Processing, which involves the development of algorithms and models that can understand and generate human language.""}],""skill_priorities"":{""must_have"":[""Strong background in data mining and statistical analysis"",""Experience developing AI/ML models using Python and open source frameworks"",""Ability to work with large amounts of data"",""Experience with machine learning techniques and creating algorithms"",""Experience in any cloud environments (AWS, Azure, GCP)""],""nice_to_have"":[""Exposure to MLOps"",""Exposure to NLP concepts & implementation""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach developing a machine learning model to analyze customer use cases?"",""example_answer"":""I would start by collecting and preprocessing the data, then use techniques such as clustering and decision trees to identify patterns and trends. I would then use Python and open source frameworks like sklearn and keras to develop and train the model, and finally evaluate its performance using metrics such as accuracy and F1 score.""},{""question"":""How do you stay up-to-date with new developments in machine learning and data science?"",""example_answer"":""I regularly read industry blogs and research papers, attend conferences and meetups, and participate in online forums and communities to stay current with the latest techniques and tools.""}],""red_flags"":[""Lack of experience with cloud environments"",""Limited exposure to machine learning techniques and algorithms""],""confidence_score"":90.0}"
"Senior Data Scientist, Applied AI (Remote)","Why join us

Brex empowers the next generation of businesses with an integrated corporate card and spend management software. We make it easy for our customers to manage every aspect of spending and empower their employees to make better financial decisions from anywhere they live or work. Brex proudly serves tens of thousands of growing businesses, from early-stage startups to global enterprises.

Working at Brex allows you to push your limits, challenge the status quo, and collaborate with some of the brightest minds in the industry. We’re committed to building a diverse team and inclusive culture and believe your potential should only be limited by how big you can dream. We make this a reality by empowering you with the tools, resources, and support you need to grow your career.

Engineering at Brex

The Engineering team includes Data, IT, Security, and Software, and is responsible for building innovative products and infrastructure for both internal and external users. We have multiple autonomous and collaborative teams who are eager to learn, teach, and constantly improve how things work. Together, we strive to build robust and scalable systems that enable Brex to grow rapidly and help our customers reach their full potential.

Applied AI at Brex

As part of Brex’s AI team, Applied AI leverages cutting-edge AI/ML techniques to empower automation solutions in Brex’s spend management offering, working closely with Product, Design, and Engineering teams.

What You’ll Do

The Applied AI team drives for a more streamlined experience for our customers via AI/ML automations. We are looking for a strong Data Scientist to join our nimble and effective team. You will be responsible for the full cycle of work from ideation, research, and development to production and further improvements, working both strategically and tactically with cross-functional stakeholders to balance priority and delivery.

Responsibilities

Design and implement spend management related solutions with ML and AI techniques
Partner closely with Product Managers, Designers, and Engineers to understand their needs and identify opportunities to accelerate the AI/ML development and deployment process
Consult and educate internal teams on current and up-and-coming research, technologies, and best practices of leveraging ML and LLM in product design and development
Work closely with AI Platform engineers to identify upcoming requirements and continuously evolve the AI platform offering

Requirements

4+ years of industry experience developing optimization models that drive business impact
Passion for delivering data-driven solutions leveraging data, ML, and AI
M.S. or PhD. in Statistics, Computer Science, Math, Operations Research, Physics, Economics, or other quantitative field
Familiarity with programming languages (e.g. Python) and machine learning libraries (e.g. SciKit Learn)
Deep understanding of natural language processing techniques
Experience in overall big data analysis and system-backed integration with ML/LLM system/solution
Good understanding of quantitative disciplines such as statistics, machine learning, operations research, and causal inference
Experience productionizing and A/B testing different machine learning models

Bonus points

Experience leveraging commercial or open source LLM APIs to build solutions, such as OpenAI or llama
Experience in the finance industry

Compensation

The expected salary range for this role is $176,800 CAD - $221,000 CAD. However, the starting base pay will depend on a number of factors including the candidate’s location, skills, experience, market demands, and internal pay parity. Depending on the position offered, equity and other forms of compensation may be provided as part of a total compensation package.

Please be aware, job-seekers may be at risk of targeting by malicious actors looking for personal data. Brex recruiters will only reach out via LinkedIn or email with a brex.com domain. Any outreach claiming to be from Brex via other sources should be ignored.","{""role_summary"":""Design and implement AI/ML solutions to drive business impact and improve customer experience in spend management, collaborating with cross-functional stakeholders to deliver data-driven solutions."",""key_terms"":[{""term"":""AI/ML"",""explanation"":""Artificial Intelligence and Machine Learning techniques used to automate and optimize business processes.""},{""term"":""LLM"",""explanation"":""Large Language Models used for natural language processing and understanding.""},{""term"":""Spend management"",""explanation"":""The process of managing and optimizing business expenses and financial decisions.""}],""skill_priorities"":{""must_have"":[""4+ years of industry experience in developing optimization models"",""M.S. or PhD. in a quantitative field"",""Familiarity with programming languages (e.g. Python) and machine learning libraries (e.g. SciKit Learn)"",""Deep understanding of natural language processing techniques"",""Experience in overall big data analysis and system-backed integration with ML/LLM system/solution""],""nice_to_have"":[""Experience leveraging commercial or open source LLM APIs"",""Experience in the finance industry""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach developing an AI/ML solution to optimize spend management for a business?"",""example_answer"":""I would start by analyzing the business's current spend management process and identifying areas where AI/ML can add value. Then, I would design and implement a solution using techniques such as natural language processing and machine learning, and collaborate with cross-functional stakeholders to ensure successful deployment.""},{""question"":""How do you stay up-to-date with the latest developments in AI/ML research and technologies?"",""example_answer"":""I regularly read industry publications and attend conferences to stay current with the latest research and advancements in AI/ML. I also participate in online forums and discussions to learn from others and share my own knowledge and experiences.""}],""red_flags"":[""Lack of experience in developing optimization models that drive business impact"",""Limited understanding of natural language processing techniques"",""Inability to work collaboratively with cross-functional stakeholders""],""confidence_score"":90.0}"
Artificial intelligence (AI) Developer - Hybrid,"Company Description

ISAAC partners with North American fleets to provide a user-friendly solution that simplifies trucking. Focused 100% on the trucking industry, we help carriers overcome challenges, while boosting driver happiness. With proven system reliability and system integration capabilities driven by our open platform, our solution helps your drivers and back-office team work smoothly.

For more information, visit www.isaacinstruments.com.

We’re excited to grow our team of tech pioneers and build the future of the trucking industry. Don’t hesitate to reach out and learn more about working with our friendly, in-house group.

Job Description

Are you ready to take part in a major project and be a key contributor in building our existing data platform? As one of the largest providers of fleet management solutions across Canada, ISAAC is growing its market share in the United States, a transportation market with enormous potential. This growth will be marked by new projects related to cloud infrastructure and AI.

As part of the Data & AI team, the AI Developer will be tasked with packaging models, automating workflow, deploying AI models, as well as AI model monitoring, model retraining, and operationalizing analytics solutions to generate business value. The ideal candidate is an advanced programmer with a good understanding of data science, data engineering concepts, application development, API design, cloud computing and ML Ops.

Responsibilities

Build endpoints to serve ML models in production
ML Ops (monitor inference performance, scalability, availability, model deployment, retraining pipelines, etc.)
Have a clear understanding of how to convert a model into a user-friendly application
Manage the data science infrastructure to streamline model development and deployment
Architecting, developing, optimizing, and owning the deployment of ML functionalities into production systems
Design and evaluate new approaches for handling high-volume real-time data streams in an inferencing environment
Defining best practices for code, APIs, and frameworks that will lay the foundation for MLOps capabilities
Proposing appropriate tools (languages/libraries/frameworks) for implementing projects
Model testing, production and deployment, and continuous integration/ delivery
Work as part of a team, with frequent interactions with data scientists, data analysts, cloud solution architects; daily activities may also require close touchpoints with architecture, cloud, data engineering, and risk management teams.

Qualifications

Bachelor's degree in Computer Science, Data Science, Engineering, Operation Research, Statistics, or other related quantitative fields
1-2 years of experience developing customer-facing, production-grade machine learning solutions
Hands-on experience with large-scale systems in software engineering
Experience in productionizing code through DevOps pipeline (git, Jenkins pipeline, code scan)
Familiarity with big data processing and building data APIs. Experience with automated data quality frameworks is a plus
Working experience in building and deploying machine learning models as REST-based API using Flask
Strong software development skills with proficiency in Python
Advanced working SQL knowledge and experience working with relational databases and SQL
Experience working with cloud native architecture (PaaS) using Azure stack preferably and experience with Azure ML, DataBricks (Spark), Azure Data Factory will be an asset
Expertise delivering analytics & machine learning products, with a deep understanding of agile product delivery in an enterprise environment.

Additional Information

Collaborators are at the center of ISAAC’s interests and values. This explains the numerous benefits of working at ISAAC, namely:

varied career opportunities
a stimulating work environment focused on innovation
enthusiastic and collaborative teams
competitive salaries and benefits promoting work-life balance: a complete group insurance plan, group RRSP, an EAP, flexible hours, 4 weeks of vacation, etc.
various social activities and free snacks and coffee every day.","{""role_summary"":""The AI Developer will contribute to building ISAAC's existing data platform, focusing on packaging models, automating workflow, deploying AI models, and operationalizing analytics solutions to generate business value."",""key_terms"":[{""term"":""ML Ops"",""explanation"":""Machine Learning Operations, which involves managing and automating the machine learning lifecycle, including model deployment, monitoring, and retraining.""},{""term"":""Cloud Native Architecture"",""explanation"":""A software architecture that utilizes cloud computing principles to build scalable, flexible, and resilient systems.""},{""term"":""MLOps Capabilities"",""explanation"":""The ability to operationalize machine learning models in production environments, ensuring scalability, reliability, and maintainability.""}],""skill_priorities"":{""must_have"":[""Python"",""Machine Learning"",""Cloud Computing"",""API Design"",""Data Engineering"",""ML Ops""],""nice_to_have"":[""Azure ML"",""DataBricks (Spark)"",""Azure Data Factory"",""Automated Data Quality Frameworks""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach model deployment and retraining in a production environment?"",""example_answer"":""I use ML Ops principles to automate the deployment and retraining of models, ensuring scalability and reliability. I also monitor model performance and retrain models as needed to maintain accuracy.""},{""question"":""Can you explain how you would design a REST-based API for machine learning models?"",""example_answer"":""I would use Flask to build a REST-based API that exposes machine learning models as endpoints, ensuring scalability and ease of use. I would also implement authentication and authorization mechanisms to secure the API.""}],""red_flags"":[""Lack of experience with cloud native architecture"",""Inability to work with large-scale systems in software engineering""],""confidence_score"":90.0}"
Data scientist et développeur en Intelligence Artificielle,"EOS imaging est une société internationale spécialisée dans les solutions innovantes en imagerie et logiciels pour les soins ostéo-articulaires et la chirurgie orthopédique. La société dédie ses efforts et compétences à l'amélioration des soins ostéo-articulaires via des images médicales moins irradiantes du corps entier en position fonctionnelle, des données patients 2D/3D complètes et précises, et des outils de planification chirurgicale fondés sur l'anatomie réelle, 3D, du patient.

Elle fait partie du groupe Alphatec Spine.

Au sein du département développement IA, l'ingénieur développement en Intelligence Artificielle contribue à la mise en place des solutions de détection et de localisation de structures anatomiques et structures d'intérêts.

Missions principales

Vos activités seront les suivantes :
Contribuer à l'élaboration des spécifications techniques
Participer à la définition des architectures techniques
Concevoir, développer, industrialiser et optimiser des algorithmes par apprentissage profond
Réaliser des phases de test et de validation
Rédiger de la documentation technique
Participer à la veille scientifique et technique dans votre domaine d'expertise


Requirements

Compétences et capacités requises

Solide compétence en python
Apprentissage machine et en particulier l'apprentissage profond (Deep Convolutional Neural Networks)
Algorithmique de traitement d'image (filtrage, segmentation, reconstruction 3D)
Maitrise de librairies de machine learning (scikit-learn) et de frameworks de deep Learning (tensorflow ou pytorch)
Utilisation d'outils de développement et de partage de code tels que Git et SVN
Capacité d'analyse et de synthèse d'informations et problèmes complexes
Communication synthétique
Capacité à travailler en équipe avec les autres métiers et les autres fonctions impliquées dans les projets
Autonome
Rigoureux
Anglais courant


Formation et expérience

Formation Bac+5 (école d'ingénieur ou master des Universités) avec une spécialisation en Intelligence Artificielle
Minimum 3 ans d'expérience en intelligence artificielle dans un milieu industriel","{""role_summary"":""Contribute to the development of AI solutions for osteo-articular care and orthopedic surgery, focusing on image processing and machine learning algorithms."",""key_terms"":[{""term"":""Deep Convolutional Neural Networks"",""explanation"":""A type of machine learning algorithm used for image processing and analysis.""},{""term"":""Apprentissage profond"",""explanation"":""French term for deep learning, a subset of machine learning that involves the use of neural networks.""},{""term"":""Algorithmique de traitement d'image"",""explanation"":""Image processing algorithms used for tasks such as filtering, segmentation, and 3D reconstruction.""}],""skill_priorities"":{""must_have"":[""Python"",""Machine learning"",""Deep learning"",""Image processing algorithms"",""scikit-learn"",""TensorFlow or PyTorch"",""Git and SVN""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of deep learning and its applications in image processing?"",""example_answer"":""Deep learning is a subset of machine learning that involves the use of neural networks to analyze and interpret data. In image processing, deep learning can be used for tasks such as object detection, segmentation, and classification.""},{""question"":""How do you optimize the performance of a deep learning model?"",""example_answer"":""To optimize the performance of a deep learning model, I would consider factors such as the choice of algorithm, the size and quality of the training dataset, and the use of regularization techniques to prevent overfitting.""}],""red_flags"":[""Lack of experience with deep learning frameworks such as TensorFlow or PyTorch"",""Inability to communicate complex technical concepts effectively""],""confidence_score"":90.0}"
Machine Learning Engineer (LLM Infrastructure) - Toronto,"We are looking for a Machine Learning Engineer who has strong experience in building systems that accelerate the development and deployment of machine learning models, especially large language models (LLMs). You will partner closely with Machine Learning researchers and internal users to understand requirements and apply strong ML fundamentals to build high performance and reusable APIs and can also apply them in real production settings.

Please Note: This is a hybrid position and will require at least 2 days in the office per week. Successful candidates will need to complete a background check.

Responsibilities

Architect/Enable distributed compute aligning workloads to Small/Mid/High end GPUs
Leverage appropriate storage hardware and data formats to improve read/re-read efficiency
Identify and remediate latency contributors especially IO bottlenecks, inefficient data shuffling, under/over utilized compute
Scale models by employing distributed training using Data / Model Parallelism techniques
Parallelize inference processing to improve prediction latency.
Provide Subject Matter Expertise in Graph and Vector databases for various use cases including Knowledge Graphs, RAG etc.
Implement LLM observability and monitoring solutions
Manage infrastructure and large-scale system design and diagnose both model and system failures
Mitigate reputation risk through AI driven Data Quality to ensure highest quality data and services are offered to clients


Requirements

5-6 years of AI, Big Data and cloud expertise
3-4 years of Alternative data experience
2+ years of experience building machine learning training pipelines or inference services in a production setting
Experience with LLM deployment, fine tuning, training, prompt engineering, etc
Experience with LLM inference latency optimization techniques, e.g. kernel fusion, quantization, dynamic batching, etc.
Experience with CUDA, model compilers, and other model-specific optimizations
Experience building, deploying, and monitoring complex microservice architectures.
Degree in Computer Science or Engineering
Prior Experience with: -Docker, Kubernetes, Infrastrure as code (Terraform)and containerization, Agile Methodology, Distributed systems, Databricks ML, Cloud (Azure (preferred) or AWS)
Expert level - Python, SQL
Experience (or knowledge of) Mosaic ML, Ray Framework
Experience with Lang Chain or LlamaIndex
Experience with any vector database


Nice to have

Experience building front to back data pipelines comprising of data ingestion, enrichment, data quality, Analytics and reporting
Experience with company KPIs and back testing of alternative data factors against company KPIs
Experience with NLP techniques and transfer learning frameworks like BERT
Experience with using HuggingFace Model Artifacts


Benefits

Why You'll Love Working at Prodigy

We are a collective group of people and collaboration is key to our process
We don't work for our clients, we work with them
A Flexible Hybrid Working Environment
Easily accessible downtown location
Competitive compensation commensurate with experience
Everyone brings something valuable to the table in our supportive, challenging, and collaborative, diverse work environment


All Employees Can Participate in:

Company paid health benefits: 100% medical, dental and vision coverage
Corporate-discounted Gym Membership through GoodLife
Company discount program including Travel, Shopping, Attractions, Wellness, & Sporting events, just to name a few
Access to an Employee & Family Assistance program (EAP)
Employee Referral Program
Employee Opportunity Program
Professional Development Program
Town Halls
Philanthropic Events
Social Events


Accessibility

Prodigy is committed to providing equitable treatment and accommodation to ensure a barrier-free recruitment process and workplace. If you require accommodation at any stage during the recruitment process, please contact us at accessibility@prodigylabs.net or call 416-488-7700 ext. 4

Inclusion & Diversity

At Prodigy we foster an inclusive and diverse workforce, believing our strength stems from our individual differences. Our employees, partners, and clients continuously benefit from the innovation and creativity grounded in these values. We strive to be a company that attracts a diverse group of highly skilled people who know that their contributions will be valued and that they will be heard. We are committed to building a corporate culture with people who are excited to join our team, do their best work, and grow with us!","{""role_summary"":""A Machine Learning Engineer responsible for building systems that accelerate the development and deployment of machine learning models, especially large language models, and partnering with researchers and internal users to understand requirements."",""key_terms"":[{""term"":""LLMs"",""explanation"":""Large Language Models, a type of artificial intelligence model used for natural language processing tasks.""},{""term"":""Data Parallelism"",""explanation"":""A technique used to scale machine learning models by distributing data across multiple computing nodes.""},{""term"":""Model Parallelism"",""explanation"":""A technique used to scale machine learning models by distributing model components across multiple computing nodes.""},{""term"":""Graph and Vector databases"",""explanation"":""Types of databases used for storing and querying complex data structures, such as knowledge graphs and vector embeddings.""},{""term"":""CUDA"",""explanation"":""A parallel computing platform and programming model developed by NVIDIA for general computing on its graphics processing units (GPUs).""},{""term"":""Kernel Fusion"",""explanation"":""A technique used to optimize machine learning model inference by fusing multiple kernel operations into a single operation.""},{""term"":""Quantization"",""explanation"":""A technique used to reduce the precision of machine learning model weights and activations to improve inference efficiency.""},{""term"":""Dynamic Batching"",""explanation"":""A technique used to optimize machine learning model inference by dynamically adjusting the batch size of input data.""}],""skill_priorities"":{""must_have"":[""5-6 years of AI, Big Data and cloud expertise"",""2+ years of experience building machine learning training pipelines or inference services in a production setting"",""Experience with LLM deployment, fine tuning, training, prompt engineering, etc"",""Experience with LLM inference latency optimization techniques"",""Expert level - Python, SQL"",""Degree in Computer Science or Engineering""],""nice_to_have"":[""Experience building front to back data pipelines"",""Experience with company KPIs and back testing of alternative data factors against company KPIs"",""Experience with NLP techniques and transfer learning frameworks like BERT"",""Experience with using HuggingFace Model Artifacts"",""Experience with Mosaic ML, Ray Framework"",""Experience with Lang Chain or LlamaIndex"",""Experience with any vector database""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize the inference latency of a large language model?"",""example_answer"":""I would use techniques such as kernel fusion, quantization, and dynamic batching to reduce the computational overhead of the model. I would also consider using parallel processing and distributed computing to further improve inference efficiency.""},{""question"":""How do you handle model and system failures in a production setting?"",""example_answer"":""I would use monitoring and logging tools to detect failures, and then use debugging techniques to identify the root cause of the issue. I would also have a plan in place for rolling back to a previous version of the model or system if necessary.""}],""red_flags"":[""Lack of experience with large language models"",""Inability to optimize model inference latency"",""Limited experience with distributed computing and parallel processing""],""confidence_score"":90.0}"
"Senior Data Scientist, GivingTuesday","GivingTuesday is a global generosity movement unleashing the power of people and organizations to transform their communities and the world. The organization works with partners across sectors and borders to understand the drivers and impacts of generosity, explore giving behaviors and patterns, and use data to inspire more giving around the world. GivingTuesday offers the largest philanthropic data collaborative effort in the social sector — with unique, granular datasets from a wide range of organizations featuring key sector information

As we scale up, we are expanding our team of data scientists and engineers, who will continue to grow and improve our unique data assets, methodologies, and technical infrastructure.

In pursuit of the goals and expansion of the data commons, GivingTuesday partners with key organizations to leverage their expertise to manage and lead different aspects of the work. These data & technology partners (DARO, With Intent) manage staff, projects, and ongoing functions for the data commons with dedicated staff embedded in GivingTuesday in those capacities in cross-functional roles. This role is one of these positions - managed by our partner organizations but embedded in GivingTuesday’s Data Team.

Senior Data Scientist

Our global data science team works on a diverse set of problems and projects related to learning, insights, and impact measurement in the nonprofit sector. We are looking for a Senior Data Scientist to join our growing team, where they will work with data engineers, analysts, and other team members to develop compelling and useful knowledge products for GivingTuesday stakeholders, including academics, data partners, the social/nonprofit sector, and the general public.

In this role you will:

Work with a wide range of data types from collaborators and institutional partners in the nonprofit ecosystem to deliver analyses with actionable insights
Manage key datasets and improve their usability by creating database dictionaries and user documentation
Improve existing data processing pipelines, automate recurrent operations on core datasets
Stay abreast of new research methods, recommend and implement the right methodologies to solve our research challenges
Create impactful data visualisations and interactive data dashboards for stakeholders
Deliver briefings and rapid-response/ad-hoc data analysis to support the Chief Data Officer in their presentations and media appearances
Guide and mentor junior members of the data science team

We are looking for someone with:

Advanced analytical skills in a research context, conducting exploratory analysis and mapping data flows, integration of datasets and reviewing data sources and tools
Experience with statistical methods including hypothesis testing, regression analysis, and sampling techniques
Experience working with scripting languages (Python preferred) and data querying languages (SQL required)
Solid data visualisation skills (e.g. Looker) and an aptitude for translating technical outputs into compelling stories
Experience with software development tools and practices (e.g. version control, git)
Understanding of legislation around privacy and best practices for securing data
Solid relationship management skills, with the ability to collaborate with a variety of internal stakeholders on complex research initiatives
Outstanding written and oral communication skills in English and an ability to communicate clearly and directly
Interest in the nonprofit and philanthropic sector and use of data to promote better social outcomes

GivingTuesday is actively seeking candidates with unique and diverse work backgrounds to grow our team. We are especially excited to talk to you if have:

Programming tools: Python, Pandas, Jupyter Notebook, SQL, Git
Experience with BI dashboarding tools (ie Looker, PowerBI, Metabase)
Experience working with Airflow, Docker, Kubernetes is an asset
Experience working with data platforms such as Databricks (or other forms of data lakes/warehouses/lakehouses)
An advanced degree in a quantitative field (definitely not required!)

Position type: This is a full-time position

Location Details: Remote. We are happy to consider applicants based in countries outside of where this is posted.

Work Hours: We are looking for candidates who can overlap with a 9:00 to 5:00 EST workday for at least 4 hours per day.

Salary Range: For applicants in Canada, our salary range is $130,000 to $170,000 per year.

GivingTuesday is committed to a work environment where our employees feel included, valued, and heard. We value diversity and welcome applications from Indigenous peoples, people from systematically excluded communities, members of the LGBTQ+ community, and people with disabilities. We welcome people from neurodiverse backgrounds. If you require any accessibility accommodation in the interviewing process please let us know.

We know that applying for a job takes a lot of time and energy and we treat every application with care and attention. Only applicants chosen for interview will be contacted.

To apply, please provide us with your CV, and a short cover letter detailing your interest in our subject matter and work (2 paragraphs is sufficient).

Powered by JazzHR

zhfDbBcUmI","{""role_summary"":""A senior data scientist role at GivingTuesday, a global generosity movement, responsible for developing knowledge products, managing datasets, and creating data visualizations to support stakeholders in the nonprofit sector."",""key_terms"":[{""term"":""Data commons"",""explanation"":""A collaborative effort to share and manage data across organizations, in this case, for the social sector.""},{""term"":""Data lakes/warehouses/lakehouses"",""explanation"":""Centralized repositories that store and manage large amounts of structured and unstructured data.""},{""term"":""BI dashboarding tools"",""explanation"":""Business intelligence tools used to create interactive and visual representations of data, such as Looker or PowerBI.""}],""skill_priorities"":{""must_have"":[""Advanced analytical skills"",""Experience with statistical methods"",""Experience with scripting languages (Python preferred) and data querying languages (SQL required)"",""Solid data visualization skills"",""Experience with software development tools and practices"",""Understanding of legislation around privacy and data security""],""nice_to_have"":[""Experience with BI dashboarding tools"",""Experience working with Airflow, Docker, Kubernetes"",""Experience working with data platforms such as Databricks"",""Advanced degree in a quantitative field""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach integrating datasets from multiple collaborators in the nonprofit ecosystem?"",""example_answer"":""I would first assess the data quality and compatibility, then use Python and SQL to integrate the datasets, and finally create a data dictionary and user documentation to ensure usability.""},{""question"":""How do you stay current with new research methods and tools in data science?"",""example_answer"":""I regularly read industry blogs and research papers, attend conferences, and participate in online forums to stay updated on the latest methodologies and tools.""}],""red_flags"":[""Lack of experience working with diverse datasets and stakeholders in the nonprofit sector"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
"Data Scientist, ESG Analytics - CID&A","Requisition ID: 201793

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

The Data Scientist, ESG Analytics will be responsible for solving complex ESG problems through the use of analytical, statistical, predictive and data visualization techniques. Mainly responsible for the calculation of investment emissions to support the Banks achievement of their net zero commitment. The incumbent will work closely with the Director, ESG Data & Analytics and other internal stakeholders to turn client-level data into critical insights and knowledge that can be used to make optimal business decisions across different areas of the Bank. Problem-solving skills and programming knowledge are required to quickly draw relevant insights from multiple data sources to support Bank strategies.

Is this role right for you? In this role, you will:

Conduct data analysis to provide actionable insights to decision-makers in the Bank. Mainly, invement emissions analytical calculations to support the Bank to meet its emission reduction target commitments (Scope 3 emissions, category 15: finance and faciliated emissions)
Present insights and depict the rationale of findings in easy-to-understand terms for the business or senior management, including the use of data visualization techniques and dashboards.
Develop innovative and effective approaches and apply statistical and predictive modeling techniques to solve analytics problems and communicate results and methodologies to business clients and senior members of the analytics team.
Stay current on trends on financed and facilitated emissions standards (PCAF, GHG, etc.), data science and data product space, and translate those trends into actionable strategic and tactical objectives for the company.
Contribute to a culture of curiosity and innovation inside and outside of the company through presentation, demonstration and leading by example.

Skills

Do you have the skills that will enable you to succeed in this role? We’d love to work with you if you have experience with:

The incumbent supports a wide range of analytical activities, and must conduct unbiased, client-focused analytics
Ensuring that results do not impede client acquisition/retention, business line growth and profitability activities.
Strong knowledge of the Bank’s products and services.
Solid analytical and data wrangling skills. Must be comfortable working with large amounts of information and translating data into clear and concise findings.
Strong communication and interpersonal skills.
Strong programming skills in Python with a strong understanding of data manipulation libraries and statistical packages
Proficiency in using query languages such as SQL, HiveQL, and big data technologies such as Spark
Experienced with automated ETL process and data pipelines (i.e Airflow)
Experienced with MLOps best practices and proficient with git technologies
Prior experience with cloud platforms (Azure, AWS, GCP, etc) is preferred.
Proficient with concepts and application of machine learning algorithms.
Knowledge of visualization tools such as Power BI.
Understanding and experience of investment emissions (scope 3 emissions, category 15) calculations and standards is preferred.
Knowledge of Bank Information Systems, such as product and reporting systems, including finance systems, Salesforce, and the Enterprise Data Lake, an asset.
University education, with a specialization in Economics, Statistics, Computer Science or Engineering.
Master’s level preferred.

What's in it for you?

The opportunity to join a forward-thinking and collaborative team, surrounded by innovative thinkers.
A rewarding career path with diverse opportunities for professional development
Internal training to support your growth and enhance your skills.
An inclusive working environment that encourages creativity, curiosity, and celebrates success!
Work in an Ecosystem where you’ll have access to group seating, offices, collaboration spaces, a cafeteria with different options daily, and more.
Hybrid Work Environment

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","{""role_summary"":""The Data Scientist, ESG Analytics is responsible for solving complex ESG problems using analytical, statistical, predictive, and data visualization techniques to support the Bank's net zero commitment."",""key_terms"":[{""term"":""ESG"",""explanation"":""Environmental, Social, and Governance, referring to the Bank's commitment to responsible investment practices.""},{""term"":""Net Zero Commitment"",""explanation"":""The Bank's goal to reduce greenhouse gas emissions to zero, achieved through sustainable practices and investments.""},{""term"":""Scope 3 Emissions"",""explanation"":""Greenhouse gas emissions generated by the Bank's investments and lending activities, categorized as 'financed and facilitated emissions'.""},{""term"":""PCAF"",""explanation"":""Partnership for Carbon Accounting Financials, a standard for measuring and disclosing financed emissions.""},{""term"":""GHG"",""explanation"":""Greenhouse Gas, referring to emissions that contribute to climate change.""},{""term"":""MLOps"",""explanation"":""Machine Learning Operations, a set of practices for managing and deploying machine learning models.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load, a process for extracting data from sources, transforming it into a usable format, and loading it into a target system.""}],""skill_priorities"":{""must_have"":[""Python programming skills"",""Data manipulation libraries"",""Statistical packages"",""SQL, HiveQL, and big data technologies"",""Automated ETL process and data pipelines"",""MLOps best practices"",""Git technologies"",""Cloud platforms (Azure, AWS, GCP, etc.)"",""Machine learning algorithms"",""Data visualization tools (Power BI)""],""nice_to_have"":[""Experience with investment emissions calculations and standards"",""Knowledge of Bank Information Systems"",""Master's level education""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach calculating investment emissions for a financial institution?"",""example_answer"":""I would use a combination of data sources, including client-level data and industry standards such as PCAF, to calculate Scope 3 emissions. I would then apply statistical and predictive modeling techniques to identify trends and areas for improvement.""},{""question"":""Can you explain how you would communicate complex ESG insights to non-technical stakeholders?"",""example_answer"":""I would use data visualization techniques and dashboards to present findings in an easy-to-understand format, focusing on the business implications and recommendations for action.""}],""red_flags"":[""Lack of experience with ESG analytics and investment emissions calculations"",""Inability to communicate complex technical concepts to non-technical stakeholders"",""Limited knowledge of cloud platforms and big data technologies""],""confidence_score"":90.0}"
"Software Engineer, NLP/ML","Calabrio is looking for a highly skilled and experienced Software Engineer, NLP/ML to perform a key role in our digital transformation program, and deliver exceptional customer experience supported by trusted, and resilient business solutions. As an NLP/ML Software Engineer, you will play a pivotal role in developing and implementing cutting-edge NLP models and solutions. The ideal candidate should have a strong background in machine learning, natural language processing, and a proven track record of delivering successful projects in the field. Calabrio has embarked journey and is truly committed to establishing a value fabric that transforms its customer, employee, and stakeholder experiences through seamless integrated, agile, data-driven, and secure Digital Services. Such an endeavor requires leaders passionate about customer experience and committed to consistently delivering value while focusing on digital services with inherent trust and resilience.
  What you'll be doing{{:}}
·       Design, develop, and implement advanced NLP algorithms and models to solve complex problems in Conversation Analytics with classification, information extraction, clustering, topic modeling, text generation, and data processing.
·       Work on data engineering and processing to gather and preprocess large-scale conversation datasets for training and evaluation of NLP models.
·       Train, fine-tune, and optimize machine learning models for NLP applications.
·       Optimize models for deployment in real-world applications, considering factors such as latency, scalability, and resource efficiency.
·       Stay current with state-of-the-art research in NLP and contribute to the development of new approaches and methodologies for Conversation analytics problems.
·       Evaluate emerging technologies and tools to enhance the overall capabilities of our Conversation Analytics systems.
·       Work closely with cross-functional teams, including data scientists, software engineers, and product managers, to drive successful project outcomes. 
We're looking for{{:}}
·       Problem solving skills and an ability to devise and implement advanced NLP algorithms and models to address intricate challenges in Conversation analytics.
·       Strong team player who works with internal and external stakeholders to solve problems and actively incorporate input from various sources.
·       Excellent communication skills and collaborative working style.
·       Ability to think ""out of the box"", strong critical thinking, and analytical skills.

Requirements

·       Bachelor's Degree (MSc+ is preferred) in Computer Science/Engineering or related field.
·       2+ years of end-to-end experience of ML model training, evaluating, testing, and deploying machine learning models.
·       Strong experience working with Python, Flask(Django), Numpy and Pandas.
·       Expertise in NLP tasks such as Text classification, NER, Clustering, and Topic-modeling.
·       Robust understanding of Machine Learning fundamentals.
·       Experience with Prompt Engineering for LLM models.
·       Experience with Fine-tuning LLM models.
·       Experience with TextCNN, LSTM, Seq2Seq, and BERT models.
·       Strong understanding of transformers (tokenizers, pre-trained models, fine-tuning).
·       Experience with PyTorch, TensorFlow, and Scikit-learn.
·       Experience with NLP libraries like spaCy, etc.
·       Experience with SQL and NOSQL DB.
·       Familiarity with Linux systems.
Preferred Qualifications{{:}} 
·       Experience with AWS, Azure, or GCP.
·       Experience with Docker and Kubernetes.
·       Experience with ETL and Data Engineering projects.
·       Experience with PySpark and MapReduce.
·       Experience with PostgreSQL, Snowflake, or MongoDB.
·       Experience with Kubeflow, or Airflow.


Benefits

Calabrio People are{{:}} Open, Clear, Ambitious, Accountable, Collaborative, Consistent
What we value most...workplace diversity and ensuring an environment of mutual respect.  We believe that diversity and inclusion are critical to our success, and we are proud to be an equal opportunity employer. Our commitment is to continue to keep our people healthy, focused, and inspire creativity.  Our team members are offered comprehensive benefits for various life circumstances and needs, great opportunities for career development, and a balanced work-life to achieve personal and professional success (all benefits are subject to eligibility requirements).  As an Innovator with Purpose, you'll feel motivated and truly excited to come to work!
About Calabrio{{:}} 
Calabrio is the customer experience intelligence company that empowers organizations to enrich human interactions. The scalability of our cloud platform and our AI-driven analytics tools make it easy for contact centers to uncover customer sentiment and share compelling insights with other parts of the organization. Our solutions are built on an intuitive, web-based architecture that positions and accelerates the contact center as an epicenter for customer insight.
Awards & Accolades{{:}}
Calabrio has 300 Global Partners, more than 2.25 million agents, and over 7,000 customers worldwide. We've been doing this for more than two decades and have been recognized by leading independent third parties such as Gartner, Forrester, and G2 Crowd as a leader and visionary. Thanks to the hard work and dedication of every Calabrio team member, we have been recognized by the Star Tribune Top Workplace for 9 years in a row, a 2022 certified Great Place to Work UK, named one of BC's Top Employers for 2023, and recognized as a top 50 fast-growth company by Minneapolis/St Paul Business Journal. 
Calabrio celebrates and fosters a culture that thrives on diversity. We are an Equal Opportunity Employer that prohibits discrimination and harassment of any kind. We provide employees with a work environment free of discrimination and harassment. All employment decisions at Calabrio are based on business needs, job requirements, and individual qualifications, without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status, parental status, or any other status protected by the laws or regulations in the locations where we operate. We celebrate the >40 nationalities of team members that contribute to our success.
 ","{""role_summary"":""Design, develop, and implement advanced NLP algorithms and models to solve complex problems in Conversation Analytics, working closely with cross-functional teams to drive successful project outcomes."",""key_terms"":[{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""},{""term"":""ML"",""explanation"":""Machine Learning, a subfield of artificial intelligence that involves the use of algorithms and statistical models to enable machines to learn from data.""},{""term"":""Conversation Analytics"",""explanation"":""The process of analyzing and extracting insights from customer conversations to improve customer experience and business outcomes.""},{""term"":""LLM models"",""explanation"":""Large Language Models, a type of artificial neural network designed to process and generate human-like language.""},{""term"":""Prompt Engineering"",""explanation"":""The process of designing and optimizing input prompts to elicit specific responses from language models.""},{""term"":""Transformers"",""explanation"":""A type of neural network architecture introduced in the BERT model, designed primarily for natural language processing tasks.""}],""skill_priorities"":{""must_have"":[""Python"",""NLP"",""Machine Learning"",""PyTorch"",""TensorFlow"",""Scikit-learn"",""SQL"",""NOSQL DB"",""Linux systems""],""nice_to_have"":[""AWS"",""Azure"",""GCP"",""Docker"",""Kubernetes"",""ETL"",""Data Engineering"",""PySpark"",""MapReduce"",""PostgreSQL"",""Snowflake"",""MongoDB"",""Kubeflow"",""Airflow""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of transformers in NLP and how they are used in language models?"",""example_answer"":""Transformers are a type of neural network architecture that have revolutionized the field of NLP. They are primarily used for sequence-to-sequence tasks such as language translation, text generation, and question-answering. In language models, transformers are used to process input sequences and generate output sequences that are contextually relevant.""},{""question"":""How do you approach fine-tuning a pre-trained language model for a specific NLP task?"",""example_answer"":""When fine-tuning a pre-trained language model, I first analyze the task requirements and identify the most relevant parameters to tune. I then use techniques such as gradient descent and regularization to adjust the model's weights and biases. Finally, I evaluate the model's performance on a validation set and make adjustments as needed.""}],""red_flags"":[""Lack of experience with NLP tasks such as text classification, NER, clustering, and topic-modeling."",""Inability to work with cross-functional teams to drive successful project outcomes.""],""confidence_score"":95.0}"
Gen AI Developer,"Primary skills:Technology->Data Science->Machine Learning,Technology->Machine Learning->Python
LLM Development/Deployment Pipeline creation, workflows
Study and transform Gen AI PoCs to production grade deployment
Design machine learning systems, Run machine learning tests and experiments
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Perform statistical analysis and fine-tuning using test results
Train and retrain systems when necessary
Gen AI Technologies: Prompt Engineering, LLM Development using Langchain. Semantic Kernel , Open Source/ API based LLMs ..
Python Data Science, Machine Learning, Deep Learning, PySpark, PyTorch, TensorFlow, Keras, etc
AIML Subfields such as Neural Networks, Computer Vision, Speech Processing, Natural Language Processing
AIML Tools such as AzureML, Google ML, AWS AI/ML, H2O, DataBricks, DataRobots and any other tools
Good knowledge on software configuration management systems
Strong business acumen, strategy and cross-industry thought leadership
Awareness of latest technologies and Industry trends
Logical thinking and problem solving skills along with an ability to collaborate
Two or three industry domain knowledge
Understanding of the financial processes for various types of projects and the various pricing models available
Client Interfacing skills
Knowledge of SDLC and agile methodologies
Project and Team management","{""role_summary"":""Develop and deploy machine learning systems, design and implement ML algorithms, and perform statistical analysis to meet project requirements, while demonstrating strong business acumen and industry knowledge."",""key_terms"":[{""term"":""LLM Development/Deployment Pipeline"",""explanation"":""Creating a workflow for developing and deploying large language models.""},{""term"":""Gen AI PoCs"",""explanation"":""General Artificial Intelligence Proof of Concepts, which are early-stage projects demonstrating AI capabilities.""},{""term"":""Prompt Engineering"",""explanation"":""Designing and optimizing natural language prompts to interact with large language models.""},{""term"":""Semantic Kernel"",""explanation"":""A technology enabling the integration of multiple AI models to create a unified AI system.""},{""term"":""PySpark"",""explanation"":""A Python library for large-scale data processing, used for machine learning and data science tasks.""},{""term"":""AIML Subfields"",""explanation"":""Subfields of Artificial Intelligence and Machine Learning, including Neural Networks, Computer Vision, and Natural Language Processing.""},{""term"":""AzureML"",""explanation"":""A cloud-based platform for machine learning and AI development, offered by Microsoft.""},{""term"":""SDLC"",""explanation"":""Software Development Life Cycle, a framework for managing software development projects.""}],""skill_priorities"":{""must_have"":[""Machine Learning"",""Python"",""Data Science"",""Deep Learning"",""PyTorch"",""TensorFlow"",""Keras""],""nice_to_have"":[""LLM Development/Deployment Pipeline"",""Gen AI PoCs"",""Prompt Engineering"",""Semantic Kernel"",""PySpark"",""AIML Subfields"",""AzureML"",""SDLC""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing and implementing machine learning systems?"",""example_answer"":""I follow a structured approach, starting with problem definition, data preparation, model selection, and hyperparameter tuning. I also consider scalability, interpretability, and model explainability.""},{""question"":""Can you explain the concept of Prompt Engineering in LLM Development?"",""example_answer"":""Prompt Engineering involves designing and optimizing natural language prompts to interact with large language models, ensuring accurate and relevant responses. This requires understanding the model's capabilities, the task at hand, and the nuances of language.""}],""red_flags"":[""Lack of experience with machine learning frameworks such as PyTorch, TensorFlow, or Keras."",""Inability to explain complex machine learning concepts or algorithms.""],""confidence_score"":90.0}"
ML Engineer,"Role - Client Engineer

Location- Remote (Canada)

Jd

Client Engineer will enable AI impact at scale by transforming prototypes into production-grade AI pipelines, maintaining models in production, and contributing to our AI platform and engineering practices.

1/ Transform prototypes into production-grade models

Work with data scientists and AI strategists to develop requirements for production models
Design and develop robust applications to manage production models
Collaborate with data governance and technical teams to ensure compliance with Client AI and engineering standards

2/ Maintain models in production

Manage the full CI/CD cycle for live models including testing and deployment
Manage label feedback and model retraining processes
Develop logging, alerting, and mitigation strategies for handling model errors
Collaborate with data scientists to design and develop drift detection and accuracy measurements for live models

3/ Contribute to AI platform and engineering practices

Collaborate with DS and Client engineering leadership to develop coding standards and practices across the applied AI team
Research, test, and help train the team on using leading edge AI platforms, such as auto Client libraries, graph databases, and cloud execution frameworks
Contribute to the team's AI infrastructure strategy and management
3+ years of industry experience in Client engineering
Strong experience in Python
Experience in data product development, analytical models, and model governance
Experience with AI workflow management tools such as Airflow, Kedro, or Luigi
Exposure statistical modeling, machine learning algorithms, and predictive analytics.
Highly structured and organized work planning skills
Strong understanding of the AI development lifecycle and Agile practices
Proficiency in big data technologies like Hadoop, Spark, or similar frameworks. Experience with graph databases a plus.
Experience in working with cloud computing platforms like AWS, Azure, or Google Cloud.
Proven track record of delivering data products in environments with strict adherence to security and model governance standards.
Bachelor's degree in computer science, analytics, mathematics, statistics, economics, industrial engineering, or physical sciences.

Thanks and Regards

Saurabh Srivastava

Account Manager

E: Saurabh.srivastava@epsilonsolutions.ca","{""role_summary"":""The Client Engineer transforms prototypes into production-grade AI pipelines, maintains models in production, and contributes to the AI platform and engineering practices, enabling AI impact at scale."",""key_terms"":[{""term"":""Production-grade AI pipelines"",""explanation"":""AI models that are scalable, reliable, and meet industry standards for deployment.""},{""term"":""CI/CD cycle"",""explanation"":""Continuous Integration and Continuous Deployment, a process for automating testing, deployment, and monitoring of software applications.""},{""term"":""Auto Client libraries"",""explanation"":""Automated client libraries for AI platforms, enabling efficient development and deployment of AI models.""},{""term"":""Graph databases"",""explanation"":""Databases that store data as nodes and edges, optimized for complex relationships and AI applications.""},{""term"":""Cloud execution frameworks"",""explanation"":""Platforms that enable scalable and efficient execution of AI workloads in cloud environments.""}],""skill_priorities"":{""must_have"":[""Python"",""Data product development"",""Analytical models"",""Model governance"",""AI workflow management tools (Airflow, Kedro, or Luigi)"",""Big data technologies (Hadoop, Spark, or similar frameworks)""],""nice_to_have"":[""Graph databases"",""Cloud computing platforms (AWS, Azure, or Google Cloud)"",""Statistical modeling"",""Machine learning algorithms"",""Predictive analytics""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure model governance and compliance with industry standards in production-grade AI pipelines?"",""example_answer"":""I collaborate with data governance teams to develop and implement model governance standards, ensuring compliance with industry regulations and best practices.""},{""question"":""Can you describe your experience with AI workflow management tools, such as Airflow or Kedro?"",""example_answer"":""I have used Airflow to manage and orchestrate complex AI workflows, ensuring efficient and scalable deployment of AI models.""}],""red_flags"":[""Lack of experience with Python or data product development"",""Inability to work with cloud computing platforms or big data technologies"",""Insufficient understanding of AI development lifecycle and Agile practices""],""confidence_score"":90.0}"
AI / ML Engineer,"Experience: 10 + yrs.

Job Type: Full time

Responsibilities:

Design, develop, and deploy machine learning models and algorithms to solve business problems.
Collaborate with cross-functional teams to gather requirements, understand business objectives, and deliver AI/ML solutions.
Explore and experiment with new machine learning techniques, frameworks, and libraries to improve model performance and accuracy.
Optimize and scale machine learning algorithms to handle large volumes of data efficiently.
Conduct thorough testing and validation to ensure the quality and reliability of AI/ML models.
Stay up-to-date with the latest advancements in artificial intelligence and machine learning research and technologies.


Qualifications:

Bachelor's or Master's degree in computer science, engineering, mathematics, or a related field.
Strong proficiency in Python and experience with libraries such as TensorFlow, PyTorch, scikit-learn, etc.
Solid understanding of machine learning algorithms and techniques, including supervised and unsupervised learning, deep learning, reinforcement learning, etc.
Experience with data preprocessing, feature engineering, and model evaluation.
Familiarity with cloud platforms such as AWS, Azure, or Google Cloud for model deployment and management.
Excellent problem-solving skills and attention to detail.
Strong communication and collaboration skills, with the ability to work effectively in a team environment.


Preferred Qualifications:

Experience with natural language processing (NLP), computer vision, or other specialized areas of machine learning.
Knowledge of software development best practices, including version control, testing, and code review.
Experience with big data technologies such as Hadoop, Spark, etc.","{""role_summary"":""Design, develop, and deploy machine learning models to solve business problems, collaborating with cross-functional teams to deliver AI/ML solutions."",""key_terms"":[{""term"":""Machine Learning"",""explanation"":""A type of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""AI/ML"",""explanation"":""Artificial Intelligence and Machine Learning, referring to the development of intelligent systems that can perform tasks that typically require human intelligence.""},{""term"":""TensorFlow"",""explanation"":""An open-source machine learning library developed by Google, used for building and training machine learning models.""},{""term"":""PyTorch"",""explanation"":""An open-source machine learning library, primarily used for building and training neural networks.""},{""term"":""Scikit-learn"",""explanation"":""An open-source machine learning library for Python, providing a wide range of algorithms for classification, regression, clustering, and other tasks.""},{""term"":""Cloud Platforms"",""explanation"":""Cloud-based infrastructure services, such as AWS, Azure, or Google Cloud, used for deploying and managing machine learning models.""},{""term"":""Natural Language Processing (NLP)"",""explanation"":""A subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""},{""term"":""Computer Vision"",""explanation"":""A field of study that focuses on enabling computers to interpret and understand visual information from the world.""}],""skill_priorities"":{""must_have"":[""Python"",""Machine Learning"",""TensorFlow"",""PyTorch"",""Scikit-learn"",""Cloud Platforms""],""nice_to_have"":[""Natural Language Processing (NLP)"",""Computer Vision"",""Big Data Technologies"",""Software Development Best Practices""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of overfitting in machine learning and how to prevent it?"",""example_answer"":""Overfitting occurs when a model is too complex and performs well on the training data but poorly on new, unseen data. To prevent overfitting, we can use techniques such as regularization, early stopping, and cross-validation.""},{""question"":""How do you approach model evaluation and selection in machine learning?"",""example_answer"":""I use metrics such as accuracy, precision, recall, and F1-score to evaluate model performance. I also consider factors like model complexity, interpretability, and computational efficiency when selecting the best model for a given problem.""}],""red_flags"":[""Lack of experience with cloud platforms for model deployment and management."",""Inability to explain machine learning concepts and techniques.""],""confidence_score"":90.0}"
Python Developer,"Inviting applications for the role of Lead Consultant, Python Developer!

As a Senior Python Developer, you will be a key member of the IT Applications Development team driving the quality of the solution and services meant to run the business. you will be responsible for designing and developing solutions for client business. You should have an end-to-end understanding of business use cases, to transform them into an effective and strategic solution. You will have the opportunity to work with the latest platform and applications on the given stack.
Responsibilities
Responsible for crafting clean, functional code that flawlessly suits the needs of the company. Your main focus will be translating the design concepts and requirements into simpler implementation level details & designing and developing Python applications.
Collaborate with product owners to create and define user stories and acceptance criteria.
Translate the design concepts, requirements into simpler implementation level details
Initiating collaboration with technical and product teams to identify development requirements and terms
Analysing the clients’ requirements and prioritising their suggested features
Writing well-structured, well-tested, clean quotes with Python programming language to create new applications or add features & improvements to existing services
Working in an Agile environment, following Scrum principles to break silos and support faster iteration and implementation of codes & apps.
Excellent written and verbal communication skills.
Excellent customer facing skills that include conducting compelling technical briefing & demonstrations.
Perform code reviews and check code coverage to ensure the modularity and quality of the code and application.
Work independently with limited or no handholding.
Responsible for troubleshooting issues found during development and providing necessary resolution.
Engage in technical discussions; participate in technical designs and present technical ideas through white board.
Seed and provide feedback on design and development.
Development of features and ALM integrations REST API use
Development test cases using the BDD framework.
Creating incremental SDLC-related functionality.
Preparation and deployment to production, deployment to go live, and postproduction support, as well as bug fixes and the correction of any new or existing issues.
Qualification(Minimum Qualification)
B.Tech/B.E/ MCA
Excellent written and verbal communication skills.
Preferred Qualifications
Good Python experience (REST APIs/Flask)
Design and develop Microservices systems with Python.
AWS Compute, S3, API Gateway.
AWS Lambda based development.
Programming for backend databases like AWS DynamoDB or any other RDBMS or NoSQL DBs.
Front-end development utilizing Electron VUE
Experience with Elastic Search
Exposure to Continuous integration using DevOps - Jenkins and other CI/CD tools.
Exposure to Linux, Apache/httpd, Networking, Firewalls, security, etc.
Good Analytical, Problem-solving and design skills (HLD/LLD) skills
Fluent with object-oriented programming principles.
Familiarity with common stacks
Understanding of fundamental design principles behind a scalable application
Good Understanding of Agile Delivery Methodology & experience in working with Scrum teams
Selection Process
CV screening on the basis of basic requirements
Interview by the Function Head.","{""role_summary"":""Lead Consultant, Python Developer responsible for designing and developing solutions for client business, collaborating with product owners, and ensuring high-quality code implementation."",""key_terms"":[{""term"":""Microservices"",""explanation"":""An architectural approach to building applications as a collection of small, independent services.""},{""term"":""REST API"",""explanation"":""A type of API that uses simple, stateless, and cacheable architecture to enable communication between systems.""},{""term"":""BDD framework"",""explanation"":""A software development process that focuses on defining application behavior through executable examples.""},{""term"":""Scrum principles"",""explanation"":""A framework for project management that emphasizes teamwork, accountability, and iterative progress toward well-defined goals.""},{""term"":""ALM integrations"",""explanation"":""The integration of Application Lifecycle Management tools to manage the entire software development lifecycle.""},{""term"":""SDLC"",""explanation"":""Software Development Life Cycle, a process used to design, develop, and test software.""},{""term"":""AWS Lambda"",""explanation"":""A serverless computing service that runs code in response to events, without provisioning or managing servers.""},{""term"":""Electron VUE"",""explanation"":""A framework for building cross-platform desktop applications using web technologies such as HTML, CSS, and JavaScript.""},{""term"":""Elastic Search"",""explanation"":""A search and analytics engine that allows users to store, search, and analyze large volumes of data.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and speed up delivery.""}],""skill_priorities"":{""must_have"":[""Python programming language"",""Agile environment"",""Scrum principles"",""Excellent written and verbal communication skills""],""nice_to_have"":[""REST APIs/Flask"",""AWS Compute, S3, API Gateway"",""AWS Lambda based development"",""Programming for backend databases like AWS DynamoDB"",""Front-end development utilizing Electron VUE"",""Experience with Elastic Search"",""Exposure to Continuous integration using DevOps - Jenkins and other CI/CD tools"",""Exposure to Linux, Apache/httpd, Networking, Firewalls, security, etc.""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing and developing scalable applications?"",""example_answer"":""I focus on understanding the business requirements and then break down the problem into smaller, independent components. I use design principles like separation of concerns, abstraction, and modularity to ensure the application is scalable and maintainable.""},{""question"":""Can you explain how you would implement a REST API using Python?"",""example_answer"":""I would use a Python web framework like Flask to create the API. I would define the API endpoints, implement the business logic, and use a database like AWS DynamoDB to store and retrieve data. I would also ensure the API is secure, scalable, and follows best practices for API design.""}],""red_flags"":[""Lack of experience with Python programming language"",""Inability to work independently with limited or no handholding"",""Poor communication skills""],""confidence_score"":90.0}"
Machine Learning Engineer - NLP (Remote),"[Quora is a ""remote-first"" company. This position can be performed remotely from multiple countries around the world. Please visit careers.quora.com/eligible-countries for details regarding employment eligibility by country.]

About Quora

Quora’s mission is to grow and share the world’s knowledge. To do so, we have two knowledge sharing products:


Quora: a global knowledge sharing platform with over 400M monthly unique visitors, bringing people together to share insights on various topics and providing a unique platform to learn and connect with others.
Poe: a platform providing millions of global users with one place to chat, explore and build with a wide variety of AI language models (bots), including GPT-4, Claude 3, Gemini Pro, DALL-E 3 and more. As AI capabilities rapidly advance, Poe provides a single platform to instantly integrate and utilize these new models.


Behind these products are passionate, collaborative, and high-performing global teams. We have a culture rooted in transparency, idea-sharing, and experimentation that allows us to celebrate success and grow together through meaningful work. Join us on this journey to create a positive impact and make a significant change in the world.

About The Team And Role

Our small engineering team works on challenging problems every day. We have a culture that's rooted in constantly learning and improving, and our engineers are encouraged to think big and experiment with new ideas. Using continuous deployment, we quickly see our changes in the product and make fast iterations. Our engineers focus on creating polished products and writing high quality code by designing APIs and abstractions that are extensible and maintainable. As a remote first company, our engineers have a high degree of flexibility and autonomy. Everyone on the engineering team has a huge impact on our product and our company.

We are looking for an experienced Machine Learning engineer to join our growing engineering team. At Quora, we use machine learning in almost every part of the product and natural language processing plays an important role. As a natural language processing expert, you will help us leverage our rich textual data and help uncover new opportunities to apply machine learning to the Quora product. You will also play a key role in developing tools and abstractions that our other developers would build on top of.

Responsibilities


Improve our existing machine learning systems using your core coding skills and ML knowledge
Identify new opportunities to apply machine learning to different parts of the Quora product
Work with other machine learning engineers to implement algorithms and systems in an efficient way
Take end to end ownership of machine learning systems - from data pipelines, feature engineering, candidate extraction, model training, as well as integration into our production systems


Minimum Requirements


Ability to be available for meetings and impromptu communication during Quora's “coordination hours"" (Mon-Fri: 9am-3pm Pacific Time)
Demonstrated professional experience in software development and machine learning
3+ years of professional experience working on natural language processing, language modeling, etc
Solid understanding of mathematical foundations of machine learning algorithms
Previous experience building end to end machine learning systems
BS, MS or PhD in Computer Science, Engineering or a related technical field


Preferred Requirements


Flexible and positive team player with outstanding interpersonal skills
3+ years of experience writing Python or C++ code
Proven track record of delivering NLP models to solve industry-scale problem
Experience with transformer models
Experience with leading large-scale multi-engineer projects
Passion for Quora's mission and goals


At Quora, we value diversity and inclusivity and welcome individuals from all backgrounds, including marginalized or underrepresented groups in tech, to apply for our job openings. We encourage all candidates who share a passion for growing the world’s knowledge, even those who may not strictly meet all the preferred requirements, to apply, as we know that a diverse range of perspectives can have a significant impact on our products and our culture.

Additional Information

We are accepting applications on an ongoing basis.

Quora offers a wide range of benefits including medical/dental/vision coverage, equity refreshers, remote work reimbursement, paid time off, employee assistance programs, and more. Benefits are country-specific and may vary. For more information on benefits, visit this link: https://www.careers.quora.com/benefits

There are many factors that will determine the starting pay, including but not limited to experience, location, education, and business needs.


US candidates only: For US based applicants, the salary range is $120,800 - $275,750 USD + equity + benefits.
Canada candidates only: For Canada based applicants, the salary range is $122,471 - $279,565 CAD + equity + benefits.


We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Job Applicant Privacy Notice: https://www.careers.quora.com/applicant-privacy-notice","{""role_summary"":""As a Machine Learning Engineer at Quora, you will leverage natural language processing expertise to improve existing machine learning systems, identify new opportunities, and develop tools for other developers. You will work collaboratively with the engineering team to implement algorithms and systems efficiently."",""key_terms"":[{""term"":""Natural Language Processing (NLP)"",""explanation"":""A subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""},{""term"":""Transformer models"",""explanation"":""A type of deep learning model introduced in the paper 'Attention Is All You Need' that's primarily used for NLP tasks.""},{""term"":""Language modeling"",""explanation"":""The use of various techniques to model and generate human-like language, often used in applications like chatbots and language translation.""}],""skill_priorities"":{""must_have"":[""Professional experience in software development and machine learning"",""3+ years of experience working on natural language processing"",""Solid understanding of mathematical foundations of machine learning algorithms"",""Previous experience building end-to-end machine learning systems"",""BS, MS, or PhD in Computer Science, Engineering, or a related technical field""],""nice_to_have"":[""3+ years of experience writing Python or C++ code"",""Proven track record of delivering NLP models to solve industry-scale problems"",""Experience with leading large-scale multi-engineer projects"",""Passion for Quora's mission and goals""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of attention in transformer models and how it improves language modeling?"",""example_answer"":""The attention mechanism in transformer models allows the model to focus on specific parts of the input sequence when generating the output. This is particularly useful in language modeling as it enables the model to capture long-range dependencies and contextual relationships between words.""},{""question"":""How do you approach feature engineering for NLP tasks, and what techniques do you use to handle high-dimensional data?"",""example_answer"":""I typically start by exploring the data distribution and identifying relevant features that can capture the underlying patterns. For high-dimensional data, I use techniques like PCA, t-SNE, or feature selection to reduce the dimensionality and improve model performance.""}],""red_flags"":[""Lack of experience with NLP or machine learning"",""Inability to communicate complex technical concepts effectively"",""No experience with building end-to-end machine learning systems""],""confidence_score"":95.0}"
"Data Scientist, Decisions - Driving Experience","At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

As a Data Scientist on the Driving XP team, you will collaborate with our world class team of engineers, product managers, and designers to design the end-to-end driving experience for hundreds of thousands of drivers who interact deeply with our app every day. This includes building tools to set personal driving preferences, guidance on when and where to drive, and designing the best UI and personalized XP to get the right rides to the right drivers quickly.

Data Science is at the heart of Lyft’s products and decision-making. You will leverage data and rigorous, analytical thinking to shape our Driving XP products and make business decisions that put drivers first. This will involve identifying and scoping opportunities, shaping priorities, recommending technical solutions, designing experiments, and measuring the impact of new features.

Responsibilities:

Leverage data and analytic frameworks to identify opportunities for growth and efficiency
Partner with product managers, engineers, marketers, designers, and operators to translate data insights into decisions and action
Design and analyze online experiments; communicate results and act on launch decisions
Develop analytical frameworks to monitor business and product performance
Establish metrics that measure the health of our products, as well as rider and driver experience

Experience:

Degree in a quantitative field such as statistics, economics, applied math, operations research or engineering (advanced degrees preferred), or relevant work experience
5+ years of industry experience in a data science or analytical role
Proficiency in SQL - able to write structured and efficient queries on large data sets
Experience in programming, especially with data science and visualization libraries in Python or R
Experience in online experimentation and statistical analysis
Experience in applying Machine Learning techniques (e.g. reinforcement learning) to solve customer problems (e.g. personalization, segmentation)
Strong oral and written communication skills, and ability to collaborate with and influence cross-functional partners

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Access to a Health Care Savings Account
In addition to provincial observed holidays, team members get 15 days paid time off, with an additional day for each year of service
4 Floating Holidays each calendar year prorated based off of date of hire
10 paid sick days per year regardless of province
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid","{""role_summary"":""As a Data Scientist on the Driving XP team, you will design the end-to-end driving experience for hundreds of thousands of drivers, leveraging data and analytical thinking to shape products and make business decisions that put drivers first."",""key_terms"":[{""term"":""Data Science"",""explanation"":""The practice of extracting insights and knowledge from data using various techniques, including machine learning and statistical analysis.""},{""term"":""Driving XP"",""explanation"":""The overall experience of drivers using the Lyft app, including features such as personalized ride matching and guidance on when and where to drive.""},{""term"":""Online Experiments"",""explanation"":""A/B testing or other experiments conducted on a live product to measure the impact of new features or changes.""},{""term"":""Machine Learning"",""explanation"":""A subset of artificial intelligence that involves training algorithms to learn from data and make predictions or decisions.""},{""term"":""Reinforcement Learning"",""explanation"":""A type of machine learning that involves training models to make decisions based on rewards or penalties, often used for personalization and optimization.""}],""skill_priorities"":{""must_have"":[""Degree in a quantitative field"",""5+ years of industry experience in data science or analytical role"",""Proficiency in SQL"",""Experience in programming with data science and visualization libraries in Python or R"",""Strong oral and written communication skills""],""nice_to_have"":[""Advanced degree"",""Experience in applying Machine Learning techniques""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to design and analyze an online experiment to measure the impact of a new feature?"",""example_answer"":""In my previous role, I designed an A/B test to measure the impact of a new recommendation algorithm on user engagement. I worked with cross-functional teams to define the experiment, wrote the SQL queries to extract the data, and analyzed the results using statistical methods. The experiment showed a significant increase in user engagement, and we were able to roll out the new algorithm to all users.""},{""question"":""How do you stay up-to-date with new developments in machine learning and data science?"",""example_answer"":""I regularly read industry blogs and research papers, attend conferences and meetups, and participate in online forums to stay current with new developments in machine learning and data science. I also experiment with new techniques and tools in my own projects to deepen my understanding and stay hands-on.""}],""red_flags"":[""Lack of experience with online experimentation and statistical analysis"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
Senior Data Scientist,"Come aboard a multinational Fortune 500 project in Canada as a Senior Data Scientist. Help craft groundbreaking solutions and lead the charge in technology. Apply today to become an essential part of the client's dynamic team.

Minimum Qualifications

MS/PhD in a quantitative field: Mathematics, Physical Sciences, Statistics/Analytics, Computer Science, or other relevant fields.
Solid experience and a passion for designing, analyzing, and deploying machine learning-based solutions.
Experience with Large Language Models (RAG, Generative AI) and NLP.
Fluency with one or more programming languages: Python, Java, Scala, etc.
Experience with data science toolkits like: pandas, Jupyter, scikit, TensorFlow, etc.
Experience working with big data platforms (Hadoop, Spark, Hive).
Experience working with relational SQL and/or NoSQL databases.
Ability to write high quality, well-documented, scalable code - Python preferred.
Familiarity with cloud computing (AWS).
Familiarity with Machine Learning techniques, e.g., classification, clustering, regularization, optimization, dimension reduction, etc.
Strong communication skills with the ability to explain complex/technical work to a non-technical audience and to present data effectively.
Experience with recommender systems.

Share your resume at hr@techedinlabs.com

Thank you for applying!

Techedin is a global IT Services company complementing the efforts of technology-driven enterprises in developing cutting-edge solutions for humans. We offer services in enterprise app development, content management solutions (CMS), customer relationship management (CRM), cloud engineering, custom software development, and data engineering. Our services include IT Consulting, project management, Software Quality Assurance, and data and analytics services. We develop and maintain various software applications and all other computer-related ancillary services. We have excellent professionals working round the clock to build the best technology teams and products for our customers.","{""role_summary"":""Lead the development of groundbreaking solutions as a Senior Data Scientist, utilizing machine learning and NLP expertise to drive technological advancements."",""key_terms"":[{""term"":""Large Language Models"",""explanation"":""Advanced AI models used for natural language processing and generation.""},{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of AI focused on human-computer interaction.""},{""term"":""Relational SQL"",""explanation"":""A type of database management system that stores data in structured tables.""},{""term"":""NoSQL databases"",""explanation"":""Non-relational databases that store data in flexible, schema-less formats.""},{""term"":""Cloud computing"",""explanation"":""On-demand access to computing resources and services over the internet.""},{""term"":""Recommender systems"",""explanation"":""Algorithms that suggest personalized content or products based on user behavior and preferences.""}],""skill_priorities"":{""must_have"":[""MS/PhD in a quantitative field"",""Experience with machine learning-based solutions"",""Fluency with one or more programming languages"",""Experience with data science toolkits"",""Ability to write high-quality, well-documented, scalable code""],""nice_to_have"":[""Experience with Large Language Models and NLP"",""Familiarity with cloud computing (AWS)"",""Familiarity with Machine Learning techniques"",""Experience with recommender systems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach deploying a machine learning model to a non-technical audience?"",""example_answer"":""I would start by explaining the problem the model solves, then break down the technical components into simple, relatable terms. I'd use analogies and visual aids to help the audience understand the model's functionality and benefits.""},{""question"":""How do you ensure the scalability and maintainability of your code?"",""example_answer"":""I follow best practices for coding, including modular design, clear documentation, and testing. I also consider the long-term implications of my code and plan for future updates and maintenance.""}],""red_flags"":[""Lack of experience with machine learning-based solutions"",""Inability to explain complex technical concepts to a non-technical audience""],""confidence_score"":90.0}"
"Data Scientist, Decisions - Rider Experience","At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

Data Science is at the heart of Lyft’s products and decision-making. As a member of the Rider team, you will work in a dynamic environment, where we embrace moving quickly to build the world’s best transportation. Data Scientists take on a variety of problems ranging from shaping critical business decisions to building algorithms that power our internal and external products. We’re looking for passionate, driven Data Scientists to take on some of the most interesting and impactful problems in ridesharing.

As a Data Scientist, Decisions in the Rider team, you will leverage data and rigorous, analytical thinking to shape our rider app and make business decisions that put our customers first. You will identify and scope opportunities, shape priorities, recommend technical solutions, design experiments, and measure impact. You will bring a quantitative mindset to decision-making in partnership with product, design, engineering, business, and operations stakeholders throughout the organization.

You will report to a Data Science Manager in the Rider Science team.

Responsibilities:

Leverage data and analytic frameworks to identify opportunities for growth and efficiency
Partner with product managers, engineers, marketers, designers, and operators to translate data insights into decisions and action
Design and analyze online experiments; communicate results and act on launch decisions
Develop analytical frameworks to monitor business and product performance
Establish metrics that measure the health of our products, as well as rider and driver experience

Experience:

Degree in a quantitative field such as statistics, economics, applied math, operations research or engineering (advanced degrees preferred), or relevant work experience
3+ years of industry experience in a data science or analytics role
Proficiency in SQL - able to write structured and efficient queries on large data sets
Experience in programming, especially with data science and visualization libraries in Python or R is helpful
Experience in online experimentation and statistical analysis
Strong oral and written communication skills, and ability to collaborate with and influence cross-functional partners

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Access to a Health Care Savings Account
In addition to provincial observed holidays, team members get 15 days paid time off, with an additional day for each year of service
4 Floating Holidays each calendar year prorated based off of date of hire
10 paid sick days per year regardless of province
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid","{""role_summary"":""As a Data Scientist in the Rider team, you will leverage data and analytical thinking to shape the rider app and make business decisions that put customers first, working closely with cross-functional stakeholders."",""key_terms"":[{""term"":""Data Science"",""explanation"":""The practice of extracting insights and knowledge from data to inform business decisions.""},{""term"":""Rigorous, analytical thinking"",""explanation"":""A systematic and logical approach to problem-solving, using data and evidence to support conclusions.""},{""term"":""Online experiments"",""explanation"":""Controlled tests conducted on a digital platform to measure the impact of changes on user behavior or business outcomes.""}],""skill_priorities"":{""must_have"":[""Degree in a quantitative field"",""3+ years of industry experience in data science or analytics"",""Proficiency in SQL"",""Strong oral and written communication skills""],""nice_to_have"":[""Experience with data science and visualization libraries in Python or R"",""Experience in online experimentation and statistical analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to design and analyze an online experiment to inform a business decision?"",""example_answer"":""In my previous role, I designed an A/B test to measure the impact of a new feature on user engagement. I worked with cross-functional stakeholders to define the experiment's objectives, developed the experimental design, and analyzed the results using statistical methods. The insights from the experiment informed a key business decision, resulting in a 20% increase in user engagement.""},{""question"":""How do you stay up-to-date with new developments in data science and analytics, and how do you apply that knowledge to your work?"",""example_answer"":""I regularly read industry blogs and research papers to stay current with new techniques and tools. I also participate in online forums and attend conferences to network with other professionals in the field. In my previous role, I applied my knowledge of machine learning to develop a predictive model that improved forecasting accuracy by 15%.""}],""red_flags"":[""Lack of experience with SQL or programming languages"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Data Scientist for Biomedical Signals,"About Us

At Myant, we are creating the world’s first expressive and continuous digital presence platform, enabled by integrating technology directly into clothing and augmented by other devices, wearables, and IOT. We see the evolution of society where every member gets to participate from anywhere and anytime through a whole-body experience, mostly in a passive or ambient manner to foster ubiquitous accessibility. Humans have a fundamental desire and need to be connected to our environment, family, community, and technology. This level of connection will create a paradigm shift in the way we deal with each other, especially from afar, allowing for more meaningful relationships, and more in-depth representation of ourselves.

The need for this type of connection is not new. There are many companies working on ways to connect humans in singularity with technology, however most of these technologies are based on devices that are often used in episodical ways hence, leading to poor adoption or reliability. In general, innovation and technology have delivered significant benefits for many members of society. However, there are those who are left behind, namely the very young, the marginalized, the old and the sick. The challenge of inclusion for those left behind requires us to move beyond device focused strategies, towards an interface that we use naturally, every day. We believe that textile is that primary interface, used in clothing, coverings, carpeting and more, we wear and are surrounded by textiles universally, at all times.

Such an interface could fuse data with other devices that we use periodically and data with other IoTs in the environment. People could then leverage their physical presence over their digital presence to communicate and share personal wellbeing. This could unlock healthcare that is proactive and preventative, social connectedness that is more profound, enable care distribution models to be seamless and on demand, better fitness insights, safer working environments and more.

The vision for SKIIN -our first consumer-facing brand- is to enhance human ability through connected clothing and textiles. Skiin is in beta-phase market launch and has been recently granted Health Canada medical device license and submitted to FDA for regulatory approval in the US market. The sensors and actuators embedded within our apparel create your Digital Identity, which will be consumed by those who matter to you - your family members, physicians, trainers, other IoT devices - without you consciously having to think about it. The line between the digital and physical world is becoming increasingly blurry and we believe textile is the next medium to bridge that gap.

We are a multi-disciplinary technology team solving big challenges at the intersection of electronics, deep tech., software, design, advanced manufacturing and data science.

What we offer at Myant:

Employee stock options
Paid Sick Days and Floating Days
Group Health Insurance Plan
RRSP matching Plan
Corporate Events
Exposure working in one of the most innovative and forward-thinking tech company

Myant is a diversified, equal opportunity employer. People with disability or a special accommodation request may send an email to hr@myant.ca.

Project Description:

You will be involved in Myant’s project with the Canadian Space Agency for development of mental health and sleep monitoring tools for deep space exploration. You will have to design protocols, collect and analyze data to validate the prediction capabilities of various metrics using Myant’s smart-textile based form factors. These metrics include sleep and mental health parameters. You will also be involved in integration of Myant’s system with mental health management solutions provided by other subcontractors.

Responsibilities:

Use tools and algorithms for data collection, testing and validation of our products for biosignal monitoring (e.g. sleep, activity, fatigue and stress)
Clean and organize study data and assess quality and integrity of data collected
Visualize data statistics and perform exploratory data analysis to understand relevant feature engineering approaches
Develop Signal Processing and Machine Learning Algorithms for extracting information and valuable metrics from bio-signals including ECG, activity, temperature, for continuous long-term monitoring;
Collaborate with academic and industrial partners for integration of Myant Products
Evaluate the algorithms and the system as a whole in real-world scenarios and do troubleshooting to cover corner cases
Take ownership of all your deliverables and communicate your results for timely project delivery
Working in an ISO-13485 and HIPAA regulated environment, following quality procedures for design and development as well as verification and validation for clinical use, including to support regulatory approval

Qualifications:

PhD in Biomedical, Electrical/Electronics Engineering, Computer Engineering, Computer Science, or related discipline.
Extensive experience in modern scripting languages including Python. Working familiarity with Python is a must
Knowledge and experience in Bio-signal processing, feature extraction, feature selection, sampling strategies using machine learning algorithms, and systematic hyperparameter optimization
Familiarity with following libraries is desired: scikit-learn, seaborn, plotly, pytorch/tensorflow
Previous experience working on bio-signals such as electrocardiogram, electromyogram, electroencephalogram, photoplethysmogram, IMU signals, etc
Experience on long term biomedical recording and data analysis, from wearable systems and related signal analysis, handling of noise, missing data etc.
Background in time-domain, frequency-domain, and discrete-time signal processing algorithms
Previous experience on planning and coordinating clinical studies, data collection and operating medical devices is a plus

Bonus:

Experience in implementing algorithms in C/C++, Java, Javascript and Swift
Experience in any of the following industries: pharmaceutical, medical technology, healthcare, consumer electronics, and wearables
Experience working in start-ups or growth companies

Powered by JazzHR

yB39rJuEWg","{""role_summary"":""Design and develop protocols for mental health and sleep monitoring tools using smart-textile based form factors, and integrate with mental health management solutions."",""key_terms"":[{""term"":""Bio-signal processing"",""explanation"":""The process of extracting valuable information from biological signals, such as ECG, activity, and temperature, for continuous long-term monitoring.""},{""term"":""Feature engineering"",""explanation"":""The process of selecting and transforming raw data into features that are suitable for modeling and machine learning algorithms.""},{""term"":""ISO-13485"",""explanation"":""An international standard for quality management systems in the medical device industry, ensuring the design, development, and production of safe and effective medical devices.""},{""term"":""HIPAA"",""explanation"":""The Health Insurance Portability and Accountability Act, a US law that protects sensitive patient health information and ensures confidentiality, integrity, and availability of electronic protected health information.""}],""skill_priorities"":{""must_have"":[""PhD in Biomedical, Electrical/Electronics Engineering, Computer Engineering, Computer Science, or related discipline"",""Extensive experience in modern scripting languages including Python"",""Knowledge and experience in Bio-signal processing, feature extraction, feature selection, sampling strategies using machine learning algorithms, and systematic hyperparameter optimization""],""nice_to_have"":[""Experience in implementing algorithms in C/C++, Java, Javascript and Swift"",""Experience in any of the following industries: pharmaceutical, medical technology, healthcare, consumer electronics, and wearables"",""Experience working in start-ups or growth companies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of bio-signal processing and its application in wearable devices?"",""example_answer"":""Bio-signal processing involves extracting valuable information from biological signals, such as ECG, activity, and temperature, for continuous long-term monitoring. In wearable devices, bio-signal processing enables the tracking of vital signs, activity levels, and other health metrics, providing insights into a person's overall health and wellbeing.""},{""question"":""How do you approach feature engineering for machine learning algorithms in bio-signal processing?"",""example_answer"":""I approach feature engineering by selecting and transforming raw bio-signal data into relevant features that are suitable for modeling and machine learning algorithms. This involves techniques such as filtering, normalization, and dimensionality reduction to extract meaningful patterns and relationships from the data.""}],""red_flags"":[""Lack of experience in bio-signal processing and machine learning algorithms"",""Inability to work in an ISO-13485 and HIPAA regulated environment""],""confidence_score"":90.0}"
Junior Python Engineer – up to $130k + Bonus – Montreal (Hybrid),"Python Padawans Wanted: Kickstart Your Fintech Journey in Montreal
Are you a junior Python pro with 1-4 years under your belt? Ready to join the ranks of an Elite Fintech firm and embark on an epic coding adventure? I am on the hunt for rising stars with an insatiable appetite for learning and a passion for financial technology.

Your Mission (Should You Choose to Accept It):
Develop cutting-edge financial applications using your Python skills
Gain valuable experience in distributed systems and database management
Collaborate with cross-functional teams to solve complex challenges

Your Budding Superpowers:
Bachelor's degree in Computer Science or a related field
1-4 years of professional Python development experience
Strong foundation in object-oriented programming, data structures, and algorithms
Familiarity with Django or FastAPI (a bonus, but not required)
Eagerness to learn about distributed systems and database technologies

What You'll Bring:
Unwavering problem-solving abilities and an analytical mindset
A commitment to writing clean, maintainable code
Excellent communication and collaboration skills
Adaptability to thrive in a fast-paced, dynamic environment
An insatiable thirst for learning and professional growth

The Rewards:
Join a team of coding crusaders working on cutting-edge fintech solutions
Hybrid work environment with a balance of in-office and remote flexibility
Competitive compensation and benefits package
Opportunities for professional development and career advancement

Ready to ignite your coding journey? Apply now and let's conquer the world of fintech together!","{""role_summary"":""Develop cutting-edge financial applications using Python skills, collaborate with cross-functional teams, and gain experience in distributed systems and database management."",""key_terms"":[{""term"":""Distributed systems"",""explanation"":""A computer system that consists of multiple components located on different machines, communicating and coordinating to achieve a common goal.""},{""term"":""Database management"",""explanation"":""The process of designing, implementing, and maintaining databases to store and retrieve data efficiently.""},{""term"":""Object-oriented programming"",""explanation"":""A programming paradigm that organizes software design around objects and the interactions between them.""},{""term"":""Fintech"",""explanation"":""The intersection of finance and technology, referring to companies that use technology to improve or automate financial services.""}],""skill_priorities"":{""must_have"":[""Python development experience"",""Object-oriented programming"",""Data structures"",""Algorithms""],""nice_to_have"":[""Django or FastAPI experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach problem-solving in a complex distributed system?"",""example_answer"":""I would identify the key components involved, analyze the system's architecture, and then design a solution that takes into account the interactions between components.""},{""question"":""Can you explain the concept of abstraction in object-oriented programming?"",""example_answer"":""Abstraction is the process of exposing only the necessary information to the outside world while hiding the implementation details, allowing for modular and reusable code.""}],""red_flags"":[""Lack of experience with Python development"",""Inability to work in a fast-paced, dynamic environment""],""confidence_score"":90.0}"
Senior Machine Learning Engineer,"Physicians, the backbone of our healthcare system, have long been burdened by excessive administrative tasks and documentation requirements compounded by EMR regulations resulting in the widespread issue of physician burnout. The toll of spending 10-15 hours per week on these tasks has led to a concerning trend known as the ""great resignation of healthcare,"" with doctors leaving their positions due to overwhelming stress and exhaustion.

Tali AI is dedicated to tackling the issue of physician burnout through the development of a voice-enabled virtual assistant designed specifically for physicians. Our voice enabled AI innovative assistant streamlines their professional lives by significantly minimizing the time spent on documentation and administrative tasks.

Tali AI is looking for a Senior Machine Learning Engineer to play a crucial role in advancing our capabilities in understanding, processing and generating natural language, as well as improving the accuracy and efficiency of our speech recognition systems.

Who You Are:

You have a degree in Computer Science, Engineering, or a related field with a focus on machine learning, NLP, ASR, or equivalent practical experience
You have at least 8 years of professional experience in machine learning engineering, with a strong emphasis on NLP and ASR
Proficiency in programming languages such as Python, Java, or C++ for implementing machine learning algorithms and building scalable systems
Deep understanding of NLP techniques including text classification, named entity recognition, sentiment analysis, and machine translation
Solid grasp of ASR concepts such as acoustic modeling, language modeling, and speech signal processing
Strong problem-solving skills and the ability to think creatively to overcome challenges in machine learning projects
Excellent communication skills and the ability to collaborate effectively in a team environment

What You'll Do:

Lead the design, development, and implementation of state-of-the-art machine learning models and algorithms for NLP and ASR applications
Conduct research and stay up-to-date with the latest advancements in NLP and ASR to continuously enhance our technology stack
Collaborate with cross-functional teams including software engineers, data scientists, and product managers to integrate machine learning solutions into our products and services
Analyze and preprocess large volumes of text and speech data to extract meaningful insights and features for model training
Optimize model performance and scalability to meet stringent latency and throughput requirements
Conduct thorough experimentation and evaluation to assess the performance of NLP and ASR models and identify areas for improvement
Provide mentorship and guidance to junior members of the machine learning team, fostering a culture of continuous learning and innovation

Our Core Values

Growth: we have a growth mindset; we want to learn and improve a little (or a lot!) every day
Purpose: we care about our team and our community; we understand the purpose of our work and take it seriously
Innovation: we're all about innovation and cutting edge technology; we don't shy away from a challenge

Perks and Benefits

Comprehensive health and wellness benefits package from day one
Three weeks paid vacation and additional company-wide holiday between Dec 25 - Jan 1
Half day Fridays (35-hour work week)
“Knowledge Dollars” to invest in annual professional development
Quarterly socials & company outings
Fully remote work

Recruitment Process

Here’s what to expect from the recruitment process:

Selected candidates will be contacted for an initial 30-minute interview
Hiring Manager Interview
Interview with a Co-Founder/Executive Leader
Decision Stage

Working at Tali:

Our core values:

Growth: we have a growth mindset; we want to learn and improve a little (or a lot!) every day
Purpose: we care about our team and our community; we understand the purpose of our work and take it seriously
Innovation: we're all about innovation and cutting edge technology; we don't shy away from a challenge

Recruitment Process

Here’s what to expect from the recruitment process:
Selected candidates will be contacted for an initial 30-minute interview
Hiring Manager Interview
Interview with a Co-Founder/Executive Leader
Decision Stage

We thank all applicants for their interest; only those candidates selected for an interview will be contacted. Tali is committed to providing a barrier-free recruitment process for all candidates. Should you require accommodations at any point throughout the hiring process, please contact the Human Resources team at

Powered by JazzHR

8EDI4E3n59","{""role_summary"":""Lead the development and implementation of machine learning models and algorithms for natural language processing and automatic speech recognition applications, focusing on improving the accuracy and efficiency of speech recognition systems."",""key_terms"":[{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""},{""term"":""ASR"",""explanation"":""Automatic Speech Recognition, a technology that enables computers to recognize and transcribe spoken language into text.""},{""term"":""EMR"",""explanation"":""Electronic Medical Record, a digital version of a patient's medical chart, containing their medical history, diagnoses, medications, test results, and other relevant information.""}],""skill_priorities"":{""must_have"":[""Machine learning engineering experience"",""NLP and ASR expertise"",""Programming skills in Python, Java, or C++"",""Strong problem-solving skills""],""nice_to_have"":[""Experience with text classification, named entity recognition, sentiment analysis, and machine translation"",""Knowledge of acoustic modeling, language modeling, and speech signal processing""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach optimizing the performance of a speech recognition model for a voice-enabled virtual assistant?"",""example_answer"":""I would start by analyzing the model's current performance metrics, identifying areas for improvement, and then experimenting with techniques such as data augmentation, hyperparameter tuning, and model ensemble methods to optimize the model's accuracy and efficiency.""},{""question"":""Can you explain the concept of acoustic modeling in the context of automatic speech recognition?"",""example_answer"":""Acoustic modeling involves using statistical models to represent the relationship between spoken sounds and their corresponding audio signals, enabling the speech recognition system to accurately transcribe spoken language into text.""}],""red_flags"":[""Lack of experience with NLP and ASR"",""Inability to communicate complex technical concepts effectively""],""confidence_score"":95.0}"
"Data Scientist, Canada - BCG X","Locations: Toronto | Montreal

Who We Are

***To submit an application in French, please go to your settings at the top of the page and select French as your language preference. This will enable you to view the portal and application questions in French.***

***Pour soumettre une candidature en français, veuillez accéder à vos paramètres en haut de la page et sélectionner le français comme langue de préférence. Cela vous permettra de consulter le portail et les questions relatives à la candidature en français.***

Boston Consulting Group (BCG) is a global management consulting firm and the world’s leading advisor on business strategy. We partner with clients from the private, public, and not-for-profit sectors in all regions to identify their highest-value opportunities, address their most critical challenges, and transform their enterprises. Our customized approach combines deep insight into the dynamics of companies and markets with close collaboration at all levels of the client organization. This ensures that our clients achieve sustainable competitive advantage, build more capable organizations, and secure lasting results. Founded in 1963, BCG is a private company with offices in more than 90 cities in 50 countries. For more information, please visit bcg.com.

BCG’s clients are the world’s top business leaders. From computers to retailing, our professional expertise spans over 50 industries. The vast majority of our clients rank among the 500 largest companies in each of our three major regions–Americas (North and South), Europe Middle East and Africa, and Asia Pacific. Additionally, we work with a number of small- to medium-sized companies, both public and private.

The success of our assignments routinely leads our clients to maintain long-term relationships with us. Over 85 percent of our revenues come from clients who continue to work with us from one year to the next to maintain the momentum for change and to continually improve bottom-line results they have achieved with our help.

We pride ourselves on our fresh thinking. Our evolving ideas profoundly change the way most businesses think about competition. Many leading business concepts over the past three decades originated with BCG–including, experience curve, time-based competition, Segment-of-One® marketing, deconstruction, and trading up. Our recent Collateral Damage publication series has addressed the implications for managers of the on-going financial crisis.

We believe that no other consulting organization has concentrated as thoroughly on understanding business competition and helping companies make the changes necessary to succeed in increasingly competitive markets.

La réputation mondiale du cabinet de conseil en gestion Boston Consulting Group (BCG), comme l'un des meilleurs en gestion, découle de plus de cinquante années d'expérience à aider les cadres supérieurs à découvrir et réaliser tout le potentiel de leur entreprise. Notre mission consiste à appuyer nos clients à réaliser des avantages concurrentiels durables en offrant des solutions personnalisées. Nous croyons fermement qu'il faut travailler avec nos clients, pas à leurs dépens. Nous collaborons avec chaque client pour l'aider à prendre une direction et à faire face aux défis organisationnels et opérationnels.

Fondé en 1963, BCG compte maintenant plus de 11,000 experts-conseils, et ce, dans plus de 90 bureaux dans le monde entier. Les clients du BCG sont les dirigeants des plus importantes entreprises du monde. Des ordinateurs jusqu'à la vente au détail, notre expertise professionnelle s'étend à plus de 50 industries. La grande majorité de nos clients figurent parmi les 500 plus grandes entreprises dans chacune de nos trois régions principales – Les Amériques (nord et sud), l'Europe (incluant le Moyen-Orient et l'Afrique) et l'Asie-Pacifique. De plus, nous travaillons avec un certain nombre de petites et moyennes entreprises, tant publiques que privées.

Notre succès, provenant des mandats qui nous sont assignés, nous permet d'établir des relations à long terme avec nos clients. Plus de 85 pourcents de nos revenus proviennent de clients qui continuent à travailler avec nous d'une année à l'autre pour conserver l'élan de changement et pour améliorer continuellement les résultats nets qu'ils ont réalisés grâce à notre aide.

Nous sommes fiers de notre approche innovatrice. Nos idées évolutives changent profondément la manière dont la plupart des entreprises considèrent la concurrence. Plusieurs des principaux concepts d'affaires, au cours des trois dernières décennies, ont commencé avec BCG, y compris la courbe d'apprentissage, la concurrence calculée sur le temps, le marketing Segment-of-One®, le démantèlement et l'extension ascendante. Nos récentes publications de la série Collateral Damage ont traité de l'implication des dirigeants face à la crise financière en cours.

Nous croyons qu'aucune autre organisation de conseil en gestion ne s'est concentrée aussi attentivement à la compréhension de la concurrence en affaires et à aider les entreprises à effectuer les changements nécessaires pour réussir sur des marchés de plus en plus compétitifs.

We Are BCG X

We’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.

What You'll Do

Our BCG X teams own the full analytics value-chain end to end: framing new business challenges, designing innovative algorithms, implementing, and deploying scalable solutions, and enabling colleagues and clients to fully embrace AI. Our product offerings span from fully custom-builds to industry specific leading edge AI software solutions.

As a Data Scientist, you'll be part of our rapidly growing team. You'll have the chance to apply data science methods and analytics to real-world business situations across a variety of industries to drive significant business impact. You'll have the chance to partner with clients in a variety of BCG regions and industries, and on key topics like climate change, enabling them to design, build, and deploy new and innovative solutions.

Additional responsibilities will include developing and delivering thought leadership in scientific communities and papers as well as leading conferences on behalf of BCG X. Successful candidates are intellectually curious builders who are biased toward action, scrappy, and communicative.

We are looking for talented individuals with a passion for data science, statistics, operations research and transforming organizations into AI led innovative companies. Successful candidates possess the following:

Comfortable in a client-facing role with the ambition to lead teams
Likes to distill complex results or processes into simple, clear visualizations
Explain sophisticated data science concepts in an understandable manner
Love building things and are comfortable working with modern development tools and writing code collaboratively (bonus points if you have a software development or DevOps experience)
Significant experience applying advanced analytics to a variety of business situations and a proven ability to synthesize complex data
Deep understanding of modern machine learning techniques and their mathematical underpinnings, and can translate this into business implications for our clients
Have strong project management skills

Nos équipes BCG X sont responsables de l’ensemble de la chaîne de valeur de l’analyse de bout en bout : encadrer de nouveaux défis commerciaux, concevoir des algorithmes d’innovation, mettre en œuvre et déployer des solutions évolutives, et permettre à nos collègues et clients d’adopter pleinement l’IA. Nos offres de produits s’étendent des versions entièrement personnalisées aux solutions logicielles d’IA de pointe spécifiques à l’industrie.

En tant que scientifique des données, vous ferez partie de notre équipe en pleine croissance. Vous aurez l’occasion d’appliquer des méthodes et des analyses de science des données à des situations commerciales réelles dans une variété d’industries pour avoir un impact commercial important. Vous aurez l’occasion de collaborer avec des clients de diverses régions et industries du BCG et sur des sujets clés comme le changement climatique, leur permettant de concevoir, de construire et de déployer des solutions nouvelles et d’innovation.

Les responsabilités supplémentaires comprendront le développement et la prestation d’un leadership éclairé dans les communautés et les articles scientifiques, ainsi que la direction de conférences au nom du BCG X. Les candidats à succès sont des bâtisseurs intellectuels curieux qui ont un parti pris vers l’action, sont ambitieux et ont le sens de la communication.

Nous sommes à la recherche de personnes talentueuses passionnées par la science des données, les statistiques, la recherche sur les opérations et la transformation d’organisations en entreprises innovantes dirigées par l’IA. Les candidats à succès possèdent les compétences suivantes :

Aisance à occuper un rôle de contact avec les clients et ambition de diriger des équipes
Aime distiller des résultats ou des processus complexes en visualisations simples et claires
Capacité d’expliquer les concepts sophistiqués de la science des données de manière compréhensible
Aime construire des choses et est à l’aise de travailler avec des outils de développement modernes et de rédiger des codes en collaboration (points en prime si vous avez une expérience en développement de logiciels ou DevOps)
Vaste expérience dans l’application d’analyses avancées dans diverses situations d’affaires et capacité reconnue de synthétiser des données complexes
Compréhension approfondie des techniques modernes d’apprentissage automatique et de leurs fondements mathématiques, et capacité de traduire cela en implications commerciales pour nos clients
Solides compétences pour la gestion de projets

What You'll Bring

TECHNOLOGIES:

Programming Languages: Python

Ce que vous apporterez

TECHNOLOGIES :

Langues de programmation : Python

Additional info

Additional info

We seek people with drive, energy, first-rate minds, and ability to lead and persuade. In selecting people to join the firm, we carry out an intensive interviewing process. Candidates should demonstrate success in their academic and extracurricular activities, whether that be through volunteer work, professional experiences, or through personal initiatives. Compensation for associates entering the firm is extremely competitive and grows rapidly with strong performance.

Language of work for positions permanently located in Quebec

Knowledge of French is required for positions permanently located in Quebec so incumbents can communicate with their colleagues and suppliers in Quebec as necessary. French-language training is offered to all incumbents in permanent positions in Quebec who do not have a good knowledge of French.

Other Language Requirement

Fluent English is required for this position in order to communicate with clients, partners and colleagues, who are predominantly located outside Quebec.

How To Apply

Candidates interested in applying must submit an application including a cover letter and résumé.

Nous recherchons des personnes ambitieuses, énergiques, avec de la capacité intellectuelle à mener au bout des projets et à persuader. En choisissant des personnes à se joindre à l'entreprise, nous procédons à un processus intensif d'entrevue.

Les candidats doivent démontrer leur succès dans leurs activités universitaires ou parascolaires, que ce soit par un travail bénévole, des stages professionnels ou encore des initiatives personnelles. La rémunération pour les analystes qui se joignent à l'entreprise est extrêmement concurrentielle et augmente rapidement en fonction de performance.

Langue de travail pour les postes situés en permanence au Québec

La connaissance du français est requise pour les postes situés en permanence au Québec afin que le titulaire puisse communiquer au besoin avec ses collègues et les fournisseurs au Québec. Une formation en français est offerte à tout titulaire d’un poste permanent au Québec qui ne possède pas une bonne connaissance du français.

Autre exigence linguistique

La maîtrise de l’anglais est requise pour ce poste afin de pouvoir communiquer avec les clients, partenaires et collègues qui sont majoritairement situés à l’extérieur du Québec.

Comment postuler?

Les candidats intéressés à postuler un poste d'analyste à l'un de nos bureaux canadiens du BCG doivent soumettre une demande, qui consiste en une lettre de présentation, un curriculum vitae, et un relevé de notes le plus récent.

Boston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.

BCG is an E - Verify Employer. Click here for more information on E-Verify.","{""role_summary"":""As a Data Scientist at BCG X, you will apply data science methods and analytics to real-world business situations across various industries, driving significant business impact and partnering with clients to design, build, and deploy new and innovative solutions."",""key_terms"":[{""term"":""Data Science"",""explanation"":""The extraction of insights and knowledge from structured and unstructured data using various techniques, including machine learning and statistical modeling.""},{""term"":""AI"",""explanation"":""Artificial Intelligence, which refers to the development of computer systems that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, and decision-making.""},{""term"":""Machine Learning"",""explanation"":""A subset of AI that involves training algorithms to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development (Dev) and IT operations (Ops) to improve the speed, quality, and reliability of software releases and deployments.""}],""skill_priorities"":{""must_have"":[""Python programming language"",""Data science methods and analytics"",""Machine learning techniques"",""Project management skills""],""nice_to_have"":[""Software development or DevOps experience"",""French language skills (for positions in Quebec)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach a complex data science problem and communicate the results to a non-technical stakeholder?"",""example_answer"":""I would first clarify the problem and identify the key stakeholders, then gather and preprocess the relevant data. Next, I would apply machine learning techniques to develop a predictive model, and finally, I would communicate the results using clear and concise visualizations and language, highlighting the key insights and recommendations.""},{""question"":""How do you stay current with new developments in machine learning and AI?"",""example_answer"":""I regularly read industry publications and research papers, attend conferences and meetups, and participate in online forums and discussions to stay up-to-date with the latest advancements and trends in machine learning and AI.""}],""red_flags"":[""Lack of experience with data science methods and analytics"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Research Associate/Associate Scientist – Antibody Drug Conjugates,"Who We Are

Abdera Therapeutics Inc. is a precision oncology company developing next-generation targeted radiation therapies- one of the most cutting-edge and highly promising areas of drug development. The company is built on a proprietary modular technology platform optimized for the delivery of radioisotopes to selectively destroy tumor cells while sparing healthy cells. Abdera is using this platform to enable the rapid development of a broad range of safe and efficacious therapies serving cancer patients with limited treatment options.

Abdera Therapeutics is growing rapidly and seeking key new team members who thrive at the cutting-edge of innovation. Come join us and be a part of the ground-breaking team set to unlock the power of targeted radiotherapy!

What We Look For

At Abdera Therapeutics, we are looking for curious and committed individuals who are ready for the opportunity to transform the way people living with cancer can be treated. We are determined in our focus to offer new hope to families facing devastating diagnoses. We are in search of team members who work collaboratively with a diverse group of colleagues, respectfully engaging one another while collectively and inclusively tackling any challenges we may face. We are building an exciting and fast paced company passionate about discovering and developing tomorrow’s most innovative cancer therapies.

Salary Range: CAD$ 85K - 120K

Job Summary

Abdera Therapeutics is seeking a highly motivated and skilled Research Associate or Associate Scientist to support antibody drug conjugation and characterization in the Biologics team. This position will provide an exciting and dynamic opportunity to positively contribute to research programs developing next-generation targeted radiopharmaceutical therapies and develop essential skills and expertise in therapeutic antibody discovery.

Principal Responsibilities

Performs antibody conjugation and purification.
Performs antibody biophysical analysis including quantification, aggregation, and stability analysis.
Performs antibody developability assessment using a suite of industry standard and newly developed assays.
Analyze and present data to the team.
Work cross-functionally with other teams.

Qualifications, Education & Experience

BSC/MSc in Molecular Biology, Biochemistry or related field, with 1-5 years relevant experience, or PhD.
Hands-on experience with protein characterization essential

Skills & Abilities

Protein purification by various chromatography techniques, using FPLC systems.
Protein quantification, and CE-SDS, cIEF
Antibody purification, analysis or conjugation experience an asset.
Strong organizational skills and attention to detail
Exceptional interpersonal skills, ability to work collaboratively with a cross-functional team.
Good communication and presentation skills
Ability to prioritize and execute to meet project deadlines.

Abdera is an equal opportunity employer that is committed to diversity and inclusion in the workplace. At Abdera, we prohibit harassment of any kind and any form of discrimination including but not limited to discrimination based on race, color, sex, religion, marital status, sexual orientation, national origin, disability, veteran status, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws.

This is applicable to all employment practices within our organization, including hiring, recruiting, promotion, termination, layoff, recall, leave of absence, compensation, benefits, training, and apprenticeship.","{""role_summary"":""Support antibody drug conjugation and characterization in the Biologics team, contributing to research programs developing next-generation targeted radiopharmaceutical therapies."",""key_terms"":[{""term"":""Antibody drug conjugation"",""explanation"":""The process of linking an antibody to a drug or toxin to create a targeted therapy.""},{""term"":""Biologics"",""explanation"":""Biological products, such as antibodies, used to prevent or treat diseases.""},{""term"":""Radiopharmaceutical therapies"",""explanation"":""Medicines that use small amounts of radioactive materials to diagnose or treat diseases, including cancer.""},{""term"":""FPLC systems"",""explanation"":""Fast Protein Liquid Chromatography systems, used for protein purification and analysis.""},{""term"":""CE-SDS"",""explanation"":""Capillary Electrophoresis-Sodium Dodecyl Sulfate, a technique used for protein analysis and quantification.""},{""term"":""cIEF"",""explanation"":""Capillary IsoElectric Focusing, a technique used for protein analysis and characterization.""}],""skill_priorities"":{""must_have"":[""Protein purification by various chromatography techniques"",""Protein quantification, and CE-SDS, cIEF"",""Strong organizational skills and attention to detail"",""Exceptional interpersonal skills, ability to work collaboratively with a cross-functional team"",""Good communication and presentation skills""],""nice_to_have"":[""Antibody purification, analysis or conjugation experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with protein purification and characterization techniques?"",""example_answer"":""I have hands-on experience with FPLC systems and have used CE-SDS and cIEF for protein analysis and quantification.""},{""question"":""How do you prioritize and manage multiple projects with tight deadlines?"",""example_answer"":""I use project management tools and create detailed timelines to ensure timely completion of tasks, and communicate regularly with the team to ensure everyone is on track.""}],""red_flags"":[""Lack of hands-on experience with protein characterization"",""Inability to work collaboratively with a cross-functional team""],""confidence_score"":90.0}"
Python/Data Scientist-Canada,"Role: Python/Data Scientist

Location: Mississauga, ON, Canada(from day 1 should be able to work at client site)

Duration: 6+ Months

Job Description

Roles and Responsibilities:

8-10+ years total work experience
5+ years of experience in developing scalable distributed machine learning systems
Should be able to work with a distributed multi-vendor team in a multi-cultural environment across multiple geographies taking care of a complex web application
Should be extremely good at communication and be able to manage conflicts constructively and proactively
Should be self driven and be able to take ownership of tasks end to end
Should have a researcher attitude
5+ years of experience in developing and deploying machine learning models and algorithms for time series data analysis, e.g., anomaly detection and forecasting.
Expertise in Python programming and machine learning libraries such as PyTorch, Scikit-learn, and Pandas.
Strong understanding of time series models such as ARIMA, SARIMA, Prophet, and LSTM, and experience in building custom models.
Experience with anomaly detection techniques

Skills

Python , machine learning libraries such as PyTorch, Scikit-learn, and Pandas
Models: ARIMA, SARIMA, Prophet, and LSTM

Note

A master's degree in business or a technical discipline (Computer Science, Information Systems, Engineering) required.
This is an independent contributor role from day 1 and should be able to work at client site from day 1
Travel option is not provided","{""role_summary"":""A Python/Data Scientist responsible for developing and deploying machine learning models and algorithms for time series data analysis, working with a distributed team, and communicating effectively with stakeholders."",""key_terms"":[{""term"":""Scalable distributed machine learning systems"",""explanation"":""Machine learning systems that can handle large amounts of data and scale up or down as needed, often using distributed computing techniques.""},{""term"":""Time series data analysis"",""explanation"":""The process of analyzing data that is ordered in time, often to identify patterns, trends, or anomalies.""},{""term"":""ARIMA, SARIMA, Prophet, and LSTM"",""explanation"":""Types of time series models used for forecasting and anomaly detection.""},{""term"":""Anomaly detection"",""explanation"":""The process of identifying unusual or unexpected patterns in data.""}],""skill_priorities"":{""must_have"":[""Python"",""Machine learning libraries (PyTorch, Scikit-learn, Pandas)"",""Experience with time series models (ARIMA, SARIMA, Prophet, LSTM)"",""Anomaly detection techniques""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a scalable machine learning system for time series data analysis?"",""example_answer"":""I would start by identifying the key requirements for the system, such as scalability and performance. Then, I would design a distributed architecture using technologies like PyTorch and Pandas, and implement models like ARIMA and LSTM for time series analysis.""},{""question"":""How do you handle conflicts and communication with a distributed team?"",""example_answer"":""I believe in proactive communication and setting clear expectations with the team. I would establish regular check-ins and use collaboration tools to ensure everyone is aligned and working towards the same goal.""}],""red_flags"":[""Lack of experience with distributed machine learning systems"",""Inability to work independently and take ownership of tasks""],""confidence_score"":90.0}"
Biomedical Big Data Engineer,"About Us:

At Myant, we are creating the world’s first expressive and continuous digital presence platform, enabled by integrating technology directly into clothing and augmented by other devices, wearables, and IOT. We see the evolution of society where every member gets to participate from anywhere and anytime through a whole-body experience, mostly in a passive or ambient manner to foster ubiquitous accessibility. Humans have a fundamental desire and need to be connected to our environment, family, community, and technology. This level of connection will create a paradigm shift in the way we deal with each other, especially from afar, allowing for more meaningful relationships, and more in-depth representation of ourselves.

The need for this type of connection is not new. There are many companies working on ways to connect humans in singularity with technology, however most of these technologies are based on devices that are often used in episodical ways hence, leading to poor adoption or reliability. In general, innovation and technology have delivered significant benefits for many members of society. However, there are those who are left behind, namely the very young, the marginalized, the old and the sick. The challenge of inclusion for those left behind requires us to move beyond device focused strategies, towards an interface that we use naturally, every day. We believe that textile is that primary interface, used in clothing, coverings, carpeting and more, we wear and are surrounded by textiles universally, at all times.

Such an interface could fuse data with other devices that we use periodically and data with other IoTs in the environment. People could then leverage their physical presence over their digital presence to communicate and share personal wellbeing. This could unlock healthcare that is proactive and preventative, social connectedness that is more profound, enable care distribution models to be seamless and on demand, better fitness insights, safer working environments and more.

The vision for SKIIN -our first consumer-facing brand- is to enhance human ability through connected clothing and textiles. Skiin is in beta-phase market launch and has been recently granted Health Canada medical device license and submitted to FDA for regulatory approval in the US market. The sensors and actuators embedded within our apparel create your Digital Identity, which will be consumed by those who matter to you - your family members, physicians, trainers, other IoT devices - without you consciously having to think about it. The line between the digital and physical world is becoming increasingly blurry and we believe textile is the next medium to bridge that gap.

We are a multi-disciplinary technology team solving big challenges at the intersection of electronics, deep tech., software, design, advanced manufacturing and data science.

What we offer at Myant:

Employee stock options
Paid Sick Days and Floating Days
Group Health Insurance Plan
RRSP matching Plan
Corporate Events
Exposure working in one of the most innovative and forward-thinking tech company

Myant is a diversified, equal opportunity employer. People with disability or a special accommodation request may send an email to hr@myant.ca.

Position Overview:

As a Biomedical Big Data Engineer at Myantx, you will play a key role in designing, developing, and maintaining our big data infrastructure. You will work closely with datascience, biomedical systems and software teams to implement scalable and efficient data processing solutions, ensuring the availability and reliability of our data pipelines. You will also contribute in defining along with all stake holders the efforts on big data analysis, planning for execution, providing the timeline and leading the efforts. This is an exciting opportunity to contribute to the advancement of our data architecture and analytics capabilities.

Responsibilities:

Take ownership of all your deliverables and communicate your results for timely project delivery
Design, implement, and optimize big data processing systems and infrastructure both for offline analysis and as part of the Myant Health platform
Develop and maintain scalable ETL (Extract, Transform, Load) processes for large volumes of structured and unstructured data from wearable systems including noise and missed data
Collaborate with data scientists and analysts to understand data requirements and ensure data availability for analytical purposes
Implement data governance and security best practices to safeguard sensitive information
Troubleshoot and optimize existing data pipelines for performance and reliability
Prepared and organize large scale biomedical datasets gathered by Skiin or other devices, as well as clinical datasets to be used for data analysis and development of medical and health related algorithms/models
Contribute in big data analysis using statistical methods, causal inference techniques and machine learning approaches.
Creating and managing data warehouses and data lakes to facilitate efficient data storage and retrieval
Stay current with emerging technologies and industry trends in big data and analytics
Collaborate with cross-functional teams, partners and external researchers/companies to define and execute data-driven projects
Working in an ISO-13485 and HIPAA regulated environment, following quality procedures for design and development as well as verification and validation for clinical use, including to support regulatory approval

Qualifications:

PhD in Computer Science, Electrical or Biomedical Engineering, or MSc plus equivalent experience in relevant industry.
Extensive experience in modern scripting languages including Python and Java.
Proven experience as a Big Data Engineer or similar role, with expertise in designing and implementing large-scale data processing solutions
Familiarity with data modeling, database design, and SQL
Experience with big data technologies, including Hadoop, Spark, Kafka, and related ecosystems
Strong understanding of distributed computing principles and cloud platforms (e.g., AWS, Azure, GCP)
Excellent communication skills, with the ability to convey complex technical concepts to non-technical stakeholders

Preferred Qualifications:

Experience working in the medical device industry, or working with industrial partners on large scale biomedical datasets.
Familiarity with streaming data processing and real-time analytics
Experience in implementing algorithms in C/C++, Javascript and Swift
Experience in biomedical data analysis from wearable systems and related signal analysis, handling of noise, missing data etc.
Experience working on bio-signals such as electrocardiogram, electromyogram, electroencephalogram, photo-plethysmogram, accelerometry signals

What We Offer

Employee stock options
Paid Sick Days and Floating Days
Group Health Insurance Plan
RRSP matching Plan
Corporate Events
Exposure working in one of the most innovative and forward-thinking tech company

We are a diversified, equal opportunity employer. People with disability or a special accommodation request may send an email to hr@myant.ca.

Powered by JazzHR

fbGBqFuHQJ","{""role_summary"":""Design, develop, and maintain big data infrastructure, ensuring data pipeline availability and reliability, and contributing to data architecture and analytics capabilities."",""key_terms"":[{""term"":""Big Data Engineer"",""explanation"":""A professional responsible for designing, developing, and maintaining large-scale data processing solutions.""},{""term"":""ETL (Extract, Transform, Load)"",""explanation"":""A process used to extract data from various sources, transform it into a standardized format, and load it into a target system.""},{""term"":""Data Governance"",""explanation"":""The practice of managing and overseeing data management practices to ensure data quality, security, and compliance.""},{""term"":""Data Lakes"",""explanation"":""A centralized repository that stores raw, unprocessed data in its native format, allowing for flexible and scalable data storage.""},{""term"":""ISO-13485"",""explanation"":""An international standard for quality management systems in the medical device industry, ensuring the safety and efficacy of medical devices.""},{""term"":""HIPAA"",""explanation"":""The Health Insurance Portability and Accountability Act, a US law that protects sensitive patient health information.""}],""skill_priorities"":{""must_have"":[""PhD in Computer Science, Electrical or Biomedical Engineering, or MSc plus equivalent experience"",""Experience in modern scripting languages including Python and Java"",""Proven experience as a Big Data Engineer or similar role"",""Familiarity with data modeling, database design, and SQL"",""Experience with big data technologies, including Hadoop, Spark, Kafka, and related ecosystems""],""nice_to_have"":[""Experience working in the medical device industry"",""Familiarity with streaming data processing and real-time analytics"",""Experience in implementing algorithms in C/C++, Javascript and Swift"",""Experience in biomedical data analysis from wearable systems""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a scalable ETL process for large volumes of structured and unstructured data from wearable systems?"",""example_answer"":""I would use a distributed computing framework like Apache Spark to handle large volumes of data, and implement data quality checks to ensure data integrity. I would also consider using data lakes to store raw data and data warehouses for processed data.""},{""question"":""How do you ensure data governance and security best practices in a big data infrastructure?"",""example_answer"":""I would implement data encryption, access controls, and auditing mechanisms to ensure data security. I would also establish data quality checks and data validation rules to ensure data accuracy and completeness.""}],""red_flags"":[""Lack of experience in big data technologies"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Intermediate Data Scientist,"Employment Type: Full-time Regular

City: Calgary, AB (YYC)

Posting Open Date: 06/21/2024

Posting Close Date: 07/05/2024 (Please note the posting will close at 11:59pm MST)

Remote Work:

This position is eligible for Hybrid work in Calgary, Alberta, under our mobile workforce program.

Why WestJet:

Every WestJet journey has the potential to enrich lives; a career with us is no exception.

WestJet arrived on the Canadian airline scene in 1996 and changed the industry for the better. We made air travel more affordable for Canadians and now we're going global.

Join us and love where you’re going.

Intermediate Data Scientist - Advanced Analytics

We are seeking a talented Intermediate Data Scientist to join the Advanced Analytics team. If you are passionate about data, have a proven track record of solving complex problems, and want to contribute to meaningful projects, we encourage you to apply.

As an Intermediate Data Scientist, you will play a crucial role in driving data-driven decision-making and delivering actionable insights. You will work collaboratively with senior data scientists and cross functional teams — including data engineers, product managers, and business stakeholders — to design, develop, and deploy advanced analytics solutions.

Key Responsibilities:

Data Analysis: Conduct exploratory data analysis to identify trends, patterns, and opportunities within large and complex datasets.
Model Development: Develop and implement predictive and prescriptive models using machine learning and statistical techniques to solve business problems.
Feature Engineering: Create and engineer features from various data sources to improve model performance.
Data Visualization: Collaborate with Technical Product Managers and Data Visualization Developers to communicate findings and insights effectively through data visualization tools and reports (Power BI and Tableau).
Collaboration: Collaborate closely with the Senior Technical Product Manager and cross functional teams to define business problems, scope and success criteria, and translate them into advanced analytics solutions.
Model Deployment: Deploy and monitor models in production, ensuring their performance and scalability.
Community & Research: Keep current on data science and AI tools, techniques and best practices and provide advice to citizen data analysts/scientists and the community of practice.

Qualifications:

Bachelor’s Degree in Data Science, Mathematics, Statistics, Computer Science, or a related field with 3-5 years of relevant experience.
Strong proficiency in SQL and Python is a must have — with expertise in machine learning libraries and frameworks. R and other similar languages would be an asset.
Experience in predictive modelling, statistical analysis and machine learning techniques.
Prior experience deploying AI models into production environments.
Proven experience developing dashboards in Power BI or Tableau.
Proficiency in cloud platforms (e.g., Azure ML Studio, Snowflake).
Excellent problem-solving skills and the ability to work independently and collaboratively within a team.
Strong communication skills, with the ability to convey complex findings and AI model outputs to both technical and non-technical stakeholders.

Nice to Have:

Familiarity with MLOPs.
Data Science/AI training or certification.
A master's degree and/or Ph.D. in Data Science, Statistics, Computer Science, or a related field.
Prior experience working for an airline.
Agile training or certification

The benefits of being a WestJetter:

WestJet provides all WestJetters with a competitive total rewards package. On top of that, we offer:

A fun and friendly culture with colleagues who work together to win
Travel privileges for you and your family, effective from your start date
Savings and Benefit programs that are flexible to meet your specific needs

Think we are a fit? Apply now!

About WestJet Group Of Companies

Together with WestJet's regional airline, WestJet Encore, we offer scheduled service to more than 100 destinations in North America, Central America, the Caribbean and Europe and to more than 175 destinations in over 20 countries through our airline partnerships.

Our Safety Promise

At WestJet, the safety and security of our people and our guests is a core value and at the heart of what we do. As safety and security is a shared responsibility, it is expected that you will use safe work practices to ensure your well-being and the safety of others.

WestJet recognizes that the use of Alcohol and Drugs can adversely impact a safe work environment and the well-being of others including guests, suppliers and the public, as well as place WestJet's operations at risk. All roles that are identified as safety sensitive are required to pass a Pre-Employment Alcohol and Drug Test as per WestJet's Alcohol and Drug Policy.

Our Commitment to Diversity and Inclusion

We embrace what makes us each unique, and what makes us uniquely WestJet. WestJet is committed to inclusiveness, equity, and accessibility and if you require accommodation during the selection process, please let our Talent Acquisition team know. We encourage all qualified candidates to apply. We thank all applicants for their interest in WestJet; however, only those candidates who are selected will be contacted.

Interview Process Outline:

Digital Interview
Technical Assessment
Interview with Advanced Analytics Team

For more information about everything WestJet, please visit WestJet.com","{""role_summary"":""An Intermediate Data Scientist will drive data-driven decision-making and deliver actionable insights by conducting data analysis, developing predictive models, and collaborating with cross-functional teams."",""key_terms"":[{""term"":""Predictive models"",""explanation"":""Statistical models that forecast future outcomes based on historical data.""},{""term"":""Prescriptive models"",""explanation"":""Models that provide recommendations for business actions based on data analysis.""},{""term"":""Feature engineering"",""explanation"":""The process of selecting and transforming raw data into features that can be used in machine learning models.""},{""term"":""MLOps"",""explanation"":""A set of practices that combines machine learning and DevOps to streamline the deployment of AI models.""}],""skill_priorities"":{""must_have"":[""SQL"",""Python"",""Machine learning libraries and frameworks"",""Predictive modelling"",""Statistical analysis"",""Experience deploying AI models into production environments"",""Developing dashboards in Power BI or Tableau"",""Proficiency in cloud platforms (e.g., Azure ML Studio, Snowflake)""],""nice_to_have"":[""R and other similar languages"",""Familiarity with MLOPs"",""Data Science/AI training or certification"",""A master's degree and/or Ph.D. in Data Science, Statistics, Computer Science, or a related field"",""Prior experience working for an airline"",""Agile training or certification""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of overfitting in machine learning and how you would prevent it?"",""example_answer"":""Overfitting occurs when a model is too complex and performs well on the training data but poorly on new, unseen data. To prevent overfitting, I would use techniques such as regularization, early stopping, and cross-validation to ensure the model generalizes well to new data.""},{""question"":""How do you approach feature engineering for a machine learning model?"",""example_answer"":""I would start by understanding the problem and the data, then use techniques such as correlation analysis and mutual information to select relevant features. I would also consider using dimensionality reduction techniques to reduce the feature space.""}],""red_flags"":[""Lack of experience with cloud platforms"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Generative AI Engineer,"About Alexa Translations

Alexa Translations provides translation services in the legal, financial, and securities sectors by leveraging proprietary A.I. technology and a team of highly specialized linguistic experts. Unmatched in speed and quality, our machine translation engine is best-in-class and specifically trained for the French-Canadian market. If that wasn’t enough, our technology is backed by two decades of award-winning client service.

About The Role

We are looking for a Generative AI Engineer to develop our next-generation intelligent translation and translation-related service engine, using Generative AI (GenAI) and Large Language Model (LLM) technologies. You will report to the team lead on GenAI, develop and implement state-of-the-art algorithms by fast prototyping, and collaborate with the software team to deploy models. We expect our Generative AI Engineer to stay current with the technological cutting edge and build applications of LLM and GenAI to machine translation with best industry practices, as well as having solid background and hands-on experience with deep learning, machine learning, natural language processing, and big data.

Responsibilities

Research and implement state-of-the-art LLM techniques including continued pre-training, instruction fine-

tuning, preference alignment, and LLM deployment while also focusing on prompt engineering and GenAI more

broadly.

Work closely with machine learning engineers and data scientists to design, build, and test models
Contribute to technological innovations by staying current to the cutting-edge achievements of GenAI and LLM

from industry and academia.

Develop efficient and scalable algorithms for training and inference of generative models, leveraging deep

learning frameworks such as TensorFlow or PyTorch and optimizing performance on diverse hardware platforms.

Train and evaluate generative models using appropriate metrics and benchmarks, fine-tuning model parameters, architectures, and hyperparameters to optimize performance, stability, and generalization
Work closely with software and DevOps engineers to deploy GenAI models
Document code, algorithms, and experimental results, following best practices for reproducibility, version

control, and software engineering, and contribute to internal knowledge sharing and continuous improvement

initiatives.

Requirements

Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Machine Learning, or related field
1+ years of industry experience developing GenAI and LLM applications is preferred
Proficiency in Python programming and software development practices, with experience in building and

maintaining scalable, production-grade software systems.

Working knowledge and project-based record of all of the following: prompt tuning, RAG, ICL
Working knowledge and project-based record of at least one of the following is a plus: continued pre-training,

instruction fine-tuning, Agent.

Strong problem-solving skills, attention to detail, and the ability to work independently and collaboratively in

a fast-paced environment.

Hands-on experience with Huggingface APIs or Amazon Bedrock
Expert skills of Python, including PyTorch, TensorFlow, Pandas, etc
Experience with cloud platforms like AWS, GCP, or Azure
Self-driven, self-motivated with excellent time management skills
Excellent communication skills, with the ability to convey complex technical concepts clearly and effectively to

both technical and non-technical stakeholders.

Familiarity with GPU programming and optimization techniques for accelerating deep learning computations
Ability to adapt to shifting priorities without compromising deadlines and momentum
Prior experience in generative AI research, projects, or internships, with contributions to open-source projects

or publications in relevant conferences or journals.

Powered by JazzHR

U9Z0boGW1L","{""role_summary"":""Develop and implement state-of-the-art algorithms for a next-generation intelligent translation and translation-related service engine using Generative AI and Large Language Model technologies."",""key_terms"":[{""term"":""Generative AI (GenAI)"",""explanation"":""A type of artificial intelligence that involves generating new content, such as text or images, based on patterns and structures learned from large datasets.""},{""term"":""Large Language Model (LLM)"",""explanation"":""A type of artificial intelligence model that is trained on large amounts of text data to generate language outputs that are coherent and natural-sounding.""},{""term"":""Prompt engineering"",""explanation"":""The process of designing and optimizing the input prompts or instructions given to a language model to elicit specific responses or behaviors.""},{""term"":""Deep learning"",""explanation"":""A subfield of machine learning that involves the use of neural networks to analyze and interpret data.""},{""term"":""Natural Language Processing (NLP)"",""explanation"":""A subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""},{""term"":""Big data"",""explanation"":""Large and complex datasets that require specialized processing and analysis techniques.""}],""skill_priorities"":{""must_have"":[""Python programming"",""Deep learning"",""Machine learning"",""Natural Language Processing (NLP)"",""Big data""],""nice_to_have"":[""Experience with cloud platforms like AWS, GCP, or Azure"",""Familiarity with GPU programming and optimization techniques"",""Prior experience in generative AI research, projects, or internships""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of prompt engineering in the context of Large Language Models?"",""example_answer"":""Prompt engineering involves designing and optimizing the input prompts or instructions given to a language model to elicit specific responses or behaviors. This can involve techniques such as fine-tuning the model on specific tasks or datasets, or using techniques like reinforcement learning to optimize the prompts for a particular goal.""},{""question"":""How would you approach developing efficient and scalable algorithms for training and inference of generative models?"",""example_answer"":""I would approach this by leveraging deep learning frameworks such as TensorFlow or PyTorch, and optimizing performance on diverse hardware platforms. I would also consider using techniques such as model parallelism, data parallelism, and pipeline parallelism to improve scalability.""}],""red_flags"":[""Lack of experience with Generative AI and Large Language Model technologies"",""Inability to work independently and collaboratively in a fast-paced environment""],""confidence_score"":90.0}"
AI/ML and MLOps Field Engineer,"Canonical is a leading provider of open source software and operating systems to the global enterprise and technology markets. Our platform, Ubuntu, is very widely used in breakthrough enterprise initiatives such as public cloud, data science, AI, engineering innovation and IoT. Our customers include the world's leading public cloud and silicon providers, and industry leaders in many sectors. The company is a pioneer of global distributed collaboration, with 1000+ colleagues in 70+ countries and very few roles based in offices. Teams meet two to four times yearly in person, in interesting locations around the world, to align on strategy and execution.

The company is founder led, profitable and growing.

We are hiring an AI/ML and MLOps Field Engineer to help global companies embrace AI in their business, using the latest open source capabilities on public and private cloud infrastructure, Linux and Kubernetes. Our team applies expert insights to real-world customer problems, enabling the enterprise adoption of Ubuntu, Kubeflow, MLFlow, Feast, DVC and related analytics, machine learning and data technologies. We are working to create the world's best open source data platform, covering traditional SQL databases and today's NoSQL data stores, as well as the machinery which turns data into insights and executable models.

The people who love this role are software engineers who enjoy customer conversations and solving customer problems during the presales cycle. They are are developers who like to solve customer problems through architecture, presentations and training. Ubuntu is used by pretty much every enterprise in the world, in every industry. This is a fantastic opportunity to learn about the open source technology landscape and develop your business technology insights. You will see first hand in various industries how Linux - and Ubuntu in particular - is shaping innovation and changing the world for the better.

This role is particularly suited to candidates with a technical background who are business minded and driven by commercial success. This role is on our global Field Engineering team and will work closely with enterprise sales leads. We are specifically looking for people interested in solving the most difficult problems in modern data architectures. Training LLMs on multiple K8s clusters deployed on a hybrid cloud infrastructure with GPU sharing across multiple teams? Processing 10M events in real time for financial transactions? Object detection on 10k parallel 4K video streams? These are the problems we solve day to day.

Location: Most of our colleagues work from home. We are growing teams in EMEA, Americas and APAC time zones, so can accommodate candidates from almost any country.

What your day will look like

The global Field Engineering team members are Linux and cloud solutions architects for our customers, designing private and public cloud solutions fitting their workload needs. They are the cloud consultants who work hands-on with the technologies by deploying, testing and handing over the solution to our support or managed services team at the end of a project. They are also software engineers who use Python to develop Kubernetes operators and Linux open source infrastructure-as-code.

Work across the entire Linux stack, from kernel, networking, storage, to applications
Architect cloud infrastructure solutions like Kubernetes, Kubeflow, OpenStack, and Spark
Deliver solutions either on-premise or in public cloud (AWS, Azure, Google Cloud)
Collect customer business requirements and advise them on Ubuntu and relevant open source applications
Grow a healthy, collaborative engineering culture in line with the company values
Deliver presentations and demonstrations of Ubuntu Pro and AI/ML capabilities to prospective and current clients
Liaise with product teams to give them feedback on requirements to influence roadmap
Work collaboratively with your sales team to reach our common targets
Global travel up to 25% of time for internal and external events and 25% to customer meetings

What we are looking for in you

Exceptional academic track record from both high school and university
Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path
Experience in data engineering, MLOps, or big data solutions deployment
Experience with a relevant programming language, like Python, R, or Rust.
Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation
Track record of going above-and-beyond expectations to achieve outstanding results
Demonstrated personal interest in continuous learning and development
Practical knowledge of Linux, virtualisation, containers and networking
Business-minded technology thinker and problem solver
Knowledge of cloud computing concepts & leaders, such as Kubernetes, AWS, Azure, GCP
Interest in large-scale enterprise open source - private clouds, machine learning and AI, data and analytics
Intermediate level Python programming skills
Passion for technology evidenced by personal projects and initiatives
The work ethic and confidence to shine alongside motivated colleagues
Professional written and spoken English with excellent presentation skills
Experience with Linux (Debian or Ubuntu preferred)
Excellent interpersonal skills, curiosity, flexibility, and accountability
A dynamic person who loves to jump in new projects and interact with people
Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation
Thoughtfulness and self-motivation
Result-oriented, with a personal drive to follow up and meet commitments
Ability to travel internationally, for company events up to two weeks long, and customer or industry meetings

What you'll learn

Architect and deploy AI/ML infrastructures, data processing pipelines and multi-cluster distributed training
Wide range of open source applications and skills
Work directly with customers in a range of different businesses
Real-life and hands-on exposure to a wide range of emerging technologies and tools

What we offer colleagues

We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus or commission. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally.

Distributed work environment with twice-yearly team sprints in person
Personal learning and development budget of USD 2,000 per year
Annual compensation review
Recognition rewards
Annual holiday leave
Maternity and paternity leave
Employee Assistance Programme
Opportunity to travel to new locations to meet colleagues
Priority Pass, and travel upgrades for long haul company events

About Canonical

Canonical is a pioneering tech firm at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world of software. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Most colleagues at Canonical have worked from home since its inception in 2004. Working here is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game.

Canonical is an equal opportunity employer

We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.","{""role_summary"":""Work as an AI/ML and MLOps Field Engineer to help global companies adopt AI using open source capabilities on public and private cloud infrastructure, Linux, and Kubernetes, and provide expert insights to real-world customer problems."",""key_terms"":[{""term"":""MLOps"",""explanation"":""Machine Learning Operations, a set of practices that combines machine learning and DevOps to streamline the machine learning lifecycle.""},{""term"":""Kubeflow"",""explanation"":""An open-source machine learning platform that enables easy deployment of machine learning models on Kubernetes.""},{""term"":""MLFlow"",""explanation"":""An open-source platform for machine learning lifecycle management, including experimentation, reproducibility, and deployment.""},{""term"":""Feast"",""explanation"":""An open-source feature store for machine learning, providing a centralized repository for features and enabling real-time access.""},{""term"":""DVC"",""explanation"":""An open-source tool for data versioning, management, and collaboration, enabling data scientists to track and reproduce machine learning experiments.""}],""skill_priorities"":{""must_have"":[""Experience in data engineering, MLOps, or big data solutions deployment"",""Experience with a relevant programming language, like Python, R, or Rust"",""Practical knowledge of Linux, virtualisation, containers and networking"",""Business-minded technology thinker and problem solver"",""Knowledge of cloud computing concepts & leaders, such as Kubernetes, AWS, Azure, GCP"",""Intermediate level Python programming skills""],""nice_to_have"":[""Experience with Linux (Debian or Ubuntu preferred)"",""Passion for technology evidenced by personal projects and initiatives""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would architect a cloud infrastructure solution using Kubernetes and Kubeflow?"",""example_answer"":""I would start by understanding the customer's workload needs and then design a scalable and secure cloud infrastructure using Kubernetes and Kubeflow. I would ensure that the solution is deployable on-premise or in public cloud, and provide a seamless experience for the customer.""},{""question"":""How do you stay up-to-date with the latest developments in AI, ML, and data technologies?"",""example_answer"":""I regularly follow industry blogs and publications, attend conferences and meetups, and participate in online forums to stay current with the latest advancements in AI, ML, and data technologies.""}],""red_flags"":[""Lack of experience in data engineering, MLOps, or big data solutions deployment"",""Inability to communicate technical concepts to non-technical stakeholders"",""Limited knowledge of cloud computing concepts and leaders""],""confidence_score"":90.0}"
Data Scientist Specialist,"Job Description:

The Opportunity:

's Data Product Development group specializes in creating unique and insightful data products. Utilizing data from both internal and external sources, we deliver innovative products that power some of the world’s most successful organizations.

We’re currently seeking a Data Scientist - NLP, LLM, and GenAI (contract) to join our team and to help create new products and services powered by modern AI technologies, including Large Language Models (LLM). The ideal candidate is autonomous, creative, and laser-focused on driving tangible business value through their ingenuity.

The Role:

Collaborate with Product, Data, and Technology teams to design and create new products and services powered by AI
Work alongside a team of data scientists in applying state-of-the-art LLMs from OpenAI, Anthropic, Meta, and Mistral to address the unique challenges of financial data
Create models and pipelines for Named Entity Recognition and Entity Resolution
Assess the quality and robustness of your solutions and iterate to optimize performance
Apply best practices of MLOps / LLMOps in deploying new products and services to production

Qualifications and Skills:

5+ years of experience processing structured and unstructured data using NLP
1+ years of experience applying LLMs to solve real-world, industry problems
Solid understanding of NLP and related concepts such as vectorization, entity recognition, semantic search, and so forth
Experience with RAG and LLM fine-tuning is a strong plus
Python experience is required, AWS/FastAPI/Gradio/Docker is a plus
Passionate about Generative AI, consistently tracking the latest industry developments
Bachelors Degree in Computer Science, Computer Engineering, or related discipline

*** This is a contract role for immediate hire with a scheduled end date of Sept 30, 2024 ***

About US Tech Solutions:

US Tech Solutions is a global staff augmentation firm providing a wide range of talent on-demand and total workforce solutions. To know more about US Tech Solutions, please visit www.ustechsolutions.com.

US Tech Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.","{""role_summary"":""Collaborate with teams to design and create new AI-powered products and services, applying NLP and LLM expertise to drive business value."",""key_terms"":[{""term"":""LLM"",""explanation"":""Large Language Model, a type of AI technology used for natural language processing.""},{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of AI that deals with human-computer interaction.""},{""term"":""GenAI"",""explanation"":""Generative Artificial Intelligence, a type of AI that generates new content, such as text or images.""},{""term"":""MLOps/LLMOps"",""explanation"":""Machine Learning Operations/Large Language Model Operations, practices for deploying and managing AI models in production.""},{""term"":""RAG"",""explanation"":""A type of AI model fine-tuning technique used for natural language processing.""}],""skill_priorities"":{""must_have"":[""5+ years of NLP experience"",""1+ years of LLM experience"",""Python experience"",""Solid understanding of NLP concepts""],""nice_to_have"":[""Experience with RAG and LLM fine-tuning"",""AWS/FastAPI/Gradio/Docker experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would apply LLMs to address the unique challenges of financial data?"",""example_answer"":""I would use LLMs to develop models that can accurately identify and extract relevant information from financial data, and then fine-tune the models using techniques like RAG to improve their performance.""},{""question"":""How do you ensure the quality and robustness of your NLP solutions?"",""example_answer"":""I use a combination of metrics such as accuracy, precision, and recall to evaluate the performance of my models, and then iterate on the models to optimize their performance.""}],""red_flags"":[""Lack of experience with LLMs"",""Inability to explain NLP concepts""],""confidence_score"":90.0}"
AI Scientist,"Company Information

Name of Hiring Company: Nuvoola AI

Nuvoola AI is an artificial intelligence firm based in Quebec, Ontario, and New Brunswick. We are market leader in Artificial Intelligence (AI) computer vision, implementing virtual guard solutions, with facial, license plate and character recognition, leveraging natural language interaction for various market and industries. We thrive at optimizing business processes and solving complex operational problems. We are a recognized and talented team partnering with the best in the industry and take serious proud of helping our customer reduce their operating cost, be more competitive while improving their overall efficiency.

We offer a stimulating, high technology work environment and state-of-the-art projects, coupled with professional development and continuing education with access to international conferences and sophisticated work equipment.

Nuvoola subscribes to the principle of equal access to employment and promotes the diversity of the workforce.

Please apply via https://www.nuvoola.com/company#careers

Job Title: AI Scientist

Sector

☐ Management

☐ Finances and Administration

☒ Natural and Applied Science + Related Fields

☐ Health

☐ Sales & Services

☐ Supply chain, Transportation, and Related Fields

☐ Natural Resources, Agriculture

☐ Public Utilities – Fabrication & Services

Number of Opening: 1

Designated Work Area

Montreal or Chambly (QC), Ottawa (ON), Caraquet (NB), Remote

Job Description

Are you passionate about building bleeding edge solutions?

Join the Nuvoola AI team as an AI Scientist and contribute to solving interesting business challenges. This is a unique opportunity to make a big impact!

You will develop innovative solutions in-house and with clients in a variety of industries, such as Utility, Entertainment, Financial Services, Public Sector, Retail, and Transportation. We believe in small multi-disciplinary teams of developers, architects, designers, and industry experts that collaborate in short sprints and agile cycles. This role will involve significant client interaction and outputs may be used for board level demonstrations.

Essential Skills & Qualifications

PhD/Master’s degree in computer science, engineering, or mathematics fields
Prior experience in artificial intelligence, machine learning
Minimum 3 years of machine learning experience in Python with interest in Deep Learning
A track record of outstanding AI (Deep Learning focus) software development with Github (or similar) evidence
Demonstrated abilities in designing AI systems
Demonstrated interest in applied Deep Learning, including early stage of data preparation, augmentation, generation, systematic Deep Learning model tuning, replicable Machine Learning experiments modeling, Deep Learning pipeline for ML model selection and validation
Expert-level knowledge and experience working with at least one data science programming language (e.g. Python, R, Scala) to explore, understand, and build analytic models from data assets of varying size, type, and quality
Expertise in Embedded Machine Learning (e.g. Deep Learning quantization) is a strong plus
Good foundation in mathematics, statistics, and probability
Strong knowledge of Machine Learning foundations with one or more of the following:
Computer Vision applications
Natural human interaction
Predictive analytics
Knowledge of mainstream Deep Learning architectures (MLP, CNN, UNET, etc) and Deep Generative Learning architectures (GAN, VAE) for computer vision tasks
Strong Python programming skills
Working knowledge of Linux OS
Eagerness to contribute in a goal-oriented environment
Ability to work creatively and analytically in a problem-solving environment
Proven verbal and written communication skills in English (talks, presentations, publications, etc.)

Key Personal Competencies

Great communicator
Team player
Critical thinker
Avid learner
Focus driven
Transformational agent

Diplomas

☐ High School

☐ Professional Training

☐ Bachelor’s degree

☒ Master

☒ PhD

☒ Required / ☐ Privileged

Level in French

☐ Bilingual

☒ Fluent

☐ Good

☐ Average

☐ School level

☐ Required / ☒ Privileged

Level in English

☒ Bilingual

☐ Fluent

☐ Good

☐ Average

☐ School level

☒ Required/ ☐ Privileged

Number of Years of Experience: 3 years

☐ Requited / ☒ Privileged

Duration of Contract

☐ Fixed Duration (temporary)

☒ Undetermined Duration (permanent)

Starting Date : As soon as possible

Remuneration (Mandatory)

☒ Annual

☐ Monthly

☐ Weekly

☐ Hourly

Amount ($ CAN):

From____$______ To _____$______

The Information On The Salary Is

☒ Confidential

☐ Public

Additional Information

Why work at Nuvoola AI:

Stimulating work environment and state-of-the-art projects,
Professional development and continuing education with access to international conferences,
Benefits after 3 months in position providing excellent coverage,
Open work environment and sophisticated work equipment.

Nuvoola subscribes to the principle of equal access to employment and promotes the diversity of the workforce.","{""role_summary"":""Contribute to solving business challenges as an AI Scientist, developing innovative solutions in-house and with clients across various industries, collaborating in small multi-disciplinary teams, and interacting with clients."",""key_terms"":[{""term"":""Artificial Intelligence (AI) computer vision"",""explanation"":""The use of AI to enable computers to interpret and understand visual information from the world.""},{""term"":""Deep Learning"",""explanation"":""A subfield of machine learning that involves the use of artificial neural networks to analyze and interpret data.""},{""term"":""Embedded Machine Learning"",""explanation"":""The integration of machine learning models into embedded systems, such as microcontrollers or other devices with limited computing resources.""},{""term"":""Natural Language Interaction"",""explanation"":""The ability of computers to understand and process human language, enabling humans to interact with machines more naturally.""}],""skill_priorities"":{""must_have"":[""PhD/Master's degree in computer science, engineering, or mathematics fields"",""Prior experience in artificial intelligence, machine learning"",""Minimum 3 years of machine learning experience in Python with interest in Deep Learning"",""Expert-level knowledge and experience working with at least one data science programming language"",""Strong knowledge of Machine Learning foundations"",""Strong Python programming skills"",""Working knowledge of Linux OS""],""nice_to_have"":[""Expertise in Embedded Machine Learning"",""Knowledge of mainstream Deep Learning architectures""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of Deep Learning and its applications in computer vision?"",""example_answer"":""Deep Learning is a subfield of machine learning that involves the use of artificial neural networks to analyze and interpret data. In computer vision, Deep Learning can be used for tasks such as image classification, object detection, and image segmentation.""},{""question"":""How do you approach designing AI systems, and what considerations do you take into account?"",""example_answer"":""When designing AI systems, I consider factors such as the problem domain, data availability, and model interpretability. I also ensure that the system is scalable, efficient, and meets the required performance metrics.""}],""red_flags"":[""Lack of experience with Deep Learning frameworks and tools"",""Inability to communicate complex technical concepts effectively""],""confidence_score"":95.0}"
"Senior Data Scientist (AI, Revenue management)","What is Pricepoint?
Pricepoint is a rapidly growing hotel revenue management startup that pioneers advanced data science and machine learning to empower hotels in optimizing pricing strategies for maximum revenue potential.

Who Are We?
We are a friendly team eager to build the most sophisticated pricing technology powered by AI. Our goal has never been to pretend that we’re a corporation. However, while we don’t like vertical structures or closed offices, we do hope that each team member will deliver to the best of their abilities not only on their projects but on helping us maintain an open and friendly work environment. “Trust” is the foundation of what we want to build with our clients and our colleagues. If there is trust then there is truth, responsibility, and respect.

What Will You Do?
We are seeking a highly skilled and experienced Senior Data Scientist to join our team. In this role, you will develop and improve our AI-based revenue management and dynamic pricing systems, optimizing pricing strategies and managing the lifecycle of perishable products using cutting-edge machine learning and optimization techniques. As a vital member of the Data Science team, you will contribute by planning, designing, and developing the analytical decision-making core of our hotel Revenue Management system as well as building new AI-powered modules. Your primary role involves enhancing, designing, developing, testing, and operating Pricepoint's intelligent pricing systems and algorithms, utilizing cutting-edge Machine Learning and Operations Research techniques. Python, SQL, data analysis, and statistics will be your primary tools on this journey. This position reports to the Chief Data Scientist.

How You Will Contribute?
As a member of our AI and Data Science team, you will:
Develop and enhance forecasting and demand modeling techniques
Design and develop price optimization algorithmic methodologies
Perform data analytics and business intelligence tasks to support decision-making
Automate processes to improve efficiency and accuracy
Analyze and present results to stakeholders
Collaborate with teams in Sales, IT, and Customer Support to explore ideas and develop solutions
Maintain and document the codebase

Qualifications:
Master’s or Ph.D. degree in Data Science, Computer Science, Operations Research, Statistics, or a related field.
5-7 years of relevant professional experience (8-10+ years preferred).
Eager to research and learn new methodologies.
Proven experience in developing forecasting models, particularly in the transportation or hospitality industries.
Proven experience in developing and deploying NLP models and Large Language Models.
Strong background in Reinforcement Learning, with a track record of successful implementations.
Proficiency in Python programming and experience with relevant libraries and frameworks.
Previous experience or strong knowledge of revenue management practices in the hospitality industry is a significant advantage.
Hands-on experience with AI and Machine Learning models used in forecasting and optimization.
Experience in dynamic pricing algorithms and real-time price adjustments.
Background in managing perishable inventory to minimize waste and maximize profitability.
Practical experience in software development and deployment, including CI/CD practices.
Proficiency in business intelligence and data analytics tools.
Excellent communication skills and the ability to work collaboratively in a dynamic startup environment.

Join Our Team:
If you're a passionate and experienced Senior Data Scientist eager to revolutionize hotel revenue management, apply now via LinkedIn or send your CV to morad@pricepoint.co to join Pricepoint and contribute to our innovative solutions.

Job Type: Full-time

............................
Qu'est-ce que Pricepoint?
Pricepoint est une startup en pleine croissance spécialisée dans la gestion des revenus hôteliers. Nous utilisons des techniques avancées de science des données et d'apprentissage automatique pour aider les hôtels à optimiser leurs stratégies tarifaires et maximiser leur potentiel de revenus.

Qui sommes-nous?
Nous sommes une équipe conviviale dédiée à la création de la technologie de tarification la plus sophistiquée alimentée par l'IA. Nous privilégions une structure ouverte et la confiance mutuelle avec nos clients et collègues, valorisant la vérité, la responsabilité et le respect.

Ce que vous ferez
Nous recherchons un(e) Senior Data Scientist expérimenté(e) pour développer et améliorer nos systèmes de gestion des revenus et de tarification dynamique basés sur l'IA. Vous serez responsable de la planification, de la conception et du développement des systèmes de prise de décision analytique, ainsi que de nouveaux modules alimentés par l'IA. Vous utiliserez des techniques de Machine Learning et de recherche opérationnelle de pointe, avec des outils comme Python, SQL, l'analyse de données et les statistiques. Ce poste relève du Chief Data Scientist.

Comment vous contribuerez
En tant que membre de notre équipe IA et Data Science, vous serez impliqué(e) dans :

Le développement et l'amélioration des techniques de prévision et de modélisation de la demande
La conception et le développement de méthodologies algorithmiques d'optimisation des prix
L'analyse de données et les tâches de business intelligence pour soutenir la prise de décision
L'automatisation des processus pour améliorer l'efficacité et la précision
L'analyse et la présentation des résultats aux parties prenantes
La collaboration avec les équipes des ventes, de l'informatique et du support client pour explorer des idées et développer des solutions
La maintenance et la documentation du code

Qualifications
Master ou Ph.D. en science des données, informatique, recherche opérationnelle, statistiques ou un domaine connexe
5-7 ans d'expérience professionnelle pertinente (8-10+ ans préféré)
Expérience avérée dans le développement de modèles de prévision, en particulier dans les industries du transport ou de l'hôtellerie
Expérience dans le développement et le déploiement de modèles NLP et de grands modèles de langage
Solide expérience en apprentissage par renforcement, avec des implémentations réussies
Maîtrise de la programmation en Python et des bibliothèques/frameworks pertinents (e.g., TensorFlow, PyTorch, scikit-learn, pandas, NumPy)
Connaissance des pratiques de gestion des revenus dans l'industrie hôtelière
Expérience pratique avec des modèles d'IA et de Machine Learning utilisés dans la prévision et l'optimisation
Expérience des algorithmes de tarification dynamique et des ajustements de prix en temps réel
Expérience en gestion d'inventaire périssable pour minimiser les pertes et maximiser la rentabilité
Expérience en développement et déploiement de logiciels, y compris les pratiques CI/CD
Compétences en communication et capacité à travailler en collaboration dans un environnement de startup dynamique

Rejoignez notre équipe
Si vous êtes un(e) Senior Data Scientist passionné(e) et expérimenté(e) désireux(se) de révolutionner la gestion des revenus hôteliers, postulez via LinkedIn ou envoyez votre CV à morad@pricepoint.co pour rejoindre Pricepoint et contribuer à nos solutions innovantes.

Type de poste: Temps plein","{""role_summary"":""Develop and improve AI-based revenue management and dynamic pricing systems, optimizing pricing strategies and managing the lifecycle of perishable products using cutting-edge machine learning and optimization techniques."",""key_terms"":[{""term"":""Machine Learning"",""explanation"":""A type of artificial intelligence that enables systems to learn from data and improve their performance over time.""},{""term"":""Operations Research"",""explanation"":""A discipline that deals with the application of advanced analytical methods to optimize decision-making in complex systems.""},{""term"":""Reinforcement Learning"",""explanation"":""A type of machine learning that involves training agents to make decisions based on rewards or penalties in complex, uncertain environments.""},{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of artificial intelligence that deals with the interaction between computers and human language.""},{""term"":""Large Language Models"",""explanation"":""AI models that are trained on large amounts of text data to generate language outputs that are coherent and natural-sounding.""}],""skill_priorities"":{""must_have"":[""Python programming"",""Machine Learning"",""Operations Research"",""Data analysis"",""Statistics"",""Reinforcement Learning"",""NLP"",""Large Language Models""],""nice_to_have"":[""Experience in hospitality industry"",""Knowledge of revenue management practices"",""Experience with dynamic pricing algorithms"",""Background in managing perishable inventory""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach developing a forecasting model for hotel revenue management?"",""example_answer"":""I would start by collecting and analyzing historical data on hotel bookings and revenue. Then, I would use machine learning techniques such as regression analysis and time series forecasting to develop a model that can accurately predict future revenue. Finally, I would validate the model using techniques such as cross-validation and walk-forward optimization.""},{""question"":""How do you stay current with new developments in machine learning and AI?"",""example_answer"":""I regularly read industry publications and research papers, attend conferences and meetups, and participate in online forums and discussion groups to stay up-to-date with the latest developments in machine learning and AI.""}],""red_flags"":[""Lack of experience with machine learning and AI"",""Inability to communicate complex technical concepts to non-technical stakeholders"",""Limited experience with Python programming and relevant libraries and frameworks""],""confidence_score"":90.0}"
AIML Research Engineer,"About InterDigital

InterDigital is a global research and development company focused primarily on wireless, video, artificial intelligence (“AI”), and related technologies. We design and develop foundational technologies that enable connected, immersive experiences in a broad range of communications and entertainment products and services. We license our innovations worldwide to companies providing such products and services, including makers of wireless communications devices, consumer electronics, IoT devices, cars and other motor vehicles, and providers of cloud-based services such as video streaming. As a leader in wireless technology, our engineers have designed and developed a wide range of innovations that are used in wireless products and networks, from the earliest digital cellular systems to 5G and today’s most advanced Wi-Fi technologies. We are also a leader in video processing and video encoding/decoding technology, with a significant AI research effort that intersects with both wireless and video technologies. Founded in 1972, InterDigital is listed on Nasdaq.

InterDigital is a registered trademark of InterDigital, Inc.

For more information, visit: www.interdigital.com.

Interdigital is looking to add to the Wireless Standards team an AIML Research Engineer for Wireless Systems, 3GPP Standards

Job Description

The candidate will join the Wireless Standards team and be part of our AIML for 3GPP RAN project. The candidate will have a solid theoretical background in artificial intelligence, neural networks and machine learning. The candidate will preferably have some practical experience with AI/ML model design and training as well as in applying AI/ML techniques in specific domain expertise e.g., imaging, video, large language models and/or wireless.

The candidate will conduct research with focus on fundamental aspects of deploying AI/ML techniques in wireless systems, develop innovative solutions addressing the challenges of advanced deployments of AI/ML in future wireless systems with focus on the design of solutions applied to physical radio layer techniques (PHY Layer 1), medium access control (MAC Layer 2) and/or resource control functions (RRC Layer 3) as well as novel applications for specific use cases such as joint communication and sensing, mobility optimizations or the likes.

The candidate will contribute to the 3GPP RAN AI/ML team:

By carrying out research on fundamental and/or applied AI/ML techniques targeting the evolution and/or design of the physical radio layer for 5G-Advanced radio technologies, for 6G radio access and beyond ;
By conducting evaluation, analysis, and development of innovative AI-driven solutions applicable in L1/PHY, L2/MAC and/or L3/RRM such as feedback compression, channel state prediction, beam management, mobility and RRM management, positioning and/or sensing ;
By supporting 3GPP standardization activities through the preparation of AI/ML models, simulations, and contributions in Radio Access Network (RAN) Working Groups (WG).


Qualifications/Requirements

B.Eng., M.S., or Ph.D. in Computer Science, Statistics, Electrical Engineering, Applied Math or other relevant discipline (or similar / equivalent)
0-5 years of relevant experience in the field of machine learning with theoretical understanding of various training methods + neutral networks
In-depth knowledge in one or more of the following areas: machine learning, deep learning, data mining, optimization
Hands on experience with ML frameworks such as Pytorch, Tensorflow
Strong analytical, technical, innovative and leadership skills
Ability to thrive in a dynamic, innovative, collaborative and team-oriented work environment
Dedicated, result oriented professional with an attitude for getting the work done
Willing to take challenges in a fast paced and high-pressure environment
Experience with wireless communications and/or signal processing may be considered an advantage
Experience with GitHub/GitLab, Matlab, NS-3, C/C++ and/or Python may be considered an advantage


Location: Montreal, Canada

InterDigital is an equal employment opportunity employer. InterDigital will not engage in or tolerate unlawful discrimination with regard to any employment decision, policy or practice based on a person’s sex, gender, pregnancy (including childbirth, breastfeeding and related medical conditions), age, race, color, religion, creed, national origin, ancestry, citizenship, military status, veteran status, mental or physical disability, medical condition, genetic information, sexual orientation, gender identity or expression, or any other factor protected by applicable federal, state or local law. This policy applies to all terms and conditions of employment, including, but not limited to, recruiting, hiring, compensation, benefits, training, assignments, evaluations, coaching, promotion, discipline, discharge and layoff.

At InterDigital our DEI strategy embraces and revolves around TEAM. Talent – is the heart of our innovation, Empowerment – we inspire our employees with the knowledge and tools needed to succeed, Amplify – we celebrate the unique identities and cultures among us, Membership – we are connected as a diverse, global community. We strive to be a TEAM that upholds each other’s values and continues to strengthen our inclusive culture.



Interested in helping shape the technologies that make life boundless? InterDigital employees are part of something bigger than themselves, shared by our commitment to innovate. Join our TEAM. Show up as your authentic self, as we work to create, connect, live and inspire a better world through new technologies. We are #oneIDteam.","{""role_summary"":""Conduct research and develop innovative solutions for deploying AI/ML techniques in wireless systems, focusing on physical radio layer techniques, medium access control, and resource control functions."",""key_terms"":[{""term"":""AIML"",""explanation"":""Artificial Intelligence and Machine Learning, referring to the application of AI and ML techniques in wireless systems.""},{""term"":""3GPP RAN"",""explanation"":""3rd Generation Partnership Project Radio Access Network, a standardization organization for wireless communication systems.""},{""term"":""PHY Layer 1"",""explanation"":""Physical Layer 1, a layer in the OSI model responsible for transmitting raw bits over a physical link.""},{""term"":""MAC Layer 2"",""explanation"":""Medium Access Control Layer 2, a layer in the OSI model responsible for controlling data transmission between devices.""},{""term"":""RRC Layer 3"",""explanation"":""Radio Resource Control Layer 3, a layer in the OSI model responsible for managing radio resources in wireless communication systems.""}],""skill_priorities"":{""must_have"":[""Solid theoretical background in artificial intelligence, neural networks, and machine learning"",""Practical experience with AI/ML model design and training"",""Hands-on experience with ML frameworks such as Pytorch, Tensorflow"",""Strong analytical, technical, innovative, and leadership skills""],""nice_to_have"":[""Experience with wireless communications and/or signal processing"",""Experience with GitHub/GitLab, Matlab, NS-3, C/C++ and/or Python""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of feedback compression in AI-driven wireless systems?"",""example_answer"":""Feedback compression is a technique used to reduce the amount of feedback data sent from the receiver to the transmitter in wireless communication systems. In AI-driven systems, this can be achieved through the use of machine learning algorithms that learn to compress the feedback data while maintaining the required level of accuracy.""},{""question"":""How would you approach the design of a novel AI-driven solution for mobility optimization in 5G-Advanced radio technologies?"",""example_answer"":""I would start by conducting a thorough analysis of the current mobility optimization techniques and identifying areas where AI can be applied to improve performance. Then, I would design and train an AI model using relevant data and evaluate its performance using simulations and real-world testing.""}],""red_flags"":[""Lack of experience with AI/ML model design and training"",""Inability to work in a fast-paced and high-pressure environment""],""confidence_score"":90.0}"
Data Scientist - WECJP00028799,"Are you a Data Scientist looking for a new opportunity?

Are you looking for a new contract opportunity?

We are pleased to offer you a new contract opportunity for you to consider: Data Scientist

Start: ASAP
Estimated length: 6 months
Location: Mississauga
Hybrid role- 2-3 days in office, Tuesdays and Thursdays.

Advantages

You will have an opportunity to work with a leading employer in the local market.

Responsibilities

Collect, clean, and transform data from diverse sources to be used for training or evaluation datasets.
Develop, validate, and implement predictive models and machine learning algorithms.
Familiarize and utilize end-to-end ML product to develop data science models.
Perform exploratory data analysis to understand the data and develop hypotheses.
Propose solutions and strategies to business challenges.
Present findings to both technical and non-technical stakeholders.

Qualifications

Bachelor’s or Master’s degree in Computer Science, Data Science, Statistics, Mathematics, or a related field.
1-2 years of experience in data science or a related field.
Experience with Python and its primary data science libraries, alongside essential SQL knowledge for database management.
Proficiency in building and fine-tuning machine learning models.
Deep understanding of model confidence measurements and where to utilize one model over the other.
Robust understanding of various machine learning algorithms
Strong skills in data preprocessing, data exploration, and feature engineering.

Preferred Skills

Experience with sequence classification, named entity recognition, image classification, and object detection models
Proficiency with cloud services, specifically Vertex AI and BigQuery (GCP)
Strong problem-solving skills with an emphasis on product development.
Excellent written and verbal communication skills.
Experience with regular expressions is an asset.

Summary

Do you have this experience? If you answer YES, then please apply IMMEDIATELY to so we can then discuss your experience and interest in this opportunity!

Randstad Technologies Group

Canada's largest provider of IT Staffing Solutions, offering hundreds of permanent and contract opportunities across all roles, levels and platforms. Our Web-based tools help you see and apply for jobs matched automatically to your skills and preferences. When you're ready to interview we meet with you in person to help you build the technology career path you've always wanted. Visit www.randstad.ca to get started!

Randstad Canada is committed to fostering a workforce reflective of all peoples of Canada. As a result, we are committed to developing and implementing strategies to increase the equity, diversity and inclusion within the workplace by examining our internal policies, practices, and systems throughout the entire lifecycle of our workforce, including its recruitment, retention and advancement for all employees. In addition to our deep commitment to respecting human rights, we are dedicated to positive actions to affect change to ensure everyone has full participation in the workforce free from any barriers, systemic or otherwise, especially equity-seeking groups who are usually underrepresented in Canada's workforce, including those who identify as women or non-binary/gender non-conforming; Indigenous or Aboriginal Peoples; persons with disabilities (visible or invisible) and; members of visible minorities, racialized groups and the LGBTQ2+ community.

Randstad Canada is committed to creating and maintaining an inclusive and accessible workplace for all its candidates and employees by supporting their accessibility and accommodation needs throughout the employment lifecycle. We ask that all job applications please identify any accommodation requirements by sending an email to accessibility@randstad.ca to ensure their ability to fully participate in the interview process.","{""role_summary"":""A Data Scientist responsible for collecting, cleaning, and transforming data to develop predictive models and machine learning algorithms, and presenting findings to stakeholders."",""key_terms"":[{""term"":""Predictive models"",""explanation"":""Statistical models that forecast outcomes based on historical data and patterns.""},{""term"":""Machine learning algorithms"",""explanation"":""Programs that enable computers to learn from data and improve their performance on a task without being explicitly programmed.""},{""term"":""End-to-end ML product"",""explanation"":""A comprehensive machine learning platform that supports the entire lifecycle of data science models, from development to deployment.""},{""term"":""Vertex AI and BigQuery (GCP)"",""explanation"":""Cloud-based services offered by Google Cloud Platform for machine learning and data analytics.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Machine learning models"",""Data preprocessing"",""Data exploration"",""Feature engineering""],""nice_to_have"":[""Sequence classification"",""Named entity recognition"",""Image classification"",""Object detection"",""Cloud services (Vertex AI and BigQuery)"",""Regular expressions""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of model confidence measurements and how you would decide which model to use in a given scenario?"",""example_answer"":""Model confidence measurements refer to the probability that a model's predictions are accurate. I would consider factors such as the model's performance metrics, data quality, and business requirements to decide which model to use.""},{""question"":""How do you approach data preprocessing and feature engineering in your data science workflow?"",""example_answer"":""I follow a structured approach to data preprocessing, including data cleaning, normalization, and transformation. For feature engineering, I use techniques such as feature selection, extraction, and creation to develop relevant features that improve model performance.""}],""red_flags"":[""Lack of experience with Python and its primary data science libraries"",""Inability to explain machine learning algorithms and their applications""],""confidence_score"":90.0}"
Research Scientist,"Grow your career. Be the difference. Leading the commercialization of ground-breaking technology that captures CO₂ directly from air is challenging and exhilarating. As a member of the CE team, you’ll be surrounded by smart, adventurous, curious people committed to progressing our Direct Air Capture (DAC) and AIR TO FUELS TM technologies. We’re a diverse team of innovators hailing from around the world with a shared vision, purpose, and commitment to deliver large scale climate change solutions. Our headquarters is in Squamish, B.C., and our presence is expanding in many other markets around the world as we commercialize our technologies

Our culture combines our heritage as a small company with our ambitious goals. We have a passion for what we do and believe our work will have a true and lasting impact on the world. Many of our employees are drawn to CE because of the direct connection between the game-changing work we do and their own personal values.

At our core, Carbon Engineering values integrity, growth, excellence in execution, and fun. This is an environment where people matter, and contributions are noticed. Our employees work hard and are given the opportunity to learn and grow from mistakes. Diversity is embraced, and we value an inclusive work environment where every employee has an equal opportunity to be heard. We work in a dynamic environment and thrive on tackling rewarding and complex problems as a team.

The Technology Development Group

The Technology Development Group is Carbon Engineering’s core research and development team. We are a multidisciplinary team of research scientists and engineers responsible for driving next-generation DAC technology improvements through evolutionary and revolutionary innovation. We value a collaborative and inclusive research environment which fosters curious and explorer-driven mindsets.

Position Scope

As a Research Scientist in the Technology Development group, you will join an elite, multidisciplinary team of scientists and engineers who are responsible for the development of Carbon Engineering’s next-generation technologies. You will work within collaborative research teams on projects spanning fundamental laboratory studies to process validation at pilot scale. Your objective will be to conceptualize, develop, and demonstrate technology solutions that drive cost reductions, enabling new market opportunities and accelerating widespread adoption of DAC technology.

We would love to hear from you if:

You thrive in a collaborative, team-centric work environment
You are excited by the prospect of advancing a technology from the conceptualization stage through to demonstration
You have a strong chemistry background in a research laboratory environment
You are a self-motivated, curious, and creative problem solver
You value a rigorous, data-driven approach to decision-making
You are passionate about leading the future of clean technologies for carbon-circular economies to address the social and environmental impacts of climate change

Responsibilities

Technical:

Perform experiments in the laboratory, bench, or pilot scales
Perform standard and unique analytical chemistry methods
Process and analyze experimental data using appropriate statistical methods
Stay up to date on emerging research and new technology development
Connect existing knowledge, new learnings, and original ideas to create new concepts
Continuously contribute to the company’s intellectual property portfolio
Rapidly assess the high-level technical and economic feasibility of new concepts to understand opportunities and roadblocks
Define the key questions that need to be answered to gain a strong fundamental understanding of new concepts, and plan, design, and execute the experiments required to answer them
Interpret the results and communicate the learnings in both written and verbal formats to a diverse audience to support rigorous, data-driven decision making
Use the learnings to define the logical next steps for the project
Perform necessary design calculations when selecting new equipment or instrumentation, and if applicable, identify third party consultants for technical review or independent design consultation

Safety:

Demonstrate and champion a positive culture of environmental and personal health and safety
Follow all company safety requirements and procedures
Implement and maintain safe work procedures for unique Technology Development equipment and experiments
Identify, report, and resolve unsafe conditions, processes, or actions within the workplace
Ensure that all safety related incidents, accidents and near misses are reported and investigated in line with company policy
Complete training curriculum and maintain required certifications
Contribute to laboratory upkeep and safety reviews

Qualifications & Experience

Education:

B.Sc. (minimum) or M.Sc./PhD (preferred) in Chemistry, Materials Science, Physics or related disciplines

Experience:

Minimum of 2+ years research experience in academic or industrial laboratory environments
Experience designing and constructing test equipment at the laboratory, bench, or pilot scales is an asset
Experience in CO2, other gas scrubbing, or mass transfer technologies is an asset
Experience in industrial process chemistry is an asset

Key Competencies:

Key competencies of interest include, but are not limited to:

Analytical methods including spectroscopic, crystallographic and gravimetric techniques
Materials characterization
Inorganic and organic synthetic techniques
Electrochemistry and membrane science
Statistical methods and regression analysis
Reaction kinetics elucidation and modeling

Offers And Benefits

Carbon Engineering offers a competitive compensation package including extended health benefits.

Base Salary for an Intermediate to Advanced level role is $81,000 to $140,000 with additional bonus pay.

This position is eligible for our standard 40 hours/week work schedule, or our 9/80 work schedule which provides every second Friday off.

Our location in the outdoor recreation hub of Squamish gives you access to world class skiing, mountain biking, climbing, hiking, and other outdoor activities within minutes of the office, while in close proximity to Vancouver, one of the most beautiful and culturally diverse cities in Canada.

Joining Carbon Engineering provides you more than a career – it’s a calling for those who are ready to make a difference in climate action. We provide hope.

Carbon Engineering is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants are encouraged to apply and will receive equal consideration for employment regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, disability, or age.

Powered by JazzHR

0xLqBmlkrc","{""role_summary"":""Conduct research and development to drive next-generation Direct Air Capture (DAC) technology improvements, focusing on cost reductions and new market opportunities."",""key_terms"":[{""term"":""Direct Air Capture (DAC)"",""explanation"":""A technology that captures CO2 directly from the air.""},{""term"":""AIR TO FUELS TM"",""explanation"":""A technology that converts air into fuels.""},{""term"":""CO2 scrubbing"",""explanation"":""A process of removing CO2 from the air or other gases.""},{""term"":""Mass transfer technologies"",""explanation"":""Technologies that facilitate the transfer of mass or substances between phases or systems.""}],""skill_priorities"":{""must_have"":[""Strong chemistry background"",""Experience in research laboratory environment"",""Analytical methods including spectroscopic, crystallographic and gravimetric techniques"",""Statistical methods and regression analysis""],""nice_to_have"":[""Experience in CO2, other gas scrubbing, or mass transfer technologies"",""Experience in industrial process chemistry"",""Designing and constructing test equipment at the laboratory, bench, or pilot scales""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to design and execute an experiment to test a new concept in a laboratory setting?"",""example_answer"":""In my previous role, I designed an experiment to test the feasibility of a new catalyst in a CO2 scrubbing process. I worked with a team to set up the equipment, collected and analyzed the data, and presented the results to our stakeholders. The experiment was successful, and we were able to implement the new catalyst in our process, resulting in a 20% reduction in costs.""},{""question"":""How do you stay current with emerging research and new technology developments in your field?"",""example_answer"":""I regularly read industry publications and attend conferences to stay up-to-date on the latest developments in chemistry and materials science. I also network with colleagues and peers to learn about new breakthroughs and advancements.""}],""red_flags"":[""Lack of experience in a research laboratory environment"",""Inability to work collaboratively in a team-centric work environment""],""confidence_score"":90.0}"
Junior Full Stack Developer React/Python,"This is a remote position.

Junior Full Stack Developer React/Python - Remote Job, 1+ Year Experience

Annual Income: $62K - $72K

A valid work permit is necessary in Canada

About us: Patterned Learning is a platform that aims to help developers code faster and more efficiently. It offers features such as collaborative coding, real-time multiplayer editing, and the ability to build, test, and deploy directly from the browser. The platform also provides tightly integrated code generation, editing, and output capabilities.

Responsibilities:

Architect, design, and implement solutions to complex engineering problems
Provide coding expertise in Python (FastAPI and Django), React JS, TypeScript, SQL, NoSQL, and AWS to develop frontend and backend applications.
Collaborate with other developers to deliver working software solutions
Assist project management with planning, product roadmap planning, and release planning
Assist with code reviews and technical reviews

Qualifications:

1 year of professional experience with React JS and Python
Bachelor's degree in computer science, engineering, or related
Good communication skills, both oral and written

Nice to Have experience:

Mobile app development in React Native
Thirst For Tech Learning

Benefits

401(k) matching
Flexible spending account
Flextime
Health insurance
Health savings account
Paid time off
Relocation assistance
Tuition reimbursement

Why Patterned Learning LLC?

Patterned Learning can provide intelligent suggestions, automate repetitive tasks, and assist developers in writing code more effectively. This can help reduce coding errors, improve productivity, and accelerate the development process.

Pattern recognition is particularly relevant in the context of coding. Neural networks, especially deep learning models, are commonly employed for pattern detection and classification tasks. These models simulate human decision-making and can identify patterns in data, making them well-suited for tasks like code analysis and generation.","{""role_summary"":""Design and implement solutions to complex engineering problems as a Junior Full Stack Developer, collaborating with other developers to deliver software solutions."",""key_terms"":[{""term"":""FastAPI"",""explanation"":""A modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.""},{""term"":""Django"",""explanation"":""A high-level Python web framework that encourages rapid development and clean, pragmatic design.""},{""term"":""TypeScript"",""explanation"":""A superset of JavaScript that adds optional static typing and other features to improve the development experience.""},{""term"":""SQL"",""explanation"":""A standard language for managing relational databases, used for storing, manipulating, and retrieving data.""},{""term"":""NoSQL"",""explanation"":""A type of database that does not use the traditional table-based relational model, instead using a variety of other models such as key-value, document, or graph.""},{""term"":""AWS"",""explanation"":""Amazon Web Services, a cloud computing platform that provides a wide range of services including computing power, storage, databases, analytics, machine learning, and more.""},{""term"":""React Native"",""explanation"":""A framework for building native mobile apps using React and JavaScript.""},{""term"":""Pattern recognition"",""explanation"":""The process of identifying patterns in data, often using machine learning and deep learning models, to make predictions, classify data, or generate code.""}],""skill_priorities"":{""must_have"":[""React JS"",""Python"",""1 year of professional experience""],""nice_to_have"":[""Mobile app development in React Native"",""Thirst For Tech Learning""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach architecting a solution to a complex engineering problem using React JS and Python?"",""example_answer"":""I would start by breaking down the problem into smaller components, identifying the key requirements and constraints. Then, I would design a high-level architecture using React JS for the frontend and Python for the backend, considering factors such as scalability, performance, and maintainability. Finally, I would implement the solution, ensuring it meets the requirements and is well-tested.""},{""question"":""Can you explain the benefits of using FastAPI and Django in a Python-based project?"",""example_answer"":""FastAPI provides a modern, fast, and scalable way to build APIs, while Django provides a high-level framework for building robust and maintainable web applications. Together, they offer a powerful combination for building efficient and effective backend applications.""}],""red_flags"":[""Lack of experience with React JS and Python"",""Poor communication skills""],""confidence_score"":90.0}"
Data Scientist (L5) - Content,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

TUDUM is Netflix’s home for fans, where our daily breaking news, original videos, exclusive interviews, and behind-the-scenes storytelling reach millions of fans every month. We aim to bring members joy by deepening their connections to their favorite movies and series and helping them discover their next obsession.

Data is a crucial component in shaping TUDUM’s strategy. In Content & Conversation Applied Science and Analytics (CASAS) DSE, we focus on delivering data products and insights that support our business partners in their complex and nuanced decision-making processes. We are a highly collaborative team that partners across Netflix to drive impact.

We are seeking a talented Senior Data Scientist to provide key insights and thought partnership to our TUDUM decision makers. You will generate insights by scoping and executing deep dive analysis and experimentation with the TUDUM product, engineering, and editorial teams. In success, you will collaborate on existing priorities but also will propose and execute on new opportunities. This role features ample opportunity for project ownership, leadership and direct influence on impactful business decisions.

In This Role, You Will

Be a strategic thought partner with business stakeholders to define high impact problems and innovative ways to solve them with data.
Develop statistical models explaining TUDUM engagement, impact, and other key behavioral patterns and drive causal inferences between TUDUM and the engagement with other netflix channels
Translate insights into actionable recommendations for business improvement, and communicate these findings clearly to a broad audience
Identify and proactively socialize TUDUM insights, especially those that may be impactful to other business areas

What You’ll Bring

Exceptional interpersonal and communication skills to influence stakeholders using clear insights and recommendations
Adept at cultivating strong partnerships
Exceptional thought partnership and engagement abilities with a diverse set of stakeholders and passionate about communicating difficult concepts to non-technical audiences
Highly skilled in leading through influence
Exceptional facilitation, planning and organization skills
Strong statistical knowledge: understanding of predictive modeling; ability to tease out incrementality vs. correlations, confounder identification and amelioration, etc.
Strong understanding of experimentation including power calculations and interpretation of results
Strong SQL skills and experience with distributed analytic processing technologies (S3, Presto, Hive & Spark)
Strong skills in Python or R
Self-starter who thrives under a high level of autonomy.
Enthusiastic about Netflix culture

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.","{""role_summary"":""Provide key insights and thought partnership to TUDUM decision makers at Netflix, generating insights through data analysis and experimentation to drive business impact."",""key_terms"":[{""term"":""Content & Conversation Applied Science and Analytics (CASAS) DSE"",""explanation"":""A team at Netflix that focuses on delivering data products and insights to support business partners in their decision-making processes.""},{""term"":""TUDUM"",""explanation"":""Netflix's home for fans, featuring daily breaking news, original videos, exclusive interviews, and behind-the-scenes storytelling.""},{""term"":""Predictive modeling"",""explanation"":""A statistical technique used to forecast future outcomes based on historical data and patterns.""},{""term"":""Distributed analytic processing technologies"",""explanation"":""Tools and systems that enable fast and efficient processing of large datasets, such as S3, Presto, Hive, and Spark.""}],""skill_priorities"":{""must_have"":[""Exceptional interpersonal and communication skills"",""Strong statistical knowledge"",""Strong understanding of experimentation"",""Strong SQL skills"",""Experience with distributed analytic processing technologies"",""Strong skills in Python or R""],""nice_to_have"":[""Exceptional facilitation, planning, and organization skills"",""Enthusiasm for Netflix culture""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing TUDUM engagement and identifying key behavioral patterns?"",""example_answer"":""I would start by collecting relevant data on user interactions with TUDUM, such as clickstream data and user feedback. Then, I would apply statistical models to identify correlations and causal relationships between TUDUM engagement and other Netflix channels. Finally, I would communicate my findings and recommendations to stakeholders in a clear and actionable way.""},{""question"":""How do you stay up-to-date with the latest developments in data science and analytics?"",""example_answer"":""I regularly read industry blogs and research papers, attend conferences and meetups, and participate in online forums to stay current with the latest techniques and tools in data science and analytics.""}],""red_flags"":[""Lack of experience with distributed analytic processing technologies"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
Data Scientist (L4) - Growth and Membership,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

Data is at the heart of our payment strategy and innovation at Netflix. In the Payments Data Science & Engineering team, we provide guidance to the business not only through analysis, metrics research, experimentation, causal inference, and modeling, but also through exceptional judgment, partnership, and business acumen. These deeply collaborative, innovative efforts unlock millions of dollars of revenue impact each year.

As a Data Scientist, you will join a team of other stunning Data Scientists, Analytics Engineers, Machine Learning Scientists, and Research Engineers. You will use data to identify opportunities and help shape product decisions. You will collaborate with the payments team and ML scientists and engineers to identify opportunities in our existing production ML systems, suggest improvements, and evaluate their impact.

In This Role, You Will

Effectively identify and leverage experimentation and other analysis techniques, as appropriate, to solve business problems.
Be a strategic thought partner with payments, product, engineering, analysts, data engineering etc.
Influence decision-making through data-driven insights and recommendations
Proactively identify and perform data exploration to inform future product directions
Prioritize competing demands toward the most impactful items
Develop and validate the appropriate metrics to measure success in a given product area
Contribute to the excellence of experimentation methodology within the Netflix data science community
Live Netflix values while bringing a new perspective to continue improving our culture.

To Be Successful In This Role, You Have

Strong statistical skills such as regression and A/B testing experimentation
Strong data manipulation and quantitative programming skills in SQL and Python or R
Exceptional communication with technical and non-technical audiences
Willingness to learn and rapidly absorb business context in the complex payments ecosystem
Comfort with ambiguity; ability to thrive with minimal oversight and process
An advanced degree (Masters or PhD) in Statistics, Mathematics, Computer Science, Economics, or a related quantitative field
Experience with algorithms as a product (e.g. recommendation systems, payment fraud detection) a bonus
Causal inference and offline model performance evaluation methodologies a bonus

A few more things to know: Our culture is unique and we live by our values, so it's worth learning more about Netflix at jobs.netflix.com/culture. We regularly share examples of our work on our tech blog. You will need to be comfortable working in the most agile of environments. Requirements will be vague. Iterations will be rapid. You will need to be nimble and take smart risks. Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top-of-market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000. Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more details about our Benefits here. Netflix is a unique culture and environment. Learn more here.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.","{""role_summary"":""As a Data Scientist at Netflix, you will use data to identify opportunities and inform product decisions, collaborating with cross-functional teams to drive business impact."",""key_terms"":[{""term"":""Causal inference"",""explanation"":""A statistical technique to establish cause-and-effect relationships between variables, used to evaluate the impact of business decisions.""},{""term"":""A/B testing experimentation"",""explanation"":""A method to compare two or more versions of a product or feature to determine which one performs better.""},{""term"":""Machine Learning Scientists"",""explanation"":""Experts who develop and deploy machine learning models to solve complex business problems.""},{""term"":""Offline model performance evaluation methodologies"",""explanation"":""Techniques used to assess the performance of machine learning models in a non-production environment.""}],""skill_priorities"":{""must_have"":[""Strong statistical skills"",""Strong data manipulation and quantitative programming skills in SQL and Python or R"",""Exceptional communication with technical and non-technical audiences"",""Advanced degree (Masters or PhD) in Statistics, Mathematics, Computer Science, Economics, or a related quantitative field""],""nice_to_have"":[""Experience with algorithms as a product (e.g. recommendation systems, payment fraud detection)"",""Causal inference and offline model performance evaluation methodologies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design an A/B testing experiment to measure the impact of a new feature on customer engagement?"",""example_answer"":""I would start by defining the problem statement and identifying the key metrics to measure. Then, I would design the experiment to ensure randomization and adequate sample size. Finally, I would analyze the results using statistical methods and communicate the findings to stakeholders.""},{""question"":""How do you stay up-to-date with new developments in machine learning and data science?"",""example_answer"":""I regularly read industry blogs and research papers, attend conferences, and participate in online forums to stay current with the latest advancements in machine learning and data science.""}],""red_flags"":[""Lack of experience working with large datasets"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
Data Scientist (Energy Systems),"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time. However, there are problems!

The Problem

80% of clean energy projects that developers start never actually get built because most projects are started without deep due diligence on zoning and interconnection due to the cost of collecting that data. This means $17B worth of canceled projects per year.

Our Solution

Paces is software for green infrastructure developers to identify the best places to build and manage their projects. First we collect environmental, permitting, zoning, energy grid data from various different sources; then we analyze the data and use AI to identify the best places for developers to build their next projects.

Our Team

We are building a team where people can proudly say their time at Paces is the most impactful, meaningful work of their career. Our amazing team in Brooklyn, New York includes incredible engineers and growth team members from companies like Facebook, AWS, Replika, DataDog, Yotpo, Rent The Runway & Leap.

Paces is growing rapidly and looking for exceptional people to join who want to have a massive positive climate impact while building a great culture! We are looking for a Data Scientist with deep expertise in energy system modeling to join our Product team, reporting directly to the Head of Product. This role is a unique opportunity to bridge power engineering with cutting-edge software and product development.

🏆 What You’ll Achieve

Model transmission system dynamics with rapid load growth under high penetrations of renewables
Scrape and process generation and transmission upgrade queues, utility planning documents, and other unstructured and semi-structured data sources
Probabilistically model interconnection scenarios and develop technically rigorous study assumptions
Analyze output data from power flow simulations to consider the technical and commercial viability of new generation and large loads and identify the most favorable locations
Develop software solutions and data pipelines that enhance and automate power system analysis at scale
Act as an internal domain expert at Paces, developing proprietary methodologies and shaping product development

📈 Requirements

3+ years experience in data science, research science, machine learning, or a similar technical role
3+ years experience with python and the supporting computational and geospatial science tool suite (e.g. numpy, scipy, geopandas, GDAL, scikit-learn, tensorflow, etc.)
4+ years experience in the electricity and energy domain (e.g. electricity grid modeling and optimization, power system planning and operation, energy markets and regulation, price forecasting, congestion prediction, etc.)
Familiarity with at least one major ISO/RTO or wholesale market (e.g., PJM, MISO, ERCOT, CAISO, WECC, etc.).
Familiarity with at least one third party power flow or production cost modeling software (PSS/E, TARA, PLEXOS, etc.)
Strong quantitative and data wrangling abilities
Ability to think beyond traditional engineering approaches and contribute to product innovation through creative, iterative thinking

✨ About You

You will thrive in our culture if you:

You love deep in person collaboration
You get a thrill out drawing insights from messy data
You have a strong bias towards action and a high learning rate
You are always looking for better ways to automate tedious tasks

🚀 Bonus Points

Previous experience at a high-growth, fast-paced startup
Previous experience at a battery storage, solar, or datacenter developer
Degree in electrical or power engineering
Expertise in energy policy and regulatory analysis

💰 Compensation And Benefits

$130,000 - 150,000 annual compensation
Competitive equity compensation
401(k) match (4%)
Health, dental and vision insurance
Paid company holidays & unlimited PTO (minimum 15 days per year)
Hybrid work in the office in Williamsburg, Brooklyn 2-4x per week","{""role_summary"":""A Data Scientist with expertise in energy system modeling to join the Product team, bridging power engineering with cutting-edge software and product development to have a massive positive climate impact."",""key_terms"":[{""term"":""Energy system modeling"",""explanation"":""The process of simulating and analyzing energy systems to understand their behavior and optimize their performance.""},{""term"":""Power flow simulations"",""explanation"":""Computer-based simulations that model the behavior of electrical power systems to identify potential issues and optimize performance.""},{""term"":""Interconnection scenarios"",""explanation"":""Hypothetical scenarios used to model the integration of new energy sources into the existing power grid.""},{""term"":""ISO/RTO"",""explanation"":""Independent System Operators/Regional Transmission Organizations that manage the high-voltage transmission grid in specific regions.""},{""term"":""Power flow or production cost modeling software"",""explanation"":""Specialized software used to simulate and analyze the behavior of electrical power systems, such as PSS/E, TARA, PLEXOS, etc.""}],""skill_priorities"":{""must_have"":[""3+ years experience in data science, research science, machine learning, or a similar technical role"",""3+ years experience with python and supporting computational and geospatial science tool suite"",""4+ years experience in the electricity and energy domain"",""Familiarity with at least one major ISO/RTO or wholesale market"",""Familiarity with at least one third party power flow or production cost modeling software""],""nice_to_have"":[""Previous experience at a high-growth, fast-paced startup"",""Previous experience at a battery storage, solar, or datacenter developer"",""Degree in electrical or power engineering"",""Expertise in energy policy and regulatory analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would model transmission system dynamics with rapid load growth under high penetrations of renewables?"",""example_answer"":""I would use a combination of historical load data, weather patterns, and renewable energy output forecasts to create a probabilistic model of transmission system dynamics. I would then use this model to identify potential bottlenecks and optimize the system for maximum efficiency.""},{""question"":""How do you stay up-to-date with the latest developments in energy policy and regulatory analysis?"",""example_answer"":""I regularly read industry publications and attend conferences to stay current on the latest developments in energy policy and regulatory analysis. I also network with professionals in the field to stay informed about best practices and new approaches.""}],""red_flags"":[""Lack of experience with energy system modeling and power flow simulations"",""Inability to work collaboratively in a fast-paced startup environment""],""confidence_score"":90.0}"
Stanowisko ds. zarządzania obszarem BI i HD-specjalność inżynierii systemów Hurtowni Danych,"Nazwa jednostki organizacyjnej

ZUS III Oddział w Warszawie

Nazwa komórki organizacyjnej

Departament Statystyki i Prognoz Aktuarialnych

Miejsce pracy

ZUS III Oddział w Warszawie

Adres miejsca pracy

ul. Czerniakowska 16, 00-701 Warszawa

Województwo

mazowieckie

Nazwa stanowiska

Stanowisko ds. zarządzania obszarem BI i HD-specjalność inżynierii systemów Hurtowni Danych

Zadania

Zadania

zapewniać utrzymanie i rozwój architektury biznesowej i technicznej obszaru Hurtowni Danych
odpowiadać za proponowanie, budowanie i wdrażanie rozwiązań z zakresu technologii przetwarzania dużych zbiorów danych (Big Data), m.in. modelowania danych, projektowanie modelów ekstrakcji danych, projektowania i utrzymanie systemów magazynowania danych
odpowiadać za analizowanie wydajności sprzętu i oprogramowania w obszarze Hurtowni Danych
uczestniczyć w planowaniu inicjatyw i projektów mających na celu rozbudowę i optymalizację wykorzystywanych rozwiązań w obszarze Hurtowni Danych
współpracować przy projektowanie procesów ETL (Extract, Transform, Load), ELT (Extract, Load, Transform) w celu pozyskiwania, przetwarzania i ładowania danych z różnych źródeł do systemów klasy Hurtowni Danych
uczestniczyć w pracach projektowych, wdrożeniowych i testowych w obszarze Hurtowni Danych
wspierać użytkowników w ramach wdrożeń systemów i narzędzi w obszarze Hurtowni Danych
uczestniczyć w przygotowaniu planu rozwoju (roadmapy) dla środowiska Business Intelligence i Hurtowni Danych
proponować usprawnienia dla realizowanych procesów i zmiany w dokumentacji
Wymagania

Wymagania Niezbędne

wykształcenie wyższe
doświadczenie zawodowe minimum 1 rok (w pracy związanej z planowaniem, tworzeniem i rozwojem w obszarach Business Intelligence i\lub Hurtowni Danych)
staż pracy ogółem minimum 2 lata

Mile Widziane

wykształcenie wyższe (matematyka, informatyka, statystyka)
doświadczenie zawodowe minimum 2 lata (w pracy związanej z planowaniem, tworzeniem i rozwojem w obszarach Business Intelligence i\lub Hurtowni Danych)

Wymagania Dodatkowe

umiejętność obsługi programów MS Office
Znajomość języka SQL
orientacja na cel
orientacja na jakość
komunikacja
współpraca
elastyczność
nastawienie na rozwój
negocjowanie i wywieranie wpływu
podejmowanie decyzji
umiejętność rozwiązywania problemów
innowacyjność

Wymagane Dokumenty

CV
listu motywacyjnego
skan dokumentów potwierdzających wykształcenie
skan dokumentów potwierdzających wymagane doświadczenie zawodowe
skan świadectw pracy dokumentujących wymagany staż pracy lub zaświadczenie o zatrudnieniu zawierające okresy zatrudnienia, w przypadku pozostania w stosunku pracy

Dokumenty należy przesyłać poprzez formularz aplikacyjny 'Aplikuj', znajdujący się na dole oferty

Dodatkowe Informacje

proces rekrutacji obejmować będzie rozmowę kwalifikacyjną (przeprowadzoną w formie zdalnej przez komunikator internetowy - wywiad on-line) lub stacjonarnie
skontaktujemy się tylko z kandydatami spełniającymi wymagania formalne
oferty niekompletne tj. niezawierające skanu, któregokolwiek wymaganego dokumentu nie będą rozpatrywane
oferty przesłane po terminie nie będą rozpatrywane
miejscem świadczenia pracy będzie Centrala ZUS lub dowolny Oddział ZUS
możliwość pracy w trybie stacjonarnym, zdalnym lub hybrydowym
Termin, do którego należy składać dokumenty

12-02-2025

Oferujemy

Oferujemy

stabilne zatrudnienie na podstawie umowy o pracę
możliwość rozwoju zawodowego
bogaty pakiet świadczeń socjalnych
system premiowy

Zakład Ubezpieczeń Społecznych jest pracodawcą przyjaznym osobom z niepełnosprawnościami. Stwarza pracownikom optymalne środowisko pracy, uwzględniając ich potrzeby. Istnieje możliwość dostosowania stanowiska pracy i jego wyposażenia do indywidualnych potrzeb osób z niepełnosprawnościami

Wyposażenie Stanowiska Pracy

sprzęt komputerowy,
sprzęt biurowy.

Warunki Wykonywania Pracy

spełniają warunki określone wymogami bhp i ppoż.,
polegają na obsłudze komputera powyżej 4 godzin na dobę,
konieczność poruszania się po całym obiekcie,
konieczność wykonywania pracy poza biurem,
konieczność odbywania podróży służbowych,
budynek 3-piętrowy z windą oraz pomieszczeniami sanitarnymi dostosowanymi do potrzeb osób niepełnosprawnych,
stanowisko pracy zlokalizowane w pomieszczeniach biurowych na 3- piętrze,
miejsce pracy dostosowane do osób poruszających się przy pomocy wózka inwalidzkiego,
wejście do budynku jest zorganizowane z poziomu chodnika,
drzwi przy wejściu do budynku otwierają się automatycznie,
w bezpośrednim sąsiedztwie wejścia do budynku znajdują się miejsca parkingowe dla osób z niepełnosprawnościami","{""role_summary"":""Manage and develop the Business Intelligence and Data Warehouse area, ensuring the maintenance and development of business and technical architecture, proposing and implementing Big Data solutions, and analyzing hardware and software performance."",""key_terms"":[{""term"":""Big Data"",""explanation"":""Refers to the large and complex sets of data that require specialized processing and analysis techniques.""},{""term"":""Business Intelligence"",""explanation"":""The process of gathering, analyzing, and providing access to data to help business users make better decisions.""},{""term"":""Data Warehouse"",""explanation"":""A central repository that stores data from various sources in a single location, making it easier to analyze and report.""},{""term"":""ETL (Extract, Transform, Load)"",""explanation"":""A process used to extract data from multiple sources, transform it into a standardized format, and load it into a target system.""},{""term"":""ELT (Extract, Load, Transform)"",""explanation"":""A variation of ETL that loads data into a target system and then transforms it.""}],""skill_priorities"":{""must_have"":[""Experience in planning, creating, and developing Business Intelligence and Data Warehouse solutions"",""Knowledge of SQL"",""MS Office skills""],""nice_to_have"":[""Higher education in mathematics, computer science, or statistics"",""2+ years of experience in Business Intelligence and Data Warehouse"",""Innovative thinking"",""Problem-solving skills""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach designing a data warehouse for a large-scale organization?"",""example_answer"":""I would start by identifying the business requirements and then design a scalable and flexible architecture that can handle large volumes of data. I would also ensure data quality and integrity by implementing data validation and cleansing processes.""},{""question"":""What is your experience with ETL/ELT processes, and how have you optimized them in the past?"",""example_answer"":""I have experience with ETL/ELT processes using tools like Informatica and Talend. I have optimized them by implementing parallel processing, data caching, and optimizing database queries.""}],""red_flags"":[""Lack of experience in Business Intelligence and Data Warehouse"",""Inability to work with large datasets"",""Poor problem-solving skills""],""confidence_score"":90.0}"
"Data Scientist, Investing","The Wealthfront Data Science Team utilizes our rich financial and behavioral data to influence key product and marketing decisions, as well as to safeguard our client’s information and assets. The team draws from backgrounds in Computer Science, Statistics, Operations Research, Economics, and Natural Sciences. We value analytical rigor, clear communication, and proactivity. We believe that good ideas can come from anywhere and encourage Data Scientists to pursue self-directed explorations in search of business value. 
The Data Scientist in this role will be primarily embedded within Wealthfront’s Investing area. The vision of this area is to enable our clients to confidently grow, preserve, and manage their wealth by making the most effective investing strategies more convenient, accessible, and affordable.
Potential project areas for this role include (but are not limited to):
• Analysis of client and prospect behavior such as funnel drop-off, cross-product-adoption, deposit patterns, asset allocation, and product usage
• Opportunity sizing for new products
• Creating dashboards to visualize and track product and area metrics
• Building pipelines to ingest and organize data
• Collaborating on blog posts discussing Wealthfront products and general investing
• Research and development of predictive models to forecast product interest and demand

Responsibilities
Formulate project plans with clear rationale, candidate approaches and milestones.
Employ a high degree of mathematical rigor and best practices for software development.
Collaborate with cross functional stakeholders to identify key initiatives for the Investing area and champion the role of Data Science within these initiatives.
Formulate project plans with clear rationale, candidate approaches and milestones.
Guide execution of project plans with a combination of delegation and hands-on work.
Interpret and contextualize statistical results for business stakeholders and help translate numbers into recommendations.
Enhance overall Data Science team execution through hands-on help, design feedback and peer review.
Identify and formulate steps to automate repetitive manual work (toil).

Requirements
A Bachelor's degree in Computer Science, Statistics, Mathematics, Economics, Operations Research, or Natural Sciences with 4+ years of prior experience in a Data Science role. Exceptions to these requirements may be considered on a case-by-case basis.  
Prior experience in financial services or knowledge of finance basics is helpful but not required.
Strong communication and collaboration skills and a record of partnering across organizations to sharpen project requirements. Sometimes this includes re-framing the original request to solve a more general problem with similar effort. 
Hands-on mathematical and software engineering skills to execute on complex projects.
Proficiency in Python and SQL.
Desire and ability to mentor junior Data Scientists within the team by exemplifying math, engineering and technical communication skills.


Estimated annual salary range: $164,000 - $184,000 USD plus equity and a discretionary bonus.
Benefits include medical, vision, dental, 401K plan, generous time off, parental leave, wellness reimbursements, professional development, employee investing discount, and more!

About Wealthfront
Here at Wealthfront, our mission is to create a financial system that favors people, not institutions. We do this by leveraging technology to build powerful, low-cost, and easy-to-use financial products that help modern investors grow and manage their money.
We started with the ambition to transform the investment advisory business. By automating strategies typically reserved for the wealthy, we unlocked access to high quality investment advice for a digitally-native generation that was underserved by traditional institutions. Since then, we've expanded to a full suite of products designed to help our clients turn their savings into long-term wealth, including:
• A Cash Account that, through our partner banks, offers one of the highest annual percentage yields on uninvested cash in the industry, while providing instant and secure access to your money with no account fees and a full suite of checking features.
• A zero-commission Stock Investing Account with 50+ handpicked collections that help DIY investors discover new companies and make smarter investing decisions.
• Multiple automated investing portfolios designed to unlock tax savings through sophisticated strategies like fixed income, tax-loss harvesting, and direct indexing—which we offer at industry-leading low costs and accessible minimums.
Our award-winning products have attracted over 1 million clients who trust us with more than $80 billion of their hard earned savings—and we're far from done. If you’re inspired to help us reshape the financial industry as we create our next chapter, let’s talk!
For more information please visit www.wealthfront.com.We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Please review our candidate privacy notice. 
Disclosures: All investing involves risk, including the possible loss of principal. Tax-Loss Harvesting benefits vary depending on the client's entire tax and investment profile. Wealthfront doesn’t provide tax advice. The Cash Account is offered by Wealthfront Brokerage LLC (“Wealthfront Brokerage”), Member of FINRA/SIPC. Wealthfront Brokerage is not a bank. We convey funds to partner banks who accept and maintain deposits, provide the variable interest rate, and provide access to FDIC pass-through insurance. Investment management and advisory services–which are not FDIC insured–are provided by Wealthfront Advisers LLC (“Wealthfront Advisers”), an SEC-registered investment adviser. The checking features offered in the Wealthfront Cash Account are provided by Green Dot Bank, Member FDIC. Fees and Eligibility requirements may apply to certain checking features, please see the Deposit Account Agreement for details.
By “award-winning products”, please refer to www.wealthfront.com/reviews for more information. Wealthfront Corporation oversees Total Client Assets and Trusted Clients through Wealthfront Advisers and Wealthfront Brokerage. Wealthfront Advisers and Wealthfront Brokerage are wholly owned subsidiaries of Wealthfront Corporation.  ","{""role_summary"":""The Data Scientist will work within Wealthfront's Investing area, analyzing client behavior, developing predictive models, and creating dashboards to inform product decisions and drive business growth."",""key_terms"":[{""term"":""Predictive models"",""explanation"":""Statistical models that forecast future events or behaviors, such as product interest and demand.""},{""term"":""Funnel drop-off"",""explanation"":""The point at which customers abandon a process or transaction, often used to identify areas for improvement.""},{""term"":""Cross-product adoption"",""explanation"":""The use of multiple products or services by a single customer, often indicating customer loyalty and retention.""},{""term"":""Asset allocation"",""explanation"":""The process of dividing investments among different asset classes, such as stocks, bonds, and cash, to manage risk and optimize returns.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Strong communication and collaboration skills"",""Hands-on mathematical and software engineering skills""],""nice_to_have"":[""Prior experience in financial services"",""Knowledge of finance basics""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach analyzing client behavior to inform product decisions?"",""example_answer"":""I would start by identifying key metrics, such as funnel drop-off and cross-product adoption, and then use statistical models to analyze the data. I would also collaborate with cross-functional stakeholders to ensure that the insights are actionable and aligned with business goals.""},{""question"":""Can you walk me through your process for developing predictive models?"",""example_answer"":""I would start by collecting and cleaning the data, then use techniques such as regression analysis and machine learning to develop the model. I would also validate the model using techniques such as cross-validation and walk-forward optimization.""}],""red_flags"":[""Lack of experience with Python and SQL"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Decision Scientist,"Decision Scientist

Job Summary:
We are seeking a talented and dynamic Decision Scientist with strong expertise in Tableau and SQL to join our dynamic team. The candidate will leverage a mix of data engineering, analytics, dashboarding and storytelling to derive actionable insights and help improve customer experience across digital journeys.
Our ideal candidate is someone who is proficient at execution, adept at managing timelines and roadmaps and is constantly looking to innovate and automate to bring greater efficiencies and drive strong business outcomes

Key Responsibilities:
Extract, process, and analyze large datasets from multiple sources to identify trends and patterns.
Create and maintain visually compelling dashboards and reports using Tableau to present insights to stakeholders.
Develop compelling presentations on Keynote to communicate strategic insights to leadership
Collaborate with cross-functional teams to understand business needs and translate them into data solutions.
Perform exploratory data analysis (EDA) and apply statistical techniques for hypothesis testing.
Optimize data models and enhance data processing pipelines for efficiency and scalability.
Communicate findings clearly to both technical and non-technical audiences.
Stay updated with the latest trends and advancements in data analytics and visualization.
Identify growth opportunities in form of automation, new solutions, enhancements etc. and follow an agile approach to translate ideas into outcomes

Required Qualifications:
Master’s degree in Data Science, Computer Science, Statistics, or a related field, or equivalent work experience.
Proven experience with data visualization and storytelling.
Proficiency in Tableau for creating dashboards, reports, and data models.
Strong skills in SQL for data extraction and manipulation, with a strong emphasis on self-driven and structured quality check process
Familiarity with data integration tools and ETL processes.
Excellent analytical, problem-solving, and communication skills.
Excellent at cross-functional collaboration working with global teams, as well as independent execution and proactive management of timelines and dependencies
(Strongly preferred) Experience with digital analytics (Adobe Workspace or Google Analytics)
(Good to have) Hands-on experience with programming languages such as Python or R.
(Good to have) Solid understanding of statistical methods and machine learning algorithms.","{""role_summary"":""A Decision Scientist who analyzes data to improve customer experience across digital journeys, creating actionable insights and dashboards to present to stakeholders."",""key_terms"":[{""term"":""Tableau"",""explanation"":""A data visualization tool used to create dashboards and reports.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational databases.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process used to integrate data from multiple sources into a single, unified view.""},{""term"":""Data Engineering"",""explanation"":""The process of designing, building, and maintaining the infrastructure that stores, processes, and retrieves large datasets.""},{""term"":""Data Analytics"",""explanation"":""The process of extracting insights and patterns from data to inform business decisions.""},{""term"":""Data Visualization"",""explanation"":""The process of presenting data in a graphical or visual format to facilitate understanding and communication.""},{""term"":""Statistical Methods"",""explanation"":""Mathematical techniques used to analyze and interpret data, such as hypothesis testing and confidence intervals.""},{""term"":""Machine Learning Algorithms"",""explanation"":""Programs that enable computers to learn from data and make predictions or decisions without being explicitly programmed.""}],""skill_priorities"":{""must_have"":[""Tableau"",""SQL"",""Data Visualization"",""Data Analytics"",""Communication Skills"",""Analytical Skills"",""Problem-Solving Skills""],""nice_to_have"":[""Python"",""R"",""Adobe Workspace"",""Google Analytics"",""Machine Learning Algorithms"",""Statistical Methods""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for creating a dashboard in Tableau?"",""example_answer"":""I would start by identifying the key insights I want to communicate, then select the most relevant data and create a wireframe of the dashboard. Next, I would use Tableau to connect to the data source, create the visualizations, and add interactive elements. Finally, I would test and refine the dashboard to ensure it effectively communicates the insights.""},{""question"":""How do you stay updated with the latest trends and advancements in data analytics and visualization?"",""example_answer"":""I regularly read industry blogs and publications, attend webinars and conferences, and participate in online forums to stay current with the latest developments and best practices in data analytics and visualization.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
"Data Scientist, YouTube Search","Minimum qualifications:

Master's degree in Statistics, Data Science, Mathematics, Physics, Economics, Operations Research, Engineering, or a related quantitative field.
3 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or a PhD degree.

Preferred qualifications:

5 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or a PhD degree.

About The Job

Despite being used over one billion times per day, YouTube Search has only been recently explored from a data science perspective. There is quite a bit of unexplored territory where we can define foundational concepts with large scale impact and leverage.

In this role, you will be the first go-to analyst to work on Search Verticals. Search Verticals is a full-stack area, and you will leverage your skills across multiple core competencies, such as ML classifier development, ranking, and experiments, to understand and optimize the YouTube Search Vertical experience.

At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.

The US base salary range for this full-time position is $141,000-$202,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities

Collaborate with stakeholders in cross-project and team settings to identify and clarify business or product questions to answer. Provide feedback to translate and refine business questions into tractable analysis, evaluation metrics, or mathematical models.
Use custom data infrastructure or existing data models as appropriate, using specialized knowledge. Design and evaluate models to mathematically express and solve defined problems with limited precedent.
Gather information, business goals, priorities, and organizational context around the questions to answer, as well as the existing and upcoming data infrastructure.
Own the process of gathering, extracting, and compiling data across sources via relevant tools (e.g., SQL, R, Python). Independently format, re-structure, and/or validate data to ensure quality, and review the dataset to ensure it is ready for analysis.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .","{""role_summary"":""Work as a data analyst to solve product or business problems using analytics, coding, and querying databases, with a focus on YouTube Search Verticals."",""key_terms"":[{""term"":""ML classifier development"",""explanation"":""Machine learning classifier development refers to the process of creating and training algorithms to classify data into different categories.""},{""term"":""Ranking"",""explanation"":""Ranking in the context of YouTube Search Verticals refers to the process of ordering search results based on relevance and importance.""},{""term"":""Experiments"",""explanation"":""Experiments in this role involve designing and testing hypotheses to understand and optimize the YouTube Search Vertical experience.""}],""skill_priorities"":{""must_have"":[""Master's degree in Statistics, Data Science, Mathematics, Physics, Economics, Operations Research, Engineering, or a related quantitative field"",""3 years of experience using analytics to solve product or business problems"",""Coding skills (e.g., Python, R, SQL)""],""nice_to_have"":[""5 years of experience using analytics to solve product or business problems"",""PhD degree""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach optimizing the YouTube Search Vertical experience using analytics and machine learning?"",""example_answer"":""I would start by gathering data on user behavior and search patterns, then use machine learning algorithms to identify trends and areas for improvement. I would also collaborate with stakeholders to define key performance indicators and develop experiments to test hypotheses.""},{""question"":""How do you stay up-to-date with new developments in data science and analytics?"",""example_answer"":""I regularly read industry blogs and research papers, attend conferences and meetups, and participate in online forums to stay current with the latest techniques and tools in data science and analytics.""}],""red_flags"":[""Lack of experience with machine learning and analytics"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Jr. Data Scientist,"The Junior Data Scientist is an essential member of the CSE's Transparency and Insights (T&I) team, supporting the organization's analysis, evaluation, and implementation of decarbonization programs. This role enhances the team's capabilities by ensuring efficient and reliable access to program data, managing, analyzing, and interpreting data, and contributing to analytics that determine the impacts of policy designs and technology deployments.
Essential Functions and Responsibilities:
Data Analysis and Insights Generation
Extract, transform, analyze, and interpret data from diverse sources to meet both internal and external client requirements.
Apply descriptive statistics, statistical models and machine learning techniques to derive insights from data.
Ensure the quality and accuracy of data operations and analysis performed, implementing quality control (QC) measures.
Document analytical methods and contribute to the development of standard operating procedures (SOPs).
Data Visualization and Application Support
Develop and maintain web-based data visualizations, interactive maps, and reporting tools to communicate insights effectively.
Facilitate the extraction and reporting of data from PostgreSQL databases, flat files, columnar file formats, and other data sources.
Work under the mentorship of senior T&I team members to meet project objectives.
QUALIFICATIONS
Essential Knowledge, Skills, and Abilities:
Required
Technical Proficiency
Proficient in Python for data and statistical analysis, utilizing libraries like pandas, matplotlib, and sklearn.
Knowledgeable in object-oriented programming and ETL pipeline development.
Experienced with software version control using Git.
Strong skills in Microsoft Excel, Word, and PowerPoint.
Cloud Computing
Basic knowledge of AWS services such as IAM, EC2 and RDS.
Soft Skills
Exceptional attention to detail, along with strong organizational and problem-solving abilities.
Excellent communication skills, both oral and written.
Self-motivated with the ability to manage deadlines for multiple concurrent projects, using project management tools effectively.
Proactive in communicating with team members in a remote environment and open to seeking and receiving feedback.
Special Interests
A keen interest in data science applications within research and sustainable energy sectors.
Preferred
Skilled in geospatial analysis, including the use of libraries like Geopandas and Shapely.
A foundational understanding of the energy sector, including electric vehicles, energy efficiency, distributed generation, or energy storage.
Experience with data visualization tools (e.g., Tableau, PowerBI, Plotly) and survey platforms (e.g., Alchemer).
Education:
Bachelor’s degree in a field with substantial analytical content, such as statistics, economics, computer science, social science, environmental science, or engineering.
Experience:
1-3 years of experience in data analysis or a related field.
WORKING CONDITIONS
Work Environment:
Works in a home (remote) or office environment
Occasional evening and weekend work may be required to meet project deadlines.

Physical Demands:
The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Must have manual dexterity sufficient to operate a computer keyboard and other equipment customarily present in an office environment.","{""role_summary"":""Support the organization's decarbonization programs by ensuring efficient and reliable access to program data, managing and analyzing data, and contributing to analytics that determine policy and technology impacts."",""key_terms"":[{""term"":""Decarbonization programs"",""explanation"":""Initiatives aimed at reducing greenhouse gas emissions and mitigating climate change.""},{""term"":""ETL pipeline development"",""explanation"":""Extract, Transform, Load process for data integration and processing.""},{""term"":""Geospatial analysis"",""explanation"":""Study of data with geographic or spatial aspects, often used in mapping and location-based applications.""}],""skill_priorities"":{""must_have"":[""Python programming"",""Data analysis and statistical modeling"",""ETL pipeline development"",""Cloud computing (AWS)"",""Microsoft Office (Excel, Word, PowerPoint)"",""Git version control""],""nice_to_have"":[""Geospatial analysis"",""Data visualization tools (Tableau, PowerBI, Plotly)"",""Survey platforms (Alchemer)"",""Energy sector knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach data quality control measures in a data analysis project?"",""example_answer"":""I would implement quality control measures such as data validation, data normalization, and data visualization to ensure data accuracy and reliability.""},{""question"":""Can you explain the concept of ETL pipeline development and its importance in data integration?"",""example_answer"":""ETL pipeline development is the process of extracting data from various sources, transforming it into a standardized format, and loading it into a target system for analysis. It's essential for data integration as it enables efficient data processing and reduces data inconsistencies.""}],""red_flags"":[""Lack of experience with cloud computing (AWS)"",""Inability to work effectively in a remote environment""],""confidence_score"":90.0}"
Data Scientist (Junior - Senior),"Clear Ridge Defense is seeking TS/SCI cleared professionals to serve as Data Scientists in Fort Meade, MD.

Roles And Responsibilities

You will...

Devise strategies for extracting meaning and value from large datasets.
Make and communicate principled conclusions from data employing mathematics, statistics, computer science, and application-specific knowledge.
Use various forms of analysis methodology to characterize, explore, and assess large complex datasets.
Translate practical mission needs and analytics questions related to large datasets into technical requirements.
Assist teammates in drawing appropriate conclusions from the analysis of such data.
Effectively communicate complex technical concepts to non-technical audiences.
Make informed recommendations regarding technical solutions, while maintaining awareness of unique and dynamic customer collection, processing, storage, and analytic capabilities.

Must-Haves

You possess...

Excellent interpersonal communication skills.
A Top Secret clearance with polygraph.
Years (3+) of relevant experience in machine learning, data science, programming, or statistical analysis.
A Bachelor's Degree in a Computer Science/Mathematics related field.
An ability to work in a fast-paced and dynamic workplace with unique TTPs.

Nice-To-Haves

Leadership experience.

Additional Information

Ranking #5 in Maryland and #7 in Government Services! And see how we were ranked a 2023 Top Workplace by the Baltimore Sun!

Clear Ridge Defense Is The Premier Service Solutions Provider Supporting The Service And Joint Cyberspace Operations And Intelligence Community In Three Core Areas Of Expertise

Cyber Systems & Software Engineering
Cyber Intelligence & Operations Planning
Security Risk Analysis, Mitigation & Training

All delivered by highly talented and focused team members that are supported by an unmatched professional and family-oriented culture that leverages and builds on sound, proven principles.

Benefits Snapshot

100% Fully-Covered Health, Dental, and Vision Insurance
100% Fully-Covered Short-Term and Long-Term Disability Insurance
100% Fully-Covered Life and AD&D Insurance
Unique Flexible PTO
11 Paid Federal Holidays
$500 New Uniform Bonus for Transitioning Military
Monthly Tax-Free Cell Phone Stipend
Monthly Tax-Free Gym Wellness / Streaming Subscription Stipend to include Amazon Prime, Netflix, Audible, etc.
Competitive 401k Matching to plan for retirement
Free financial advising from qualified experts
Annual $5,000 Training Allotment
One-of-a-kind Referral Program: $5,000 per referral OR $250/mo indefinitely, with no limit to number of referrals
Business Development and Client Expansion Bonuses
Monthly Company-Paid Socials and Events
Access to our Company Swag Store

Benefits

CRD fully supports Maryland’s Equal Pay for Equal Work – Wage Range Transparency law, which mandates employers to provide detailed wage and benefits information in all job postings. The salary range for this position is:

$98,000 - $215,000 / year

Salary Ranges Provided Are Subject To The Following Variables And Circumstances, Which May Impact Whether The Actual Paid Salary Falls Within The Range

The contract the employee is assigned to support. For example, this advertised position may support multiple contracts.
The negotiated rates between CRD and our client.
The option year of the contract the employee is assigned to.
Annual performance of the employee and/or the company.
If the employee takes on additional company responsibilities.
If the company makes a strategic hiring decision (e.g., investment in the employee) for growth opportunities.
If the employee does not meet the qualifications fully but a waiver is provided by CRD or our clients.
If the employee is assigned a lower-level labor category due to external circumstances than they actually qualify for.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.","{""role_summary"":""Data Scientist responsible for extracting insights from large datasets, communicating complex technical concepts, and making informed recommendations to support mission needs."",""key_terms"":[{""term"":""TS/SCI cleared"",""explanation"":""Top Secret security clearance with polygraph, required for working with sensitive government information.""},{""term"":""Machine learning"",""explanation"":""A subset of artificial intelligence that involves training algorithms to learn from data and make predictions or decisions.""},{""term"":""Data science"",""explanation"":""The process of extracting insights and knowledge from structured and unstructured data using various techniques and tools.""},{""term"":""TTPs"",""explanation"":""Tactics, Techniques, and Procedures, referring to the unique and dynamic methods used in the workplace.""}],""skill_priorities"":{""must_have"":[""Excellent interpersonal communication skills"",""Top Secret clearance with polygraph"",""3+ years of experience in machine learning, data science, programming, or statistical analysis"",""Bachelor's Degree in a Computer Science/Mathematics related field"",""Ability to work in a fast-paced and dynamic workplace""],""nice_to_have"":[""Leadership experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a large complex dataset to extract meaningful insights?"",""example_answer"":""I would first explore the dataset to understand the variables and their relationships, then apply statistical and machine learning techniques to identify patterns and trends. Finally, I would communicate my findings and recommendations to stakeholders in a clear and concise manner.""},{""question"":""How do you stay current with new developments in machine learning and data science?"",""example_answer"":""I regularly read industry publications and attend conferences to stay up-to-date on the latest techniques and tools. I also participate in online forums and discussions to learn from others in the field.""}],""red_flags"":[""Lack of experience working with sensitive government information"",""Inability to effectively communicate complex technical concepts to non-technical audiences""],""confidence_score"":95.0}"
"Data Scientist, Gmail and Chat AI Model Quality","For United States Applicants:

The application window will be open until at least March 4, 2025. This opportunity will remain online based on business needs which may be before or after the specified date.

Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Sunnyvale, CA, USA; Boulder, CO, USA; Kirkland, WA, USA; New York, NY, USA; San Francisco, CA, USA; Waterloo, ON, Canada; Los Angeles, CA, USA; Seattle, WA, USA.Minimum qualifications:

Bachelor's degree in Statistics, Mathematics, Data Science, Engineering, Physics, Economics, or a related quantitative field.
13 years of work experience using analytics to solve product or business problems, performing statistical analysis, and coding (e.g., Python, R, SQL) (or 10 years work experience and a Master's degree).

Preferred qualifications:

Master's degree in Statistics, Mathematics, Data Science, Engineering, Physics, Economics, or a related quantitative field.
12 years of experience solving product or business problems, performing statistical analysis, and coding (e.g., Python, R, SQL).
Experience in extracting large sets of data with SQL and in designing ETL flows.
Experience working with Developers and Product Managers, especially around providing product-centric insights.
Track record of solving unstructured business problems with data science, translating results into impactful business recommendations, and measuring the success of those initiatives.

About The Job

Help serve Google's worldwide user base of more than a billion people. Data Scientists provide quantitative support, market understanding and a strategic perspective to our partners throughout the organization. As a data-loving member of the team, you serve as an analytics expert for your partners, using numbers to help them make better decisions. You will weave stories with meaningful insight from data. You will make critical recommendations for your fellow Googlers in Developing and Product Management. You relish tallying up the numbers one minute and communicating your findings to a team leader the next.

The Communications & Time Management (CTM) Data Science team shapes decision-making and provides actionable insights to guide product development and strategy for popular Google products like Gmail, Chat, and Calendar.

As a Data Scientist on the team, you will work closely with product and Developer teams to build products enjoyed by users globally.

This is a high-visibility role that partners closely with CTMI Product and Developer leads. You will also regularly share your findings and present your work to Workspace leadership.

Google is an engineering company at heart. We hire people with a broad set of technical skills who are ready to take on some of technology's greatest challenges and make an impact on users around the world. At Google, Developers not only revolutionize search, they routinely work on scalability and storage solutions, large-scale applications and entirely new platforms for developers around the world. From Google Ads to Chrome, Android to YouTube, social to local, Google Developers are changing the world one technological achievement after another.

The US base salary range for this full-time position is $227,000-$320,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities

Perform data exploration to understand user behavior and identify opportunities for improving GenAI models across Gmail and Chat.
Perform evaluations of model performance across assistive writing, summarization, and inbox highlights.
Define, own, and evolve model evaluation metrics and frameworks.
Lead the design, analysis, and interpretation of product experiments.
Partner with Product, Developers, and cross-functional teams to influence, prioritize, and support product strategy.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .","{""role_summary"":""As a Data Scientist, you will provide quantitative support, market understanding, and strategic perspective to partners throughout the organization, using analytics to solve product or business problems and making critical recommendations."",""key_terms"":[{""term"":""ETL flows"",""explanation"":""Extract, Transform, Load flows, a process used to extract data from multiple sources, transform it into a standardized format, and load it into a target system for analysis.""},{""term"":""SQL"",""explanation"":""Structured Query Language, a programming language used to manage and manipulate data in relational database management systems.""},{""term"":""GenAI models"",""explanation"":""General Artificial Intelligence models, a type of AI model that can perform any intellectual task that a human can, such as understanding user behavior and identifying opportunities for improvement.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in Statistics, Mathematics, Data Science, Engineering, Physics, Economics, or a related quantitative field"",""13 years of work experience using analytics to solve product or business problems, performing statistical analysis, and coding (e.g., Python, R, SQL)""],""nice_to_have"":[""Master's degree in Statistics, Mathematics, Data Science, Engineering, Physics, Economics, or a related quantitative field"",""Experience in extracting large sets of data with SQL and designing ETL flows"",""Experience working with Developers and Product Managers, especially around providing product-centric insights""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach solving an unstructured business problem using data science?"",""example_answer"":""I would start by defining the problem and identifying the key stakeholders, then gather and analyze relevant data to identify patterns and trends. Next, I would develop and test hypotheses, and finally, translate the results into actionable business recommendations.""},{""question"":""How do you stay current with new developments in data science and analytics?"",""example_answer"":""I regularly read industry publications and attend conferences to stay up-to-date on the latest techniques and tools. I also participate in online forums and discussion groups to learn from others and share my own knowledge.""}],""red_flags"":[""Lack of experience working with large datasets and performing statistical analysis"",""Inability to communicate complex technical results to non-technical stakeholders""],""confidence_score"":95.0}"
Decision Scientist (Hybrid Role - New York),"OLAPLEX, a category-defining leader in prestige hair care, continuously seeks talented individuals to join in our mission to transform foundational hair health and deliver great hair days today, tomorrow, and for years to come.

As the original bond builder, we are dedicated to fostering a culture that celebrates the bonds within our teams. OLAPLEX elevates individuals from all backgrounds with the belief that together we can unlock the full potential of science to extend the health, life, and beauty of hair for all.

About the Role:

OLAPLEX is seeking a hands-on Decision Scientist to be the business-oriented expert in delivering analytics and insights to leaders at all levels across the organization. The Decision Scientist must be a strong business partner, driven to succeed in both the art and science of analytics, and a collaborator who loves to address real business problems. You will work with the Head of Data, internal stakeholders, and outsourced partners to help define our data strategy, focusing on delivering insights and building comprehensive reporting, analytics, and insights solutions using tools like Snowflake, Tableau, and ThoughtSpot. The ideal candidate will have a keen business curiosity and experience in advanced analytics, foundational knowledge in statistics or data visualization, and experience working with business stakeholders. This position will report to the Head of Data.

Build, maintain, and enhance our data platform, focusing on creating actionable insights and user-friendly data products
Partner with the Head of Data and business leads across departments to create and maintain a data-driven culture, focusing on leveraging data to solve business challenges
Develop and design data visualization solutions using Tableau and ThoughtSpot to support business decision-making
Assist with data analysis, reporting needs, continuous improvement initiatives, change management, and support for optimal usage within the data lake / data warehouse
Perform sophisticated analysis activities, including defining, measuring, and communicating core operational metrics
Deliver training and documentation support on data products and analytics tools
Maintain up-to-date knowledge and documentation of data platform best practices, functionality, customizations, and integrations, and proactively identify opportunities for process and workflow improvements
Develop systems and processes to ensure compliance with data privacy regulations by properly implementing and documenting clear and complete processes and procedures for enterprise data stores and reporting systems
Collaborate with business teams to map data fields to hypotheses, and prepare data for use in reporting, analytics, and data science
Structure and redesign data flows to maintain a single source of truth for all master data and consistent reporting
Analyze data flowing through existing ERP, CRM, and other workflow systems
Maintain the highest security standards across the entire data ecosystem

About You:

3+ years of professional experience in a data-driven role, such as Business Analyst, Decision Scientist, or Data Scientist
2+ years of experience in data analysis and reporting
Proficiency in SQL, preferably Snowflake, and experience with data visualization tools like Tableau and ThoughtSpot
Strong business curiosity and the ability to work backwards from business problems to data solutions; must be able to own and write end-user requirements in collaboration with business stakeholders
Advanced knowledge of statistics, and application of stats to business domains
Exceptional ability to identify anomalies and patterns in business data
Strong understanding of relational database principles
Experience working in a cloud platform such as AWS, GCP, or Azure
Experience with other programming languages to manipulate data, such as Python or R, is a plus
Experience using tools and platforms like Snowflake, Jira/Asana, Google Analytics, and CPDs
Strong communication (written/verbal), presentation, and facilitation skills

We'd love to have you apply, even if you don't feel you meet every single requirement. What's most important to us is finding authentic and accountable people who feel connected to our mission and values, not just candidates who check off all the boxes. We are looking for someone who will bring all their expertise, learn, and grow with us.

Our Total Rewards:

The annual base pay for this position is $120,000 - $140,000 with eligibility for an annual bonus. The actual base pay will vary based on factors such as qualifications, years of relevant experience, skill level, functional expertise, certificates or other professional licenses held and geographic location.

Competitive compensation
Work/Life Balance: Flexible paid time off, 11 paid holidays, and flexible work schedules
Wellness: Company Contribution to Medical, Dental, and Vision Insurance for Employees and their Families, Company Paid Employee Life Insurance, Optional additional Life Insurance, and Short and Long-Term Disability Coverage Options
Parental Leave: Up to 18 weeks for birthing-parents and up to 10 weeks for non-birthing new parents
Financial Well-being: Roth and 401k plans: 100% match up to the first 4% and is immediately vested
Professional Development Reimbursement Program: Career development is as important to us as we know it is to you!
Culture: Our team has an ""attitude of gratitude"" and a shared passion for our brand. Join our culture committee and/or DE&I champion team to play a role in building and sustaining our ""secret sauce""
Products: Twenty (20) free products per year, plus a friends and family discount

Our Commitment to Diversity, Equity, and Inclusion:

Our mission is to create a culture that celebrates our bonds by embracing, elevating, and empowering individuals from all backgrounds.

OLAPLEX is proud to be an Equal Opportunity Employer. We do not discriminate based on race, color, ancestry, national origin, religion, or religious creed, mental or physical disability, medical condition, genetic information, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, gender expression, age, marital status, military or veteran status, citizenship, or other characteristics protected by state or federal law or local ordinance.","{""role_summary"":""The Decision Scientist will be a business-oriented expert in delivering analytics and insights to leaders across the organization, focusing on building comprehensive reporting, analytics, and insights solutions using tools like Snowflake, Tableau, and ThoughtSpot."",""key_terms"":[{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform used for storing and processing large amounts of data.""},{""term"":""Tableau"",""explanation"":""A data visualization tool used to create interactive dashboards and reports.""},{""term"":""ThoughtSpot"",""explanation"":""A search and AI-driven analytics platform used for data analysis and visualization.""},{""term"":""Data Lake"",""explanation"":""A centralized repository that stores all types of data in its native format, allowing for flexible schema-on-read analytics.""},{""term"":""Data Warehouse"",""explanation"":""A centralized repository that stores structured and processed data, optimized for querying and analysis.""},{""term"":""ERP"",""explanation"":""Enterprise Resource Planning system, used to manage and integrate business operations and data.""},{""term"":""CRM"",""explanation"":""Customer Relationship Management system, used to manage customer interactions and data.""}],""skill_priorities"":{""must_have"":[""SQL"",""Data analysis and reporting"",""Data visualization tools like Tableau and ThoughtSpot"",""Strong business curiosity"",""Advanced knowledge of statistics"",""Strong understanding of relational database principles""],""nice_to_have"":[""Experience with cloud platforms like AWS, GCP, or Azure"",""Experience with programming languages like Python or R"",""Experience with tools and platforms like Jira/Asana, Google Analytics, and CPDs""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a data strategy for our organization?"",""example_answer"":""I would start by understanding the business goals and objectives, then identify the key performance indicators and metrics that need to be tracked. Next, I would assess the current data infrastructure and identify areas for improvement. Finally, I would develop a roadmap for implementing a data strategy that aligns with the business goals and objectives.""},{""question"":""How do you stay current with new tools and technologies in the data analytics space?"",""example_answer"":""I regularly read industry blogs and publications, attend conferences and webinars, and participate in online forums and communities to stay up-to-date on the latest trends and technologies.""}],""red_flags"":[""Lack of experience working with business stakeholders"",""Inability to communicate complex data insights to non-technical stakeholders"",""Limited experience with data visualization tools""],""confidence_score"":90.0}"
Machine Learning / Deep Learning Engineer,"About the Company - Waymo is an autonomous driving technology company with the mission to be the most trusted driver. Since its start as the Google Self-Driving Car Project in 2009, Waymo has focused on building the Waymo Driver—The World's Most Experienced Driver™—to improve access to mobility while saving thousands of lives now lost to traffic crashes. The Waymo Driver powers Waymo One, a fully autonomous ride-hailing service, and can also be applied to a range of vehicle platforms and product use cases. The Waymo Driver has provided over one million rider-only trips, enabled by its experience autonomously driving tens of millions of miles on public roads and tens of billions in simulation across 13+ U.S. states.

About the Role - Our Perception team builds the system that ""sees"" the world around the self-driving car. We conduct research to address real-world problems and collaborate with research teams at Alphabet. We have access to millions of miles of driving data from a diverse set of sensors, enabling researchers like you to develop complex models and techniques at scale. In this hybrid role, you will report into an Engineering Director.


Responsibilities -

Experience applying machine learning techniques to build multi-modal sensor fusion architectures including object detection and tracking, segmentation, road understanding, flow estimation and future prediction.
Design large-scale foundation models trained on our vast data
Develop data mining, labeling, training and evaluation pipelines to help the Waymo Driver

Qualifications - Bachelors in Computer Science or a similar discipline, or an equivalent amount of deep learning experience


Required Skills -

3+ years experience in Computer Vision and Machine Learning
Experience with Python/C++


Preferred Skills -

PhD degree in Computer Science or a similar discipline
Publications at top-tier conferences like CVPR, ICCV, ECCV, ICLR, ICML, ICRA, RSS, NeurIPS, AAAI, IJCV, PAMI


Pay range and compensation package - The expected base salary range for this full-time position across US locations is listed below. Actual starting pay will be based on job-related factors, including exact work location, experience, relevant training and education, and skill level. Your recruiter can share more about the specific salary range for the role location or, if the role can be performed remote, the specific salary range for your preferred location, during the hiring process. Waymo employees are also eligible to participate in Waymo’s discretionary annual bonus program, equity incentive plan, and generous Company benefits program, subject to eligibility requirements.


Equal Opportunity Statement - Include a statement on commitment to diversity and inclusivity.","{""role_summary"":""Design and develop machine learning models for multi-modal sensor fusion architectures to enable the Waymo Driver to 'see' the world around the self-driving car."",""key_terms"":[{""term"":""Multi-modal sensor fusion"",""explanation"":""Combining data from different sensors to create a comprehensive view of the environment.""},{""term"":""Object detection and tracking"",""explanation"":""Identifying and following objects in the environment, such as other cars or pedestrians.""},{""term"":""Segmentation"",""explanation"":""Dividing the environment into distinct regions or objects.""},{""term"":""Road understanding"",""explanation"":""Interpreting the layout and rules of the road.""},{""term"":""Flow estimation and future prediction"",""explanation"":""Predicting the movement of objects and the future state of the environment.""}],""skill_priorities"":{""must_have"":[""3+ years experience in Computer Vision and Machine Learning"",""Experience with Python/C++""],""nice_to_have"":[""PhD degree in Computer Science or a similar discipline"",""Publications at top-tier conferences""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach designing a multi-modal sensor fusion architecture for a self-driving car?"",""example_answer"":""I would start by identifying the different sensor modalities available, such as cameras, lidar, and radar. Then, I would design a fusion framework that combines the strengths of each modality to create a robust and accurate perception of the environment. This would involve developing algorithms for sensor calibration, data alignment, and feature extraction, as well as implementing techniques for handling uncertainty and ambiguity.""},{""question"":""How do you stay current with the latest developments in computer vision and machine learning?"",""example_answer"":""I regularly read research papers and articles, attend conferences and workshops, and participate in online forums and discussion groups. I also experiment with new techniques and tools to stay hands-on and practical.""}],""red_flags"":[""Lack of experience with large-scale machine learning models"",""Inability to work with diverse sensor data""],""confidence_score"":90.0}"
Data Scientist - Product Analytics,"LatentView Analytics is a leading global analytics and decision sciences provider, delivering solutions that help companies drive digital transformation and use data to gain a competitive advantage. With analytics solutions that provide a 360-degree view of the digital consumer, fuel machine learning capabilities and support artificial intelligence initiatives., LatentView Analytics enables leading global brands to predict new revenue streams, anticipate product trends and popularity, improve customer retention rates, optimize investment decisions, and turn unstructured data into valuable business assets.


6+ years of experience working in a data scientist role
Produces insights into business performance, KPI trends, drivers etc.
Performs business analysis using various techniques, e.g. statistical analysis, explanatory and predictive modeling, data mining.
Determines best practices and develops actionable insights and recommendations for the current business operations.
Produce adhoc reports, conduct data discovery and quality checks needed for reports

Skills:
Fluency in data analysis, including defining KPIs, statistical and predictive modeling concepts, descriptive statistics, customer segmentation, and funnel analysis
Hands-on expertise with SQL, R/Python and statistical modeling techniques (e.g. regression, classification, time series) to answer a wide range of measurement questions.
Ability to tell stories clearly and concisely with data, and how they drive business outcomes
Demonstrates strong business acumen and curiosity
Excellent problem-solving skills and end-to-end quantitative thinking","{""role_summary"":""A data scientist who analyzes business performance, identifies trends, and develops actionable insights to drive business outcomes."",""key_terms"":[{""term"":""Predictive modeling"",""explanation"":""A statistical technique used to forecast future outcomes based on historical data.""},{""term"":""Descriptive statistics"",""explanation"":""A branch of statistics that summarizes and describes the basic features of a dataset.""},{""term"":""Customer segmentation"",""explanation"":""The process of dividing customers into distinct groups based on their characteristics, needs, and behaviors.""},{""term"":""Funnel analysis"",""explanation"":""A method used to measure the conversion rates of customers as they move through a sales or marketing process.""},{""term"":""Regression"",""explanation"":""A statistical technique used to establish a relationship between a dependent variable and one or more independent variables.""},{""term"":""Classification"",""explanation"":""A type of supervised learning in machine learning where the model predicts a categorical label or class.""},{""term"":""Time series"",""explanation"":""A sequence of data points measured at regular time intervals, used to analyze patterns and trends over time.""}],""skill_priorities"":{""must_have"":[""Fluency in data analysis"",""Hands-on expertise with SQL, R/Python"",""Statistical and predictive modeling concepts"",""Ability to tell stories clearly and concisely with data""],""nice_to_have"":[""Excellent problem-solving skills"",""End-to-end quantitative thinking""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach a project to analyze customer churn?"",""example_answer"":""I would start by collecting relevant data, such as customer demographics and transaction history. Then, I would use statistical techniques like regression and classification to identify key factors contributing to churn. Finally, I would develop actionable insights and recommendations to reduce churn rates.""},{""question"":""How do you stay up-to-date with new developments in machine learning and predictive modeling?"",""example_answer"":""I regularly read industry blogs and research papers, attend conferences and webinars, and participate in online forums to stay current with the latest techniques and tools.""}],""red_flags"":[""Lack of experience with SQL, R/Python"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
ML Engineer/Data Scientist,"Adapty is a revenue management platform for mobile apps that simplifies subscription implementation and paywall management. We help developers quickly monetize their apps, serving 7,000 apps and processing $1 billion in in-app subscriptions annually. Backed by top investors like 500 Startups and Surface Ventures.

At Adapty, we pride ourselves on offering the best analytics for subscription apps. In addition, we provide powerful predictive tools, including the ability to forecast the outcomes of A/B tests and predict revenue and LTV for cohorts.

We’re looking for ML Engineer/Data Scientist to join us and drive our machine learning and data science initiatives even further.

What You Will Do

Take ownership of your models, guiding them from initial research to full deployment in production, and ensuring they continue to deliver value over time.
Build and improve models to predict customer revenue and lifetime value (LTV) for mobile apps, helping our customers make better business decisions.
Providing benchmarks for customer metrics, including Install-to-Trial conversions, Install-to-Paid conversions, and LTV compared to industry standards.
Make A/B testing smarter by developing tools that identify winning strategies faster and with less data.
Create models that design highly effective paywalls tailored to each app’s category and audience, optimizing pricing, layout, and content.
Use data to uncover actionable insights, such as identifying where a small price adjustment could significantly boost revenue.

What We Expect

Strong Analytical Foundation: You have a solid grasp of math, statistics, and probability theory.
Machine Learning Expertise: You know how to build both interpretable and advanced black-box machine learning models, and you’ve put them into production before.
Revenue-Focused Experience: You’ve worked on predictive models for metrics like revenue and LTV, and you understand the challenges in these areas.
End-to-End Ownership: You’re comfortable taking a model from an idea to a live, production-ready system—and keeping it running smoothly.
Product-based Approach: You focus on results that make a difference for users, driving value with every project you take on.

What We Offer

Flexible Remote Work: Work from anywhere with a schedule that fits your life. While our core team operates in Europe, we welcome global candidates via deel.com.
Perfect Product Fit: Promote a product that aligns seamlessly with market needs, making your work impactful and fulfilling.
Direct Communication: A transparent and efficient work environment focused on achieving goals.
Fast-Track Impact: Receive clear, market-driven feedback on your work as we expand into the US and beyond.
Additional Benefits: Enjoy perks like free English lessons, sports and laptop reimbursements, and ample opportunities for professional growth.

Join Adapty and help shape the future of mobile app monetization through cutting-edge machine learning and data science solutions!

Share This Job

Job Information

Department

Development

Location

Remote

Employee Type

Full-time

Apply for a job now","{""role_summary"":""Adapty is seeking a Machine Learning Engineer/Data Scientist to drive machine learning and data science initiatives, focusing on predictive models for revenue and lifetime value, A/B testing, and paywall optimization."",""key_terms"":[{""term"":""A/B testing"",""explanation"":""A method of comparing two or more versions of a product, web page, or application to determine which one performs better.""},{""term"":""LTV (Lifetime Value)"",""explanation"":""A metric that estimates the total value a customer is expected to bring to a business over their lifetime.""},{""term"":""Machine Learning Models"",""explanation"":""Algorithms and statistical models that enable machines to learn from data, make predictions, and improve over time.""},{""term"":""Paywall"",""explanation"":""A system that restricts access to content or a service until a user pays a fee or subscription.""}],""skill_priorities"":{""must_have"":[""Strong analytical foundation in math, statistics, and probability theory"",""Machine learning expertise with experience in building and deploying models"",""Revenue-focused experience with predictive models for metrics like revenue and LTV""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a predictive model for customer revenue and LTV?"",""example_answer"":""I would start by collecting and preprocessing relevant data, then explore different machine learning algorithms to identify the best fit. I would also consider factors like seasonality, trends, and customer behavior to ensure the model is accurate and reliable.""},{""question"":""How do you ensure that your machine learning models are interpretable and explainable?"",""example_answer"":""I use techniques like feature importance, partial dependence plots, and SHAP values to provide insights into how the model is making predictions. This helps stakeholders understand the model's decisions and build trust in the results.""}],""red_flags"":[""Lack of experience with machine learning model deployment and maintenance"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Data Scientist (L5) - Cloud Games Quality of Experience,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

This data scientist role will focus on characterizing the quality of experience specific to our nascent cloud games offering, and operationalizing it across the business to illuminate and drive prioritization against the highest impact opportunities. You will join the team of Analytics Engineers, Data Scientists, and Data Engineers who partner with our infrastructure engineering teams to create metrics, perform analysis, and develop the tools and data products that help us make better decisions about our infrastructure and its impact on our product’s quality of experience.

What You’ll Do

Establish the fundamental set of quality of experience metrics used to evaluate our Cloud Games sessions, which is likely to include research and development of several new metrics.
Become the resident expert on all things Cloud Games Quality of Experience, partnering closely with Games Engineering and Games Studio teams to drive a culture of data-informed decision-making about our games title portfolio and the games platform infrastructure.
Develop deep expertise in how the Cloud Games infrastructure works, and understand how data, analytics, experimentation, and algorithms can play an impactful role in driving improvements to its performance.
Use a combination of experiment and observational data to understand the Netflix member perspective on their gaming experiences. Help us understand the Netflix member perspective on their experiences.
Translate valuable insights and data from this domain to initiatives in other parts of the business.

You Have

Advanced training in a quantitative field (Data Science, Statistics, Mathematics, Engineering, Physics, Economics, etc) or commensurate work experience.
Fluent in SQL. Comfortable prototyping pipelines of moderate complexity, with the ability to effectively partner with data engineering teams building more scalable solutions for important use cases
Strong Quantitative Programming skills in Python, R experience a plus
Passion for instrumenting and analyzing products to drive improvements to user experience, backed by strong product knowledge and intuition - ideally utilized in consumer/user interface settings or internally serving technical audiences such as engineers.
Demonstrated effectiveness at developing meaningful stakeholder relationships and deep domain expertise.
The demonstrated ability to communicate technical and statistical concepts clearly and concisely among audiences at many different levels.
Comfort with ambiguity, and the ability to thrive with minimal oversight and process.
Embodied the Netflix values while bringing a new perspective to continue improving our culture.

Generally, our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000.

Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.

Netflix is a unique culture and environment. Learn more here.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.","{""role_summary"":""This data scientist role focuses on characterizing the quality of experience for Netflix's cloud games offering, operationalizing it across the business, and driving prioritization against high-impact opportunities."",""key_terms"":[{""term"":""Cloud Games"",""explanation"":""Netflix's cloud-based gaming service, allowing users to play games across various genres and languages.""},{""term"":""Quality of Experience"",""explanation"":""The overall performance and user satisfaction of Netflix's cloud games service, encompassing factors like latency, graphics, and overall user experience.""},{""term"":""Analytics Engineers"",""explanation"":""Professionals responsible for developing and maintaining the analytics infrastructure, tools, and data products that support data-driven decision-making at Netflix.""}],""skill_priorities"":{""must_have"":[""Advanced training in a quantitative field (Data Science, Statistics, Mathematics, Engineering, Physics, Economics, etc)"",""Fluent in SQL"",""Strong Quantitative Programming skills in Python""],""nice_to_have"":[""R experience"",""Passion for instrumenting and analyzing products to drive improvements to user experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach developing a set of quality of experience metrics for a cloud-based gaming service?"",""example_answer"":""I would start by researching existing metrics and conducting stakeholder interviews to understand the key aspects of the gaming experience. Then, I would develop a set of metrics that capture the user's perspective, such as latency, graphics quality, and overall satisfaction. Finally, I would validate these metrics through experimentation and observational data analysis.""},{""question"":""Can you give an example of how you've effectively communicated technical and statistical concepts to non-technical stakeholders in the past?"",""example_answer"":""In my previous role, I had to present complex data insights to product managers and engineers. I used clear, concise language and visualizations to explain the concepts, and provided actionable recommendations that resonated with the stakeholders.""}],""red_flags"":[""Lack of experience with cloud-based gaming services"",""Inability to effectively communicate technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
"Data Scientist, Healthcare - Remote","Job Posting - Salary Range: $87,248 - $151,230

Company Description

Experian is a global data and technology company, powering opportunities for people and businesses around the world. We help to redefine lending practices, uncover and prevent fraud, simplify healthcare, create marketing solutions, and gain deeper insights into the automotive market, all using our unique combination of data, analytics and software. We also assist millions of people to realise their financial goals and help them save time and money.

We operate across a range of markets, from financial services to healthcare, automotive, agribusiness, insurance, and many more industry segments.

We invest in people and new advanced technologies to unlock the power of data. As a FTSE 100 Index company listed on the London Stock Exchange (EXPN), we have a team of 22,500 people across 32 countries. Our corporate headquarters are in Dublin, Ireland. Learn more at experianplc.com

Job Description

Reporting to the Director of Analytics, the Data Scientist drives development efforts on Experian Health priority data science and machine learning projects.

You Will

You are innovative and will help build data science models that addresses critical healthcare challenges for patients.
Have a strong background in statistics, analyzing large data sets, building machine learning models, implementing MLOps best practices, and designing experiments with appropriate documentation and cataloging.
Have experience as a full-stack data scientist, developing models from project ideation through production.

Qualifications

Qualifications:

Degree(s) in Machine Learning, Data Science, Statistics, Computer Science, Computer Engineering, Electrical Engineering, Physics, Applied Math or other quantitative fields
1+ years industry experience in data science and predictive modeling
Knowledge of machine learning algorithms, statistical methods, and data mining techniques, with experience applying them to real-world problems
Familiarity with MLOps practices and tools for model deployment, monitoring, and management in production environments (e.g., Sagemaker, MLflow, or similar ML platform)
Experience with model governance including model versioning and experiment tracking
Strong proficiency in Python and SQL
As a full-stack data scientist, experience creating data pipelines to source new data for model building
Proven ability to work independently on development of models with extremely large and complex data structures

Desired Expertise With

Strong understanding of healthcare concepts, terminologies, and data (e.g., claims/EHR data, ICD, CPT)
Experience with big data technologies such as Spark
Agile methods for software development

Benefits/Perks

You will be fully remote from within the US
Great compensation package and bonus plan
Core benefits including medical, dental, vision, and matching 401K
Flexible work environment, ability to work remote, hybrid or in-office
Flexible time off including volunteer time off, vacation, sick and 12-paid holidays

Additional Information

Our uniqueness is that we celebrate yours. Experian's culture and people are important differentiators. We take our people agenda very seriously and focus on what matters; DEI, work/life balance, development, authenticity, collaboration, wellness, reward & recognition, volunteering... the list goes on. Experian's people first approach is award-winning; World's Best Workplaces™ 2024 (Fortune Top 25), Great Place To Work™ in 24 countries, and Glassdoor Best Places to Work 2024 to name a few. Check out Experian Life on social or our Careers Site to understand why.

Experian is proud to be an Equal Opportunity and Affirmative Action employer. Innovation is an important part of Experian's DNA and practices, and our diverse workforce drives our success. Everyone can succeed at Experian and bring their whole self to work, irrespective of their gender, ethnicity, religion, colour, sexuality, physical ability or age. If you have a disability or special need that requires accommodation, please let us know at the earliest opportunity.","{""role_summary"":""The Data Scientist drives development efforts on Experian Health priority data science and machine learning projects, building data science models that address critical healthcare challenges for patients."",""key_terms"":[{""term"":""MLOps"",""explanation"":""Machine Learning Operations, a set of practices that combines machine learning and DevOps to streamline the machine learning lifecycle.""},{""term"":""Full-stack data scientist"",""explanation"":""A data scientist who can handle all aspects of data science, from data acquisition to model deployment, including data engineering, machine learning, and visualization.""},{""term"":""Model governance"",""explanation"":""The process of managing and maintaining machine learning models throughout their lifecycle, including model versioning, experiment tracking, and deployment.""}],""skill_priorities"":{""must_have"":[""Degree in Machine Learning, Data Science, Statistics, Computer Science, or other quantitative fields"",""1+ years industry experience in data science and predictive modeling"",""Knowledge of machine learning algorithms, statistical methods, and data mining techniques"",""Familiarity with MLOps practices and tools"",""Strong proficiency in Python and SQL""],""nice_to_have"":[""Strong understanding of healthcare concepts, terminologies, and data"",""Experience with big data technologies such as Spark"",""Agile methods for software development""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a machine learning model to address a critical healthcare challenge?"",""example_answer"":""I would start by understanding the problem and the data available, then explore different machine learning algorithms and techniques to identify the most suitable approach. I would also consider the need for model interpretability and explainability in a healthcare context.""},{""question"":""How do you ensure model governance and versioning in your machine learning projects?"",""example_answer"":""I use tools such as MLflow or Sagemaker to track model versions and experiments, and ensure that models are properly documented and cataloged. I also follow best practices for model deployment and monitoring in production environments.""}],""red_flags"":[""Lack of experience with MLOps practices and tools"",""Inability to work independently on complex data science projects""],""confidence_score"":90.0}"
Data Scientist - Deep Learning Focus,"About Sense:

At Sense, our mission is to make all homes intelligent by keeping people informed about what's happening in their homes, helping to make them safer, more efficient, and more reliable.

We are committed to making a real impact on climate change by developing cutting-edge AI solutions for energy monitoring and smart home intelligence.

About the Role:

We are looking for a Data scientist with a passion for deep learning and time series analysis to join our team. In this role, you will work on developing and optimizing machine learning models that help detect and analyze energy usage in homes.

This is a great opportunity for someone early in their career to gain hands-on experience with real-world machine learning applications, work with large datasets, and contribute to both cloud and embedded AI deployments.

Responsibilities:

Assist in designing and training deep learning models for device disaggregation
Perform data preprocessing and analysis to prepare datasets for model training
Conduct experiments with different model architectures and hyperparameters to optimize performance
Help curate ground truth datasets for model evaluation
Work with the engineering team to support model deployment in both cloud-based and embedded systems
Stay updated on deep learning advancements and contribute to best practices in model development
Collaborate with senior data scientists and engineers to improve data science infrastructure

Qualifications:

Bachelor's or Master's degree in Computer Science, Machine Learning, Electrical Engineering, or a related field
1 to 3 years of professional experience in data science or machine learning
Familiarity with deep learning frameworks like TensorFlow or PyTorch
Basic understanding of neural network architectures (CNNs, RNNs, Transformers)
Proficiency in Python and relevant data science libraries (NumPy, Pandas, Scikit-learn)
Experience working with large datasets is a plus
Strong problem-solving and analytical skills
Enthusiasm for learning and growing in a collaborative, fast-paced environment


Benefits

Flexible time away policy
Paid parental leave
A wide range of difficult and interesting problems to be solved
Work with a small team of experienced entrepreneurs creating revolutionary technology
Great opportunity to gain experience at a consumer smart home startup
Competitive compensation and generous healthcare benefits
A great office in Central Square in Cambridge, MA right by the Red Line
Compensation 170k to 190k
Stock Options and 401k with up to 10k match


Why Sense

Join Sense and be part of our mission to reduce global carbon emissions by making homes smart and more efficient. Our energy data and tools demystify home energy use, empower people to take command of their usage, and enable utilities to build a cleaner and more resilient grid.

Sense supports a diverse and inclusive workplace where we all learn from each other. We welcome candidates with backgrounds that are traditionally underrepresented in tech, and we strive to foster an engaging, respectful and supportive community where everyone feels empowered to do their best work. Sense is committed to be an equal opportunity employer.

Be a part of building something that will make a difference in the world
Have a big impact at a VC-backed consumer startup that's doing big things:
Best Startups in Cambridge - Tech Tribune
""One of the world's top 100 AI companies"" - VentureBeat
Clean Tech Company of the Year - New England Venture Capital Association
50 on Fire - BostInno
Top 100 - Red Herring
Best Consumer AI Technology - AI Dev World
Global Cleantech 100","{""role_summary"":""Work as a Data Scientist to develop and optimize machine learning models that detect and analyze energy usage in homes, contributing to Sense's mission of making homes intelligent and reducing global carbon emissions."",""key_terms"":[{""term"":""Deep learning"",""explanation"":""A subfield of machine learning that involves the use of artificial neural networks to analyze and interpret data.""},{""term"":""Time series analysis"",""explanation"":""A statistical technique used to analyze and extract insights from data that is ordered in time.""},{""term"":""Device disaggregation"",""explanation"":""The process of breaking down total energy consumption into individual device-level usage.""},{""term"":""Cloud-based and embedded systems"",""explanation"":""Refers to the deployment of machine learning models in both cloud computing environments and embedded systems, such as smart home devices.""},{""term"":""Neural network architectures"",""explanation"":""Refers to the design and structure of artificial neural networks, including types such as CNNs, RNNs, and Transformers.""}],""skill_priorities"":{""must_have"":[""Bachelor's or Master's degree in Computer Science, Machine Learning, Electrical Engineering, or a related field"",""Familiarity with deep learning frameworks like TensorFlow or PyTorch"",""Proficiency in Python and relevant data science libraries (NumPy, Pandas, Scikit-learn)"",""Strong problem-solving and analytical skills""],""nice_to_have"":[""Experience working with large datasets"",""1 to 3 years of professional experience in data science or machine learning""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of device disaggregation and how it applies to energy monitoring in smart homes?"",""example_answer"":""Device disaggregation is the process of breaking down total energy consumption into individual device-level usage. In the context of smart homes, this involves using machine learning models to identify the energy usage patterns of individual devices, such as refrigerators or air conditioners, and providing insights to homeowners to optimize their energy consumption.""},{""question"":""How do you stay updated with the latest advancements in deep learning, and how do you contribute to best practices in model development?"",""example_answer"":""I regularly read research papers and articles on deep learning, attend conferences and meetups, and participate in online forums to stay updated with the latest advancements. I contribute to best practices in model development by following established guidelines, such as those provided by TensorFlow or PyTorch, and by collaborating with senior data scientists and engineers to improve our data science infrastructure.""}],""red_flags"":[""Lack of experience with deep learning frameworks"",""Inability to work with large datasets"",""Poor problem-solving and analytical skills""],""confidence_score"":95.0}"
Data Scientist - Energy Markets,"Company Overview:

GridStor is a rapidly growing, grid-scale energy storage developer, owner and operator backed by Goldman Sachs Asset Management (“GSAM”) and led by experienced clean energy industry professionals. We acquire and develop battery storage projects in markets across North America. GridStor’s mission is to accelerate the transition to a carbon-free, resilient grid by rapidly deploying stand-alone energy storage at scale.

GridStor is based in Portland, Oregon, and offers competitive compensation and a wide selection of benefits including unlimited paid time off. Read more about life at GridStor at: https://gridstor.com/careers/

Role Summary:

GridStor is looking for an experienced Data Scientist to help advance our growing company. This role will work closely with the Analytics, Solutions, and Market Operations team members to create advanced data pipelines, design optimization tools for battery storage assets in support of trading activities, and analyze market behavior for competitor and market intelligence. The data scientist will be given significant responsibility across the modeled markets and will be exposed to dynamic market environments within a growing, entrepreneurial business. This position reports to the Vice President of Analytics.

Key Responsibilities:

Data Pipelines and ETL: Work closely with Solutions to create data pipelines that enable the development of machine learning and artificial intelligence models on platforms such as AWS using serverless functions, PostgreSQL, and various TCP application protocols, with a focus on data quality, structure, and processing.
Model Development: Design and implement sophisticated time series models to forecast and analyze asset performance, delivering actionable insights to the Commercial organization. Leverage advanced statistical techniques, machine learning, and artificial intelligence to generate robust backcasts, forecasts, and performance analyses.
Market Optimization: Maintain and develop optimization tools for day-ahead and real-time energy markets for BESS assets in coordination with the Trading Desk. Focus both on optimal bidding strategies and forecasting (short-term modeling of multiple price series).
Competitor and Market Intelligence: Develop approaches to measuring and benchmarking competitor performance and market participation across wholesale energy markets.
Reporting: Communicate key commercial takeaways to organization leadership to improve both market operations and provide feedback to stakeholders such as Development, Transmission/Interconnection, and M&A teams.


Qualifications & Competencies:

Education: Bachelor’s degree in computer science, data science, engineering, or other quantitative field, with a Masters or PhD required.
Experience: A minimum of 3+ years of prior work experience in the energy industry (developer, IPP, consulting, ISOs, or other).
Clear expertise in deploying statistical and optimization tools to wholesale power markets.
Experience and knowledge of ERCOT and CAISO market policy and protocols.
Location & Availability: Must be based in Portland or LA with periodic travel to Portland as needed. Standard 40-hour workweek, additional hours may be required as needed for projects.
Organizational Skills: Exceptional organizational abilities with keen attention to detail. Capable of managing multiple tasks simultaneously in a fast-paced environment and seeing delegated projects through to completion.
Adaptability: Ability to be agile and flexible, readily taking on tasks outside the typical scope of the role as needed.
Confidentiality: Proven ability to handle highly confidential information with utmost discretion.
Integrity & Judgment: Strong track record of excellent judgment and integrity in previous roles.
Technical Proficiency: Demonstrated proficiency in the Microsoft Office suite and TEAMS.
Visualization experience (Tableau, Qlikview, Shiny, seaborn, or other).
Experience with machine learning/artificial intelligence models on time series, linear/mixed integer programming, and stochastic modeling.
Knowledge of data pipeline development and engineering on relevant cloud platforms (AWS, GCP, Azure, etc.) and big-data technologies (ex: Hadoop).
Expertise in Python-based development environments, APIs, and packages.
Communication Skills: Excellent verbal and written communication skills.
Problem-Solving: Adaptable, with the ability to prioritize tasks effectively and approach challenges with a creative, proactive mindset.
Team Orientation: Highly motivated to support and collaborate with team members, contributing to collective success.


Compensation and Benefits:

GridStor offers an attractive Total Rewards package, including:
Competitive base salaries commensurate with experience with an annual cash bonus (based on Company and individual performance)
Generous paid leave
Employee participation in Long Term Incentive Plan
Comprehensive benefits package including medical, dental, vision, life, and disability insurance, including coverage for domestic partners and eligible domestic partner children
HSA/FSA for participating employees
401(k) plan with company match and immediate vesting
Continuing education and professional development
Cellphone reimbursement, hybrid work environment, healthy snacks, volunteer opportunities, company outings, and more.
Company Operating Principles:

GridStor’s Operating Principles represent who we are, how we work, and what we believe.

We Collaborate. We believe trust is given, not earned. We honor each other’s zone of genius and seek to challenge ideas, not each other. We listen to each other’s points of view and work hard to find the better solution. We are one team.

We Are Humble. We like hard work, but don’t make work hard. We know we have a lot to learn and never grandstand or take up all the space in the room. We are kind. We are welcoming. We are inspired by our mission to decarbonize the grid.

We Create the Future. We are curious. We go deep, search for the best idea, and then move fast. We always focus on the few things that matter most. We know there will be setbacks, so we show up every day ready to learn and be better, together.

We Show Up for Each Other. We keep each other fully informed. We seek to understand. We coach, we don’t blame. We share our points of view and seek to make each other better every day. We believe everyone creates culture in every moment, every day.

We Do Hard Things. We view challenges as opportunities. We are resilient. We are all owners, and we act like it. We understand change requires taking risks and we push ourselves and our partners. We do what is right as opposed to what might be best for any one of us.

Apply online at www.gridstor.com/careers","{""role_summary"":""GridStor is seeking an experienced Data Scientist to advance the company's growth by creating data pipelines, designing optimization tools, and analyzing market behavior for competitor and market intelligence."",""key_terms"":[{""term"":""Machine Learning"",""explanation"":""A type of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Time Series Models"",""explanation"":""Statistical models that analyze and forecast data with temporal dependencies, often used in energy markets to predict asset performance.""},{""term"":""ERCOT and CAISO"",""explanation"":""Two major wholesale energy markets in the United States, with ERCOT (Electric Reliability Council of Texas) serving Texas and CAISO (California Independent System Operator) serving California.""},{""term"":""Linear/Mixed Integer Programming"",""explanation"":""Optimization techniques used to solve complex problems with multiple variables and constraints, often applied in energy markets to optimize bidding strategies.""},{""term"":""Stochastic Modeling"",""explanation"":""A mathematical approach to model and analyze systems with uncertain outcomes, often used in energy markets to forecast and analyze asset performance.""}],""skill_priorities"":{""must_have"":[""Experience in the energy industry"",""Statistical and optimization tools expertise"",""Knowledge of ERCOT and CAISO market policy and protocols"",""Python-based development environments, APIs, and packages"",""Data pipeline development and engineering on cloud platforms (AWS, GCP, Azure, etc.)""],""nice_to_have"":[""Visualization experience (Tableau, Qlikview, Shiny, seaborn, or other)"",""Machine learning/artificial intelligence models on time series"",""Big-data technologies (ex: Hadoop)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design an optimization tool for day-ahead energy markets?"",""example_answer"":""I would use linear/mixed integer programming to develop an optimization model that takes into account market constraints and forecasts. I would also leverage machine learning algorithms to improve the accuracy of the model.""},{""question"":""How do you stay up-to-date with changes in energy market policy and protocols?"",""example_answer"":""I regularly review industry publications and attend conferences to stay informed about changes in market policy and protocols. I also network with industry professionals to stay current.""}],""red_flags"":[""Lack of experience in the energy industry"",""Inability to work with large datasets"",""Poor communication skills""],""confidence_score"":90.0}"
Data Scientist - All Levels,"Description

Interclypse is seeking Data Scientists.

The Interclypse difference is our emphasis on employee growth and development through continuous learning, mentorship, and empowerment. Interclypse employees grow in a positive cultivating work environment with endless career opportunities. Let Interclypse empower you by putting you in the driver's seat of your career.

Currently, Interclypse is seeking motivated, career and customer-oriented Data Scientists to join our team to provide exemplary support to our customers and to begin an exciting and rewarding career within Interclypse. As a Data Scientist, you will enjoy leading edge work developing innovative solutions to address data analytics challenges, to collect large volumes of data from varying sources, perform data cleansing, transformation, interpretation, inferencing, create solutions to overcome mission challenges, and communicate with interested stakeholders.

Requirements

Education

Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science is required.

Primary Responsibilities

Engage in developing innovative solutions to address data analytics challenges, to collect large volumes of data from varying sources, perform data cleansing, transformation, interpretation, inferencing, create solutions to overcome mission challenges, and communicate with interested stakeholders.
To succeed in this position; you need to be curious, creative, and tech-savvy.
You need to stay up to date with data processing software and algorithms, have an in-depth understanding of statistics and mathematics and be proficient in writing data processing algorithms.
You must be persistent and have excellent analytical and problem-solving skills.
Devise strategies for extracting semantic value from large datasets.
Develop conclusions from data using mathematics, statistics, computer science, and application specific knowledge and concisely communicate these conclusions.
Provide informed recommendations regarding competing technical solutions through awareness of the constantly shifting collections, processing, storage and analytic capabilities and limitations.

Required Skills/Experience

Experience with SQL databases and data models (e.g., PostgreSQL , Amazon Aurora)
Experience with programming in R, Python, Java
Experience with NoSQL databases ( e.g., MongoDB, Accumulo)
Experience designing data models and approaches
Experience working in a cloud environment ( e.g., AWS, Azure)
Experience with Linux
Excellent interpersonal skills and ability to get along with data scientists, engineers, and customers at all levels
Ability to work in a dynamic team-oriented environment, demonstrate teamwork and initiative, and function productively in a dynamic work environment

Desired Skills/Experience

Experience with programming in TensorFlow, PyTorch
Experience with Hadoop, MapReduce
Experience with Tableau
Experience with Cognos
Experience with designing, implementing, and using REST APIs
Experience with RDF/OWL, SPARQL, and Semantic Web technologies
Experience with Statistical and ML analytics and modeling (e.g., R, Spark, etc.) or other deep learning frameworks a plus
Experience with Data catalogs and data management
Ability to help visualize the data for analysis and to display results

Why You Might Like This Job

You’re tired of working for a massive organization.
You want to work for an established company that values your stable career.
You want to work with a team who loves their job and making cool stuff.
You want to be part of a team focused on making a positive impact.
You want to grow your skills in management or work toward becoming an expert.
You want to have the option for career mentorship, both in technology and in business.
You value a company with a strong culture of growth and support.

Benefits

Employee Impact Program. Every employee has the opportunity to define and get rewarded for their contributions they can make toward the long-term health of the company, customer, and employee. This program in combination with our comprehensive time off and leave programs allow you to design a career and compensation program that enables near infinite flexibility while ensuring both company, customer, and individual health and prosperity.
Comprehensive time off and leave programs:
31 Days (248 hours) of Paid Personal Time Off (PTO) for any vacation, holidays, illnesses, and birthdays
Parental Leave: 40 Hours
Bereavement Leave: 24 hours.
Military Reserve Leave (up to 80 hours, see employee handbook for details).
Jury Duty Leave 16 hours.
Retirement: Unlimited 401K match up to 8% of your salary up to the federal maximum
Health Insurance (Medical, Dental, Vision): Premium is 100% company paid (contact us for specific plan details).
Health Savings Account (HSA): Interclypse contributes $750 for individuals and $1500 for families
Vision Insurance
Dental Insurance includes orthodontics coverage
Life Insurance
Accidental Death and Dismemberment Insurance
Disability: Short-term and long-term disability coverage
Educational support: reimbursement up to the federal max of $5,250
Company apparel: $200 for company apparel each year
Social events: Holiday Party, Spring Picnic, Fall Picnic, happy hours and moreInterclypse isn’t your typical company. We strive to have a positive & transformational impact on our community, our industry, and individuals. We keep this focus through our motto: ""Doing What is Right"". Apply today to see how you can join our winning team and start down the career path that’s right for you!
EOE AA M/F/Vet/Disability

Interclypse is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.

The base salary range provided is not adjusted for geographic differences associated with where the work is being performed. Actual salaries will vary depending on factors including but not limited to location, candidate’s experience and education/training, internal peer equity, and market and business consideration.","{""role_summary"":""As a Data Scientist at Interclypse, you will develop innovative solutions to address data analytics challenges, collect and process large datasets, and communicate insights to stakeholders. You will stay up-to-date with data processing software and algorithms, and have excellent analytical and problem-solving skills."",""key_terms"":[{""term"":""Data Analytics"",""explanation"":""The process of extracting insights and patterns from large datasets to inform business decisions.""},{""term"":""Data Cleansing"",""explanation"":""The process of identifying and correcting errors, inconsistencies, and inaccuracies in a dataset to improve its quality.""},{""term"":""NoSQL Databases"",""explanation"":""A type of database that does not use the traditional table-based relational model, instead using a variety of other models such as key-value, document, or graph.""},{""term"":""Cloud Environment"",""explanation"":""A computing environment where resources such as servers, storage, and applications are provided as a service over the internet.""},{""term"":""Semantic Value"",""explanation"":""The process of extracting meaningful insights and patterns from large datasets to inform business decisions.""}],""skill_priorities"":{""must_have"":[""Experience with SQL databases and data models"",""Experience with programming in R, Python, or Java"",""Experience with NoSQL databases"",""Experience designing data models and approaches"",""Experience working in a cloud environment"",""Excellent interpersonal skills""],""nice_to_have"":[""Experience with TensorFlow, PyTorch"",""Experience with Hadoop, MapReduce"",""Experience with Tableau"",""Experience with Cognos"",""Experience with designing, implementing, and using REST APIs"",""Experience with RDF/OWL, SPARQL, and Semantic Web technologies"",""Experience with Statistical and ML analytics and modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of data cleansing and how you would approach it in a real-world scenario?"",""example_answer"":""Data cleansing is the process of identifying and correcting errors, inconsistencies, and inaccuracies in a dataset to improve its quality. In a real-world scenario, I would approach data cleansing by first identifying the sources of the data, then using tools such as data profiling and data quality metrics to identify errors and inconsistencies. I would then use techniques such as data normalization and data transformation to correct the errors and improve the quality of the data.""},{""question"":""How do you stay up-to-date with the latest developments in data processing software and algorithms?"",""example_answer"":""I stay up-to-date with the latest developments in data processing software and algorithms by attending industry conferences, reading industry publications, and participating in online forums and communities. I also make it a point to regularly review and update my skills in programming languages such as R, Python, and Java, and stay current with the latest developments in NoSQL databases and cloud environments.""}],""red_flags"":[""Lack of experience with SQL databases and data models"",""Lack of experience with programming in R, Python, or Java"",""Lack of experience working in a cloud environment"",""Poor interpersonal skills""],""confidence_score"":90.0}"
Staff Data Scientist,"Employee Applicant Privacy Notice

Who we are:

Shape a brighter financial future with us.

Together with our members, we’re changing the way people think about and interact with personal finance.

We’re a next-generation financial services company and national bank using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. Join us to invest in yourself, your career, and the financial world.

The role:

The Risk Data Science team is looking for a Staff Data Scientist to develop advanced machine learning models, guide measurement, strategy, and data-driven decision making to support various credit risk areas at SoFi. The Staff Data Scientist will work closely with Credit Risk, Product, Engineering teams to design solutions for credit underwriting. These tasks involve researching and applying state of the art machine learning modeling methodologies to solve complex business problems. This role is very rewarding as your work will have a direct and immediate impact on the business’ profitability.

By joining SoFi, you'll become part of a forward-thinking company that is transforming financial services for the better. We offer the excitement of a rapidly growing startup with the stability of an industry leading leadership team.

What you’ll o:

The Staff Data Scientist will help SoFi develop better data driven model solutions by:


Proactively identify opportunities and collaborate cross functionally to develop, implement, and continuously improve machine learning models and strategies that support credit underwriting
Proactively identify opportunities to apply AI and advanced machine learning approaches to solve complex business problems
Evaluate alternative data sources and external vendor solutions by defining and driving proof of concept projects to demonstrate the solutions’ business values
Explore and leverage in-house, external, and other open-source machine learning software/algorithms
Contribute in enhancing SoFi’s risk model development code base by developing customized Python scripts or packages
Collaborate with Model Risk Management team and Fair Lending team to demonstrate models are developed with high level rigor that satisfy Model Risk Management requirements, Fair Lending requirements, and other regulatory requirements
Spearhead model deployment by collaborating with cross functional teams including Credit, Product, Engineering, and Business Unit
Present model performance and insights to Credit, Risk, and Business Unit leaders


What you’ll need:


6+ years of work experience in the related areas especially unsecured loan underwriting with a Master’s or PhD degree in Statistics, Mathematics, Economics, Engineering, Computer Science, or a quantitative field.
Excellent knowledge and experience of machine learning and statistical modeling methods for supervised and unsupervised learning. These methods include (but not limited to) regression, clustering, outlier detection, novelty detection, decision trees, nearest neighbors, support vector machines, ensemble methods and boosting, neural networks, deep learning and its various applications. Continuously follow the advancement of machine learning and artificial intelligence to update your knowledge and skills in order to solve business problems with the most efficient methodologies
Strong knowledge of AI and AI safety
Strong programming skills in Python
Strong knowledge of databases and related languages/tools such as SQL, NoSQL, Hive, etc.
Strong presentation skills: able to use data to tell a clear and compelling story; comfortable with public speaking across various forums, including regulatory examinations, and able to effectively and logically communicate when information is being challenged in an open forum.
Ability and confidence to exercise influence over a wide range of individuals at different levels of technical and business leadership.
Someone who is highly motivated and drives change, is eager to learn and able to work collaboratively in a complex and fluid environment


Nice to have:


Experience in communicating with OCC, Fed, and CFPB


Compensation And Benefits

The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location.

To view all of our comprehensive and competitive benefits, visit our Benefits at SoFi page!

SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law.

The Company hires the best qualified candidate for the job, without regard to protected characteristics.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

New York applicants: Notice of Employee Rights

SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com.

Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time.

Internal Employees

If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.","{""role_summary"":""Develop advanced machine learning models to support credit risk areas, guide measurement, strategy, and data-driven decision making, and collaborate with cross-functional teams to design solutions for credit underwriting."",""key_terms"":[{""term"":""Machine learning"",""explanation"":""A type of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Credit risk"",""explanation"":""The risk of loss due to a borrower's failure to meet their debt obligations.""},{""term"":""AI safety"",""explanation"":""The practice of designing and developing artificial intelligence systems that are safe, reliable, and aligned with human values.""},{""term"":""Supervised and unsupervised learning"",""explanation"":""Types of machine learning approaches, where supervised learning involves training models on labeled data, and unsupervised learning involves training models on unlabeled data to discover patterns or relationships.""}],""skill_priorities"":{""must_have"":[""6+ years of work experience in related areas, especially unsecured loan underwriting"",""Master's or PhD degree in Statistics, Mathematics, Economics, Engineering, Computer Science, or a quantitative field"",""Excellent knowledge and experience of machine learning and statistical modeling methods"",""Strong programming skills in Python"",""Strong knowledge of databases and related languages/tools such as SQL, NoSQL, Hive, etc."",""Strong presentation skills""],""nice_to_have"":[""Experience in communicating with OCC, Fed, and CFPB""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of overfitting in machine learning and how you would prevent it in a credit risk model?"",""example_answer"":""Overfitting occurs when a model is too complex and performs well on the training data but poorly on new, unseen data. To prevent overfitting, I would use techniques such as regularization, early stopping, and cross-validation to ensure the model generalizes well to new data.""},{""question"":""How would you approach explaining complex machine learning models to non-technical stakeholders?"",""example_answer"":""I would focus on using clear, non-technical language to explain the model's purpose, inputs, and outputs. I would also use visualizations and examples to illustrate how the model works and its benefits, avoiding technical jargon and complex mathematical concepts.""}],""red_flags"":[""Lack of experience in machine learning and statistical modeling methods"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Data Scientist - Python (US Remote),"About KnowBe4

KnowBe4, the provider of the world's largest security awareness training and simulated phishing platform, is used by tens of thousands of organizations around the globe. KnowBe4 enables organizations to manage the ongoing problem of social engineering by helping them train employees to make smarter security decisions, every day.

Fortune has ranked us as a best place to work for women, for millennials, and in technology for four years in a row! We have been certified as a ""Great Place To Work"" in 8 countries, plus we've earned numerous other prestigious awards, including Glassdoor's Best Places To Work.

Our team values radical transparency, extreme ownership, and continuous professional development in a welcoming workplace that encourages all employees to be themselves. Whether working remotely or in-person, we strive to make every day fun and engaging; from team lunches to trivia competitions to local outings, there is always something exciting happening at KnowBe4.

Remote positions open to the US only.

Data scientists work closely with business stakeholders to understand their goals and identify data-driven strategies to achieve those goals. They design data modeling processes, create algorithms and predictive models to extract the insight the business needs and help analyze the data to increase the productivity and efficiency of the business.

Responsibilities

Expertise working experience with programming languages like Python, R, and SQL
Solid understanding of statistics, probability, and machine learning
Research, design, and implement Machine Learning algorithms to solve complex problems
Communicate complex concepts and statistical models to non-technical audiences through data visualizations

Required Skills

BS or equivalent plus 3 years experience
MS/Ph.D. or equivalent; no experience required
Expert-level SQL proficiency with experience in Snowflake, dbt, and Looker
Advanced Python programming with demonstrated expertise in data science libraries (numpy, pandas, matplotlib, scikit-learn)
Strong foundation in statistics and mathematical principles underlying data science algorithms
Extensive experience in developing and deploying machine learning models, including
Feature engineering and selection, Model training, validation, and testing, Sampling and data reduction techniques
Experience in establishing and implementing DataOps and MLOps best practices
Demonstrated ability to quantify and communicate business impact through data-driven insights
Track record of identifying and leading high-impact data science initiatives
Experience in building and maintaining stakeholder relationships across all organizational levels
Excellent communication skills, particularly in explaining technical concepts to non-technical audiences

The base pay for this position ranges from $100,000 - $120,000, which will vary depending on how well an applicant's skills and experience align with the job description listed above.

We will accept applications until 5/25/2025.

Our Fantastic Benefits

We offer company-wide bonuses based on monthly sales targets, employee referral bonuses, adoption assistance, tuition reimbursement, certification reimbursement, certification completion bonuses, and a relaxed dress code - all in a modern, high-tech, and fun work environment. For more details about our benefits in each office location, please visit www.knowbe4.com/careers/benefits.

Note: An applicant assessment and background check may be part of your hiring procedure.

Individuals seeking employment at KnowBe4 are considered without prejudice to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, sexual orientation or any other characteristic protected under applicable federal, state, or local law. If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please visit www.knowbe4.com/careers/request-accommodation.

No recruitment agencies, please.","{""role_summary"":""A data scientist at KnowBe4 works closely with stakeholders to identify data-driven strategies, designs data modeling processes, and develops machine learning algorithms to solve complex problems and increase business productivity."",""key_terms"":[{""term"":""Machine Learning algorithms"",""explanation"":""Computer programs that enable machines to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""DataOps and MLOps"",""explanation"":""Practices that combine data engineering, data science, and model deployment to improve collaboration, automation, and efficiency in data-driven projects.""},{""term"":""Feature engineering and selection"",""explanation"":""The process of selecting and transforming raw data into features that are suitable for modeling, to improve the performance of machine learning algorithms.""}],""skill_priorities"":{""must_have"":[""Python programming"",""SQL proficiency"",""Statistics and probability"",""Machine learning"",""Data visualization"",""Communication skills""],""nice_to_have"":[""R programming"",""Snowflake, dbt, and Looker experience"",""MS/Ph.D. or equivalent""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach feature engineering for a complex machine learning problem?"",""example_answer"":""I would start by understanding the problem and the available data, then use techniques like correlation analysis and recursive feature elimination to select the most relevant features. I would also consider using dimensionality reduction techniques like PCA or t-SNE to reduce the feature space.""},{""question"":""How do you communicate complex data insights to non-technical stakeholders?"",""example_answer"":""I use data visualization tools like Tableau or Power BI to create interactive dashboards that allow stakeholders to explore the data themselves. I also focus on telling a story with the data, highlighting key insights and recommendations in a clear and concise manner.""}],""red_flags"":[""Lack of experience with machine learning model deployment"",""Inability to communicate technical concepts to non-technical audiences""],""confidence_score"":90.0}"
Data Scientist II AI/ML,"At Claritev, we pride ourselves on being a dynamic team of innovative professionals. Our purpose is simple - we strive to bend the cost curve in healthcare for all. Our dedication to service excellence extends to all of our stakeholders - internal and external - driving us to consistently exceed expectations. We are intentionally bold, we foster innovation, we nurture accountability, we champion diversity, and empower each other to illuminate our collective potential.

Be part of our amazing transformational journey as we optimize the opportunity towards becoming a leading technology, data, and innovation voice in healthcare. Onward and upward!!! Preference will be given to candidates in and around our NYC, NY office. Other candidates in EST and CST time zones will be considered based on experience.

Job Summary

At Claritev, we are revolutionizing healthcare payments through innovative solutions and data-driven insights. As an AI Data Scientist, you will spearhead the evolution of our AI capabilities, leveraging generative AI to enhance our end-to-end operations from experimentation to deployment. You will be key in creating new AI-driven products to solve the unique and complex problems within healthcare payments and claims processing with broad impact on both the business and patient care. Join us in transforming the healthcare landscape!

Key Responsibilities

Enhance AI Operations: Utilize generative AI / ML and knowledge of statistics, data modeling, optimization, simulation and advanced mathematics to recognize patters, identify opportunities, pose business questions and make valuable discoveries leading to new and innovative products.
Lead R&D Efforts: Drive research and development using generative AI to create reusable code components and establish best practices.
Stakeholder Collaboration: Partner with stakeholders to identify opportunities for new AI-driven products through data insights.
Program-Level Initiatives: Lead initiatives focused on the initial development of AI-powered products.
Ethical AI/ML Practices: Ensure AI models are transparent, relevant, and ethically used.
Team Collaboration: Work closely with senior data scientists and other team members, fostering a culture of continuous learning and innovation.
Compliance: Ensure adherence to HIPAA regulations and data privacy standards.

Job Scope

This role requires independent work with minimal technical guidance, handling varied and complex tasks that demand intellectual curiosity and expert-level technical knowledge. You will leverage generative AI to drive innovation and efficiency in our AI operations.

,

JOB REQUIREMENTS (Education, Experience, And Training)

Education: Bachelor's in Quantitative Science; Master's or PhD preferred.
Experience: 3+ years in Quantitative Data Science, with experience in R&D and collaboration with cross-functional teams.
Technical Skills: Proficiency in data mining, model building, algorithms, simulations, and statistical techniques. Proficiency in Python and generative AI technologies preferred.
Other Skills: Problem-solving, critical thinking, creativity, organizational, and communication skills.
Preferred Experience: Healthcare, process optimization, Generative AI (GenAI), and Large Language Models (LLMs).

Compensation

The salary range for this position is $115K to $125K. Specific offers take into account a candidate’s education, experience and skills, as well as the candidate’s work location and internal equity. This position is also eligible for health insurance, 401k and bonus opportunity.

Benefits

We realize that our employees are instrumental to our success, and we reward them accordingly with very competitive compensation and benefits packages, an incentive bonus program, as well as recognition and awards programs. Our work environment is friendly and supportive, and we offer flexible schedules whenever possible, as well as a wide range of live and web-based professional development and educational programs to prepare you for advancement opportunities.

Your Benefits Will Include

Medical, dental and vision coverage with low deductible & copay
Life insurance
Short and long-term disability
401(k) + match
Generous Paid Time Off
Paid company holidays
Paid Parental Leave
Tuition reimbursement
Flexible Spending Account
Employee Assistance Program
Summer Hours

EEO STATEMENT

Claritev is an Equal Opportunity Employer and complies with all applicable laws and regulations. Qualified applicants will receive consideration for employment without regard to age, race, color, religion, gender, sexual orientation, gender identity, national origin, disability or protected veteran status. If you would like more information on your EEO rights under the law, please click here.","{""role_summary"":""Lead the development of AI capabilities to enhance healthcare payments and claims processing, creating innovative products and driving business impact."",""key_terms"":[{""term"":""Generative AI"",""explanation"":""A type of artificial intelligence that can generate new, original content, such as code or data, to enhance AI operations.""},{""term"":""HIPAA regulations"",""explanation"":""Health Insurance Portability and Accountability Act regulations, which ensure the protection of sensitive patient health information.""},{""term"":""Large Language Models (LLMs)"",""explanation"":""AI models that can process and generate human-like language, often used in natural language processing applications.""}],""skill_priorities"":{""must_have"":[""Python"",""Generative AI"",""Data mining"",""Model building"",""Algorithms"",""Simulations"",""Statistical techniques""],""nice_to_have"":[""Healthcare experience"",""Process optimization"",""Large Language Models (LLMs)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would leverage generative AI to enhance our end-to-end operations in healthcare payments?"",""example_answer"":""I would utilize generative AI to identify patterns in payment data, develop predictive models, and create new AI-driven products to streamline the payment process, ultimately reducing costs and improving patient care.""},{""question"":""How do you ensure ethical AI practices in your work?"",""example_answer"":""I ensure transparency in AI model development, consider potential biases, and adhere to HIPAA regulations to maintain data privacy and security.""}],""red_flags"":[""Lack of experience with generative AI"",""Inability to work independently with minimal technical guidance""],""confidence_score"":90.0}"
Data Scientist - Bellevue,"JOB DESCRIPTION - Data Scientist
Title: Data Scientist
Job Function: Product
Role Type: Full time
Location: Bellevue, WA
Reporting to: Head Data Scientist
Stakeholders: Project Managers/Head of Product
About Resulticks
Resulticks is a fully integrated, real-time marketing automation platform designed to help brands worldwide reach, acquire, and retain satis&#64257;ed customers. Built from the ground up by experts in marketing, technology, and business management, Resulticks enables brands to make a transformational leap to conversion-driven, growth-focused personalized engagement. With an advanced CDP at its core. Resulticks offers AI-powered omnichannel orchestration, complete analytics, next-best engagement, attribution at the segment-of-one level, and the world’s first marketing block chain.
Resulticks has been named to the Gartner’s Magic Quadrant 2022 for Multichannel Marketing Hubs for six years in a row and has been awarded with the Microsoft “Elevating Customer Experience with AI” award.
Headquartered in Singapore and New York City, Resulticks is one of the top global martech solutions servicing both B2B/B2B2C and B2C segments. Resulticks’ global presence includes the United States, India, Singapore, Indonesia, Malaysia, Vietnam, Thailand, and the Philippines.
Watch video on RESULTICKS - https://www.youtube.com/watch?v=G_OwGy6unP8
Candidate Profile
Resulticks seeks an optimistic, experienced data scientist who can analyze data and deliver insights on a regular basis to join our team.
The ideal candidate will have mathematical and statistical experience while also having a creative mind. Problem-solving is an integral skill for this position for interpreting various data sets and making clear recommendations based on that.
You must also have the ability to work in a team with members from multiple disciplines to solve any issues that may arise or improve on any processes where there is scope. The ideal candidate must be confident to present their findings and recommendations in front of senior management who will be involved in big business decisions.
Key Responsibilities
Work with large, complex data sets and solve problems by applying advanced analytical methods.
Conduct end-to-end analysis which includes data gathering, processing, visualization, etc.
Develop comprehensive understanding of data structures and metrics, advocating for change where needed.
Build and prototype analysis pipelines iteratively to provide insights at scale.
Work closely with engineers to identify opportunities for improved design and suggest improvements to products.
Make business recommendations by presenting your findings to multiple levels of stakeholders.
Research and develop forecasting, and optimization methods to improve the quality of our user facing products.
Interact cross-functionally with a wide variety of people and teams.
Pre-Requisites
5 years of relevant work experience in data science
Proficiency with data mining, mathematics, and statistical analysis
Experience with Tableau, SQL, Excel, PowerPoint, and programming languages
Ability to work effectively in a dynamic, research-oriented group that has several concurrent projects.
Desirable Skills
Experience with statistical software and database languages.
Skills in selecting the right statistical tools given a data analysis problem
Two or more years of project management experience
Professional certification.
Experience and Academic Qualifications
At minimum, MSc statistician degree in a quantitative discipline
Advanced marketing degree, or MBA is a plus
Must have authorization to work in the United States
Resulticks is an equal opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind based on race, color, gender, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws.
Powered by JazzHR
ZT8Fn6QCY5","{""role_summary"":""A data scientist responsible for analyzing complex data sets, developing insights, and presenting recommendations to stakeholders to drive business growth."",""key_terms"":[{""term"":""CDP"",""explanation"":""Customer Data Platform, a software that unifies customer data from various sources to provide a single customer view.""},{""term"":""Omnichannel orchestration"",""explanation"":""The process of integrating and managing multiple marketing channels to provide a seamless customer experience.""},{""term"":""Marketing block chain"",""explanation"":""A decentralized, transparent, and secure way to manage and track marketing data and transactions.""},{""term"":""Segment-of-one level"",""explanation"":""A level of personalization where individual customers are targeted with tailored messages and offers.""}],""skill_priorities"":{""must_have"":[""Data mining"",""Mathematics"",""Statistical analysis"",""Tableau"",""SQL"",""Excel"",""PowerPoint"",""Programming languages""],""nice_to_have"":[""Statistical software"",""Database languages"",""Project management experience"",""Professional certification""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach solving complex data analysis problems?"",""example_answer"":""I would first identify the key objectives and requirements, then break down the problem into smaller components, and finally apply advanced analytical methods to develop insights and recommendations.""},{""question"":""Can you give an example of a time when you had to present complex data insights to non-technical stakeholders?"",""example_answer"":""In my previous role, I had to present customer segmentation analysis to the marketing team. I used clear and concise language, visualizations, and storytelling to ensure they understood the insights and recommendations.""}],""red_flags"":[""Lack of experience working with large, complex data sets"",""Inability to effectively communicate technical insights to non-technical stakeholders""],""confidence_score"":90.0}"
Data Scientist I (Clinical),"Immediate need for a talented Data Scientist I (Clinical). This is a 12+months contract opportunity with long-term potential and is located in Waltham, MA (Onsite). Please review the job description below and contact me ASAP if you are interested.

Job ID:25-63119
Pay Range: $50 - $55/hour. Employee benefits include, but are not limited to, health insurance (medical, dental, vision), 401(k) plan, and paid sick leave (depending on work location).
Key Responsibilities:

Work hands-on with R&B Scientists & technicians in specific sites to upgrade current data operations and practices to build impactful ways of working.
Work hands-on with R&B users to build automated data workflows where not available (new technologies) and trouble shoot workflows that are flawed or inefficient.
In association with data continuum and digital team ensure proper functioning of data collection process, integration, software and Internet applications.
Design, develop, and modify data infrastructure and templates to help scientist accelerate the processes of data analysis and reporting.
Organize appropriate data collection and raw data processing methods at various users/experimental read outs across R&B teams leading to harmonized data management and utilization.
Resolve data ingestion issues for benchling including legacy and current data. Deploy simplification and or data automation tools
Towards Data management & Continuum
Create and implement digital tracking, inventory management, and automated QC dashboard within Benchling.
Support R&B scientists to organize and ingest unstructured data.
Collaborate with Data Science to maintain data management plans for all critical data related to test articles at R&B – Dashboards, meta data etc.
Ensure scientists at R&B have visibility and access to dashboards and meta data
Assess system performance and make recommendations and updates for hardware, software, and data storage improvements.

Key Requirements and Technology Experience:

Key Skills: Benchling, NGS, Data Visualization, computational biology, bioinformatic .
Hands on basic IT environment and script programming for automated tools in data acquisition, integration, cleaning, and data management.
Experience of programing with C#, C++ or Python, SQL.
Thorough understanding of management and data administration duties such as collection, analysis, and distribution.
In-depth understanding of modern database and information technologies and ability to organize large volumes of data.
Ability to develop tools to interface with electronic lab notebook Benchling.
Ability to develop, evaluate, and implement workflows for technology, optimize and standardized existing techniques and workflows with respect to experimental HT mRNA generation process workflow including DNA & IVT-RNA production, and in vitro/in vivo screening is desired.
Working knowledge of nucleic acids DNA/RNA analytical performance assessment tools: PCR, Cloning/plasmid generation and design, Quality control on DNA/RNA (capillary electrophoresis, UV quantification, Sanger sequencing, NGS…) is desired.
Past experience with Data mining, data base, functional analysis, machine learning algorithm, dashboarding and data visualization is desirable.
Function in highly collaborative, cross functional team (EU/US) emphasize with networking.
Open to work and to share information across different groups, as well as identify key needs.

Our client is a leading Pharmaceutical Industry, and we are currently interviewing to fill this and other similar contract positions. If you are interested in this position, please apply online for immediate consideration.

Pyramid Consulting, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, colour, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

By applying to our jobs you agree to receive calls, AI-generated calls, text messages, or emails from Pyramid Consulting, Inc. and its affiliates, and contracted partners. Frequency varies for text messages. Message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You can reply STOP to cancel and HELP for help. You can access our privacy policy here.","{""role_summary"":""Work with scientists and technicians to upgrade data operations, build automated workflows, and ensure proper data collection and management. Design and develop data infrastructure, resolve data ingestion issues, and support data management plans."",""key_terms"":[{""term"":""Benchling"",""explanation"":""An electronic lab notebook for managing and tracking experimental data.""},{""term"":""NGS"",""explanation"":""Next-Generation Sequencing, a high-throughput DNA sequencing technology.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to facilitate understanding and insights.""},{""term"":""Computational Biology"",""explanation"":""The application of computational tools and methods to analyze and interpret biological data.""},{""term"":""Bioinformatic"",""explanation"":""The use of computational tools and methods to analyze and interpret biological data, particularly in the context of genomics and proteomics.""}],""skill_priorities"":{""must_have"":[""Benchling"",""NGS"",""Data Visualization"",""Computational Biology"",""Bioinformatic"",""C#"",""C++"",""Python"",""SQL""],""nice_to_have"":[""Data Mining"",""Machine Learning Algorithm"",""Dashboarding""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would troubleshoot a flawed or inefficient data workflow?"",""example_answer"":""I would first identify the root cause of the issue, then use tools like Benchling to analyze the data and develop a plan to optimize the workflow. I would also collaborate with the R&B team to ensure a smooth implementation of the solution.""},{""question"":""How do you ensure data quality and integrity in your workflows?"",""example_answer"":""I use a combination of automated tools and manual checks to ensure data quality and integrity. I also work closely with the R&B team to develop and implement data management plans that meet their needs.""}],""red_flags"":[""Lack of experience with Benchling or similar electronic lab notebooks."",""Inability to work collaboratively in a cross-functional team.""],""confidence_score"":90.0}"
Data Scientist - (Remote - US),"Jobgether has ALL remote jobs globally. We match you to roles where you're most likely to succeed, and provide feedback on every application to help you learn. No more guesswork, application black holes, or recruiter ghosting in your job search.

For one of our clients, we are looking for a Data Scientist, remotely from the United States.

As a Data Scientist, you will be part of a growing team dedicated to improving pediatric healthcare by utilizing data science to enhance clinical outcomes for children with special healthcare needs. This role will involve developing machine learning (ML) models, analyzing data from clinical, claims, and social determinants of health (SDoH), and delivering insights that directly impact patient care. Your work will support the strategic goals of the business by providing actionable data-driven recommendations that enhance decision-making across the organization.

Accountabilities:

Work closely with business stakeholders to translate healthcare goals into actionable ML/AI models aimed at improving clinical outcomes
Collaborate with cross-functional teams to define requirements, optimize data collection, and build data assets
Develop and refine ML models using clinical, claims, and SDoH data to generate insights and improve patient care
Independently query and manage data in Snowflake, preparing it for exploratory analysis and modeling
Present findings and insights to non-technical staff in a clear and accessible manner


Requirements

At least 3 years of experience, with proficiency in Python and SQL
Strong background in study design, causal inference, hypothesis testing, and research methods
Experience in working with healthcare data and a deep understanding of its complexities is preferred
Ability to communicate technical findings to non-technical stakeholders across the organization
Experience working in a startup or growth environment is essential
Familiarity with Snowflake, AWS, and Tableau is a plus


Benefits

Base salary range of $135,000 - $170,000, plus annual bonus incentive
Competitive medical, dental, and vision insurance
Healthcare and Dependent Care FSA, and company-funded HSA
401(k) with a 4% match, vested 100% from day one
Employer-paid short and long-term disability
Life insurance equal to 1x annual salary
20 days of PTO, 10 company holidays, and 2 floating holidays
Paid new parent leave
Additional benefits to be detailed in the offer","{""role_summary"":""A Data Scientist role focused on improving pediatric healthcare by developing machine learning models and analyzing data to enhance clinical outcomes for children with special healthcare needs."",""key_terms"":[{""term"":""Machine Learning (ML) models"",""explanation"":""Statistical models that enable computers to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Social Determinants of Health (SDoH)"",""explanation"":""Non-medical factors that influence health outcomes, such as socioeconomic status, education, and environment.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and analyzing large datasets.""},{""term"":""Causal Inference"",""explanation"":""A statistical technique used to establish cause-and-effect relationships between variables.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Study design"",""Causal inference"",""Hypothesis testing"",""Research methods""],""nice_to_have"":[""Snowflake"",""AWS"",""Tableau"",""Healthcare data experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach developing a machine learning model to improve clinical outcomes for children with special healthcare needs?"",""example_answer"":""I would start by collaborating with stakeholders to understand the healthcare goals and requirements. Then, I would collect and preprocess the relevant data from clinical, claims, and SDoH sources. Next, I would develop and refine a machine learning model using Python and Snowflake, and finally, present the findings and insights to non-technical stakeholders in a clear and accessible manner.""},{""question"":""How do you ensure that your data-driven recommendations are actionable and impactful for the organization?"",""example_answer"":""I would work closely with cross-functional teams to define requirements and optimize data collection. I would also ensure that my recommendations are data-driven, well-documented, and communicated effectively to non-technical stakeholders.""}],""red_flags"":[""Lack of experience working with healthcare data"",""Inability to communicate technical findings to non-technical stakeholders""],""confidence_score"":90.0}"
"Data Scientist, Legal","We are looking for a Data Scientist to work on our eDiscovery & Information Governance Legal team. You will enjoy working with one of the richest data sets in the world, cutting edge technology, and the opportunity to have your insights turned into real world impact. Join us to dive into the technical details of our large-scale data stack. Help us to answer some of the most challenging and novel data issues facing the technology industry.

Data Scientist, Legal Responsibilities:

Collaborate with a variety of technical and non-technical stakeholders (including engineers, data scientists, and attorneys) to understand and identify data needs, understand business problems and design analytics solutions
Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
Design and communicate analytics solutions to help drive understanding across some of the largest data sets in the world
Mentor others and contribute to development of documentation, protocols and procedures, training guides, workflows, etc.

Minimum Qualifications:

3+ years of experience doing quantitative analysis
Experience with SQL and at least one programming language (e.g., Python, C, R.)
Bachelor's degree in Computer Science, Economics, or relevant technical field
Experience initiating and driving projects to completion with minimal guidance
Experience working cross-functionally and communicating technical content to general audiences

Preferred Qualifications:

MBA or Masters in a technical discipline
Experience with Unix/Linux
Experience with distributed computing (Hive/Hadoop)
Experience with Machine Learning/AI to automate tasks, identify patterns, make predictions
Experience working in technology industry

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$124,000/year to $176,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.","{""role_summary"":""Work as a Data Scientist on the eDiscovery & Information Governance Legal team, collaborating with stakeholders to identify data needs, designing analytics solutions, and mentoring others to drive insights from large-scale data sets."",""key_terms"":[{""term"":""eDiscovery"",""explanation"":""Electronic discovery, the process of identifying, collecting, and producing electronically stored information in legal proceedings.""},{""term"":""Information Governance"",""explanation"":""The set of policies, procedures, and controls implemented to manage and protect an organization's information assets.""},{""term"":""Distributed computing"",""explanation"":""A model of computing where tasks are distributed across multiple computers or nodes to improve processing power and scalability.""},{""term"":""Machine Learning/AI"",""explanation"":""The application of artificial intelligence to enable machines to learn from data, identify patterns, and make predictions or automate tasks.""}],""skill_priorities"":{""must_have"":[""Quantitative analysis"",""SQL"",""Programming language (e.g., Python, C, R.)"",""Experience working cross-functionally"",""Communication of technical content to general audiences""],""nice_to_have"":[""MBA or Masters in a technical discipline"",""Unix/Linux experience"",""Distributed computing (Hive/Hadoop) experience"",""Machine Learning/AI experience"",""Experience working in the technology industry""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a project where you had to design and implement an analytics solution to drive insights from a large-scale data set?"",""example_answer"":""In my previous role, I worked on a project to analyze customer behavior using a 10TB dataset. I designed a solution using Python and Hive to process the data, and then created visualizations to communicate the insights to stakeholders. The project resulted in a 20% increase in sales.""},{""question"":""How do you ensure data quality, security, and compliance in your analytics solutions?"",""example_answer"":""I follow a data governance framework to ensure data quality, implement data encryption and access controls for security, and comply with relevant regulations such as GDPR and CCPA.""}],""red_flags"":[""Lack of experience working with large-scale data sets"",""Inability to communicate technical content to non-technical stakeholders"",""Limited experience with distributed computing or machine learning""],""confidence_score"":90.0}"
Data Scientist (III or IV),"About the Role
Donegal Insurance Grouphas an opening fora Data Scientist (III or IV). The Data Scientist is responsible for developing predictive models and complex analytical solutions.This position may be preformed remotely or onsite at our Marietta, PA corporate office. Job Summary
Develop predictive models and complex analytical solutions in support of Underwriting, Pricing, Claims, and Marketing.
Provide requirements or build tools to integrate analytical solutions to enhance decision-making and/or refine operations
Interpret results from multiple sources using a variety of techniques, ranging from simple data aggregation via statistical analysis to complex data mining
Design, develop, and implement business solutions for the organization
Prepare big data, implement data models and develop database to support the business solutions
Work on advanced, complex technical projects or business issues requiring state of the art technical or industry knowledge. Goals are generally communicated in solution or project goal terms.
Serve as a leadership role for the work group through knowledge in the area of specialization.
Responsibilities and Duties
Identify business trends and problems through complex big data analysis
Use various quantitative modeling techniques to analyze company specific experience and external data to better market, price, and underwrite company products
Develop financial and/or quantitative models to gauge the impact of corporate decisions
Ensure duties are performed in adherence to all Federal, State, and Local laws and regulations
Comply with guidelines, policies, and directives outlined in the company handbook and department manuals
Provide timely, courteous, and quality customer service to customers
Clearly demonstrate commitment and participation to team goals and objectives
Reliable attendance and punctuality
Qualifications and Skills
Experience dependent on the level of Data Scientist. The current opening requires a minimumof 3 years of experience, at least 5 years experience preferred
Experience working with property/casualty insurance preferred
Bachelor’s Degree in Data Science, Data & Analytics, Mathematics, Statistics, Actuarial Science or related field
Master’s Degree or continuing education in a similar field preferred
PC skills to include:
Python
A Python model framework (Sklearn, Keras, H2O, Tensorflow, etc.)
Flask / Django exposure (or other web development framework exposure) for deployment focused role
Pandas package (+ data wrangling skills)
Additional preferred skills:
SQL
Docker
Linux command line
git
Data visualization
Hardware requirements
Database platforms
Industry specific software applications applicable to performance of position responsibilities
Microsoft Office applications
Starting Pay:The pay range for this position is $100,000 to $140,000 annually. The specific offer will vary based on an applicant's education, qualifications, professional experience, skills, abilities, and any applicable designations/certifications. The posted pay range reflects our ability to hire at different position titles and levels depending on background and experience. The pay range may also be adjusted based on an applicant's geographic location.The base pay is just one component of Donegal's total compensation package for employees. This role may also be eligible to participate in a discretionary annual incentive program. The amount of any bonus varies and is subject to the terms and conditions of the applicable incentive plan.Application deadline to apply is March 14, 2025. For full consideration, applications must be received by the deadline; however, the posting will be kept open until the position is filled.
To apply, please submit your resume and online application


Competitive Benefits Package


Donegal Insurance Group offers a comprehensive benefits package for all full-time, permanent positions including:



Medical, Dental, and Vision Coverage: Available to you and your dependents. Coverage begins the first of the month after start date.

401(k) with the first 3% matched at 100%: the next 6% is matched at 50%

Paid Time Off: Paid vacation, sick days, paid holidays, & bereavement days

Career Development: Including college partnership discounts and industry designation(s) reimbursements



Additional benefits include company-paid basic life insurance; short & long-term disability insurance; employee stock purchase plan; and employee assistance program (EAP). Learn more about our full benefit offerings by visiting our Benefits page.


Who We Are


Donegal Insurance Group provides commercial and personal insurance products through a network of independent agents in 21 states and across several regions of the U.S. In Texas, Colorado, Utah, New Mexico and Arizona, business is conducted under the Mountain States Insurance Group name; and in Michigan, business is conducted under the Michigan Insurance name.


Headquartered in Lancaster County, Pennsylvania, along with four (4) regional offices located in: Athens, GA, Grand Rapids, MI, Albuquerque, NM, and Glen Allen, VA, our steady growth and successes have allowed us to establish a culture of which we're proud. Check out our Glassdoor profile where our rating speaks for itself:




By joining the Donegal family, you would be joining a team of dedicated, hard-working employees, all with a common goal of providing peace of mind to our policyholders and being There when it matters most.™.


Work Arrangement


With each department and position being different, the work arrangement for a specific position will be reviewed with candidates during a initial phone screening. For a position not requiring an onsite expectation at one of our offices, the ideal candidate must live within our Donegal footprint. Current approved states are: AL, AZ, CT, DE, FL, GA, IA, IL, IN, MD, MI, MN, MO, NC, ND, NE, NH, NJ, NM, NY, OH, PA, SC, SD, TN, TX, UT, VA, WI, and, WV. (Please note, this list is subject to change without notice.)


E-Verify


Donegal Insurance Group participates in E-Verify in the following states: Alabama, Arizona, Florida, Georgia, Louisiana, Mississippi, Nebraska, North Carolina, South Carolina, Tennessee, and Utah. If you reside in one of the listed states, please review the ""Notice of E-Verify Participation"" and the ""Right to Work Poster"" on the links below:



Notice of E-Verify Participation Poster (English and Spanish)

Right to Work Poster (English and Spanish)

Powered by JazzHR
g4IygZpdPh","{""role_summary"":""Develop predictive models and complex analytical solutions to support Underwriting, Pricing, Claims, and Marketing, and provide leadership in the area of specialization."",""key_terms"":[{""term"":""Predictive models"",""explanation"":""Statistical models that forecast outcomes based on historical data and patterns.""},{""term"":""Complex analytical solutions"",""explanation"":""Advanced data analysis techniques to identify trends, patterns, and insights from large datasets.""},{""term"":""Big data"",""explanation"":""Large, complex datasets that require specialized tools and techniques to process and analyze.""},{""term"":""Data mining"",""explanation"":""The process of automatically discovering patterns, relationships, and insights from large datasets.""},{""term"":""Data visualization"",""explanation"":""The process of creating graphical representations of data to communicate insights and trends.""}],""skill_priorities"":{""must_have"":[""Python"",""Data Science"",""Mathematics"",""Statistics"",""Actuarial Science"",""Pandas"",""Data wrangling""],""nice_to_have"":[""SQL"",""Docker"",""Linux command line"",""git"",""Data visualization"",""Hardware requirements"",""Database platforms"",""Industry specific software applications"",""Microsoft Office applications""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would develop a predictive model to forecast insurance claims?"",""example_answer"":""I would start by collecting and cleaning the relevant data, then use techniques such as regression analysis or decision trees to identify patterns and relationships. I would then validate the model using techniques such as cross-validation and walk-forward optimization.""},{""question"":""How do you stay current with new developments in data science and analytics?"",""example_answer"":""I regularly read industry publications and blogs, attend conferences and webinars, and participate in online forums and communities to stay up-to-date with the latest trends and techniques.""}],""red_flags"":[""Lack of experience working with property/casualty insurance"",""Limited knowledge of data visualization tools and techniques"",""Inability to work independently and lead a team""],""confidence_score"":90.0}"
Stanowisko ds. zarządzania obszarem BI i HD-specjalność analityki biznesowej,"Nazwa jednostki organizacyjnej

ZUS III Oddział w Warszawie

Nazwa komórki organizacyjnej

Departament Statystyki i Prognoz Aktuarialnych

Miejsce pracy

ZUS III Oddział w Warszawie

Adres miejsca pracy

ul. Czerniakowska 16, 00-701 Warszawa

Województwo

mazowieckie

Nazwa stanowiska

Stanowisko ds. zarządzania obszarem BI i HD-specjalność analityki biznesowej

Zadania

Zadania

gromadzić, rejestrować, analizować i nadzorować realizację wymagań użytkowników w zakresie tworzenia i rozwoju systemów i narzędzi Business Intelligence i Hurtowni Danych w ZUS.
odpowiadać za analizę potrzeb biznesowych z obszaru analityki danych oraz ich specyfikację w formie realizowalnych wymagań dla systemów informatycznych w ramach przygotowywanych i realizowanych projektów.
utrzymywać portfel potrzeb i projektów w obszarze Business Intelligence i Hurtowni Danych .
brać udział w realizacji projektów informatycznych związanych z rozwojem środowiska Business Intelligence i Hurtowni Danych.
uczestniczyć w pracach wdrożeniowych i testowych w obszarze Business Intelligence i Hurtowni Danych.
proponować usprawnienia dla realizowanych procesów i zmiany w dokumentacji.
uczestniczyć w przygotowaniu planu rozwoju (roadmapy) dla środowiska Business Intelligence i Hurtowni Danych.
Wymagania

Wymagania Niezbędne

wykształcenie wyższe
doświadczenie zawodowe minimum 1 rok (w pracy związanej z planowaniem, tworzeniem i rozwojem w obszarach Business Intelligence i\lub Hurtowni Danych)
staż pracy ogółem minimum 2 lata

Mile Widziane

wykształcenie wyższe (matematyka, informatyka, statystyka)
doświadczenie zawodowe minimum 2 lata (w pracy związanej z planowaniem, tworzeniem i rozwojem w obszarach Business Intelligence i\lub Hurtowni Danych)

Wymagania Dodatkowe

umiejętność obsługi programów MS Office
wiedza z zakresu dobrych praktyk zbierania wymagań biznesowych
orientacja na cel
orientacja na jakość
komunikacja
współpraca
elastyczność
nastawienie na rozwój
negocjowanie i wywieranie wpływu
podejmowanie decyzji
umiejętność rozwiązywania problemów
innowacyjność

Wymagane Dokumenty

CV
listu motywacyjnego
skan dokumentów potwierdzających wykształcenie
skan dokumentów potwierdzających wymagane doświadczenie zawodowe
skan świadectw pracy dokumentujących wymagany staż pracy lub zaświadczenie o zatrudnieniu zawierające okresy zatrudnienia, w przypadku pozostania w stosunku pracy

Dokumenty należy przesyłać poprzez formularz aplikacyjny 'Aplikuj', znajdujący się na dole oferty

Dodatkowe Informacje

proces rekrutacji obejmować będzie rozmowę kwalifikacyjną (przeprowadzoną w formie zdalnej przez komunikator internetowy - wywiad on-line) lub stacjonarnie
skontaktujemy się tylko z kandydatami spełniającymi wymagania formalne
oferty niekompletne tj. niezawierające skanu, któregokolwiek wymaganego dokumentu nie będą rozpatrywane
oferty przesłane po terminie nie będą rozpatrywane
miejscem świadczenia pracy będzie Centrala ZUS lub dowolny Oddział ZUS
możliwość pracy w trybie stacjonarnym, zdalnym lub hybrydowym.
Termin, do którego należy składać dokumenty

12-02-2025

Oferujemy

Oferujemy

stabilne zatrudnienie na podstawie umowy o pracę
możliwość rozwoju zawodowego
bogaty pakiet świadczeń socjalnych
system premiowy

Zakład Ubezpieczeń Społecznych jest pracodawcą przyjaznym osobom z niepełnosprawnościami. Stwarza pracownikom optymalne środowisko pracy, uwzględniając ich potrzeby. Istnieje możliwość dostosowania stanowiska pracy i jego wyposażenia do indywidualnych potrzeb osób z niepełnosprawnościami

Wyposażenie Stanowiska Pracy

sprzęt komputerowy,
sprzęt biurowy.

Warunki Wykonywania Pracy

spełniają warunki określone wymogami bhp i ppoż.,
polegają na obsłudze komputera powyżej 4 godzin na dobę,
konieczność poruszania się po całym obiekcie,
konieczność wykonywania pracy poza biurem,
konieczność odbywania podróży służbowych,
budynek 3-piętrowy z windą oraz pomieszczeniami sanitarnymi dostosowanymi do potrzeb osób niepełnosprawnych,
stanowisko pracy zlokalizowane w pomieszczeniach biurowych na 3- piętrze,
miejsce pracy dostosowane do osób poruszających się przy pomocy wózka inwalidzkiego,
wejście do budynku jest zorganizowane z poziomu chodnika,
drzwi przy wejściu do budynku otwierają się automatycznie,
w bezpośrednim sąsiedztwie wejścia do budynku znajdują się miejsca parkingowe dla osób z niepełnosprawnościami","{""role_summary"":""Manage the development and maintenance of Business Intelligence and Data Warehouse systems, ensuring they meet user requirements and business needs."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""A set of technologies and tools used to analyze and present business data to support better decision-making.""},{""term"":""Data Warehouse"",""explanation"":""A central repository that stores data from various sources in a single location, making it easier to analyze and report on.""},{""term"":""Hurtowni Danych"",""explanation"":""Polish term for Data Warehouse, a central repository that stores data from various sources in a single location.""}],""skill_priorities"":{""must_have"":[""Experience in planning, creating, and developing Business Intelligence and/or Data Warehouse systems"",""Higher education degree"",""At least 1 year of professional experience"",""At least 2 years of overall work experience""],""nice_to_have"":[""Higher education degree in mathematics, computer science, or statistics"",""At least 2 years of professional experience in Business Intelligence and/or Data Warehouse systems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would analyze business needs and specify requirements for a Business Intelligence system?"",""example_answer"":""I would start by conducting stakeholder interviews to understand their needs and pain points. Then, I would document the requirements using a business requirements document (BRD) and ensure they are aligned with the overall business strategy.""},{""question"":""How do you stay up-to-date with the latest trends and developments in Business Intelligence and Data Warehouse systems?"",""example_answer"":""I regularly read industry blogs and attend webinars to stay current on the latest technologies and best practices. I also participate in online forums and discussion groups to network with other professionals in the field.""}],""red_flags"":[""Lack of experience in Business Intelligence and/or Data Warehouse systems"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":80.0}"
"Data Scientist, Algorithms - Pricing","Location: Software Technology Innovation Center (STIC), Menlo Park, CA, USA

We are seeking scientists and engineers with a strong fundamental understanding of various modern machine-learning methods to address highly challenging scientific & engineering problems

The Data Scientist is responsible for conducting undirected technology development and tackle open-ended data problems and questions. Drawing on an advanced degree in a quantitative field such as computer science, physics, statistics or applied mathematics, the Data Scientist demonstrates the knowledge to invent new algorithms to solve data problems.

The Data Scientist participates in the areas of data science, industrial analytics, data-driven prognostics, data mining, and machine learning. Data scientist researches and assesses next-generation technologies for data-driven modeling and optimization of complex systems and has advanced working knowledge and experience with machine learning algorithms and population-based meta-heuristic and gradient-based optimization methods.

Relationships: Reports to Software Project Manager, Engineering Manager or Team Lead

Essential Responsibilities and Duties:

Research and develop data analytics and/or machine learning systems for business applications;
Work with domain experts to understand needs and constraints;
Work with software engineers to integrate ML solutions in business workflows;
Communicate sophisticated ML concepts to management, clients, and the business community
Research and assess next-generation technologies for inference, predictive modeling, general purpose data-driven modeling and optimization of complex systems. Demonstrate advanced working knowledge and experience with, data analytics, machine learning algorithms and optimization methods.
Generate innovative ideas, establish new technology development directions, and shape and execute on technical projects.
Maintain state-of-the-art knowledge and contribute to technical discussions and reviews as an expert in related areas of responsibility.
Apply theoretical knowledge to solve industrial problems.
Process large multivariate data sets collected from equipment operations, manufacturing tests and diagnostic routines.
Communicate ideas, plans and results effectively via oral and written reports. Works effectively with peers, management, operations groups, and outside organizations
May participate in the relevant technical reviews and audits of the projects
May review, mentor and coach, while define and promote usage of standards, best practices and lessons learned
Work across multiple cross-functional teams in high visibility roles to prototype end-to-end data solutions


Qualifications & Experience:

MS / PhD in computer science, mathematics, applied statistics, physics, engineering or similar disciplines with demonstrated research capability with software experience or education
Probability theory, decision theory, statistics, machine learning, reasoning and inference frameworks
Software development skills and familiarity with database, programming, and data science development languages such as R, Python, TensorFlow and PyTorch
Experience in a few of the following areas: deep neural networks, reinforcement learning, Markov Random Fields, Bayesian networks, semi-supervised learning, computer vision, image processing, signal processing, distributed computing, and/or numerical optimization.
Familiarity with ML frameworks such as Tensorflow, PyTorch. is a plus.
Experience with big-data technologies such as Hadoop/Spark or GCP-BigQuery is a plus.
Strong oral and written communication skills
Ability to work within a team of scientists and engineers and strong oral and written communication skills
Strong data dexterity using current big data analytics tools


Behavior:

An enthusiasm for science and technology
Analytical thinker
Conscious of data quality
Strong communication skills
Function independently and in a team
Provide creative and innovative solutions


Data Scientist will work at Schlumberger Software Technology Innovation Center (STIC) at Menlo Park, California. Schlumberger STIC is the newest facility of Schlumberger, located in the Silicon Valley, working in close collaboration with major players in the Valley network. The STIC offers its professionals a broad aspect of interaction opportunities within leading software industry partners, universities and the large network of Schlumberger Technology Centers around the world, that support Schlumberger activities in more than 85 countries.

STIC is part of the Schlumberger Software Technology organization, responsible for leading the Schlumberger digital technology initiatives. As the oil and gas industry’s leading supplier of technology, integrated project management, and information solutions to customers worldwide, the Schlumberger digital technology development and management initiatives play a key role in driving of the oilfield service industry’s digital technology transformation.

Schlumberger is an equal employment opportunity employer. Qualified applicants are considered without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, status as a protected veteran or other characteristics protected by law. Schlumberger is a VEVRAA Federal Contractor – priority referral Protected Veterans requested.

#Schlumberger","{""role_summary"":""The Data Scientist is responsible for conducting undirected technology development, tackling open-ended data problems, and researching next-generation technologies for data-driven modeling and optimization of complex systems."",""key_terms"":[{""term"":""Machine Learning"",""explanation"":""A type of artificial intelligence that enables computers to learn from data without being explicitly programmed.""},{""term"":""Data Analytics"",""explanation"":""The process of examining data sets to draw conclusions and make informed decisions.""},{""term"":""Meta-heuristic"",""explanation"":""A high-level algorithm that uses heuristics to search for good solutions to complex optimization problems.""},{""term"":""Gradient-based Optimization"",""explanation"":""A method of optimization that uses gradients to find the minimum or maximum of a function.""},{""term"":""Population-based Optimization"",""explanation"":""A method of optimization that uses a population of candidate solutions to search for the optimal solution.""}],""skill_priorities"":{""must_have"":[""MS / PhD in computer science, mathematics, applied statistics, physics, engineering or similar disciplines"",""Software development skills"",""Familiarity with database, programming, and data science development languages such as R, Python, TensorFlow and PyTorch"",""Experience in machine learning algorithms and optimization methods""],""nice_to_have"":[""Familiarity with ML frameworks such as Tensorflow, PyTorch"",""Experience with big-data technologies such as Hadoop/Spark or GCP-BigQuery""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of overfitting in machine learning and how to prevent it?"",""example_answer"":""Overfitting occurs when a model is too complex and performs well on the training data but poorly on new, unseen data. To prevent overfitting, we can use regularization techniques such as L1 and L2 regularization, early stopping, and cross-validation.""},{""question"":""How do you handle missing values in a dataset?"",""example_answer"":""I would use techniques such as mean/median imputation, regression imputation, or listwise deletion depending on the nature of the data and the problem at hand.""}],""red_flags"":[""Lack of experience with machine learning algorithms and optimization methods"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Applied Scientist - Pipeline Data Science,"Company Description

Syngenta is one of the world’s leading companies with more than 27.000 employees in over 90 countries dedicated to our purpose: Bringing plant potential to life. Through world-class science, global reach and commitment to our customers we help to increase crop productivity, protect the environment and improve health and quality of life. For more information about us please go to www.syngenta.com.

Job Description

The Seeds Development department for Syngenta seeks a passionate candidate for a full-time position of:

Applied Scientist - Pipeline Data Science

Type: Permanent

Department: Seeds Development / Vegetables

Location: Durham, NC, USA

Into action

Do you thrive at the intersection of data engineering, predictive analytics, and innovation? As our Applied Scientist - Pipeline Data Science, you will play a crucial role in designing scalable data solutions that drive actionable insights. By consolidating complex datasets into robust, efficient pipelines, you’ll empower teams to make better decisions and uncover new possibilities in plant breeding. This is your opportunity to work on impactful projects in a collaborative and cutting-edge environment where data drives transformation.

The challenge

Responsibilities

As an Applied Scientist, you’ll focus on building the infrastructure that makes data accessible, reliable, and actionable for diverse stakeholders. Your key responsibilities will include:

Building Scalable Data Pipelines: Design, implement, and optimize data pipelines that integrate and consolidate data from multiple sources, ensuring seamless data flow and availability.
Ensuring Data Quality and Reliability: Develop systems to track, monitor, and maintain the quality, consistency, and integrity of data to ensure robust outputs for analysis and decision-making.
Driving Data Modeling and Mining: Create and implement processes for advanced data modeling and mining to support innovative analytical approaches.
Collaborating Across Teams: Work closely with IT, applied data science teams, and business stakeholders to align data solutions with organizational goals, addressing unique data needs efficiently.
Identify opportunities to incorporate advanced analytics, including machine learning frameworks and cloud platforms to continuously improve predictive pipelines.
Influence adoption of prediction methods, contribute towards their integration in the breeding process and the transformation of breeding schemes.

This role combines creativity and problem-solving with a focus on real-world applications. You’ll not only shape the way data is managed but also contribute to meaningful outcomes in plant breeding and sustainable agriculture. Every dataset you refine and every system you enhance will drive smarter decisions and impactful innovations.

Qualifications

Your profile

We’re Looking For a Driven And Detail-oriented Applied Scientist With a Master’s Degree In Computer Science, Statistics, Applied Mathematics, Or a Related Field. You Bring a Strong Mix Of Technical Expertise, Analytical Acumen, And a Collaborative Mindset

Programming: Proficiency in Python, R, and SQL. Experience in both relational and NoSQL databases.
Cloud Proficiency: Familiarity with AWS services and cloud infrastructure
Analytical Acumen: Exceptional analytical skills, with the ability to identify patterns and trends in large and diverse datasets and translate them into meaningful recommendations.
Collaboration & Communication: A strong team player who thrives in cross-functional settings and communicates technical concepts effectively to diverse stakeholders.
Additionally, hands-on experience with containerization tools (e.g., Docker, Kubernetes) and machine learning frameworks (e.g., Keras, PyTorch, scikit-learn), along with an interest in plant breeding or agricultural innovation, would make you an ideal fit for this role.

Take your chance!

Syngenta is proud of its unique culture and the values that are at the heart of it. We also foster a strong learning culture with plenty of opportunities for personal development. Why? Because our work matters! We offer a competitive salary package, flexible working hours and excellent benefits.

Are you ready to grow your career with us?

Additional Information

All your information will be kept confidential according to EEO guidelines.","{""role_summary"":""Design and implement scalable data solutions to drive actionable insights in plant breeding, ensuring data quality, reliability, and accessibility for diverse stakeholders."",""key_terms"":[{""term"":""Predictive analytics"",""explanation"":""Using statistical models and machine learning to forecast outcomes and make informed decisions.""},{""term"":""Data pipelines"",""explanation"":""A series of processes that extract, transform, and load data from multiple sources into a usable format.""},{""term"":""Cloud platforms"",""explanation"":""On-demand computing resources and services provided over the internet, such as AWS.""},{""term"":""Containerization tools"",""explanation"":""Software that enables packaging, shipping, and running applications in containers, such as Docker and Kubernetes.""},{""term"":""Machine learning frameworks"",""explanation"":""Software libraries that provide tools and structures for building and training machine learning models, such as Keras, PyTorch, and scikit-learn.""}],""skill_priorities"":{""must_have"":[""Python"",""R"",""SQL"",""Cloud proficiency (AWS)"",""Analytical acumen"",""Collaboration and communication skills""],""nice_to_have"":[""Containerization tools (Docker, Kubernetes)"",""Machine learning frameworks (Keras, PyTorch, scikit-learn)"",""Experience in plant breeding or agricultural innovation""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a scalable data pipeline to integrate and consolidate data from multiple sources?"",""example_answer"":""I would use a cloud-based data warehousing solution, such as AWS Redshift, to store and process large datasets. I would then implement data pipelines using tools like Apache Beam or AWS Glue to extract, transform, and load data from various sources into the data warehouse.""},{""question"":""Can you explain how you would ensure data quality and reliability in a data pipeline?"",""example_answer"":""I would implement data validation and data quality checks at each stage of the pipeline to ensure data consistency and accuracy. I would also use data profiling techniques to identify and handle outliers and anomalies.""}],""red_flags"":[""Lack of experience with cloud-based data solutions"",""Inability to communicate technical concepts effectively to non-technical stakeholders""],""confidence_score"":90.0}"
Data Scientist V,"Title: Data Scientist V
Location: Remote (EST))
Duration: 6+ Month Contract
Compensation: $84.00 - 104.00
Work Requirements: US Citizen, GC Holders or Authorized to Work in the U.S.

Job Description: Summary:
The main function of the Data Scientist is to produce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets.

Job Responsibilities:
• Apply knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvement.
• Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data.
• Generate and test hypotheses and analyze and interpret the results of product experiments.
• Work with product engineers to translate prototypes into new products, services, and features and provide guidelines for large-scale implementation.
• Provide Business Intelligence (BI) and data visualization support, which includes, but limited to support for the online customer service dashboards and other ad-hoc requests requiring data analysis and visual support.

Skills:
8+ years of experience as a Data Scientist
Experience with Media data or Media analytic companies 
Experienced in either programming languages such as SQL/Python and/or R, big data tools such as Hadoop, or data visualization tools such as Tableau.
 Experience with building data pipelines
The ability to communicate effectively in writing, including conveying complex information and promoting in-depth engagement on course topics.
Experience working with large datasets.
Education/Experience:
• Bachelors of Science degree in computer science or in a relevant field.

Our benefits package includes: 
Comprehensive medical benefits
Competitive pay
401(k) retirement plan
…and much more!
 
About INSPYR Solutions


Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.
 
INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.
 ","{""role_summary"":""The Data Scientist will develop innovative solutions using exploratory data analysis from complex datasets, applying statistical and machine learning techniques to identify opportunities and improve products."",""key_terms"":[{""term"":""Exploratory data analysis"",""explanation"":""A method of analyzing data to identify patterns and relationships, often using statistical and machine learning techniques.""},{""term"":""Predictive models"",""explanation"":""Mathematical models that use data to forecast or predict future outcomes or behaviors.""},{""term"":""Data pipelines"",""explanation"":""A series of processes that extract, transform, and load data from various sources into a target system for analysis or storage.""},{""term"":""Big data tools"",""explanation"":""Software and systems designed to handle and process large amounts of structured and unstructured data, such as Hadoop.""}],""skill_priorities"":{""must_have"":[""8+ years of experience as a Data Scientist"",""Experience with Media data or Media analytic companies"",""Programming skills in SQL/Python and/or R"",""Experience with building data pipelines"",""Ability to communicate complex information effectively""],""nice_to_have"":[""Experience with Hadoop"",""Experience with Tableau"",""Bachelors of Science degree in computer science or a relevant field""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a project where you used exploratory data analysis to identify opportunities and improve a product?"",""example_answer"":""In my previous role, I used Python and SQL to analyze customer purchase data and identified a pattern of frequent buyers. I developed a predictive model that increased sales by 15% through targeted marketing campaigns.""},{""question"":""How do you approach building and evaluating predictive models?"",""example_answer"":""I use a combination of statistical and machine learning techniques to develop models, and then evaluate them using metrics such as accuracy, precision, and recall. I also consider business requirements and iterate on the model to ensure it meets the desired outcome.""}],""red_flags"":[""Lack of experience with large datasets"",""Inability to communicate complex technical information effectively""],""confidence_score"":90.0}"
Stanowisko ds. zarządzania obszarem BI i HD-specjalność inżynierii systemów Business Intelligence,"Nazwa jednostki organizacyjnej

ZUS III Oddział w Warszawie

Nazwa komórki organizacyjnej

Departament Statystyki i Prognoz Aktuarialnych

Miejsce pracy

ZUS III Oddział w Warszawie

Adres miejsca pracy

ul. Czerniakowska 16, 00-701 Warszawa

Województwo

mazowieckie

Nazwa stanowiska

Stanowisko ds. zarządzania obszarem BI i HD-specjalność inżynierii systemów Business Intelligence

Zadania

Zadania

zapewniać utrzymanie i rozwój architektury biznesowej i technicznej obszaru Business Intelligence
współpracować w realizacji zleceń analityczno-raportowych pochodzących od komórek i jednostek biznesowych Zakładu
odpowiadać za proponowanie, budowanie i wdrażanie rozwiązań z zakresu technologii przetwarzania dużych zbiorów danych (Big Data), m.in. modelowania danych, wizualizacji danych
uczestniczyć w przygotowaniu planu rozwoju (roadmapy) dla środowiska Business Intelligence i Hurtowni Danych
uczestniczyć w planowaniu inicjatyw i projektów mających na celu rozbudowę i optymalizację wykorzystywanych rozwiązań Business Intelligence
uczestniczyć w pracach projektowych, wdrożeniowych i testowych w obszarze Business Intelligence
wspierać użytkowników w ramach wdrożeń systemów i narzędzi w obszarze Business Intelligence
proponować usprawnienia dla realizowanych procesów i zmiany w dokumentacji
współpracować w realizacji zleceń analityczno-raportowych pochodzących od komórek i jednostek biznesowych Zakładu
Wymagania

Wymagania Niezbędne

wykształcenie wyższe
doświadczenie zawodowe minimum 1 rok (w pracy związanej z planowaniem, tworzeniem i rozwojem w obszarach Business Intelligence i\lub Hurtowni Danych)
staż pracy ogółem minimum 2 lata

Mile Widziane

wykształcenie wyższe (matematyka, informatyka, statystyka)
doświadczenie zawodowe minimum 2 lata (w pracy związanej z planowaniem, tworzeniem i rozwojem w obszarach Business Intelligence i\lub Hurtowni Danych)

Wymagania Dodatkowe

umiejętność obsługi programów MS Office
znajomości tworzenia szablonów formularzy lub raportów dynamicznych
znajomość tworzenia paneli wizualizacyjnych lub cocpitów
orientacja na cel
orientacja na jakość
komunikacja
współpraca
elastyczność
nastawienie na rozwój
negocjowanie i wywieranie wpływu
podejmowanie decyzji
umiejętność rozwiązywania problemów
innowacyjność

Wymagane Dokumenty

CV
listu motywacyjnego
skan dokumentów potwierdzających wykształcenie
skan dokumentów potwierdzających wymagane doświadczenie zawodowe
skan świadectw pracy dokumentujących wymagany staż pracy lub zaświadczenie o zatrudnieniu zawierające okresy zatrudnienia, w przypadku pozostania w stosunku pracy

Dokumenty należy przesyłać poprzez formularz aplikacyjny 'Aplikuj', znajdujący się na dole oferty

Dodatkowe Informacje

proces rekrutacji obejmować będzie rozmowę kwalifikacyjną (przeprowadzoną w formie zdalnej przez komunikator internetowy - wywiad on-line) lub stacjonarnie
skontaktujemy się tylko z kandydatami spełniającymi wymagania formalne
oferty niekompletne tj. niezawierające skanu, któregokolwiek wymaganego dokumentu nie będą rozpatrywane
oferty przesłane po terminie nie będą rozpatrywane
miejscem świadczenia pracy będzie Centrala ZUS lub dowolny Oddział ZUS
możliwość pracy w trybie stacjonarnym, zdalnym lub hybrydowym.
Termin, do którego należy składać dokumenty

12-02-2025

Oferujemy

Oferujemy

stabilne zatrudnienie na podstawie umowy o pracę
możliwość rozwoju zawodowego
bogaty pakiet świadczeń socjalnych
system premiowy

Zakład Ubezpieczeń Społecznych jest pracodawcą przyjaznym osobom z niepełnosprawnościami. Stwarza pracownikom optymalne środowisko pracy, uwzględniając ich potrzeby. Istnieje możliwość dostosowania stanowiska pracy i jego wyposażenia do indywidualnych potrzeb osób z niepełnosprawnościami

Wyposażenie Stanowiska Pracy

sprzęt komputerowy,
sprzęt biurowy.

Warunki Wykonywania Pracy

spełniają warunki określone wymogami bhp i ppoż.,
polegają na obsłudze komputera powyżej 4 godzin na dobę,
konieczność poruszania się po całym obiekcie,
konieczność wykonywania pracy poza biurem,
konieczność odbywania podróży służbowych,
budynek 3-piętrowy z windą oraz pomieszczeniami sanitarnymi dostosowanymi do potrzeb osób niepełnosprawnych,
stanowisko pracy zlokalizowane w pomieszczeniach biurowych na 3- piętrze,
miejsce pracy dostosowane do osób poruszających się przy pomocy wózka inwalidzkiego,
wejście do budynku jest zorganizowane z poziomu chodnika,
drzwi przy wejściu do budynku otwierają się automatycznie,
w bezpośrednim sąsiedztwie wejścia do budynku znajdują się miejsca parkingowe dla osób z niepełnosprawnościami","{""role_summary"":""The role is responsible for maintaining and developing the business intelligence and technical architecture, proposing and implementing big data solutions, and supporting users in the implementation of business intelligence systems."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""The practice of using data and analytics to inform business decisions.""},{""term"":""Big Data"",""explanation"":""Large and complex datasets that require specialized processing and analysis.""},{""term"":""Data Modeling"",""explanation"":""The process of creating a conceptual representation of data structures and relationships.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to facilitate understanding and decision-making.""}],""skill_priorities"":{""must_have"":[""Experience in business intelligence and data analysis"",""Knowledge of data modeling and data visualization"",""Ability to work with MS Office""],""nice_to_have"":[""Higher education in mathematics, computer science, or statistics"",""Experience in creating reports and dashboards"",""Knowledge of data governance and quality""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of data warehousing and how it is used in business intelligence?"",""example_answer"":""A data warehouse is a centralized repository that stores data from various sources in a single location, making it possible to analyze and report on the data. In business intelligence, data warehousing is used to create a single source of truth for reporting and analysis, enabling organizations to make data-driven decisions.""},{""question"":""How do you approach data modeling and what are some best practices you follow?"",""example_answer"":""I approach data modeling by first understanding the business requirements and then designing a conceptual data model that meets those requirements. Some best practices I follow include using entity-relationship diagrams, normalizing data, and using data governance principles to ensure data quality and consistency.""}],""red_flags"":[""Lack of experience in business intelligence and data analysis"",""Inability to work with MS Office"",""Poor communication and collaboration skills""],""confidence_score"":80.0}"
Data Scientist (L5) - Games Product Measurement Research,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

We are seeking a Senior Data Scientist with strong causal inference and experimentation experience to elevate and evolve the Games experience for our members. In this role, you will lead Games research to establish core product metrics and tradeoffs and deepen our understanding of product behavior among gamers. Working in a highly collaborative and cross-functional environment, you will be responsible for partnering with our Product and Engineering teams to identify, incubate, and enable product innovations leveraging robust measurement techniques (e.g. experimentation, modeling, analytics).

As a Data Scientist, you’ll be at the forefront of product innovation and measurement. You’ll work with other data scientists, research scientists, data and analytics engineers, and business teams to drive product vision and advance measurement strategy through new metrics, methodological approaches, and deep-dive analyses. You will be jumping in at a critical time in our Games adventure - this is an exciting time to help us redefine what a Netflix subscription means for our members around the world!

In This Role, You Will

Drive causal inference research to establish a robust measurement of game engagement within the Netflix ecosystem, informing core product metrics, innovation budgets, and tradeoffs.
Develop experimentation and measurement frameworks to increase the velocity of investments and aid complex decision-making, including long-term holdback and meta-analysis approaches.
Deepen our understanding of product behavior among gamers to guide strategy for game promotion on our shared product canvases.
Establish strong partnerships with PMs, data scientists, and engineers across the company to improve our product understanding and measurement approaches.
Be flexible to changing circumstances—Netflix Games and our core Product experience are evolving rapidly, and this role will help shape that joint evolution.

To Be Successful In This Role, You Have

Advanced degree in Statistics, Mathematics, Computer Science, Economics, or related quantitative field.
5+ years of relevant experience designing experiments and conducting causal studies with demonstrated impact. ML depth is a plus.
Strong Quantitative Programming skills in a language such as Python.
Exceptional oral and written communication skills, with demonstrated experience managing large stakeholder landscapes.
Passion for driving product vision and innovation strategy by leveraging a broad set of techniques and building strong partnerships with stakeholders.
Ability to work independently and drive your own projects.
Embodies Netflix values while bringing a new perspective to continue to improve our culture.

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000.

Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.

Netflix is a unique culture and environment. Learn more here.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.","{""role_summary"":""Lead Games research to establish core product metrics and tradeoffs, and deepen understanding of product behavior among gamers as a Senior Data Scientist at Netflix."",""key_terms"":[{""term"":""Causal Inference"",""explanation"":""A statistical technique to establish cause-and-effect relationships between variables, used to measure game engagement and inform product metrics.""},{""term"":""Experimentation"",""explanation"":""A method to test hypotheses and measure the impact of product changes on user behavior, used to drive product innovation and measurement strategy.""},{""term"":""Meta-Analysis"",""explanation"":""A statistical technique to combine results from multiple studies to draw more general conclusions, used to aid complex decision-making.""}],""skill_priorities"":{""must_have"":[""Advanced degree in Statistics, Mathematics, Computer Science, Economics, or related quantitative field"",""5+ years of relevant experience designing experiments and conducting causal studies"",""Strong Quantitative Programming skills in Python"",""Exceptional oral and written communication skills""],""nice_to_have"":[""ML depth""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design an experiment to measure the impact of a new game feature on user engagement?"",""example_answer"":""I would use a randomized controlled trial to isolate the effect of the new feature, and then use causal inference techniques to estimate the treatment effect. I would also consider using techniques like propensity scoring to ensure that the treatment and control groups are comparable.""},{""question"":""How do you stay up-to-date with new developments in causal inference and experimentation?"",""example_answer"":""I regularly read research papers and attend conferences in the field, and I also participate in online forums and discussion groups to stay current with best practices.""}],""red_flags"":[""Lack of experience with experimentation and causal inference"",""Poor communication skills""],""confidence_score"":95.0}"
"Data Scientist, Product Analytics","As a Data Scientist at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Oculus). By applying your technical skills, analytical mindset, and product intuition to one of the richest data sets in the world, you will help define the experiences we build for billions of people and hundreds of millions of businesses around the world. You will collaborate on a wide array of product and business problems with a wide-range of cross-functional partners across Product, Engineering, Research, Data Engineering, Marketing, Sales, Finance and others. You will use data and analysis to identify and solve product development's biggest challenges. You will influence product strategy and investment decisions with data, be focused on impact, and collaborate with other teams. By joining Meta, you will become part of a world-class analytics community dedicated to skill development and career growth in analytics and beyond.Product leadership: You will use data to shape product development, quantify new opportunities, identify upcoming challenges, and ensure the products we build bring value to people, businesses, and Meta. You will help your partner teams prioritize what to build, set goals, and understand their product's ecosystem.Analytics: You will guide teams using data and insights. You will focus on developing hypotheses and employ a varied toolkit of rigorous analytical approaches, different methodologies, frameworks, and technical approaches to test them.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Scientist, Product Analytics Responsibilities:

Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches
Apply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products that serve billions of people and hundreds of millions of businesses
Identify and measure success of product efforts through goal setting, forecasting, and monitoring of key product metrics to understand trends
Define, understand, and test opportunities and levers to improve the product, and drive roadmaps through your insights and recommendations
Partner with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions

Minimum Qualifications:

A minimum of 6 years of work experience in analytics (minimum of 4 years with a Ph.D.)
Bachelor's degree in Mathematics, Statistics, a relevant technical field, or equivalent practical experience
Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R)

Preferred Qualifications:

Master's or Ph.D. Degree in a quantitative field

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$173,000/year to $242,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.","{""role_summary"":""As a Data Scientist at Meta, you will shape the future of people-facing and business-facing products by applying technical skills, analytical mindset, and product intuition to one of the richest data sets in the world."",""key_terms"":[{""term"":""Data Mining"",""explanation"":""The process of automatically discovering patterns or relationships in large datasets.""},{""term"":""Quantitative Analysis"",""explanation"":""A method of analyzing data using mathematical and statistical techniques to understand behavior and trends.""},{""term"":""Product Analytics"",""explanation"":""The process of using data and analysis to inform product development, quantify opportunities, and identify challenges.""}],""skill_priorities"":{""must_have"":[""Experience with data querying languages (e.g. SQL)"",""Experience with scripting languages (e.g. Python)"",""Experience with statistical/mathematical software (e.g. R)"",""Bachelor's degree in Mathematics, Statistics, a relevant technical field, or equivalent practical experience""],""nice_to_have"":[""Master's or Ph.D. Degree in a quantitative field""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a complex dataset to identify trends and opportunities?"",""example_answer"":""I would start by cleaning and preprocessing the data, then use statistical and machine learning techniques to identify patterns and correlations. I would also consider using data visualization tools to communicate my findings effectively.""},{""question"":""How do you stay up-to-date with new developments in data science and analytics?"",""example_answer"":""I regularly read industry blogs and research papers, attend conferences and meetups, and participate in online forums to stay current with the latest techniques and tools.""}],""red_flags"":[""Lack of experience working with large and complex datasets"",""Inability to communicate technical insights effectively to non-technical stakeholders""],""confidence_score"":95.0}"
Associate Data Scientist,"Req137897

Key Responsibilities

Implement data science projects that drive profitability, optimize efficiency, and enhance customer experience.
Develop solutions by applying advanced machine learning methods and algorithms for identifying trends and providing business solutions.
Create and implement algorithms and models for analyzing large datasets yielding valuable business insights.
Support data science projects by conducting effective analysis to solve business problems.
Execute tasks with high levels of efficiency and quality.
Consult with Data Scientists or Senior Data Scientists on appropriate selection, utilization, and interpretation of advanced analytical methodologies.
Gain familiarity with the relevant business domains to enhance problem-solving by integrating domain-specific expertise.
Articulate findings and recommendations to both technical and non-technical stakeholders with clarity and impact.
Provide reports, updates and/or presentations related to progress made on a project or solution.
Highlight potential impacts of recommendations to drive alignment and appropriate implementation.
Stay up to date on industry trends, best practices, and emerging methodologies.
Continuously improve your data science skills and seek out practical applications for your knowledge.
Telecommuting available.

Minimum Qualifications

Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Master’s degree in Business Analytics, Supply Chain Management, Mathematics, Statistics, Economics, or a related field. The following skills are required:
Python and SQL
Statistics and Probability
Machine Learning Techniques

Apply End Date: 03/27/2025","{""role_summary"":""This role involves implementing data science projects to drive profitability, optimize efficiency, and enhance customer experience. The Data Scientist will develop and apply advanced machine learning methods to analyze large datasets, provide business insights, and solve business problems."",""key_terms"":[{""term"":""Machine Learning"",""explanation"":""A type of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Algorithms"",""explanation"":""A set of instructions used to analyze data, identify patterns, and make predictions or decisions.""},{""term"":""Data Science"",""explanation"":""The process of extracting insights and knowledge from data using various techniques, including machine learning and statistical analysis.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Statistics and Probability"",""Machine Learning Techniques""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach a project to optimize efficiency using machine learning?"",""example_answer"":""I would start by collecting and preprocessing the relevant data, then apply machine learning algorithms to identify trends and patterns. I would also consider factors such as data quality, model interpretability, and scalability to ensure the solution is effective and practical.""},{""question"":""How do you stay current with industry trends and emerging methodologies in data science?"",""example_answer"":""I regularly read industry publications, attend conferences, and participate in online forums to stay up-to-date on the latest developments in data science. I also experiment with new tools and techniques to apply them to real-world problems.""}],""red_flags"":[""Lack of experience with Python and SQL"",""Inability to articulate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Machine Learning / Research Engineer - Deep Learning - Capital Markets,"Machine Learning / Research Engineer - Python, C++, CUDA
Capital Markets - Tier 1 Finance Firm
Miami, FL
FTE

As a Machine Learning / Research Engineer you will advance the deep learning library at a leading global market maker, collaborating closely with researchers to enhance functionality and optimize workflows for improved training speeds and cost efficiency. Leveraging cutting-edge technologies and financial market expertise, your work will enable over 100 researchers to accelerate their agendas and unlock new experimental possibilities.

In this role, you will grow and maintain the internal deep learning library, integrating open-source tools with proprietary systems. You’ll work with researchers to identify needs, add functionality, and collaborate with HPC experts to optimize distributed workflows. This includes scaling PyTorch-based workflows, applying Python, CUDA, and C++ expertise, and ensuring the system remains at the forefront of innovation.

The ideal candidate has 5+ years of experience in machine learning and software development, strong distributed systems skills, and a proven track record with large-scale deep learning frameworks.","{""role_summary"":""Develop and maintain a deep learning library to support researchers in a financial market maker, improving training speeds and cost efficiency."",""key_terms"":[{""term"":""Deep learning library"",""explanation"":""A collection of software tools and frameworks used for building and training artificial intelligence models.""},{""term"":""PyTorch"",""explanation"":""An open-source machine learning framework used for building and training AI models.""},{""term"":""CUDA"",""explanation"":""A parallel computing platform and programming model developed by NVIDIA for general computing on its graphics processing units (GPUs).""},{""term"":""HPC"",""explanation"":""High-performance computing, which refers to the use of supercomputers and parallel processing techniques to solve complex computational problems.""}],""skill_priorities"":{""must_have"":[""Machine learning"",""Software development"",""Distributed systems"",""Large-scale deep learning frameworks"",""Python"",""C++"",""CUDA""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize the performance of a deep learning model on a distributed computing system?"",""example_answer"":""I would use techniques such as data parallelism, model parallelism, and pipeline parallelism to distribute the computation across multiple machines. I would also leverage tools like PyTorch's DistributedDataParallel module to simplify the process.""},{""question"":""Can you describe a project where you integrated open-source tools with proprietary systems?"",""example_answer"":""In my previous role, I integrated the TensorFlow framework with our company's proprietary data processing pipeline to build a real-time object detection system. I worked closely with the research team to ensure seamless integration and optimized performance.""}],""red_flags"":[""Lack of experience with large-scale deep learning frameworks"",""Inability to work with distributed systems""],""confidence_score"":90.0}"
ML Research Scientist,"Seer are currently partnered with an AI-powered drug discovery business pushing the frontier of state-of-the-art generative Machine Learning models for biomolecular design.

They're now searching for ML Research Scientists/Engineers with the following experience:

Experience:
4+ years of experience building and running deep learning models.
Demonstrated capability to summarize scientific content to navigate complex and unknown problems.
Experience working with industrial scale models on distributed infrastructure.
Experience with Protein Generative Models or Molecular Biology are a plus.

Responsibilities:
Build machine learning tooling and library code that enables an efficient, flexible, and scalable platform
Integrate feedback from biological labs performing large-scale experiments on proteins and cancer cells.
Build and run deep learning models, preferably with LLMs.
Manage cloud-based state-of-the-art generative models for biomolecular design.

They're offering competitive salaries and benefits packages with the role being fully remote across the East Coast!","{""role_summary"":""Develop and implement machine learning models for biomolecular design, integrating feedback from biological labs and managing cloud-based generative models."",""key_terms"":[{""term"":""Generative Machine Learning models"",""explanation"":""Machine learning models that generate new, unique outputs, such as protein structures, rather than simply predicting existing ones.""},{""term"":""Distributed infrastructure"",""explanation"":""A computer system that uses multiple machines or nodes to process large amounts of data, often used for industrial-scale machine learning models.""},{""term"":""Protein Generative Models"",""explanation"":""Machine learning models that generate new protein structures or sequences, often used in biomolecular design.""},{""term"":""LLMs"",""explanation"":""Large Language Models, a type of deep learning model that processes and generates human-like language, often used in natural language processing tasks.""}],""skill_priorities"":{""must_have"":[""Building and running deep learning models"",""Experience with industrial scale models on distributed infrastructure"",""Ability to summarize scientific content to navigate complex and unknown problems""],""nice_to_have"":[""Experience with Protein Generative Models"",""Experience with Molecular Biology""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to integrate feedback from multiple stakeholders to improve a machine learning model?"",""example_answer"":""In my previous role, I worked with a team of biologists to integrate feedback from their experiments into our deep learning model, which improved its accuracy by 20%. I had to communicate complex technical concepts to non-technical stakeholders and navigate conflicting opinions to find a solution that worked for everyone.""},{""question"":""How do you approach scaling deep learning models to industrial scale on distributed infrastructure?"",""example_answer"":""I've used distributed computing frameworks like Hadoop and Spark to scale my deep learning models to industrial scale. I've also implemented data parallelism and model parallelism to optimize model training and inference times.""}],""red_flags"":[""Lack of experience with cloud-based infrastructure"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
AI Data Scientist,"AI Data Scientist Full-time | Remote (U.S.-based) | Entry Level

Company Overview: Insilicom provides AI-driven solutions to harness Big Data and accelerate research and development efforts in both industry and academia. We specialize in document retrieval, information extraction, knowledge management, and knowledge discovery using knowledge graph-based AI algorithms.

Position Summary: We are seeking an innovative AI Data Scientist to join our team in advancing biomedical research through artificial intelligence. This role combines expertise in machine learning, deep learning, and large language models (LLMs) with a focus on biomedical data analysis and natural language processing.

Work Authorization: Must be legally authorized to work in the United States (including OPT, H-1B, or other valid work authorizations)

Key Responsibilities:
●    Develop and implement advanced deep learning and NLP models for biomedical data analysis.
●    Design, optimize, and fine-tune LLMs (e.g., GPT-4, Claude, or similar models) for entity recognition, classification, relation extraction, and text generation.
●    Lead end-to-end model development, from data preprocessing to production deployment, ensuring scalable and efficient performance.
●    Utilize neural network architectures (transformers, RNNs, CNNs, etc.) for various machine learning tasks.
●    Engineer and optimize prompting techniques for improving LLM performance in knowledge discovery and information retrieval.
●    Collaborate with cross-functional teams to integrate AI models into production pipelines.
●    Conduct thorough model evaluation, hyperparameter tuning, and performance optimization.
●    Maintain well-documented, modular, and reusable Python code and AI model repositories.
●    Stay current with cutting-edge research in AI, machine learning, and NLP, and apply best practices.

Required Qualifications:
●    Master's or Ph.D. in Computer Science, Statistics, Computational Biology, Bioinformatics, Physics, or related fields.
●    Strong proficiency in Python (NumPy, Pandas, TensorFlow, PyTorch, Hugging Face Transformers).
●    Experience with Linux OS, shell scripting, and version control (Git).
●    Expertise in:
Neural networks and deep learning architectures (e.g., transformers, LSTMs, CNNs).
Natural Language Processing (NLP) and information retrieval techniques.
LLM prompt engineering and optimization (e.g., GPT-4, Claude).
Large-scale data processing, training, and fine-tuning models.
●    Proven ability to develop, optimize, and deploy machine learning models in production environments.
●    Strong analytical, problem-solving, and collaborative skills.
 Preferred Qualifications:
●    Hands-on experience with fine-tuning transformer-based architectures (e.g., BERT, T5, LLaMA).
●    Familiarity with cloud platforms (AWS, GCP, Azure) for AI model deployment.
●    Advanced knowledge of feature engineering, hyperparameter tuning, and model optimization.
●    Published research or industry experience in ML/AI, NLP, or LLMs.
●    Strong communication skills with the ability to explain complex AI models to non-technical stakeholders.

Application Requirements:
1.   Resume/CV (PDF format)
2.   Responses to the following questions in your LinkedIn application:
Educational background confirmation
Technical expertise verification
Machine learning knowledge assessment
U.S. work authorization status

Application Process: Rolling applications with priority consideration for early submissions. Candidates are encouraged to apply promptly, as interviews will begin immediately.","{""role_summary"":""Develop and implement AI models for biomedical data analysis, focusing on natural language processing and machine learning."",""key_terms"":[{""term"":""LLMs"",""explanation"":""Large Language Models, such as GPT-4 or Claude, used for entity recognition, classification, and text generation.""},{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of AI that deals with the interaction between computers and human language.""},{""term"":""Knowledge Graph"",""explanation"":""A graph data model used to store and query large amounts of data, often used in knowledge discovery and information retrieval.""},{""term"":""Transformers"",""explanation"":""A type of neural network architecture used in NLP, particularly in language translation and text generation tasks.""}],""skill_priorities"":{""must_have"":[""Python"",""Neural networks and deep learning architectures"",""Natural Language Processing (NLP) and information retrieval techniques"",""LLM prompt engineering and optimization"",""Large-scale data processing, training, and fine-tuning models""],""nice_to_have"":[""Hands-on experience with fine-tuning transformer-based architectures"",""Familiarity with cloud platforms (AWS, GCP, Azure) for AI model deployment"",""Advanced knowledge of feature engineering, hyperparameter tuning, and model optimization"",""Published research or industry experience in ML/AI, NLP, or LLMs""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach optimizing a large language model for biomedical data analysis?"",""example_answer"":""I would start by fine-tuning the model on a relevant dataset, then experiment with different hyperparameters and prompt engineering techniques to improve performance. I would also consider using techniques like transfer learning and ensemble methods to further optimize the model.""},{""question"":""Can you explain the concept of knowledge graphs and how they can be applied in biomedical research?"",""example_answer"":""A knowledge graph is a graph data model that stores and queries large amounts of data. In biomedical research, knowledge graphs can be used to integrate and analyze data from various sources, such as publications, clinical trials, and genomic data. This can help researchers to identify patterns and relationships that may not be immediately apparent.""}],""red_flags"":[""Lack of experience with large language models or natural language processing"",""Inability to explain complex AI models to non-technical stakeholders""],""confidence_score"":95.0}"
Machine Learning Engineer (L4/5) - Studio Media Algorithms,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

The Studio Media Algorithms team is at the forefront of innovation to enhance and support the vision of the creators of movies, TV shows and other multimedia work. This team's work is responsible for increasing member value, and driving efficiency of the content creation process, ultimately creating more joy for viewers all over the world. To learn more about the domain, here are some links related to what we do: Creating Media with Machine Learning and Computer Vision Research at Netflix.

We are looking for a software engineer with experience in the machine learning (ML), computer vision (CV), and/or graphics domain to design and develop scalable systems and infrastructure for that effort. These systems will be used by our researchers to develop CV, graphics, audio, and natural language processing (NLP) algorithms to analyze, create, and transform media assets.

In This Role, You Will

Design and develop systems and reusable algorithms and frameworks for the full cycle of machine learning in the multimedia domain, such as data processing, feature extraction, distributed model training with GPUs, and deploying the produced models into production.
Collaborate cross-functionally with research scientists, product managers, as well as creative and business partners and stakeholders, to help define and prioritize system requirements.
Work closely with ML/CV/Graphics researchers and Studio teams to productize algorithms and models, and efficiently run human-in-the-loop inference tasks.
Participate in algorithm development and propose scalable designs.
Promote and facilitate software engineering best practices in the team.

About You

Industry experience with machine learning engineering in a production setting
Passion for turning ideas into products and improving the user experience
Experience with research and comfort with the ambiguity of an emerging field
Skills in OO programming (Python, Java, or C++)
Experience with ML, CV, and/or graphics pipelines
Excellent communication and people engagement skills
Experience with large-scale distributed data processing systems and cloud infrastructure
Industry experience in the content creation domain, such as animation, games, or visual effects
Experience with models and tools for generative models, such as Diffusion models and ComfyUI

Bonus Experience

Building end-to-end multimedia systems and algorithms
Deep learning frameworks such as PyTorch and Tensorflow
Computer graphics and VFX tools and game engines such as Unreal Engine, Unity, Maya, or Nuke

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $150,000 - $750,000.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.","{""role_summary"":""Design and develop scalable systems and infrastructure for machine learning, computer vision, and graphics domains to support content creation and enhance user experience."",""key_terms"":[{""term"":""Machine Learning (ML)"",""explanation"":""A subset of artificial intelligence that enables systems to learn from data and improve their performance without being explicitly programmed.""},{""term"":""Computer Vision (CV)"",""explanation"":""A field of study that focuses on enabling computers to interpret and understand visual information from the world.""},{""term"":""Graphics Domain"",""explanation"":""A field of study that deals with the creation and manipulation of visual content, including images, videos, and 3D models.""},{""term"":""Natural Language Processing (NLP)"",""explanation"":""A subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""},{""term"":""Distributed Model Training with GPUs"",""explanation"":""A process of training machine learning models across multiple machines, utilizing Graphics Processing Units (GPUs) to accelerate computation.""},{""term"":""Human-in-the-Loop Inference Tasks"",""explanation"":""A process that involves human input and feedback to improve the accuracy and efficiency of machine learning models.""}],""skill_priorities"":{""must_have"":[""Machine learning engineering experience in a production setting"",""OO programming skills (Python, Java, or C++)"",""Experience with ML, CV, and/or graphics pipelines"",""Excellent communication and people engagement skills"",""Experience with large-scale distributed data processing systems and cloud infrastructure""],""nice_to_have"":[""Experience with building end-to-end multimedia systems and algorithms"",""Deep learning frameworks such as PyTorch and Tensorflow"",""Computer graphics and VFX tools and game engines such as Unreal Engine, Unity, Maya, or Nuke"",""Industry experience in the content creation domain, such as animation, games, or visual effects""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing and developing scalable systems for machine learning in the multimedia domain?"",""example_answer"":""I would focus on creating modular and reusable algorithms and frameworks, leveraging distributed computing and cloud infrastructure to ensure scalability and efficiency.""},{""question"":""Can you share an experience where you had to collaborate with cross-functional teams to develop and deploy machine learning models?"",""example_answer"":""In my previous role, I worked with researchers, product managers, and engineers to develop and deploy a computer vision model for image classification, which resulted in a 30% increase in accuracy.""}],""red_flags"":[""Lack of experience with machine learning engineering in a production setting"",""Inability to communicate technical concepts to non-technical stakeholders"",""Limited experience with large-scale distributed data processing systems and cloud infrastructure""],""confidence_score"":90.0}"
"Data Scientist, Executive Analytics","Airtable is the no-code app platform that empowers people closest to the work to accelerate their most critical business processes. More than 500,000 organizations, including 80% of the Fortune 100, rely on Airtable to transform how work gets done.

Airtable's innovative approach to end-user software creation is rapidly expanding, making it an exciting time to join our Finance Analytics Team as a Data Scientist. In this crucial role, you will report directly to the Head of Analytics and work directly with Airtable’s CEO and Leadership Team. Your strategic insights will be instrumental in navigating our financial landscape and ensuring that our metrics align with the priorities of the CEO and Leadership Team.

This role offers the opportunity to significantly impact Airtable's strategy, providing you with a platform to deploy your data skills in a way that directly contributes to our company’s growth and success.

What You'll Do

Strategic Analysis: Drive in-depth financial analysis to ensure the accuracy and relevance of key metrics, aligning them with the CEO's and Leadership Team's strategic priorities. Tackle ambiguous problems to uncover business value with minimal oversight.
Communication Skills: Effectively communicate the “so-what” of an analysis, illustrating how insights can be leveraged to drive business impact across the organization.
Partner with Executive Leadership: Provide analytical insights and direct support to the CEO and Leadership Team, influencing high-level financial strategies and critical decision-making processes.
Define Executive-Level Metrics: Address complex, ambiguous business challenges by developing clear, consistent, and actionable metrics that provide transparency and track business performance at the highest levels.
Champion Data Excellence for Leadership: Foster a culture of high-standard data practices and experimentation, enhancing the analytical capabilities and decision-making power of the CEO and Leadership Team.
Develop Executive Dashboards: Design, build, and maintain sophisticated dashboards and KPIs, providing the CEO and Leadership Team with real-time insights into the company’s financial health and strategic performance.

Who You Are

6-10 year experience as a data scientist - preferable working with leadership teams at high growth startups.
Skilled in Looker Semantic Modeling and BI Tooling: Expertise in building self-service data sets in Looker, enabling easy consumption by Finance Team members and the broader company.
Detail-Oriented Investigator: Driven by curiosity to explore data beyond the surface, discovering essential insights that guide strategic decisions.
Experienced Financial Data Analyst: With at least 6 years in roles like Data Scientist, Analyst, or Engineer, you possess deep expertise in financial data strategy.
Skilled in Data Translation: Excel at transforming complex data into meaningful, actionable insights, effectively storytelling to impact high-level financial strategies.
Technically Proficient: Proficient in SQL and tools like R or Python, you handle large datasets with ease, ensuring data integrity and accessibility.
Effective Communicator: You communicate complex data insights clearly and effectively, making sophisticated analytical concepts accessible to a non-technical audience.

Airtable is an equal opportunity employer. We embrace diversity and strive to create a workplace where everyone has an equal opportunity to thrive. We welcome people of different backgrounds, experiences, abilities, and perspectives. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status or any characteristic protected by applicable federal and state laws, regulations and ordinances. Learn more about your EEO rights as an applicant.

VEVRAA-Federal Contractor

If you have a medical condition, disability, or religious belief/practice which inhibits your ability to participate in any part of the application or interview process, please complete our Accommodations Request Form and let us know how we may assist you. Airtable is committed to participating in the interactive process and providing reasonable accommodations to qualified applicants.

Compensation awarded to successful candidates will vary based on their work location, relevant skills, and experience.

Our total compensation package also includes the opportunity to receive benefits, restricted stock units, and may include incentive compensation. To learn more about our comprehensive benefit offerings, please check out Life at Airtable.

For work locations in the San Francisco Bay Area, Seattle, New York City, and Los Angeles, the base salary range for this role is:

$188,100 - $266,400 USD

For all other work locations (including remote), the base salary range for this role is:

$169,300 - $239,800 USD

Please see our Privacy Notice for details regarding Airtable’s collection and use of personal information relating to the application and recruitment process by clicking here.","{""role_summary"":""As a Data Scientist in Airtable's Finance Analytics Team, you will drive strategic financial analysis, communicate insights to executive leadership, and develop executive-level metrics to inform business decisions."",""key_terms"":[{""term"":""Looker Semantic Modeling"",""explanation"":""A data modeling technique used in Looker to create self-service data sets for easy consumption by non-technical stakeholders.""},{""term"":""BI Tooling"",""explanation"":""Business Intelligence tooling refers to the use of software and systems to analyze and present business data in a way that facilitates better decision-making.""}],""skill_priorities"":{""must_have"":[""6-10 years of experience as a Data Scientist"",""Expertise in Looker Semantic Modeling and BI Tooling"",""Deep expertise in financial data strategy"",""Proficiency in SQL and tools like R or Python""],""nice_to_have"":[""Experience working with leadership teams at high-growth startups""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for developing executive-level metrics to inform business decisions?"",""example_answer"":""I would start by understanding the CEO's and Leadership Team's strategic priorities, then identify the key metrics that align with those priorities. I would develop clear, consistent, and actionable metrics that provide transparency and track business performance at the highest levels.""},{""question"":""How do you effectively communicate complex data insights to a non-technical audience?"",""example_answer"":""I would focus on storytelling, using clear and concise language to explain complex data insights in a way that resonates with the audience. I would also use visualizations and dashboards to illustrate the insights and make them more accessible.""}],""red_flags"":[""Lack of experience working with executive leadership teams"",""Inability to effectively communicate complex data insights""],""confidence_score"":95.0}"
Senior Data Scientist - Deep Learning focus,"Senior/Principal Data Scientist - Deep Learning Focus

About Sense:

Our mission at Sense is to make all homes intelligent by keeping people informed about what's happening in their homes, and helping to make homes safer, more efficient, and more reliable.

At Sense, we are serious about having a real impact on climate change.

The technology team at Sense is looking for an experienced data scientist to help us build the ""large language model"" of electrical devices and energy.

About the Role:

We are seeking a motivated and experienced Senior/Principal Data Scientist to join our team. You will play a crucial role in developing and deploying state-of-the-art deep learning models to solve challenging problems in time series analysis and energy. You will have the opportunity to work with large, complex datasets and contribute to the entire model development lifecycle, from data exploration and preprocessing to model training, evaluation, and deployment. Models are deployed to both cloud and embedded systems where they power our consumer application and real-time embedded applications on electrical meters.

Responsibilities:

Design, develop, and implement deep learning models for device disaggregation
Conduct thorough data analysis and preprocessing to prepare data for model training
Train and evaluate deep learning models using appropriate metrics and techniques. Contribute to curation of ground truth.
Experiment with different model architectures and hyperparameters to optimize model performance
Collaborate with a cross-functional team to deploy, maintain, and support deep learning models in production environments
Stay up-to-date with the latest advancements in deep learning research and technologies
Contribute to the development of our data science infrastructure and best practices
Mentor and guide junior data scientists


Requirements

Qualifications:

Advanced degree (Master's or Ph.D.) in Computer Science, Machine Learning, Statistics, Electrical Engineering, Computer Engineering, or a related field
5+ years (Senior) / 8+ years (Principal) of experience in data science, with a strong focus on deep learning
Experience in training and deploying deep neural networks using popular frameworks such as TensorFlow, PyTorch, or Keras
Solid understanding of deep learning architectures (CNNs, RNNs, Transformers, etc.) and their applications
Proficiency in programming languages such as Python and experience with relevant libraries (e.g., NumPy, Pandas, Scikit-learn)
Experience working with large datasets
Strong communication and collaboration skills
Must be authorized to work in the U.S","{""role_summary"":""Develop and deploy deep learning models to analyze time series data and energy usage, contributing to the development of intelligent homes and tackling climate change."",""key_terms"":[{""term"":""Deep learning"",""explanation"":""A subfield of machine learning that uses neural networks to analyze and interpret data.""},{""term"":""Time series analysis"",""explanation"":""A method of analyzing data points in a sequence to identify patterns and trends over time.""},{""term"":""Device disaggregation"",""explanation"":""The process of identifying and separating individual devices' energy usage from a total energy consumption signal.""},{""term"":""Embedded systems"",""explanation"":""Computer systems with a specific function, embedded in devices such as electrical meters, to control and interact with the device.""}],""skill_priorities"":{""must_have"":[""Deep learning experience"",""Python programming"",""Experience with deep learning frameworks (TensorFlow, PyTorch, Keras)"",""Strong understanding of deep learning architectures (CNNs, RNNs, Transformers)""],""nice_to_have"":[""Experience with large datasets"",""Mentoring or guiding junior data scientists""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of device disaggregation and how you would approach it using deep learning?"",""example_answer"":""Device disaggregation involves separating individual devices' energy usage from a total energy consumption signal. I would approach this by using deep learning models such as sequence-to-sequence or graph neural networks to analyze the time series data and identify patterns specific to each device.""},{""question"":""How do you stay up-to-date with the latest advancements in deep learning research and technologies?"",""example_answer"":""I regularly read research papers and articles on deep learning, attend conferences and meetups, and participate in online forums and discussions to stay current with the latest developments and trends.""}],""red_flags"":[""Lack of experience with deep learning frameworks"",""Inability to communicate complex technical concepts effectively""],""confidence_score"":95.0}"
Data Scientist (Marketing Science),"Job Title: Data Scientist (Marketing Science)
Locations: Remote
Duration: 06 Months to start
W2 Contract

The main function of the Data Scientist is to produce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets.

Must-Have Skills:
The role is more focused on marketing science and advertising performance
Experience with building data pipelines and working with large datasets
Experienced in either programming languages such as SQL/Python and big data tools such as Hadoop, or data visualization tools such as Tableau
The ability to communicate effectively in writing, including conveying complex information and promoting in-depth engagement on course topics.

Nice-to-have Skills:
Experience with Media data or Media analytics companies
Experience with Marketing, from the advertising/business teams

Education/Experience:
Bachelors of Science degree in computer science or in a relevant field.","{""role_summary"":""Develop innovative solutions using complex data analysis to drive marketing science and advertising performance."",""key_terms"":[{""term"":""Exploratory data analysis"",""explanation"":""A statistical approach to analyze and summarize datasets to identify patterns and relationships.""},{""term"":""High-dimensional datasets"",""explanation"":""Large datasets with many variables or features, requiring specialized techniques for analysis.""},{""term"":""Data pipelines"",""explanation"":""A series of processes to extract, transform, and load data from various sources into a usable format.""},{""term"":""Big data tools"",""explanation"":""Software and frameworks designed to handle and process large datasets, such as Hadoop.""},{""term"":""Data visualization tools"",""explanation"":""Software used to create interactive and dynamic visualizations of data, such as Tableau.""}],""skill_priorities"":{""must_have"":[""Experience with building data pipelines"",""Experience with large datasets"",""Programming skills in SQL/Python"",""Experience with big data tools or data visualization tools"",""Effective written communication skills""],""nice_to_have"":[""Experience with Media data or Media analytics companies"",""Experience with Marketing, from the advertising/business teams""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a data pipeline for a large-scale marketing campaign?"",""example_answer"":""I would start by identifying the data sources, then design a pipeline using tools like Apache NiFi or AWS Glue to extract, transform, and load the data into a data warehouse. Next, I would implement data quality checks and validation to ensure data accuracy.""},{""question"":""How do you stay up-to-date with the latest developments in big data tools and technologies?"",""example_answer"":""I regularly follow industry blogs and attend webinars to stay current with the latest advancements in big data tools like Hadoop and Spark. I also participate in online forums and communities to learn from others and share my own experiences.""}],""red_flags"":[""Lack of experience with marketing science and advertising performance"",""Inability to communicate complex data insights effectively""],""confidence_score"":85.0}"
Machine Learning Engineer - Early in Career,"Splunk, a Cisco company, is building a safer and more resilient digital world with an end-to-end full stack platform made for a hybrid, multi-cloud world. Leading enterprises use our unified security and observability platform to keep their digital systems secure and reliable. Our customers love our technology, but it's our caring employees that make Splunk stand out as an amazing career destination. No matter where in the world or what level of the organization, we approach our work with kindness. So bring your work experience, problem-solving skills and talent, of course, but also bring your joy, your passion and all the things that make you, you. Come help organizations be their best, while you reach new heights with a team that has your back.

Role Summary

Splunk is looking for Bachelor’s or Master's graduates to join our team! As a Machine Learning Engineer, you will work on a real project (or a few) and have an opportunity to enjoy our dynamic environment.

You will experience Splunking and what defines our culture while honing the skills which separate our development teams from others. Working to support internal and external customer needs, you will collaborate with multi-functional teams, receive mentorship, and gain insight into our values-driven process. Our goal is both to support your growth and development while empowering you for a successful start to your career.

What you'll get to do

Integrate AI/ML solutions into Splunk products and services
Achieve data science and software engineering goals set by you and your mentor
Learn about Splunk, both the product and the company
Collaborate closely with software engineers, data scientists, and product managers

Must-have Qualifications

Actively pursuing a Bachelor’s or Master's in Computer Science, Software Engineering, Computer Engineering, Electrical Engineering, Mathematics or a related technical field, and a strong record of academic achievement

Nice-to-have Qualifications

We’ve taken special care to separate the must-have qualifications from the nice-to-haves. “Nice-to-have” means just that Nice. To. Have. So, don’t worry if you can’t check off every box. We’re not hiring a list of bullet points–we’re interested in the whole you.

Coursework or research experience in artificial intelligence and machine learning topics such as time series analysis (univariate and multivariate), anomaly detection, generative AI technology and Large Language Models (LLM)
Experience programming in a large software project – at school, professionally, or in an open source context
Coursework and project or internship experience in big data systems or distributed systems
Exposure to ML frameworks (e.g., TensorFlow, PyTorch, Ray, vLLM) and Python
Ability to work well with others in a fast-paced environment
Strong communication skills, verbal and written
Enthusiasm for solving interesting problems

Splunk is an Equal Opportunity Employer

Splunk, a Cisco company, is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, national origin, genetic information, age, disability, veteran status, or any other legally protected basis.

Note

Base Pay Range

SF Bay Area, Seattle Metro, and New York City Metro Area

Base Pay Range $119,200.00 - 163,900.00 per year

California (excludes SF Bay Area), Washington (excludes Seattle Metro), Washington DC Metro, and Massachusetts

Base Pay Range $107,280.00 - 147,510.00 per year

All other cities and states excluding California, Washington, Massachusetts, New York City Metro Area and Washington DC Metro Area.

Base Pay Range $95,360.00 - 131,120.00 per year

Splunk provides flexibility and choice in the working arrangement for most roles, including remote and/or in-office roles. We have a market-based pay structure which varies by location. Please note that the base pay range is a guideline and for candidates who receive an offer, the base pay will vary based on factors such as work location as set out above, as well as the knowledge, skills and experience of the candidate. In addition to base pay, this role is eligible for incentive compensation and may be eligible for equity or long-term cash awards.

Benefits are an important part of Splunk's Total Rewards package. This role is eligible for a competitive benefits package which includes medical, dental, vision, a 401(k) plan and match, paid time off and much more! Learn more about our next-level benefits at https //splunkbenefits.com.","{""role_summary"":""As a Machine Learning Engineer, you will work on real projects, collaborate with multi-functional teams, and gain insight into our values-driven process, while honing your skills and supporting internal and external customer needs."",""key_terms"":[{""term"":""AI/ML"",""explanation"":""Artificial Intelligence and Machine Learning, referring to the integration of AI/ML solutions into Splunk products and services.""},{""term"":""Time series analysis"",""explanation"":""A type of data analysis that deals with time-stamped data, used in anomaly detection and other machine learning applications.""},{""term"":""Generative AI technology"",""explanation"":""A type of AI that involves generating new data or content, such as images, text, or music, using machine learning models.""},{""term"":""Large Language Models (LLM)"",""explanation"":""A type of AI model that is trained on large amounts of text data to generate language outputs, such as chatbots or language translation systems.""}],""skill_priorities"":{""must_have"":[""Bachelor's or Master's in Computer Science, Software Engineering, Computer Engineering, Electrical Engineering, Mathematics or a related technical field""],""nice_to_have"":[""Coursework or research experience in artificial intelligence and machine learning topics"",""Experience programming in a large software project"",""Coursework and project or internship experience in big data systems or distributed systems"",""Exposure to ML frameworks (e.g., TensorFlow, PyTorch, Ray, vLLM) and Python"",""Ability to work well with others in a fast-paced environment"",""Strong communication skills, verbal and written"",""Enthusiasm for solving interesting problems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would integrate AI/ML solutions into a software product?"",""example_answer"":""I would start by identifying the specific problem or opportunity where AI/ML can add value, then select the most suitable ML framework and algorithm for the task, and finally implement and test the solution to ensure it meets the product requirements.""},{""question"":""How do you approach collaboration with cross-functional teams in a fast-paced environment?"",""example_answer"":""I prioritize open communication, active listening, and clear goal-setting to ensure everyone is aligned and working towards the same objectives. I also make sure to be flexible and adaptable to changing requirements and priorities.""}],""red_flags"":[""Lack of experience with AI/ML frameworks and Python"",""Inability to work collaboratively in a fast-paced environment""],""confidence_score"":90.0}"
Manufacturing Data Scientist,"Company Overview

KLA is a global leader in diversified electronics for the semiconductor manufacturing ecosystem. Virtually every electronic device in the world is produced using our technologies. No laptop, smartphone, wearable device, voice-controlled gadget, flexible screen, VR device or smart car would have made it into your hands without us. KLA invents systems and solutions for the manufacturing of wafers and reticles, integrated circuits, packaging, printed circuit boards and flat panel displays. The innovative ideas and devices that are advancing humanity all begin with inspiration, research and development. KLA focuses more than average on innovation and we invest 15% of sales back into R&D. Our expert teams of physicists, engineers, data scientists and problem-solvers work together with the world’s leading technology providers to accelerate the delivery of tomorrow’s electronic devices. Life here is exciting and our teams thrive on tackling really hard problems. There is never a dull moment with us.

Job Description/Preferred Qualifications

Manufacturing and Tools Data Scientist is responsible for collecting, analyzing, and interpreting data from KLA products during various stages of a manufacturing process to identify trends, inefficiencies, and opportunities for improvement, utilizing data visualization tools to present findings and collaborate with cross-functional teams to implement data-driven solutions for optimized production and quality control.

This is an enabling Role to support the analysis based on the data generated during the manufacturing process of KLA tools
This is a single contributor member of a multi-disciplinary team with common goals
Design and enable the creation of an analytics platform for Manufacturing
Create clear and concise data visualizations (charts, graphs, dashboards using Power BI) to communicate insights to stakeholders and decision-makers.
Develop Analytics using statistical methods, heuristics and ML Models.
Develop project plans and timelines for Analytics Products
Act as liaison between the business (Manufacturing) and the IT organization (Snowflake, Power BI and Software Developers)
Prepare the Business Requirement Document for all Analytics project derived from the tools during the manufacturing process.


Preferred Qualifications:

Proficiency in Snowflake
Bachelor's degree or equivalent experience in statistics, mathematics, computer science, industrial engineering, or a related field


Minimum Qualifications

Minimum of 5 years of related experience with a bachelor's degree; or 3 years with a master’s degree
2- 4 years of Validated experience in data analysis and reporting using data analytics tools, and working on Cloud based Data Warehouse
Expertise in data visualization tools (e.g., Tableau, Power BI)
Ability to work in a multicultural team, and with groups located in other regions like: Israel, Singapore, Wales and Germany
Ability to communicate complex subjects in simple terms is fundamental
Proficiency in SQL for data extraction and manipulation.
Programming languages like Python is a must
Experience in a manufacturing environment with a strong understanding of production processes
Excellent project Management Skills, with experience on leading and implementing Analytics Products


Base Pay Range: $88,900.00 - $151,100.00 Annually

Primary Location: USA-MI-Ann Arbor-KLA

KLA’s total rewards package for employees may also include participation in performance incentive programs and eligibility for additional benefits including but not limited to: medical, dental, vision, life, and other voluntary benefits, 401(K) including company matching, employee stock purchase program (ESPP), student debt assistance, tuition reimbursement program, development and career growth opportunities and programs, financial planning benefits, wellness benefits including an employee assistance program (EAP), paid time off and paid company holidays, and family care and bonding leave.

Interns are eligible for some of the benefits listed. Our pay ranges are determined by role, level, and location. The range displayed reflects the pay for this position in the primary location identified in this posting. Actual pay depends on several factors, including state minimum pay wage rates, location, job-related skills, experience, and relevant education level or training. We are committed to complying with all applicable federal and state minimum wage requirements where applicable. If applicable, your recruiter can share more about the specific pay range for your preferred location during the hiring process.

KLA is proud to be an Equal Opportunity Employer. We do not discriminate on the basis of race, religion, color, national origin, sex, gender identity, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other status protected by applicable law. We will ensure that qualified individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us at talent.acquisition@kla.com or at +1-408-352-2808 to request accommodation.

Be aware of potentially fraudulent job postings or suspicious recruiting activity by persons that are currently posing as KLA employees. KLA never asks for any financial compensation to be considered for an interview, to become an employee, or for equipment. Further, KLA does not work with any recruiters or third parties who charge such fees either directly or on behalf of KLA. Please ensure that you have searched KLA’s Careers website for legitimate job postings. KLA follows a recruiting process that involves multiple interviews in person or on video conferencing with our hiring managers. If you are concerned that a communication, an interview, an offer of employment, or that an employee is not legitimate, please send an email to talent.acquisition@kla.com to confirm the person you are communicating with is an employee. We take your privacy very seriously and confidentially handle your information.","{""role_summary"":""The Manufacturing and Tools Data Scientist collects, analyzes, and interprets data from KLA products during various stages of a manufacturing process to identify trends, inefficiencies, and opportunities for improvement."",""key_terms"":[{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to communicate insights and trends.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform used for storing and processing large amounts of data.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that provides interactive visualizations and business intelligence capabilities.""},{""term"":""ML Models"",""explanation"":""Machine Learning models used for predictive analytics and data-driven decision making.""}],""skill_priorities"":{""must_have"":[""Proficiency in Snowflake"",""Experience in data visualization tools (e.g., Tableau, Power BI)"",""Ability to work in a multicultural team"",""Ability to communicate complex subjects in simple terms"",""Proficiency in SQL for data extraction and manipulation"",""Programming languages like Python""],""nice_to_have"":[""Bachelor's degree or equivalent experience in statistics, mathematics, computer science, industrial engineering, or a related field"",""Experience in a manufacturing environment with a strong understanding of production processes"",""Excellent project Management Skills, with experience on leading and implementing Analytics Products""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data visualization for a complex manufacturing process?"",""example_answer"":""I would use tools like Power BI to create interactive dashboards that provide real-time insights into production trends and inefficiencies. I would also work closely with stakeholders to ensure that the visualizations meet their needs and are easy to understand.""},{""question"":""How do you stay up-to-date with new developments in machine learning and data analytics?"",""example_answer"":""I regularly read industry blogs and attend conferences to stay current with the latest advancements in ML and data analytics. I also participate in online forums and communities to learn from others and share my own experiences.""}],""red_flags"":[""Lack of experience working with cloud-based data warehousing platforms"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Machine Learning Research Engineer/Scientist,"Machine Learning Research Engineer/Scientist
$2500,000 - $450,000 + Equity + Flexible PTO + Benefits + Progression

Are you passionate about working on the edge of AI innovation, and looking for a high impact role within a well-funded startup that’s looking to rethink how AI should be implemented within government post-AGI?

This is an excellent opportunity to join a high-calibre team in a role that blends theoretical research with practical application, within a fast-paced, start-up meritocracy.

My client is looking to reshape the outdated government AI automation space, in order to allow agencies to focus on iteration and improvement, as opposed to development. This is a massive use case that is currently largely underserved by incumbent enterprises – something this company is looking to change.

Within this role, you will be building AI agents for specialised government tasks across a range of applications, with a strong focus on bring groundbreaking research into practical use.

This role would be an excellent fit for someone looking to join a fast-paced, mission driven team whist having a huge real-world impact on the deployment of compliant AI within government.

The Person:
Strong portfolio of research projects
Has worked at a top AI/ML company
Looking to join a fast paced startup

The Role:
Build AI agents for specialised government tasks
Research ML/RL theory
5 days a week on site in New York, NY
Strong benefits package","{""role_summary"":""Work on the edge of AI innovation, building AI agents for specialized government tasks and researching ML/RL theory, in a fast-paced startup environment."",""key_terms"":[{""term"":""AGI"",""explanation"":""Artificial General Intelligence, referring to AI that can perform any intellectual task that a human can.""},{""term"":""RL"",""explanation"":""Reinforcement Learning, a subfield of machine learning that involves training agents to make decisions based on rewards or penalties.""},{""term"":""ML"",""explanation"":""Machine Learning, a subfield of artificial intelligence that involves training models to make predictions or decisions based on data.""}],""skill_priorities"":{""must_have"":[""Strong portfolio of research projects"",""Experience working at a top AI/ML company""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a research project you led that involved building AI agents for specialized tasks?"",""example_answer"":""In my previous role, I led a project that involved building AI agents for natural language processing tasks. I designed and implemented the architecture, and worked with a team to deploy it in a production environment.""},{""question"":""How do you stay current with the latest developments in ML/RL theory?"",""example_answer"":""I regularly read research papers and attend conferences to stay current with the latest developments in ML/RL theory. I also participate in online forums and discussion groups to stay connected with other researchers in the field.""}],""red_flags"":[""Lack of experience working in a fast-paced startup environment"",""Limited experience with building AI agents for government tasks""],""confidence_score"":80.0}"
"Scientist, Data","Journey with us! Combine your career goals and sense of adventure by joining our incredible team of employees at Royal Caribbean Group. We are proud to offer a competitive compensation and benefits package, and excellent career development opportunities, each offering unique ways to explore the world. We are proud to be the vacation-industry leader with global brands — including Royal Caribbean International, Celebrity Cruises and Silversea Cruises — the most innovative fleet and private destinations, and the best people. Together, we are dedicated to turning the vacation of a lifetime into a lifetime of vacations for our guests.

Royal Caribbean Group’s Data Analytics has an exciting career opportunity for a full time Scientist, Data reporting to the Senior Manager , Data Science.

This position will work on-site in Miami, Florida.

Position Summary

Royal Caribbean is seeking a seasoned, experienced and inquisitive Data Scientist that will lead our Research & Development initiatives and assimilate new, cutting-edge technologies into our broader Artificial Intelligence and Machine Learning capabilities. The position demands an inquisitive individual who can direct a team of other data scientists and machine learning professionals to deliver.

This Data Scientist will focus on architecting, deploying and evaluating the feasibility of emerging technologies within the fields of Data Science, Artificial Intelligence and Machine Learning. They are expected to work independently and in collaboration with other Data Scientists to explore new capabilities that will continue to keep Royal Caribbean Cruise Lines ahead of its competitors in this space. While research oriented, the success of role will be dependent on the tangible value their efforts and the efforts of the Data Science team will add.

Essential Duties And Responsibilities

A successful candidate will possess a strong background, either professionally or academically, in statistics, mathematics, artificial intelligence, research methods, experiment design, developing novel solutions beyond the use of well-established methods, and taking new technologies to a prototype state that can be expanded into a robust product.
The candidate should demonstrate a progressive maturation of prior research projects, publications, patents or similar capabilities in the field of applied research.
This individual will be responsible for scripting / programming, mentorship, stakeholder presentation, collaboration with other team members to execute a research experiment within the framework of implementing, utilizing and expanding R&D capabilities within the broader Data Science team.

Major Responsibilities Include

Research and apply emerging forms of statistical, machine learning (neural networks / deep networks, ensemble methods, natural language processing, computer vision) and engineering methods to Royal Caribbean Cruise Lines, data science and AI ecosystem.
Must be comfortable doing so with little or not documentation or reliance on research articles and papers.
Evaluate the progress of Data Scientists, the AI & Robotics team, and company at large on the acclimation of research methods towards the rapid delivery of experimental technologies to a prototype state.
Execute these objectives with respect to both purely exploratory endeavors as well as established products requiring novel ingenuity to meet known stakeholder objectives.
Manipulates high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships and trends.
Empower and enhance the capabilities of Data Scientists and the AI & Robotics team as whole to properly design R&D explorations, rapidly experiment with, prototype, and demonstrate the viability of in-house research.
Collaborate with Digital, IT, Business stakeholders to design and implement R&D prototypes into broader automated systems and establish a Minimum Viable Product.
Assist with research related to customer based analytical practice and develop communications for management and strategies for building institutional knowledge. Work with product and enterprise teams via both Agile and Waterfall Methodologies.
Foster a data-driven culture based on pragmatism and strategic decision through rigorous factual analysis at all levels. Should be willing to engage outside the immediate team to expand data science footprint throughout organization.

Qualifications, Knowledge And Skills

Master’s degree required in Statistics, Operations Research, Mathematics, Economics, Computer Science, Engineering, Physics, Chemical Engineering or field of comparable foundations in mathematical and statistical analysis through the use of models, algorithms or programmed solutions.
5+ years’ experience with any of the following programming languages: R, Python, Java, C++, C#, Scala, SAS, MATLAB or similar scripting languages. Similar experience and proficiency with SQL required.
5+ years’ experience across a breadth of data science, AI and machine learning disciplines including, but not limited to: forecasting, natural language processing (topic modeling, semantic search, text classification), deep learning and GPU-based algorithms (CNN, LSTM), computer vision
5+ years designing experiments and researching novel solutions beyond established literature or documentation
Experience with data mining processes (SEMMA, CRISP-DM), data preparation, consolidation, imputation, transformation, interaction, variable reduction, modeling, maintenance, and post-mortem analysis.
Experience with statistical methods such t-test of means, Tukey-HSD tests of means on groups, ANOVA, Proportion tests, data normalization and scaling, univariate and multivariate outlier detection.
Experience with modeling techniques such as linear models, decision trees, neural networks, k-nearest-neighbor, support vector machines, cluster analyses, and ensemble methods.
Strong Oral and Written skills.

We know there's a lot to consider. As you go through the application process, our recruiters will be glad to provide guidance, and more relevant details to answer any additional questions. Thank you again for your interest in Royal Caribbean Group. We'll hope to see you onboard soon!

It is the policy of the Company to ensure equal employment and promotion opportunity to qualified candidates without discrimination or harassment on the basis of race, color, religion, sex, age, national origin, disability, sexual orientation, sexuality, gender identity or expression, marital status, or any other characteristic protected by law. Royal Caribbean Group and each of its subsidiaries prohibit and will not tolerate discrimination or harassment.","{""role_summary"":""Lead Research & Development initiatives and assimilate new, cutting-edge technologies into Artificial Intelligence and Machine Learning capabilities as a seasoned Data Scientist at Royal Caribbean Group."",""key_terms"":[{""term"":""Artificial Intelligence"",""explanation"":""The development of computer systems that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, and decision-making.""},{""term"":""Machine Learning"",""explanation"":""A subset of Artificial Intelligence that involves training algorithms to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Neural Networks"",""explanation"":""A type of Machine Learning model inspired by the structure and function of the human brain, composed of layers of interconnected nodes (neurons) that process and transmit information.""},{""term"":""Deep Learning"",""explanation"":""A subfield of Machine Learning that involves the use of Neural Networks with multiple layers to analyze and interpret data, such as images, speech, and text.""},{""term"":""Natural Language Processing"",""explanation"":""A subfield of Artificial Intelligence that deals with the interaction between computers and humans in natural language, enabling computers to understand, interpret, and generate human language.""},{""term"":""Computer Vision"",""explanation"":""A field of study that focuses on enabling computers to interpret and understand visual information from the world, such as images and videos.""}],""skill_priorities"":{""must_have"":[""Master's degree in Statistics, Operations Research, Mathematics, Economics, Computer Science, Engineering, Physics, Chemical Engineering or a related field"",""5+ years of experience with programming languages such as R, Python, Java, C++, C#, Scala, SAS, MATLAB"",""5+ years of experience in data science, AI, and machine learning disciplines"",""Experience with data mining processes, statistical methods, and modeling techniques""],""nice_to_have"":[""Experience with Agile and Waterfall Methodologies"",""Strong oral and written communication skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of overfitting in machine learning and how you would prevent it?"",""example_answer"":""Overfitting occurs when a model is too complex and performs well on the training data but poorly on new, unseen data. To prevent overfitting, I would use techniques such as regularization, early stopping, and cross-validation to ensure the model generalizes well to new data.""},{""question"":""How would you approach designing an experiment to test the effectiveness of a new AI-powered feature?"",""example_answer"":""I would follow the SEMMA or CRISP-DM framework to design the experiment, ensuring that the problem is well-defined, the data is properly prepared, and the results are accurately interpreted and communicated.""}],""red_flags"":[""Lack of experience with emerging technologies in AI and machine learning"",""Inability to work independently and lead a team of data scientists""],""confidence_score"":90.0}"
Senior Data Scientist (AI & ML Expert),"Key Responsibilities

Develop and deploy ML models for classification, prediction, and automation.
Design and implement end-to-end AI/ML solutions from data preprocessing to model deployment.
Utilize NLP techniques for text processing, sentiment analysis, and entity recognition.
Leverage Generative AI to create AI-driven automation solutions.
Work with large datasets to extract insights and optimize model performance.
Build and integrate automation agents using AI-driven approaches.
Collaborate with data engineers and MLOps teams for model deployment and scalability.
Stay updated with latest advancements in AI, ML, and automation technologies.

Primary Skills

Machine Learning & Deep Learning (TensorFlow, PyTorch, Scikit-learn)
Natural Language Processing (NLP) (BERT, GPT, LLMs, SpaCy)
Predictive Modeling & Classification
Generative AI & LLMs (OpenAI, Hugging Face, LangChain)
Automation Agents & AI-based Workflows
End-to-End ML Pipelines (Data preprocessing, Feature Engineering, Model Deployment)
Big Data & Cloud Platforms (AWS, GCP, Azure)
MLOps & Model Optimization (Kubeflow, MLflow, Docker, Kubernetes)
Programming (Python, SQL)","{""role_summary"":""Develop and deploy AI/ML solutions, leveraging NLP and Generative AI techniques to automate processes and extract insights from large datasets."",""key_terms"":[{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of AI that deals with the interaction between computers and humans in natural language.""},{""term"":""Generative AI"",""explanation"":""A type of AI that generates new, original content, such as text or images, based on patterns and structures learned from data.""},{""term"":""MLOps"",""explanation"":""Machine Learning Operations, a set of practices that combines machine learning and DevOps to streamline the machine learning lifecycle.""},{""term"":""LLMs"",""explanation"":""Large Language Models, a type of AI model trained on large amounts of text data to generate language outputs.""}],""skill_priorities"":{""must_have"":[""Machine Learning & Deep Learning"",""Natural Language Processing (NLP)"",""Predictive Modeling & Classification"",""Python"",""Big Data & Cloud Platforms""],""nice_to_have"":[""Generative AI & LLMs"",""Automation Agents & AI-based Workflows"",""End-to-End ML Pipelines"",""MLOps & Model Optimization"",""SQL""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach model deployment and scalability in a cloud-based environment?"",""example_answer"":""I would use containerization with Docker and orchestration with Kubernetes to ensure scalability and deploy models on cloud platforms like AWS or GCP.""},{""question"":""Can you explain how you would implement NLP techniques for sentiment analysis?"",""example_answer"":""I would use a library like SpaCy or NLTK to preprocess text data, then train a machine learning model using a technique like supervised learning to classify sentiment.""}],""red_flags"":[""Lack of experience with cloud platforms"",""Inability to explain NLP concepts"",""No knowledge of MLOps practices""],""confidence_score"":90.0}"
Machine Learning Operations (MLOps) Engineer,"Company Description

LVIS, through our advanced brain network analysis tools, provides Live Visualization to innovate how neurological diseases are diagnosed and treated. LVIS is a leader in cutting edge neural information analysis technologies that can decode brain networks and find cures for neurological diseases. LVIS owns patented technologies and our team includes leaders with strong expertise in neuroscience and engineering from Stanford University. LVIS has been selected to be a member of the Stanford StartX community and the NVIDIA inception program. We have an international team with our headquarter located in Palo Alto, California, USA and we have an office in Gangnam, Seoul, South Korea. We are looking for talented individuals to join us in transforming the neurology health care industry.

LVIS provides an environment where everyone is expected to grow with the company. We are looking for self motivated team members who will be at the leading edge of technology.

Responsibilities

Develop and maintain APIs: Deploy machine learning models as APIs and build scalable API services
Optimize machine learning workloads on the cloud: Improve performance and cost-efficiency of ML models on AWS
Ensure operational stability: Design and implement real-time data processing, logging, monitoring, and model performance tracking systems
Deploy ML models in real-world environments: Ensure reliable deployment and management of ML models and data drift in production
Utilize GPU and GPU clusters: Configure and optimize GPU-based environments for model training and inference (on Cloud and on-premise)
Build MLOps pipelines on AWS and Kubernetes: Deploy and manage containerized ML workflows in Kubernetes environments


Basic Qualifications

Bachelor's degree or higher in Computer Science, Data Science, AI, or related fields
3+ years of experience in MLOps or ML Engineering
Experience of ML related programming languages and frameworks (Python, PyTorch, TensorFlow, etc.)
Experience deploying and managing ML models using tools like MLflow, TensorFlow Serving, or TorchServe
Hands-on experience with AWS
Proficiency in managing and orchestrating containers using Kubernetes and Docker
Experience with GPU-based model training and optimization
Experience building large-scale data processing pipelines (Airflow, Kafka, etc.)


Preferred Qualifications

Hands-on experience with CI/CD pipelines (Jenkins, ArgoCD, etc.)
Experience in large-scale AI model serving
Knowledge of real-time data streaming and batch processing
Preferably DevOps experience along with MLOps","{""role_summary"":""Develop and maintain scalable machine learning APIs and services, ensuring operational stability and performance efficiency on cloud infrastructure."",""key_terms"":[{""term"":""MLOps"",""explanation"":""Machine Learning Operations, a set of practices that aims to deploy and manage machine learning models in production environments.""},{""term"":""GPU clusters"",""explanation"":""A group of Graphics Processing Units (GPUs) working together to accelerate machine learning model training and inference.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""CI/CD pipelines"",""explanation"":""Continuous Integration and Continuous Deployment pipelines, a set of practices that automate testing, building, and deployment of software applications.""}],""skill_priorities"":{""must_have"":[""MLOps or ML Engineering experience"",""Python programming language"",""AWS experience"",""Kubernetes and Docker experience"",""GPU-based model training and optimization experience""],""nice_to_have"":[""CI/CD pipelines experience"",""Large-scale AI model serving experience"",""Real-time data streaming and batch processing knowledge"",""DevOps experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize machine learning model performance on cloud infrastructure?"",""example_answer"":""I would use techniques like model pruning, knowledge distillation, and hyperparameter tuning to reduce model complexity and improve performance. I would also leverage cloud-specific optimizations like AWS SageMaker's automatic model tuning.""},{""question"":""Can you explain how you would deploy and manage machine learning models using Kubernetes?"",""example_answer"":""I would use Kubernetes to containerize my ML models and create a scalable deployment pipeline. I would also use tools like Kubernetes Deployments and Services to manage model rollouts and rollbacks.""}],""red_flags"":[""Lack of hands-on experience with MLOps tools like MLflow, TensorFlow Serving, or TorchServe"",""Inability to optimize machine learning model performance on cloud infrastructure""],""confidence_score"":90.0}"
Data Scientist - TikTok Live,"Responsibilities
TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and its offices include New York, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.
Join us.

About the Team
TikTok Live Data Science team is responsible for Live growth, ecosystem and revenue strategy analytical work. We work closely with Algorithm team and Product team. The goal of the team is to generate actionable insights from data, driving Live to create an environment that brings communities together in real time to create meaningful and interactive connections around the globe. Our main tasks include metrics defining, root cause analysis, experimentation methodology, strategy evaluation and exploratory analysis to find more opportunities.

About the Role
The primary role of a Data Scientist is to conduct deep analysis of user behavior and content ecosystems to generate business insights that could be applied to actionable improving initiatives. You will work closely with cross-function teams, such as PM\RD\MLE, to improve user experience and fulfill the growth of TikTok Live

Responsibilities - What You'II Do
1. Conduct data analysis in LIVE related business, including watching experience, creator ecosystem, agency management, algorithm improvement and etc..
2. Design metrics framework to measure product healthiness, keep tracking of core metrics and understand root causes of metric movements.
3. Conduct scientific evaluation with statistical methods, including A/B testing and casual inference.
4. Identify growth opportunities with data analytics, and drive business decisions. Work with PM/MLE/RD to deliver product and strategy improvement.
5. Research data science theories and methodology, improve analysis efficiency and data product tools.

Qualifications
Minimum Qualifications
1. Bachelor's degree in data science, statistics, econometrics or a related scientific major,
2. 2+ years of experience in Data Science or related role
3. Expertise in SQL
4. Strong analytical and causal reasoning mindset, and rigidity on statistical correctness. Strong communication and passion about product challenges.

Preferred Qualifications
1.Experience of LIVE related business.
2. Knowledge of machine learning and recommendation systems.
3. Experience programming with Python or R

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2



Job Information
【For Pay Transparency】Compensation Description (Annually)
The base salary range for this position in the selected city is $144000 - $240000 annually.
Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.
Benefits may vary depending on the nature of employment and the country work location. Employees have day one access to medical, dental, and vision insurance, a 401(k) savings plan with company match, paid parental leave, short-term and long-term disability coverage, life insurance, wellbeing benefits, among others. Employees also receive 10 paid holidays per year, 10 paid sick days per year and 17 days of Paid Personal Time (prorated upon hire with increasing accruals by tenure).
The Company reserves the right to modify or change these benefits programs at any time, with or without notice.
For Los Angeles County (unincorporated) Candidates:
Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state, and local laws including the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act. Our company believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of the conditional offer of employment:
1. Interacting and occasionally having unsupervised contact with internal/external clients and/or colleagues;
2. Appropriately handling and managing confidential information including proprietary and trade secret information and access to information technology systems; and
3. Exercising sound judgment.","{""role_summary"":""As a Data Scientist at TikTok, you will conduct deep analysis of user behavior and content ecosystems to generate business insights that can be applied to actionable improving initiatives, working closely with cross-functional teams to improve user experience and drive growth of TikTok Live."",""key_terms"":[{""term"":""A/B testing"",""explanation"":""A statistical method to compare two versions of a product or feature to determine which one performs better.""},{""term"":""Causal inference"",""explanation"":""A statistical method to identify cause-and-effect relationships between variables.""},{""term"":""Machine learning"",""explanation"":""A type of artificial intelligence that enables systems to learn from data and improve their performance over time.""},{""term"":""Recommendation systems"",""explanation"":""Algorithms that suggest personalized content or products to users based on their past behavior and preferences.""}],""skill_priorities"":{""must_have"":[""Expertise in SQL"",""Strong analytical and causal reasoning mindset"",""Strong communication and passion about product challenges""],""nice_to_have"":[""Experience of LIVE related business"",""Knowledge of machine learning and recommendation systems"",""Experience programming with Python or R""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a metrics framework to measure product healthiness in a live streaming platform?"",""example_answer"":""I would start by identifying key performance indicators such as user engagement, content quality, and revenue growth. Then, I would develop a data pipeline to collect and process data from various sources, and create dashboards to visualize the metrics. Finally, I would work with cross-functional teams to establish targets and thresholds for each metric, and develop strategies to improve product healthiness.""},{""question"":""How would you approach conducting a scientific evaluation of a new feature using A/B testing and causal inference?"",""example_answer"":""I would start by defining the research question and hypotheses, then design an experiment to test the feature. I would use A/B testing to compare the treatment and control groups, and apply causal inference methods to estimate the treatment effect. Finally, I would interpret the results and provide recommendations for product improvement.""}],""red_flags"":[""Lack of experience with SQL or data analysis"",""Inability to communicate complex technical concepts to non-technical stakeholders"",""Limited knowledge of machine learning and recommendation systems""],""confidence_score"":90.0}"
"Data Scientist, Cloud Learning Services","Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Cambridge, MA, USA; Atlanta, GA, USA; Austin, TX, USA; Seattle, WA, USA.Minimum qualifications:

Master's degree in a quantitative discipline such as Statistics, Engineering, Sciences, or equivalent practical experience
4 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis.
4 years of experience in business visualization tools like Looker, Tableau, etc.

Preferred qualifications:

Master's degree in Computer Science, Economics, or Mathematics, or a related field.
5 years of work experience in data science or quantitative analytics with focus on statistical modeling, Machine Learning, and AI.
Experience with both SQL and Python.
Experience with Machine Learning, AI or AI Pipeline.
Experience in Google Cloud Platform.

About The Job

Cloud Learning Services (CLS) is revolutionizing direct cloud learning. We empower users of all levels with interactive labs and guided experiences to build practical skills on Google Cloud Platform and other leading technologies. Our mission is to make the cloud accessible, engaging, and enjoyable to learn.

As a Business Data Scientist, you will play a key role in uncovering valuable insights from diverse data sources to solve critical business tests. You will address a wide range of exciting projects, from establishing new measurement frameworks to identifying meaningful patterns in large datasets, ultimately empowering stakeholders to make data-driven decisions.

In this role, you will need to be a detail-oriented problem-solver with a strong foundation in data analytics, data visualization, and Artificial Intelligence/Machine Learning. You will solve the real-world problems and a commitment to continuous learning. Exceptional communication and stakeholder management skills are essential, as you will collaborate extensively with cross-functional teams. If you succeed in dynamic environments and are eager to make a real impact with data, we encourage you to apply!

The US base salary range for this full-time position is $166,000-$244,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities

Extract actionable insights from large, complex datasets and build data products like dashboards to operationalize them, driving measurable improvements in Key Performance Indicators (KPIs).
Present and communicate actionable insights and recommendations to executives, leaders, and cross-functional partners, including Product, Engineering, and Marketing teams.
Serve as a peer-reviewer and consultant to other members of the team, fostering a collaborative and knowledge-sharing environment.
Learn and share knowledge of the latest advancements in AI/ML and data science that are relevant to our work.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .","{""role_summary"":""As a Business Data Scientist, you will uncover valuable insights from diverse data sources to solve critical business tests, empowering stakeholders to make data-driven decisions."",""key_terms"":[{""term"":""Machine Learning"",""explanation"":""A type of Artificial Intelligence that enables computers to learn from data without being explicitly programmed.""},{""term"":""AI Pipeline"",""explanation"":""A series of processes that enable the development, deployment, and management of Artificial Intelligence models.""},{""term"":""Google Cloud Platform"",""explanation"":""A suite of cloud computing services offered by Google, including data storage, analytics, and machine learning capabilities.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to communicate insights and trends.""},{""term"":""Statistical Modeling"",""explanation"":""The process of using mathematical and statistical techniques to analyze and understand complex data sets.""}],""skill_priorities"":{""must_have"":[""Master's degree in a quantitative discipline"",""4 years of experience using analytics to solve product or business problems"",""4 years of experience in business visualization tools"",""SQL"",""Python""],""nice_to_have"":[""Master's degree in Computer Science, Economics, or Mathematics"",""5 years of work experience in data science or quantitative analytics"",""Experience with Machine Learning, AI or AI Pipeline"",""Experience in Google Cloud Platform""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a predictive model to forecast sales trends?"",""example_answer"":""I would start by collecting and cleaning relevant data, then explore different machine learning algorithms to identify the most suitable approach. I would also consider factors like seasonality and external influences to ensure the model is robust and accurate.""},{""question"":""How do you stay current with the latest advancements in AI/ML and data science?"",""example_answer"":""I regularly read industry publications and research papers, attend conferences and webinars, and participate in online forums to stay informed about the latest developments and best practices.""}],""red_flags"":[""Lack of experience with cloud-based data analytics platforms"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
